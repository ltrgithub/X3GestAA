"use strict";
/* jshint -W079 */
/* jshint unused: false */
/* global QUnit: false, asyncTest: false, test: false, strictEqual: false, ok: false, start: false, stop: false */

/*global QUnit, start, ok*/
var syracuse = require('syracuse-main/lib/syracuse');
var helpers = require('syracuse-core/lib/helpers');
var streams = require("streamline/lib/streams/streams");
var sys = require("util");
var config = require('syracuse-main/lib/nodeconfig').config; // must be first syracuse require
var adminHelper = require("syracuse-collaboration/lib/helpers").AdminHelper;
var parser = require("syracuse-edi/lib/tool/parser");
var serializer = require("syracuse-edi/lib/tool/serializer");
var EdiProcess = require("syracuse-edi/lib/ediProcess");
var EdiEntity = require("syracuse-edi/lib/ediEntity");
var EdiType = require("syracuse-edi/lib/enumType").EdiType;
var adminTestFixtures = require("syracuse-collaboration/test/fixtures/adminTestFixtures");
var mongodb = require('streamline-mongodb');
var dataModel = require("syracuse-orm/lib/dataModel");
var registry = require("syracuse-sdata/lib/sdataRegistry");
var fs = require("streamline-fs");
var sqMap = require("syracuse-edi/lib/helpers").seqentialFilePropertyMap;
var mmMap = require("syracuse-edi/lib/helpers").messageMappingPropertyMap;
var SEQFILE_LIB = require('syracuse-edi/lib/enumType').SEQFILE_LIB;
var IMPORTFILE_LIB = require('syracuse-edi/lib/enumType').IMPORTFILE_LIB;

var upath = require('path');
var dbName = "unit_test";
var traces = false;
// activate traces
if (traces) {
	var level = "debug";
	var option = {
		name: "edi",
		enabled: true,
		level: level,
		transport: "console",
		mod: {
			name: "parser",
			enabled: true,
			level: level
		}
	};
	adminTestFixtures.setTracesOn("edi.parser", option);

	option.mod.name = "serializer";
	adminTestFixtures.setTracesOn("edi.serializer", option);
}

var globals = require('streamline/lib/globals');
var _defDataDir = upath.join(__dirname, "../server/data/");

function _getModel() {
	return dataModel.make(registry.applications.syracuse.contracts.collaboration, dbName);
}

var endpointTest = {
	dataset: function(_) {
		return "GX3APP";
	},
	getModel: function(_) {
		return {
			getEntity: function(_, nameEntity, facet) {
				return {
					name: nameEntity,
					getPrototype: function(_, name, facet) {
						return JSON.parse(fs.readFile(_defDataDir + "context/" + name + "_" + facet + ".json", 'utf-8', _));
					}
				};
			}
		};
	}
};

globals.context = globals.context || {};
globals.context.session = {
	id: helpers.uuid.generate(),
	getUserLogin: function(_) {
		return "admin";
	},
	getUserProfile: function(_) {
		return {
			selectedLocale: function(_) {
				var db = adminHelper.getCollaborationOrm(_);

				// the metamodel is associated to the orm
				var model = db.model;

				var entity = db.model.getEntity(_, "localePreference");
				return db.fetchInstance(_, entity, {
					jsonWhere: {
						code: "en-US"
					}
				});
			},
			user: function(_) {
				// getting the administration ORM
				var db = adminHelper.getCollaborationOrm(_);

				// the metamodel is associated to the orm
				var model = db.model;

				var entity = db.model.getEntity(_, "user");
				// fetchInstance(callback, entity, filter)
				return db.fetchInstance(_, entity, {
					jsonWhere: {
						login: "admin"
					}
				});

			}
		};
	},
	getSecurityProfile: function(_) {
		return null;
	}
};
var doStop = false;
QUnit.module(module.id, {
	setup: function() {},
	teardown: function() {
		if (doStop) {
			setTimeout(function() {
				process.kill(process.pid);
			}, 100);
		}
	}
});
var endpoint, db;
var prototype_EDISIH1;
var prototype_EDISIH1SCOL;
var prototype_EDIS0H2;
var prototype_EDISIH1FACTURA;

function _initPrototypeCache(_, database) {
	EdiEntity.dropAllEdiCacheEntity(_, {
		db: database
	});
	EdiProcess.removeAllEdiProcess(_, {
		db: database
	});
	prototype_EDISIH1 = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1_$details.json", 'utf-8', _));
	prototype_EDISIH1SCOL = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1SCOL_$details.json", 'utf-8', _));
	prototype_EDIS0H2 = JSON.parse(fs.readFile(_defDataDir + "context/EDISOH2_$details.json", 'utf-8', _));
	prototype_EDISIH1FACTURA = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1FACTURA_$details.json", 'utf-8', _));

}
var uuidJSonSOH;
asyncTest("init test environment ", function(_) {
	endpoint = adminTestFixtures.modifyCollaborationEndpoint(dbName);
	db = dataModel.getOrm(_, _getModel(), endpoint.datasets[dbName]);
	EdiEntity.dropAllEdiCacheEntity(_, {
		db: db
	});
	EdiProcess.removeAllEdiProcess(_, {
		db: db
	});
	start();
});
asyncTest("parser fixed size ", function(_) {

	var fileBuff = {};
	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFAC.txt", 'utf-8', _);

	var seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
	var prototype = JSON.parse(fs.readFile(_defDataDir + "context/BadProto.json", 'utf-8', _));

	var elems;
	elems = [];
	seqFile[sqMap.elem].forEach(function(item, idx, arr) {
		elems.push({
			offset: item[sqMap.elems.offset] - 1,
			length: item[sqMap.elems.length],
			expression: item[sqMap.elems.expression],
			flag: item[sqMap.elems.flag],
			isEnd: item[sqMap.elems.isEnd],
			fileName: item[sqMap.elems.fileId] === "C" ? "CABFAC" : "LINFAC"
		});
	});
	var configParser = {
		parser: SEQFILE_LIB[seqFile[sqMap.fileType]],
		sepDecimal: seqFile[sqMap.decimalSep],
		sepField: seqFile[sqMap.fieldSep],
		sepRecord: "\r\n",
		delimField: seqFile[sqMap.fieldDelimiter],
		elems: elems
	};
	var res = parser.mapParse["fixedLength"](fileBuff, configParser, prototype);

	strictEqual(JSON.stringify(res), "{\"FCC11014VEN00000014\":{}}", "generate instance json from LINFAC (with not all field  value), good seqFile and bad prototype");

	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFAC.txt", 'utf-8', _);

	seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/BadProto.json", 'utf-8', _));

	res = parser.mapParse["fixedLength"](fileBuff, configParser, prototype);
	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","SIVTYP":"FAC","ACCDAT":"2014-02-24"}}', "generate instance json from LINFAC (with not all field  value) and CABFAC, good seqFile and bad prototype");
	seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/fakePrototype.json", 'utf-8', _));

	res = parser.mapParse["fixedLength"](fileBuff, configParser, prototype);
	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24"}}', "generate instance json from LINFAC (with not all field  value) and CABFAC, good seqFile and good prototype (not describe all properties)");
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/fullPrototype.json", 'utf-8', _));

	res = parser.mapParse["fixedLength"](fileBuff, configParser, prototype);

	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24"}}', "generate instance json from LINFAC (with not all field  value) and CABFAC, good seqFile and full prototype");

	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFACIncomplete.txt", 'utf-8', _);

	res = parser.mapParse["fixedLength"](fileBuff, configParser, prototype);
	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880}}', "generate instance json from LINFAC  and CABFAC (incomplete), good seqFile and good prototype");


	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACIncomplete.txt", 'utf-8', _);

	res = parser.mapParse["fixedLength"](fileBuff, configParser, prototype);
	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880}}', "generate instance json from LINFAC (with not all field  value) and CABFAC (incomplete), good seqFile and good prototype");

	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACIncomplete2.txt", 'utf-8', _);

	res = parser.mapParse["fixedLength"](fileBuff, configParser, prototype);

	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880}}', "generate instance json from LINFAC (with not all field value version 2) and CABFAC (incomplete), good seqFile and good prototype");

	prototype = JSON.parse(fs.readFile(_defDataDir + "context/fakePrototype.json", 'utf-8', _));

	res = parser.mapParse["fixedLength"](fileBuff, configParser, prototype);

	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","QTY":2,"GROPRI":1000000}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880}}', "generate instance json from LINFAC (with not all field  value) and CABFAC (incomplete), good seqFile and good prototype");

	res = parser.mapParse["fixedLength"](fileBuff, configParser, prototype, res);
	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","QTY":2,"GROPRI":1000000},{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","QTY":2,"GROPRI":1000000}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880}}', "add to an existent instance json from LINFAC (with not all field  value) and CABFAC (incomplete), good seqFile and good prototype ");


	// test array of object or array
	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACSCOL.txt", 'utf-8', _);
	seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIHArray.json", 'utf-8', _));
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1SCOL_$details.json", 'utf-8', _));
	elems = [];
	seqFile[sqMap.elem].forEach(function(item, idx, arr) {
		elems.push({
			offset: item[sqMap.elems.offset] - 1,
			length: item[sqMap.elems.length],
			expression: item[sqMap.elems.expression],
			flag: item[sqMap.elems.flag],
			isEnd: item[sqMap.elems.isEnd],
			fileName: item[sqMap.elems.fileId] === "C" ? "CABFAC" : "LINFAC"
		});
	});
	var configParser = {
		parser: SEQFILE_LIB[seqFile[sqMap.fileType]],
		sepDecimal: seqFile[sqMap.decimalSep],
		sepField: seqFile[sqMap.fieldSep],
		sepRecord: "\r\n",
		delimField: seqFile[sqMap.fieldDelimiter],
		elems: elems
	};
	res = parser.mapParse["fixedLength"](fileBuff, configParser, prototype);
	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000,"SCOL":[{"TEST":"VALT"}]},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000,"SCOL":[{"TEST":"VALY"}]}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880}}', " parse object of array of object or array ok");

	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFACMultiple.txt", 'utf-8', _);
	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACMultiple.txt", 'utf-8', _);
	res = parser.mapParse["fixedLength"](fileBuff, configParser, prototype);
	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24"},"FCC11014VEN00000012":{"ESIH1SID":[{"NUM":"FCC11014VEN00000012","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000},{"NUM":"FCC11014VEN00000012","SIDLIN":1000,"ITMREF":"CDROM2","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM2","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}],"NUM":"FCC11014VEN00000012","BPR":"ESP0002","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24"}}', " parse multiple object in 1 header file and 1 body file");

	fileBuff["CABFAC1"] = fs.readFile(_defDataDir + "ediFiles/CABFACMultiple1.txt", 'utf-8', _);
	fileBuff["CABFAC2"] = fs.readFile(_defDataDir + "ediFiles/CABFACMultiple2.txt", 'utf-8', _);

	fileBuff["LINFAC1"] = fs.readFile(_defDataDir + "ediFiles/LINFACMultiple1.txt", 'utf-8', _);
	fileBuff["LINFAC32"] = fs.readFile(_defDataDir + "ediFiles/LINFACMultiple2.txt", 'utf-8', _);
	res = parser.mapParse["fixedLength"](fileBuff, configParser, prototype);
	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24"},"FCC11014VEN00000012":{"ESIH1SID":[{"NUM":"FCC11014VEN00000012","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000},{"NUM":"FCC11014VEN00000012","SIDLIN":1000,"ITMREF":"CDROM2","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM2","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}],"NUM":"FCC11014VEN00000012","BPR":"ESP0002","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24"}}', " parse multiple object in multiple header file and multiple line file");


	start();
});
asyncTest("serialized fixed size ", function(_) {


	var json = {
		"ESIH1SID": [{
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 1000,
			"ITMREF": "CDROM",
			"ITMDES": "CD-ROM 16X",
			"SAU": "Un",
			"QTY": 3,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 30000
		}, {
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 2000,
			"ITMREF": "CDROM1",
			"ITMDES": "CD-ROM1 16X",
			"SAU": "Un",
			"QTY": 2,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 20000
		}],
		"NUM": "FCC11014VEN00000014",
		"BPR": "ESP0001",
		"CPY": "110",
		"FCY": "C110",
		"BPAPAY": "A01",
		"CUR": "EUR",
		"PTE": "CHEQ100COMPTANT",
		"AMTATI": 75880,
		"AMTNOT": 66000,
		"SIVTYP": "FAC",
		"ACCDAT": "2014-02-24"
	};
	var seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
	elems = [];
	seqFile[sqMap.elem].forEach(function(item, idx, arr) {
		elems.push({
			offset: item[sqMap.elems.offset] - 1,
			length: item[sqMap.elems.length],
			expression: item[sqMap.elems.expression],
			flag: item[sqMap.elems.flag],
			isEnd: item[sqMap.elems.isEnd],
			fileName: item[sqMap.elems.fileId] === "C" ? "CABFAC" : "LINFAC"
		});
	});
	var configParser = {
		parser: SEQFILE_LIB[seqFile[sqMap.fileType]],
		sepDecimal: seqFile[sqMap.decimalSep],
		sepField: seqFile[sqMap.fieldSep],
		sepRecord: "\r\n",
		delimField: seqFile[sqMap.fieldDelimiter],
		elems: elems
	};

	var fileBuff = {};
	var prototype = JSON.parse(fs.readFile(_defDataDir + "context/fullPrototype.json", 'utf-8', _));

	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFAC.txt", 'utf-8', _);

	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFAC.txt", 'utf-8', _);

	var res = serializer.mapSerialize["fixedLength"](json, configParser, prototype);
	strictEqual(res !== null, true, "with correct json and good proto,  generate string for files ok ");

	strictEqual(res["CABFAC"], fileBuff["CABFAC"], "with correct json and good proto,  generate cabfac ok") // space at the end are remove automatically on certains IDE;
	strictEqual(res["LINFAC"], fileBuff["LINFAC"], "with correct json and good proto,  generate cabfac ok") // space at the end are remove automatically on certains IDE;

	var json = {
		"ESIH1SID": [{
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 1000,
			"ITMREF": "CDROM",
			"ITMDES": "CD-ROM 16X",
			"SAU": "Un",
			"QTY": 3,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 30000,
			"SCOL": [{
				"TEST": "VALT"
			}]
		}, {
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 2000,
			"ITMREF": "CDROM1",
			"ITMDES": "CD-ROM1 16X",
			"SAU": "Un",
			"QTY": 2,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 20000,
			"SCOL": [{
				"TEST": "VALY"
			}]
		}],
		"NUM": "FCC11014VEN00000014",
		"BPR": "ESP0001",
		"CPY": "110",
		"FCY": "C110",
		"BPAPAY": "A01",
		"CUR": "EUR",
		"PTE": "CHEQ100COMPTANT",
		"AMTATI": 75880,
		"AMTNOT": 66000,
		"SIVTYP": "FAC",
		"ACCDAT": "2014-02-24"
	};
	var prototype = JSON.parse(fs.readFile(_defDataDir + "context/BadProto.json", 'utf-8', _));
	try {
		var res = serializer.mapSerialize["fixedLength"](json, configParser, prototype);
		ok(false, "ERROR CASE : can't serialize , some properties doesn't match prototype ");
	} catch (e) {
		ok(true, "ERROR CASE : can't serialize , some properties doesn't match prototype  mess:" + e.message);

	}
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/fullPrototype.json", 'utf-8', _));
	json.NONEXISTPROP = "test";
	var res = serializer.mapSerialize["fixedLength"](json, configParser, prototype);
	strictEqual(res !== null, true, "with correct json and good proto,  generate string for files ok ");

	strictEqual(res["CABFAC"], fileBuff["CABFAC"], "with non exists property json and good proto,  generate cabfac ok") // space at the end are remove automatically on certains IDE;
	strictEqual(res["LINFAC"], fileBuff["LINFAC"], "with non exists property json and good proto,  generate cabfac ok") // space at the end are remove automatically on certains IDE;


	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACSCOL.txt", 'utf-8', _);
	seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIHArray.json", 'utf-8', _));
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1SCOL_$details.json", 'utf-8', _));
	var elems = [];
	seqFile[sqMap.elem].forEach(function(item, idx, arr) {
		elems.push({
			offset: item[sqMap.elems.offset] - 1,
			length: item[sqMap.elems.length],
			expression: item[sqMap.elems.expression],
			flag: item[sqMap.elems.flag],
			isEnd: item[sqMap.elems.isEnd],
			fileName: item[sqMap.elems.fileId] === "C" ? "CABFAC" : "LINFAC"
		});
	});
	var configParser = {
		parser: SEQFILE_LIB[seqFile[sqMap.fileType]],
		sepDecimal: seqFile[sqMap.decimalSep],
		sepField: seqFile[sqMap.fieldSep],
		sepRecord: "\r\n",
		delimField: seqFile[sqMap.fieldDelimiter],
		elems: elems
	};
	var res = serializer.mapSerialize["fixedLength"](json, configParser, prototype);
	strictEqual(res["CABFAC"], fileBuff["CABFAC"], "with CABFAC object or array of object of array ok") // space at the end are remove automatically on certains IDE;
	strictEqual(res["LINFAC"], fileBuff["LINFAC"], "with LINFAC object or array of object of array ok") // space at the end are remove automatically on certains IDE;
	start();

});
asyncTest("serialize import file ", function(_) {

	var json = JSON.parse(fs.readFile(_defDataDir + "context/jsonImport.json", 'utf-8', _));


	var messageMapping = JSON.parse(fs.readFile(_defDataDir + "context/messageMappingSOH.json", 'utf-8', _));

	var elems = [];
	messageMapping[mmMap.elem].forEach(function(item, idx, arr) {
		elems.push({
			offset: item[mmMap.elems.offset] - 1,
			length: item[mmMap.elems.length],
			expression: item[mmMap.elems.expression],
			flag: item[mmMap.elems.flag],
			isEnd: item[mmMap.elems.isEnd],
			fileName: item[mmMap.elems.fileId]
		});
	});
	var configParser = {
		serializer: IMPORTFILE_LIB[messageMapping[mmMap.fileType]],
		sepDecimal: messageMapping[mmMap.decimalSep],
		sepField: messageMapping[mmMap.fieldSep],
		sepRecord: "\n",
		delimField: messageMapping[mmMap.fieldDelimiter],
		elems: elems,
		fileName: "importTest_" + (new Date().getTime()) + ".csv"

	};

	var prototype = JSON.parse(fs.readFile(_defDataDir + "context/fullPrototypeImport.json", 'utf-8', _));
	var res = serializer.mapSerialize["delimited"](json, configParser, prototype);

	var result = '"E","ASN","CDE-2010-0491","LS","21/09/2010","ASN","EUR"\n' +
		'"L","CD100","Camion semi remorque rouge","Un","300000"\n' +
		'"L","ARTICLE2","Désignation article 2","Un"\n' +
		'"L","ARTICLE2","Désignation article 2","Un"\n' +
		'"L","ARTICLE4","ARTICLE4","Un"';

	strictEqual(res[configParser.fileName], result, "serialize SOH in delimited file ok");
	start();
});

asyncTest("parser", function(_) {
	_initPrototypeCache(_, db);
	// store in mongodb all needed to perform the test
	var seqFileJson = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
	var elems = [];
	seqFileJson[sqMap.elem].forEach(function(item, idx, arr) {
		elems.push({
			offset: item[sqMap.elems.offset] - 1,
			length: item[sqMap.elems.length],
			expression: item[sqMap.elems.expression],
			flag: item[sqMap.elems.flag],
			isEnd: item[sqMap.elems.isEnd],
			fileName: item[sqMap.elems.fileId] === "C" ? "CABFAC" : "LINFAC"
		});
	});
	var configParser = {
		parser: SEQFILE_LIB[seqFileJson[sqMap.fileType]],
		sepDecimal: seqFileJson[sqMap.decimalSep],
		sepField: seqFileJson[sqMap.fieldSep],
		sepRecord: "\r\n",
		delimField: seqFileJson[sqMap.fieldDelimiter],
		elems: elems
	};
	var fileBuff = {};
	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFAC.txt", 'utf-8', _);
	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFAC.txt", 'utf-8', _);
	var jsonSIH = {
		"NUM": "FCC11014VEN00000014",
		"BPR": "ESP0001",
		"CPY": "110",
		"FCY": "C110",
		"BPAPAY": "A01",
		"CUR": "EUR",
		"PTE": "CHEQ100COMPTANT",
		"AMTATI": 75880,
		"AMTNOT": 66000,
		"SIVTYP": "FAC",
		"ACCDAT": "2014-02-24",
		"ESIH1SID": [{
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 1000,
			"ITMREF": "CDROM",
			"ITMDES": "CD-ROM 16X",
			"SAU": "Un",
			"QTY": 3,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 30000
		}, {
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 2000,
			"ITMREF": "CDROM1",
			"ITMDES": "CD-ROM1 16X",
			"SAU": "Un",
			"QTY": 2,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 20000
		}]
	};
	var protocolJson = JSON.parse(fs.readFile(_defDataDir + "context/protocol.json", 'utf-8', _));



	var res = parser.parse(_, {
		configParser: configParser,
		prototype: prototype_EDISIH1,
		input: fileBuff,
		db: db
	});
	strictEqual(JSON.stringify(res.FCC11014VEN00000014), JSON.stringify(jsonSIH), "parse ok ");

	var seqFileJsonReal = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIHReal.json", 'utf-8', _)); // for some reasons the collection name in prototype is not the same as we have in the decribe we manage both case.
	var elems = [];
	seqFileJsonReal[sqMap.elem].forEach(function(item, idx, arr) {
		elems.push({
			offset: item[sqMap.elems.offset] - 1,
			length: item[sqMap.elems.length],
			expression: item[sqMap.elems.expression],
			flag: item[sqMap.elems.flag],
			isEnd: item[sqMap.elems.isEnd],
			fileName: item[sqMap.elems.fileId] === "C" ? "CABFAC" : "LINFAC"
		});
	});
	var configParser = {
		parser: SEQFILE_LIB[seqFileJsonReal[sqMap.fileType]],
		sepDecimal: seqFileJsonReal[sqMap.decimalSep],
		sepField: seqFileJsonReal[sqMap.fieldSep],
		sepRecord: "\r\n",
		delimField: seqFileJsonReal[sqMap.fieldDelimiter],
		elems: elems
	};



	res = parser.parse(_, {
		configParser: configParser,
		prototype: prototype_EDISIH1,
		input: fileBuff,
		db: db
	});
	strictEqual(JSON.stringify(res.FCC11014VEN00000014), JSON.stringify(jsonSIH), "parse with seqFile that describe collection that not correspond to the prototype ok ");

	var seqFileJsonDelim = JSON.parse(fs.readFile(_defDataDir + "context/seqFileFactureFailed.json", 'utf-8', _)); // for some reasons the collection name in prototype is not the same as we have in the decribe we manage both case.
	var elems = [];
	seqFileJsonDelim[sqMap.elem].forEach(function(item, idx, arr) {
		elems.push({
			offset: item[sqMap.elems.offset] - 1,
			length: item[sqMap.elems.length],
			expression: item[sqMap.elems.expression],
			flag: item[sqMap.elems.flag],
			isEnd: item[sqMap.elems.isEnd],
			fileName: item[sqMap.elems.fileId] === "C" ? "CABFAC" : "LINFAC"
		});
	});
	var configParser = {
		parser: SEQFILE_LIB[seqFileJsonDelim[sqMap.fileType]],
		sepDecimal: seqFileJsonDelim[sqMap.decimalSep],
		sepField: seqFileJsonDelim[sqMap.fieldSep],
		sepRecord: "\r\n",
		delimField: seqFileJsonDelim[sqMap.fieldDelimiter],
		elems: elems
	};
	//  Case of the prototype collection correspond to the expression define by applicative team and the other one following the rules implement by the supervisor


	fileBuff = {};
	fileBuff["FACTURA"] = fs.readFile(_defDataDir + "ediFiles/FACTURA.txt", 'utf-8', _);


	try {
		res = parser.parse(_, {
			configParser: configParser,
			prototype: prototype_EDISIH1FACTURA,
			input: fileBuff,
			db: db
		});
		ok(false, "ERROR CASE : can't serialize property.$type not compatible with data read in file");

	} catch (e) {
		ok(true, "ERROR CASE : can't serialize property.$type not compatible with data read in file mess:" + e.message);
	}

	start();
});

asyncTest(" serialize edi file", function(_) {
	_initPrototypeCache(_, db);
	// store in mongodb all needed to perform the test
	var seqFileJson = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
	var elems = [];
	seqFileJson[sqMap.elem].forEach(function(item, idx, arr) {
		elems.push({
			offset: item[sqMap.elems.offset] - 1,
			length: item[sqMap.elems.length],
			expression: item[sqMap.elems.expression],
			flag: item[sqMap.elems.flag],
			isEnd: item[sqMap.elems.isEnd],
			fileName: item[sqMap.elems.fileId] === "C" ? "CABFAC" : "LINFAC"
		});
	});
	var configParser = {
		serializer: SEQFILE_LIB[seqFileJson[sqMap.fileType]],
		sepDecimal: seqFileJson[sqMap.decimalSep],
		sepField: seqFileJson[sqMap.fieldSep],
		sepRecord: "\r\n",
		delimField: seqFileJson[sqMap.fieldDelimiter],
		elems: elems
	};
	var protocolJson = JSON.parse(fs.readFile(_defDataDir + "context/protocol.json", 'utf-8', _));
	var fileBuff = {};
	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFAC.txt", 'utf-8', _);
	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFAC.txt", 'utf-8', _);

	var jsonSIH = {
		"NUM": "FCC11014VEN00000014",
		"BPR": "ESP0001",
		"CPY": "110",
		"FCY": "C110",
		"BPAPAY": "A01",
		"CUR": "EUR",
		"PTE": "CHEQ100COMPTANT",
		"AMTATI": 75880,
		"AMTNOT": 66000,
		"SIVTYP": "FAC",
		"ACCDAT": "2014-02-24",
		"ESIH1SID": [{
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 1000,
			"ITMREF": "CDROM",
			"ITMDES": "CD-ROM 16X",
			"SAU": "Un",
			"QTY": 3,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 30000
		}, {
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 2000,
			"ITMREF": "CDROM1",
			"ITMDES": "CD-ROM1 16X",
			"SAU": "Un",
			"QTY": 2,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 20000
		}]
	};


	var res = serializer.serialize(_, {
		configSerializer: configParser,
		prototype: prototype_EDISIH1,
		json: jsonSIH,
		action: "edi",
		db: db
	});

	strictEqual(Object.keys(res).length, 2, "number of file ok");
	strictEqual(res["CABFAC"], fileBuff["CABFAC"], "cabfac ok ");
	strictEqual(res["LINFAC"], fileBuff["LINFAC"], "linfac ok ");



	try {
		var res = serializer.serialize(_, {
			configSerializer: configParser,
			json: jsonSIH,
			action: "edi",
			db: db
		});
		ok(false, "ERROR CASE : serialize on a non exists representation");

	} catch (e) {
		ok(true, "ERROR CASE : serialize on a non exists representation mess:" + e.stack);
	}




	start();
});

asyncTest(" serialize import files", function(_) {
	_initPrototypeCache(_, db);

	// store in mongodb all needed to perform the test
	var messageMappingJson = JSON.parse(fs.readFile(_defDataDir + "context/messageMappingSOH.json", 'utf-8', _));
	var elems = [];
	messageMappingJson[mmMap.elem].forEach(function(item, idx, arr) {
		elems.push({
			offset: item[mmMap.elems.offset] - 1,
			length: item[mmMap.elems.length],
			expression: item[mmMap.elems.expression],
			flag: item[mmMap.elems.flag],
			isEnd: item[mmMap.elems.isEnd],
			fileName: item[mmMap.elems.fileId]
		});
	});
	var configParser = {
		serializer: IMPORTFILE_LIB[messageMappingJson[mmMap.fileType]],
		sepDecimal: messageMappingJson[mmMap.decimalSep],
		sepField: messageMappingJson[mmMap.fieldSep],
		sepRecord: "\r\n",
		delimField: messageMappingJson[mmMap.fieldDelimiter],
		elems: elems,
		fileName: "importTest_" + (new Date().getTime()) + ".csv"

	};
	var protocolJson = JSON.parse(fs.readFile(_defDataDir + "context/protocol.json", 'utf-8', _));
	var fileBuff = fs.readFile(_defDataDir + "context/importSOH.csv", 'utf-8', _);

	var jsonSOH = JSON.parse(fs.readFile(_defDataDir + "context/jsonImport.json", 'utf-8', _));


	var res = serializer.serialize(_, {
		configSerializer: configParser,
		json: jsonSOH,
		prototype: prototype_EDIS0H2,
		action: "import",
		db: db
	});
	strictEqual(res !== null, true, "serialization ok ");

	strictEqual(res[Object.keys(res)[0]], fileBuff, "import file content ok");


	var messageMappingJson = JSON.parse(fs.readFile(_defDataDir + "context/messageMappingSOHReal.json", 'utf-8', _)); // for some reasons the collection name in prototype is not the same as we have in the decribe we manage both case.
	var elems = [];
	messageMappingJson[mmMap.elem].forEach(function(item, idx, arr) {
		elems.push({
			offset: item[mmMap.elems.offset] - 1,
			length: item[mmMap.elems.length],
			expression: item[mmMap.elems.expression],
			flag: item[mmMap.elems.flag],
			isEnd: item[mmMap.elems.isEnd],
			fileName: item[mmMap.elems.fileId]
		});
	});
	var configParser = {
		serializer: IMPORTFILE_LIB[messageMappingJson[mmMap.fileType]],
		sepDecimal: messageMappingJson[mmMap.decimalSep],
		sepField: messageMappingJson[mmMap.fieldSep],
		sepRecord: "\r\n",
		delimField: messageMappingJson[mmMap.fieldDelimiter],
		elems: elems,
		fileName: "importTest_" + (new Date().getTime()) + ".csv"

	};

	var res = serializer.serialize(_, {
		configSerializer: configParser,
		prototype: prototype_EDIS0H2,
		json: jsonSOH,
		action: "import",
		db: db
	});
	strictEqual(res !== null, true, "serialization with real messageMapping ok ");

	strictEqual(res[Object.keys(res)[0]], fileBuff, "import file content with real messageMapping ok");


	try {
		var res = serializer.serialize(_, {
			configSerializer: configParser,
			json: jsonSOH,
			action: "import",
			db: db
		});
		ok(false, "ERROR CASE : serialize on a non exists representation");

	} catch (e) {
		ok(true, "ERROR CASE : serialize on a non exists representation mess:" + e.message);
	}



	start();
});





asyncTest("clean edi entity mongodb", 0, function(_) {
	EdiEntity.dropAllEdiCacheEntity(_, {
		db: db
	});
	EdiProcess.removeAllEdiProcess(_, {
		db: db
	});

	start();
});

asyncTest("stop  tests", 0, function(_) {
	doStop = true;
	start();
});