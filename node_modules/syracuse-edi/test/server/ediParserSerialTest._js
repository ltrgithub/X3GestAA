"use strict";
/* jshint -W079 */
/* jshint unused: false */
/* global QUnit: false, asyncTest: false, test: false, strictEqual: false, ok: false, start: false, stop: false */

/*global QUnit, start, ok*/
var syracuse = require('syracuse-main/lib/syracuse');
var helpers = require('syracuse-core/lib/helpers');
var streams = require("streamline/lib/streams/streams");
var sys = require("util");
var config = require('syracuse-main/lib/nodeconfig').config; // must be first syracuse require
var adminHelper = require("syracuse-collaboration/lib/helpers").AdminHelper;
var parser = require("syracuse-edi/lib/parse/parser");
var serializer = require("syracuse-edi/lib/parse/serializer");
var EdiProcess = require("syracuse-edi/lib/EdiProcess");
var EdiEntity = require("syracuse-edi/lib/EdiEntity");
var EdiType = require("syracuse-edi/lib/enumType").EdiType;
var adminTestFixtures = require("syracuse-collaboration/test/fixtures/adminTestFixtures");
var mongodb = require('streamline-mongodb');
var dataModel = require("syracuse-orm/lib/dataModel");
var registry = require("syracuse-sdata/lib/sdataRegistry");
var fs = require("streamline-fs");
var upath = require('path');
var dbName = "unit_test";

var globals = require('streamline/lib/globals');
var _defDataDir = upath.join(__dirname, "../server/data/");

function _getModel() {
	return dataModel.make(registry.applications.syracuse.contracts.collaboration, dbName);
}

var endpointTest = {
	dataset: function(_) {
		return "GX3APP";
	},
	getModel: function(_) {
		return {
			getEntity: function(_, nameEntity, facet) {
				return {
					name: nameEntity,
					getPrototype: function(_, name, facet) {
						return JSON.parse(fs.readFile(_defDataDir + "context/" + name + "_" + facet + ".json", 'utf-8', _));
					}
				};
			}
		};
	}
};

globals.context = globals.context || {};
globals.context.session = {
	id: helpers.uuid.generate(),
	getUserLogin: function(_) {
		return "admin";
	},
	getUserProfile: function(_) {
		return {
			selectedLocale: function(_) {
				var db = adminHelper.getCollaborationOrm(_);

				// the metamodel is associated to the orm
				var model = db.model;

				var entity = db.model.getEntity(_, "localePreference");
				return db.fetchInstance(_, entity, {
					jsonWhere: {
						code: "en-US"
					}
				});
			},
			user: function(_) {
				// getting the administration ORM
				var db = adminHelper.getCollaborationOrm(_);

				// the metamodel is associated to the orm
				var model = db.model;

				var entity = db.model.getEntity(_, "user");
				// fetchInstance(callback, entity, filter)
				return db.fetchInstance(_, entity, {
					jsonWhere: {
						login: "admin"
					}
				});

			}
		};
	},
	getSecurityProfile: function(_) {
		return null;
	}
};
var doStop = false;
QUnit.module(module.id, {
	setup: function() {},
	teardown: function() {
		if (doStop) {
			setTimeout(function() {
				process.kill(process.pid);
			}, 100);
		}
	}
});
var endpoint, db;

function _initPrototypeCache(_, database) {
	EdiEntity.dropAllEdiCacheEntity(_, {
		db: database
	});
	EdiProcess.removeAllEdiProcess(_, {
		db: database
	});
	var prototype_EDISIH1 = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1_$details.json", 'utf-8', _));
	var prototype_EDISIH1SCOL = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1SCOL_$details.json", 'utf-8', _));
	var prototype_EDIS0H2 = JSON.parse(fs.readFile(_defDataDir + "context/EDISOH2_$details.json", 'utf-8', _));
	var prototype_EDISIH1FACTURA = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1FACTURA_$details.json", 'utf-8', _));
	EdiEntity.createEdiCacheEntity(_, {
		jsons: prototype_EDISIH1FACTURA,
		type: "GX3APP",
		id: "FACTURE",
		etag: "etagBidon",
		db: database
	});
	EdiEntity.createEdiCacheEntity(_, {
		jsons: prototype_EDISIH1,
		type: "GX3APP",
		id: "EDISIH1",
		etag: "etagBidon",
		db: database
	});
	EdiEntity.createEdiCacheEntity(_, {
		jsons: prototype_EDISIH1SCOL,
		type: "GX3APP",
		id: "EDISIH1SCOL",
		etag: "etagBidon",
		db: database
	});
	EdiEntity.createEdiCacheEntity(_, {
		jsons: prototype_EDIS0H2,
		type: "GX3APP",
		id: "EDISOH2",
		etag: "etagBidon",
		db: database
	});


}
var uuidJSonSOH;
asyncTest("init test environment ", function(_) {
	endpoint = adminTestFixtures.modifyCollaborationEndpoint(dbName);
	db = dataModel.getOrm(_, _getModel(), endpoint.datasets[dbName]);
	EdiEntity.dropAllEdiCacheEntity(_, {
		db: db
	});
	EdiProcess.removeAllEdiProcess(_, {
		db: db
	});
	start();
});
asyncTest("parser fixed size ", function(_) {

	var fileBuff = {};
	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFAC.txt", 'utf-8', _);

	var seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
	var prototype = JSON.parse(fs.readFile(_defDataDir + "context/BadProto.json", 'utf-8', _));

	var res = parser.mapParse["fixedLength"](fileBuff, seqFile.ESFESFD, prototype);
	strictEqual(JSON.stringify(res), "{}", "generate instance json from LINFAC (with not all field  value), good seqFile and bad prototype");

	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFAC.txt", 'utf-8', _);

	seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/BadProto.json", 'utf-8', _));

	res = parser.mapParse["fixedLength"](fileBuff, seqFile.ESFESFD, prototype);
	strictEqual(JSON.stringify(res), '{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","SIVTYP":"FAC","ACCDAT":"2014-02-24"}', "generate instance json from LINFAC (with not all field  value) and CABFAC, good seqFile and bad prototype");
	seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/fakePrototype.json", 'utf-8', _));

	res = parser.mapParse["fixedLength"](fileBuff, seqFile.ESFESFD, prototype);
	strictEqual(JSON.stringify(res), '{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24"}', "generate instance json from LINFAC (with not all field  value) and CABFAC, good seqFile and good prototype (not describe all properties)");
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/fullPrototype.json", 'utf-8', _));

	res = parser.mapParse["fixedLength"](fileBuff, seqFile.ESFESFD, prototype);

	strictEqual(JSON.stringify(res), '{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24"}', "generate instance json from LINFAC (with not all field  value) and CABFAC, good seqFile and full prototype");

	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFACIncomplete.txt", 'utf-8', _);

	res = parser.mapParse["fixedLength"](fileBuff, seqFile.ESFESFD, prototype);
	strictEqual(JSON.stringify(res), '{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880}', "generate instance json from LINFAC  and CABFAC (incomplete), good seqFile and good prototype");


	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACIncomplete.txt", 'utf-8', _);

	res = parser.mapParse["fixedLength"](fileBuff, seqFile.ESFESFD, prototype);
	strictEqual(JSON.stringify(res), '{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880}', "generate instance json from LINFAC (with not all field  value) and CABFAC (incomplete), good seqFile and good prototype");

	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACIncomplete2.txt", 'utf-8', _);

	res = parser.mapParse["fixedLength"](fileBuff, seqFile.ESFESFD, prototype);

	strictEqual(JSON.stringify(res), '{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880}', "generate instance json from LINFAC (with not all field value version 2) and CABFAC (incomplete), good seqFile and good prototype");

	prototype = JSON.parse(fs.readFile(_defDataDir + "context/fakePrototype.json", 'utf-8', _));

	res = parser.mapParse["fixedLength"](fileBuff, seqFile.ESFESFD, prototype);

	strictEqual(JSON.stringify(res), '{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","QTY":2,"GROPRI":1000000}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880}', "generate instance json from LINFAC (with not all field  value) and CABFAC (incomplete), good seqFile and good prototype");

	res = parser.mapParse["fixedLength"](fileBuff, seqFile.ESFESFD, prototype, res);
	strictEqual(JSON.stringify(res), '{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","QTY":2,"GROPRI":1000000},{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","QTY":2,"GROPRI":1000000}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880}', "add to an existent instance json from LINFAC (with not all field  value) and CABFAC (incomplete), good seqFile and good prototype ");


	// test array of object or array
	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACSCOL.txt", 'utf-8', _);
	seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIHArray.json", 'utf-8', _));
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1SCOL_$details.json", 'utf-8', _));

	res = parser.mapParse["fixedLength"](fileBuff, seqFile.ESFESFD, prototype);
	strictEqual(JSON.stringify(res), '{"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000,"SCOL":[{"TEST":"VALT"}]},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000,"SCOL":[{"TEST":"VALY"}]}],"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880}', " parse object of array of object or array ok");

	start();
});
asyncTest("serialized fixed size ", function(_) {


	var json = {
		"ESIH1SID": [{
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 1000,
			"ITMREF": "CDROM",
			"ITMDES": "CD-ROM 16X",
			"SAU": "Un",
			"QTY": 3,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 30000
		}, {
			"NUM": "FCC11014VEN00000012",
			"SIDLIN": 2000,
			"ITMREF": "CDROM1",
			"ITMDES": "CD-ROM1 16X",
			"SAU": "Un",
			"QTY": 2,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 20000
		}],
		"NUM": "FCC11014VEN00000014",
		"BPR": "ESP0001",
		"CPY": "110",
		"FCY": "C110",
		"BPAPAY": "A01",
		"CUR": "EUR",
		"PTE": "CHEQ100COMPTANT",
		"AMTATI": 75880,
		"AMTNOT": 66000,
		"SIVTYP": "FAC",
		"ACCDAT": "2014-02-24"
	};
	var seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
	var sContext = {
		sepDecimal: seqFile.SEPDEC,
		sepField: seqFile.SEPFLD,
		sepRecord: seqFile.SEPREC,
		getPropertyName: function(item) {
			return item.EXPRESSION;
		}
	};
	var fileBuff = {};
	var prototype = JSON.parse(fs.readFile(_defDataDir + "context/fullPrototype.json", 'utf-8', _));

	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFAC.txt", 'utf-8', _);

	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFAC.txt", 'utf-8', _);

	var res = serializer.mapSerialize["fixedLength"](json, seqFile.ESFESFD, prototype, sContext);
	strictEqual(res !== null, true, "with correct json and good proto,  generate string for files ok ");

	strictEqual(res["CABFAC"], fileBuff["CABFAC"], "with correct json and good proto,  generate cabfac ok") // space at the end are remove automatically on certains IDE;
	strictEqual(res["LINFAC"], fileBuff["LINFAC"], "with correct json and good proto,  generate cabfac ok") // space at the end are remove automatically on certains IDE;

	var json = {
		"ESIH1SID": [{
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 1000,
			"ITMREF": "CDROM",
			"ITMDES": "CD-ROM 16X",
			"SAU": "Un",
			"QTY": 3,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 30000,
			"SCOL": [{
				"TEST": "VALT"
			}]
		}, {
			"NUM": "FCC11014VEN00000012",
			"SIDLIN": 2000,
			"ITMREF": "CDROM1",
			"ITMDES": "CD-ROM1 16X",
			"SAU": "Un",
			"QTY": 2,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 20000,
			"SCOL": [{
				"TEST": "VALY"
			}]
		}],
		"NUM": "FCC11014VEN00000014",
		"BPR": "ESP0001",
		"CPY": "110",
		"FCY": "C110",
		"BPAPAY": "A01",
		"CUR": "EUR",
		"PTE": "CHEQ100COMPTANT",
		"AMTATI": 75880,
		"AMTNOT": 66000,
		"SIVTYP": "FAC",
		"ACCDAT": "2014-02-24"
	};
	var prototype = JSON.parse(fs.readFile(_defDataDir + "context/BadProto.json", 'utf-8', _));
	try {
		var res = serializer.mapSerialize["fixedLength"](json, seqFile.ESFESFD, prototype, sContext);
		ok(false, "can't serialize , some properties doesn't match prototype ok");
	} catch (e) {
		ok(true, "can't serialize , some properties doesn't match prototype ok " + e.message);

	}
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/fullPrototype.json", 'utf-8', _));
	json.NONEXISTPROP = "test";
	var res = serializer.mapSerialize["fixedLength"](json, seqFile.ESFESFD, prototype, sContext);
	strictEqual(res !== null, true, "with correct json and good proto,  generate string for files ok ");

	strictEqual(res["CABFAC"], fileBuff["CABFAC"], "with non exists property json and good proto,  generate cabfac ok") // space at the end are remove automatically on certains IDE;
	strictEqual(res["LINFAC"], fileBuff["LINFAC"], "with non exists property json and good proto,  generate cabfac ok") // space at the end are remove automatically on certains IDE;


	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACSCOL.txt", 'utf-8', _);
	seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIHArray.json", 'utf-8', _));
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1SCOL_$details.json", 'utf-8', _));
	var res = serializer.mapSerialize["fixedLength"](json, seqFile.ESFESFD, prototype, sContext);
	strictEqual(res["CABFAC"], fileBuff["CABFAC"], "with CABFAC object or array of object of array ok") // space at the end are remove automatically on certains IDE;
	strictEqual(res["LINFAC"], fileBuff["LINFAC"], "with LINFAC object or array of object of array ok") // space at the end are remove automatically on certains IDE;
	start();

});
asyncTest("serialize import file ", function(_) {

	var json = JSON.parse(fs.readFile(_defDataDir + "context/jsonImport.json", 'utf-8', _));


	var messageMapping = JSON.parse(fs.readFile(_defDataDir + "context/messageMappingSOH.json", 'utf-8', _));

	var elems = messageMapping.EMSEMSD;
	var sContext = {
		sepDecimal: messageMapping.SEPDEC,
		sepField: messageMapping.SEPFLD,
		sepRecord: "\n",
		delimField: messageMapping.FLDLIM,
		getPropertyName: function(item) {
			return item.SASVAR;
		},
		fileName: "importTest_" + (new Date().getTime()) + ".csv"


	};
	var prototype = JSON.parse(fs.readFile(_defDataDir + "context/fullPrototypeImport.json", 'utf-8', _));
	var res = serializer.mapSerialize["delimited"](json, elems, prototype, sContext);

	var result = '"E","ASN","CDE-2010-0491","LS","21/09/2010","ASN","EUR"\n' +
		'"L","CD100","Camion semi remorque rouge","Un","300000"\n' +
		'"L","ARTICLE2","Désignation article 2","Un"\n' +
		'"L","ARTICLE2","Désignation article 2","Un"\n' +
		'"L","ARTICLE4","ARTICLE4","Un"';

	strictEqual(res[sContext.fileName], result, "serialize SOH in delimited file ok");
	start();
});

asyncTest("parser", function(_) {
	_initPrototypeCache(_, db);
	// store in mongodb all needed to perform the test
	var seqFileJson = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
	var fileBuff = {};
	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFAC.txt", 'utf-8', _);
	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFAC.txt", 'utf-8', _);
	var jsonSIH = {
		"NUM": "FCC11014VEN00000014",
		"BPR": "ESP0001",
		"CPY": "110",
		"FCY": "C110",
		"BPAPAY": "A01",
		"CUR": "EUR",
		"PTE": "CHEQ100COMPTANT",
		"AMTATI": 75880,
		"AMTNOT": 66000,
		"SIVTYP": "FAC",
		"ACCDAT": "2014-02-24",
		"ESIH1SID": [{
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 1000,
			"ITMREF": "CDROM",
			"ITMDES": "CD-ROM 16X",
			"SAU": "Un",
			"QTY": 3,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 30000
		}, {
			"NUM": "FCC11014VEN00000012",
			"SIDLIN": 2000,
			"ITMREF": "CDROM1",
			"ITMDES": "CD-ROM1 16X",
			"SAU": "Un",
			"QTY": 2,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 20000
		}]
	};
	var protocolJson = JSON.parse(fs.readFile(_defDataDir + "context/protocol.json", 'utf-8', _));
	EdiEntity.createEdiCacheEntity(_, {
		jsons: seqFileJson,
		type: EdiType.SEQFILE,
		id: "test",
		etag: "etagBidon",
		db: db
	});
	EdiEntity.createEdiCacheEntity(_, {
		jsons: {},
		type: EdiType.MESSAGEMAPPING,
		id: "test",
		etag: "etagBidon",
		db: db
	});
	EdiEntity.createEdiCacheEntity(_, {
		jsons: protocolJson,
		type: EdiType.PROTOCOL,
		id: "test",
		etag: "etagBidon",
		db: db
	});

	var ediProcess = EdiProcess.createEdiProcess(_, {
		idProcess: "testParse",
		messageMapping: "test",
		sequentialFile: "test",
		protocol: "test",
		repName: "EDISIH1",
		folder: "GX3APP",
		db: db
	});
	ediProcess.endPoint(_, endpointTest);
	var res = parser.parse(_, {
		process: ediProcess,
		input: fileBuff,
		db: db
	});
	strictEqual(JSON.stringify(res), JSON.stringify(jsonSIH), "parse ok ");

	var seqFileJsonReal = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIHReal.json", 'utf-8', _)); // for some reasons the collection name in prototype is not the same as we have in the decribe we manage both case.
	//  Case of the prototype collection correspond to the expression define by applicative team and the other one following the rules implement by the supervisor
	EdiEntity.createEdiCacheEntity(_, {
		jsons: seqFileJsonReal,
		type: EdiType.SEQFILE,
		id: "testReal",
		etag: "etagBidon",
		db: db
	});

	var ediProcess = EdiProcess.createEdiProcess(_, {
		idProcess: "testParseReal",
		messageMapping: "test",
		sequentialFile: "testReal",
		protocol: "test",
		repName: "EDISIH1",
		folder: "GX3APP",
		db: db
	});
	ediProcess.endPoint(_, endpointTest);

	res = parser.parse(_, {
		process: ediProcess,
		input: fileBuff,
		db: db
	});
	strictEqual(JSON.stringify(res), JSON.stringify(jsonSIH), "parse with seqFile that describe collection that not correspond to the prototype ok ");

	var seqFileJsonDelim = JSON.parse(fs.readFile(_defDataDir + "context/seqFileFactureFailed.json", 'utf-8', _)); // for some reasons the collection name in prototype is not the same as we have in the decribe we manage both case.
	//  Case of the prototype collection correspond to the expression define by applicative team and the other one following the rules implement by the supervisor
	EdiEntity.createEdiCacheEntity(_, {
		jsons: seqFileJsonDelim,
		type: EdiType.SEQFILE,
		id: "testDelimFailed",
		etag: "etagBidon",
		db: db
	});
	seqFileJsonDelim = JSON.parse(fs.readFile(_defDataDir + "context/seqFileFacture.json", 'utf-8', _)); // for some reasons the collection name in prototype is not the same as we have in the decribe we manage both case.

	EdiEntity.createEdiCacheEntity(_, {
		jsons: seqFileJsonDelim,
		type: EdiType.SEQFILE,
		id: "testDelim",
		etag: "etagBidon",
		db: db
	});
	fileBuff = {};
	fileBuff["FACTURA"] = fs.readFile(_defDataDir + "ediFiles/FACTURA.txt", 'utf-8', _);

	ediProcess = EdiProcess.createEdiProcess(_, {
		idProcess: "testParseDelimitedFailed",
		messageMapping: "test",
		sequentialFile: "testDelimFailed",
		protocol: "test",
		repName: "FACTURE",
		folder: "GX3APP",
		db: db
	});
	ediProcess.endPoint(_, endpointTest);

	try {
		res = parser.parse(_, {
			process: ediProcess,
			input: fileBuff,
			db: db
		});
		ok(false, "can't serialize property.$type not compatible with data read in file");

	} catch (e) {
		ok(true, "can't serialize property.$type not compatible with data read in file " + e.stack);
	}
	/*
	TODO check why we can't save the proto in the cache in that case (no error raised)
	ediProcess = EdiProcess.createEdiProcess(_, {
		idProcess: "testParseDelimited",
		messageMapping: "test",
		sequentialFile: "testDelim",
		protocol: "test",
		repName: "FACTURE",
		folder: "GX3APP",
		db: db
	});
	ediProcess.endPoint(_, endpointTest);

	res = parser.parse(_, {
		process: ediProcess,
		input: fileBuff,
		db: db
	});
	strictEqual(JSON.stringify(res), '{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EURCHEQ100COMPTANT","PTE":"75880","AMTATI":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24","ESIH1SID":[{"SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"ESIH1SIDC_BASTAXLIN":[250,250],"ESIH1SIDC_AMTTAXLIN":[52,13]},{"SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"ESIH1SIDC_BASTAXLIN":[600,600],"ESIH1SIDC_AMTTAXLIN":[48,6]}]}', "parse with seqFile delimited ok ");
    */

	/* var seqFileJsonDelimX3 = JSON.parse(fs.readFile(_defDataDir + "context/seqFileFactureX3.json", 'utf-8', _)); // for some reasons the collection name in prototype is not the same as we have in the decribe we manage both case.

    EdiEntity.createEdiCacheEntity(_, {
        jsons: seqFileJsonDelimX3,
        type: EdiType.SEQFILE,
        id: "testDelimX3",
        etag: "etagBidon",
        db: db
    });
    ediProcess = EdiProcess.createEdiProcess(_, {
        idProcess: "testParseDelimitedX3",
        messageMapping: "test",
        sequentialFile: "testDelimX3",
        protocol: "test",
        repName: "EDISIH1FACTURA",
        folder: "GX3APP",
        db: db
    });
    ediProcess.endPoint(_, endpointTest);
    fileBuff = {};
    fileBuff["FACTURE"] = fs.readFile(_defDataDir + "ediFiles/FACTURA.txt", 'utf-8', _);
    res = parser.parse(_, {
        process: ediProcess,
        input: fileBuff,
    });

    console.log(JSON.stringify(res))
    strictEqual(JSON.stringify(res), '{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EURCHEQ100COMPTANT","PTE":"75880","AMTATI":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24","ESIH1SID":[{"SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"ESIH1SIDC_BASTAXLIN":[250,250],"ESIH1SIDC_AMTTAXLIN":[52,13]},{"SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"ESIH1SIDC_BASTAXLIN":[600,600],"ESIH1SIDC_AMTTAXLIN":[48,6]}]}', "parse with seqFile delimited ok ");
    */

	start();
});

asyncTest(" serialize edi file", function(_) {
	_initPrototypeCache(_, db);
	// store in mongodb all needed to perform the test
	var seqFileJson = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));

	var protocolJson = JSON.parse(fs.readFile(_defDataDir + "context/protocol.json", 'utf-8', _));
	var fileBuff = {};
	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFAC.txt", 'utf-8', _);
	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFAC.txt", 'utf-8', _);

	var jsonSIH = {
		"NUM": "FCC11014VEN00000014",
		"BPR": "ESP0001",
		"CPY": "110",
		"FCY": "C110",
		"BPAPAY": "A01",
		"CUR": "EUR",
		"PTE": "CHEQ100COMPTANT",
		"AMTATI": 75880,
		"AMTNOT": 66000,
		"SIVTYP": "FAC",
		"ACCDAT": "2014-02-24",
		"ESIH1SID": [{
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 1000,
			"ITMREF": "CDROM",
			"ITMDES": "CD-ROM 16X",
			"SAU": "Un",
			"QTY": 3,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 30000
		}, {
			"NUM": "FCC11014VEN00000012",
			"SIDLIN": 2000,
			"ITMREF": "CDROM1",
			"ITMDES": "CD-ROM1 16X",
			"SAU": "Un",
			"QTY": 2,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 20000
		}]
	};

	EdiEntity.createEdiCacheEntity(_, {
		jsons: seqFileJson,
		type: EdiType.SEQFILE,
		id: "test",
		etag: "etagBidon",
		db: db
	});

	EdiEntity.createEdiCacheEntity(_, {
		jsons: protocolJson,
		type: EdiType.PROTOCOL,
		id: "test",
		etag: "etagBidon",
		db: db
	});

	var ediProcess = EdiProcess.createEdiProcess(_, {
		idProcess: "testSerialize",
		messageMapping: "test",
		sequentialFile: "test",
		protocol: "test",
		repName: "EDISIH1",
		folder: "GX3APP",
		db: db
	});
	// override endpoint store by a custom one to not depend on network and data integration from x3
	ediProcess.endPoint(_, endpointTest);
	var res = serializer.serialize(_, {
		process: ediProcess,
		json: jsonSIH,
		action: "edi",
		db: db
	});

	strictEqual(Object.keys(res).length, 2, "number of file ok");
	strictEqual(res["CABFAC"], fileBuff["CABFAC"], "cabfac ok ");
	strictEqual(res["LINFAC"], fileBuff["LINFAC"], "linfac ok ");



	// failed test
	var ediProcess = EdiProcess.createEdiProcess(_, {
		idProcess: "testSerializefail1",
		messageMapping: "test",
		sequentialFile: "test",
		protocol: "test",
		repName: "REPBIDON",
		folder: "GX3APP",
		db: db
	});
	// override endpoint store by a custom one to not depend on network and data integration from x3
	ediProcess.endPoint(_, endpointTest);
	try {
		var res = serializer.serialize(_, {
			process: ediProcess,
			json: jsonSOH,
			action: "edi",
			db: db
		});
		ok(false, "serialize on a non exists representation");

	} catch (e) {
		ok(true, "serialize on a non exists representation");
	}

	var ediProcess = EdiProcess.createEdiProcess(_, {
		idProcess: "testSerializefail2",
		messageMapping: "test3",
		sequentialFile: "test",
		protocol: "test",
		repName: "EISIH1",
		folder: "GX3APP",
		db: db
	});
	// override endpoint store by a custom one to not depend on network and data integration from x3
	ediProcess.endPoint(_, endpointTest);
	try {
		var res = serializer.serialize(_, {
			process: ediProcess,
			json: jsonSOH,
			action: "edi",
			db: db
		});
		ok(false, "serialize on a non exists message mapping");

	} catch (e) {
		ok(true, "serialize on a non exists message mapping");
	}


	start();
});

asyncTest(" serialize import files", function(_) {
	_initPrototypeCache(_, db);

	// store in mongodb all needed to perform the test
	var messageMappingJson = JSON.parse(fs.readFile(_defDataDir + "context/messageMappingSOH.json", 'utf-8', _));

	var protocolJson = JSON.parse(fs.readFile(_defDataDir + "context/protocol.json", 'utf-8', _));
	var fileBuff = fs.readFile(_defDataDir + "context/importSOH.csv", 'utf-8', _);

	var jsonSOH = JSON.parse(fs.readFile(_defDataDir + "context/jsonImport.json", 'utf-8', _));


	EdiEntity.createEdiCacheEntity(_, {
		jsons: messageMappingJson,
		type: EdiType.MESSAGEMAPPING,
		id: "test",
		etag: "etagBidon",
		db: db
	});

	EdiEntity.createEdiCacheEntity(_, {
		jsons: protocolJson,
		type: EdiType.PROTOCOL,
		id: "test",
		etag: "etagBidon",
		db: db
	});

	var ediProcess = EdiProcess.createEdiProcess(_, {
		idProcess: "testSerialize",
		messageMapping: "test",
		sequentialFile: "test",
		protocol: "test",
		repName: "EDISOH2",
		folder: "GX3APP",
		db: db
	});
	// override endpoint store by a custom one to not depend on network and data integration from x3
	ediProcess.endPoint(_, endpointTest);
	var res = serializer.serialize(_, {
		process: ediProcess,
		json: jsonSOH,
		action: "import",
		db: db
	});
	strictEqual(res !== null, true, "serialization ok ");

	strictEqual(res[Object.keys(res)[0]], fileBuff, "import file content ok");


	var messageMappingJson = JSON.parse(fs.readFile(_defDataDir + "context/messageMappingSOHReal.json", 'utf-8', _)); // for some reasons the collection name in prototype is not the same as we have in the decribe we manage both case.
	//  Case of the prototype collection correspond to the expression define by applicative team and the other one following the rules implement by the supervisor
	EdiEntity.createEdiCacheEntity(_, {
		jsons: messageMappingJson,
		type: EdiType.MESSAGEMAPPING,
		id: "testReal",
		etag: "etagBidon",
		db: db
	});
	var ediProcess = EdiProcess.createEdiProcess(_, {
		idProcess: "testSerialize",
		messageMapping: "testReal",
		sequentialFile: "test",
		protocol: "test",
		repName: "EDISOH2",
		folder: "GX3APP",
		db: db
	});
	// override endpoint store by a custom one to not depend on network and data integration from x3
	ediProcess.endPoint(_, endpointTest);
	var res = serializer.serialize(_, {
		process: ediProcess,
		json: jsonSOH,
		action: "import",
		db: db
	});
	strictEqual(res !== null, true, "serialization with real messageMapping ok ");

	strictEqual(res[Object.keys(res)[0]], fileBuff, "import file content with real messageMapping ok");

	// failed test
	var ediProcess = EdiProcess.createEdiProcess(_, {
		idProcess: "testSerializefail1",
		messageMapping: "test",
		sequentialFile: "test",
		protocol: "test",
		repName: "REPBIDON",
		folder: "GX3APP",
		db: db
	});
	// override endpoint store by a custom one to not depend on network and data integration from x3
	ediProcess.endPoint(_, endpointTest);
	try {
		var res = serializer.serialize(_, {
			process: ediProcess,
			json: jsonSOH,
			action: "import",
			db: db
		});
		ok(false, "serialize on a non exists representation");

	} catch (e) {
		ok(true, "serialize on a non exists representation");
	}

	var ediProcess = EdiProcess.createEdiProcess(_, {
		idProcess: "testSerializefail2",
		messageMapping: "test3",
		sequentialFile: "test",
		protocol: "test",
		repName: "EDISOH2",
		folder: "GX3APP",
		db: db
	});
	// override endpoint store by a custom one to not depend on network and data integration from x3
	ediProcess.endPoint(_, endpointTest);
	try {
		var res = serializer.serialize(_, {
			process: ediProcess,
			json: jsonSOH,
			action: "import",
			db: db
		});
		ok(false, "serialize on a non exists message mapping");

	} catch (e) {
		ok(true, "serialize on a non exists message mapping");
	}

	start();
});




asyncTest("clean edi entity mongodb", 0, function(_) {
	/*EdiEntity.dropAllEdiCacheEntity(_, {
		db: db
	});
	EdiProcess.removeAllEdiProcess(_, {
		db: db
	});*/

	start();
});

asyncTest("stop  tests", 0, function(_) {
	doStop = true;
	start();
});