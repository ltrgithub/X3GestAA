"use strict";
/* jshint -W079 */
/* jshint unused: false */
/* global QUnit: false, it: false, strictEqual: false, ok: false, start: false, stop: false */

/*global QUnit, start, ok*/
var helpers = require('@sage/syracuse-core').helpers;
var streams = require("streamline-streams");
var sys = require("util");
var config = require('config'); // must be first syracuse require
var adminHelper = require("@sage/syracuse-lib/src/collaboration/helpers").AdminHelper;
var parser = require('../../lib/tool/parser');
var serializer = require('../../lib/tool/serializer');
var helpersTool = require('../../lib/tool/helpers');

var EdiProcess = require('../../lib/edi_Process');
var EdiEntity = require('../../lib/edi_Entity');
var EdiType = require('../../lib/enumType').EdiType;
var apis = require('@sage/syracuse-core').apis;
require('syracuse-main/lib/syracuse');
var testAdmin = apis.get('test-admin');
var mongodb = require('mongodb');
var dataModel = require("@sage/syracuse-lib/src/orm/dataModel");
var registry = require("@sage/syracuse-lib/src/sdata/sdataRegistry");
var fs = require("streamline-fs");
var sqMap = require('../../lib/helpers').seqentialFilePropertyMap;
var mmMap = require('../../lib/helpers').messageMappingPropertyMap;
var xmlMap = require('../../lib/helpers').xmlFilePropertyMap;

var SEQFILE_LIB = require('../../lib/enumType').SEQFILE_LIB;
var IMPORTFILE_LIB = require('../../lib/enumType').IMPORTFILE_LIB;
var ediDataFormat = require('../../lib/enumType').EDIDATEFORMAT;
var jsxml = require('js-xml');
var upath = require('path');
var dbName = "unit_test";
var traces = false;
// activate traces
if (traces) {
	var level = "error";
	var option = {
		name: "edi",
		enabled: true,
		level: level,
		transport: "console",
		mod: {
			name: "parser",
			enabled: true,
			level: level
		}
	};
	testAdmin.setTracesOn("edi.parser", option);

	option.mod.name = "serializer";
	testAdmin.setTracesOn("edi.serializer", option);
}

var globals = require('streamline-runtime').globals;
var _defDataDir = upath.join(__dirname, "../server/data/");

function _getModel() {
	return dataModel.make(registry.applications.syracuse.contracts.collaboration, dbName);
}

var endpointTest = {
	dataset: function(_) {
		return "GX3APP";
	},
	getModel: function(_) {
		return {
			getEntity: function(_, nameEntity, facet) {
				return {
					name: nameEntity,
					getPrototype: function(_, name, facet) {
						return JSON.parse(fs.readFile(_defDataDir + "context/" + name + "_" + facet + ".json", 'utf-8', _));
					}
				};
			}
		};
	}
};


function retrieveCommonPrefix(exp1, exp2) {
	var prefix = "";
	for (var i = 0; i < exp1.length && exp2.length && exp1[i] === exp2[i]; i++) {
		prefix += exp1[i];
	}
	return prefix[prefix.length - 1] === "." ? prefix.substring(0, prefix.length - 1) : prefix;
};



function createContextParser(seqFile, sqMap) {
	var mapFilesCode = {};
	var keyByFileCode = {};
	seqFile[sqMap.filesDescription] && seqFile[sqMap.filesDescription].forEach(function(item) {
		mapFilesCode[item[sqMap.filesDescriptions.fileId]] = item[sqMap.filesDescriptions.fileName];

		keyByFileCode[item[sqMap.filesDescriptions.fileName]] = {
			primary: item[sqMap.filesDescriptions.primarykey],
			foreign: item[sqMap.filesDescriptions.foreignkey],
			fatherFileId: item[sqMap.filesDescriptions.fatherFileId]
		};
	});
	var elems = [];
	var prefixExp = {};
	var currentFilename = "";
	seqFile[sqMap.elem].forEach(function(item, idx, arr) {
		var classInstname = seqFile[sqMap.classInstance] || null;
		var exp = item[sqMap.elems.expression];

		var fileName = mapFilesCode[item[sqMap.elems.fileId]];
		prefixExp[fileName] = prefixExp[fileName] == null ? exp : retrieveCommonPrefix(prefixExp[fileName], exp); // get common path for the file id
		var element = {
			isStart: currentFilename !== fileName,
			offset: item[sqMap.elems.offset] - 1,
			length: item[sqMap.elems.length],
			level: item[sqMap.elems.level],
			expression: exp,
			flag: item[sqMap.elems.flag],
			idLineElem: item[sqMap.elems.idLine],
			isEnd: item[sqMap.elems.isEnd],
			fileName: fileName,
			fileId: item[sqMap.elems.fileId]
		};
		currentFilename = fileName;
		elems.push(element);
	});
	var configParser = {
		parser: SEQFILE_LIB[seqFile[sqMap.fileType]],
		sepDecimal: seqFile[sqMap.decimalSep],
		sepField: seqFile[sqMap.fieldSep],
		sepRecord: "\n", // TODO the one in the context
		delimField: seqFile[sqMap.fieldDelimiter],
		elems: elems,
		linkKey: keyByFileCode, // primary and foreign key for the element
		exppressionPrefix: prefixExp,
		dateFormat: seqFile[sqMap.dateFormat] ? ediDataFormat[seqFile[sqMap.dateFormat]] : null

	};
	return configParser;
}

function createContextSerializer(mm, mapField, mapFilesCode, isImport) {
	// create map between file name and file code

	var serializerMethod;
	if (!isImport) {
		serializerMethod = SEQFILE_LIB[mm[mapField.fileType]];
	} else {
		serializerMethod = IMPORTFILE_LIB[mm[mapField.fileType]];
	}
	var elems = [];
	mm && mm[mapField.elem] && mm[mapField.elem].forEach(function(item, idx, arr) {
		var classInstname = mm[mapField.classInstance];
		var exp = item[mapField.elems.expression];

		elems.push({
			offset: item[mapField.elems.offset] - 1,
			length: item[mapField.elems.length],
			expression: exp, // remove the classe instance if it exists to have the property name that correspond tot he prototype arborescence
			flag: item[mapField.elems.flag],
			isEnd: item[mapField.elems.isEnd],
			fileName: mapFilesCode[item[mapField.elems.fileId]],
			level: item[mapField.elems.level],
			isMandatory: item[mapField.elems.isMandatory] === 2 ? true : false
		});
	});
	var configSerializer = {
		serializer: serializerMethod,
		sepDecimal: mm[mapField.decimalSep],
		sepField: mm[mapField.fieldSep],
		sepRecord: "\n",
		delimField: mm[mapField.fieldDelimiter],
		elems: elems,
		fileName: isImport ? "importTest_" + (new Date().getTime()) + ".csv" : null,
		dateFormat: mm[mapField.dateFormat] ? ediDataFormat[mm[mapField.dateFormat]] : null

	};
	return configSerializer;
}



globals.context = globals.context || {};
globals.context.session = {
	id: helpers.uuid.generate(),
	getUserLogin: function(_) {
		return "admin";
	},
	getUserProfile: function(_) {
		return {
			selectedLocale: function(_) {
				var db = adminHelper.getCollaborationOrm(_);

				// the metamodel is associated to the orm
				var model = db.model;

				var entity = db.model.getEntity(_, "localePreference");
				return db.fetchInstance(_, entity, {
					jsonWhere: {
						code: "en-US"
					}
				});
			},
			user: function(_) {
				// getting the administration ORM
				var db = adminHelper.getCollaborationOrm(_);

				// the metamodel is associated to the orm
				var model = db.model;

				var entity = db.model.getEntity(_, "user");
				// fetchInstance(callback, entity, filter)
				return db.fetchInstance(_, entity, {
					jsonWhere: {
						login: "admin"
					}
				});

			}
		};
	},
	getSecurityProfile: function(_) {
		return null;
	},
	getData: function(key) {
		return null;
	},
};
import {
	assert
} from 'chai';
Object.keys(assert).forEach(key => {
	if (key !== 'isNaN') global[key] = assert[key];
});

describe(module.id, () => {
	var endpoint, db;
	var prototype_EDISIH1;
	var prototype_EDISIH1SCOL;
	var prototype_EDIS0H2;
	var prototype_EDISIH1FACTURA;

	function _initPrototypeCache(_, database) {
		EdiEntity.dropAllEdiCacheEntity(_, {
			db: database
		});
		EdiProcess.removeAllEdiProcess(_, {
			db: database
		});
		prototype_EDISIH1 = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1_$details.json", 'utf-8', _));
		prototype_EDISIH1SCOL = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1SCOL_$details.json", 'utf-8', _));
		prototype_EDIS0H2 = JSON.parse(fs.readFile(_defDataDir + "context/EDISOH2_$details.json", 'utf-8', _));
		prototype_EDISIH1FACTURA = JSON.parse(fs.readFile(_defDataDir + "context/SHIPTO_$details.json", 'utf-8', _));


	}

	function sortInput(input, opt) {
		var sortInput = {};
		Object.keys(opt.linkKey).forEach(function(filenamePattern) {
			// looking for the right file
			var found = null;
			var regexp = new RegExp(filenamePattern);

			for (var i = 0; i < Object.keys(input).length && !found; i++) {
				found = regexp.test(Object.keys(input)[i]) ? Object.keys(input)[i] : null;
			}
			// add found data
			if (found) {
				sortInput[found] = input[found];
			}
		});
		return sortInput;

	}
	var uuidJSonSOH;


	function _testError(_, data, code, toXML, protopath) {
		console.log("------------------ TEST " + code)
		try {
			helpersTool.preprocessMapping(_, data, toXML, undefined, protopath)
			strictEqual(true, false, "No error for " + code);
		} catch (e) {
			strictEqual(e.code, code, "Error code " + code)
			console.log("Error " + e);
		}
	}

	it('test with prototype', function(_) {
		var prototype = {
			$properties: {
				val: {
					"$type": "application/x-string"
				},
				ref: {
					"$type": "application/x-reference",
					"$item": {
						"$properties": {
							"CUR": {
								"$type": "application/x-string"
							}
						},
					}
				},
				ref2: {
					"$type": "application/x-reference",
					"$item": {
						"$properties": {
							"ref3": {
								"$type": "application/x-reference",
								"$item": {
									"$properties": {
										"CUR": {
											"$type": "application/x-string"
										}
									},
								}
							},
							"array2": {
								$type: "application/x-array",
								$item: {
									$properties: {
										"element": {
											$type: "application/x-string"
										}
									}
								}
							}
						},
					}
				},
				array: {
					"$type": "application/x-array",
					"$item": {
						"$properties": {
							"ref4": {
								"$type": "application/x-reference",
								"$item": {
									"$properties": {
										"CUR": {
											"$type": "application/x-string"
										}
									},
								}
							},
							"entry": {
								"$type": "application/x-string"
							}
						},
					}

				}

			}
		};
		_testError(_, [{
			xml: "A.B",
			json: "ref55"
		}], "NOTINPROTOTYPE", true, prototype)
		_testError(_, [{
			xml: "A.B",
			json: "ref.CUR2"
		}], "NOTINPROTOTYPE", true, prototype)
		_testError(_, [{
			xml: "A.B",
			json: "ref"
		}], "REFERENCEVALUE", true, prototype)
		_testError(_, [{
			xml: "A.B",
			json: "ref.CUR",
			condition: "ref55 = 0"
		}], "CONDVARNOTINPROTOTYPE", true, prototype)
		_testError(_, [{
			xml: "A.B",
			json: "ref.CUR",
			condition: "ref.CUR2 = 0"
		}], "CONDVARNOTINPROTOTYPE", true, prototype)
		_testError(_, [{
			xml: "A.B",
			json: "ref.CUR",
			condition: "ref = 0"
		}], "CONDVARREFERENCEVALUE", true, prototype)
		var mappings = [{
			xml: "A.B",
			json: "ref.CUR"
		}, {
			xml: "A.D[0..n].C[0..1]",
			json: "array.ref4.CUR",
			condition: "ref.CUR = 1"
		}, {
			xml: "A.D[0..n].L[0..1]",
			json: "array.ref4.CUR",
			condition: "ref.CUR <> 1"
		}, {
			xml: "A.C",
			json: "ref2.ref3.CUR"
		}, {
			xml: "A.E[0..n].F[0..1].G",
			json: "ref2.array2.element"
		}];
		var diags = [];
		console.log("VORH 1")
		var map = helpersTool.preprocessMapping(_, mappings, true, diags, prototype);

		strictEqual(JSON.stringify(map), JSON.stringify({
			"": {
				"toXML": 1,
				"depth": 2
			},
			"ref.CUR": ["0A.0B"],
			"array": {
				"": "0A.1D",
				"ref4.CUR": ["1C", "0", null, [0, "ref.CUR", 9, 1, 0, 0], "2L", "0", null, [0, "ref.CUR", 13, 1, 0, 0]]
			},
			"ref2.ref3.CUR": ["0A.3C"],
			"ref2.array2": {
				"": "0A.4E",
				"element": ["4F.4G"]
			}
		}), "Map with references")

		console.log("map " + JSON.stringify(map))
		console.log("jjj" + JSON.stringify({
			"": {
				"toXML": 1,
				"depth": 2
			},
			"ref.CUR": ["0A.0B"],
			"array": {
				"": "0A.1D",
				"ref4.CUR": ["1C", "0", null, [0, "ref.CUR", 9, 1, 0, 0], "2L", "0", null, [0, "ref.CUR", 13, 1, 0, 0]]
			},
			"ref2.ref3.CUR": ["0A.3C"],
			"ref2.array2": {
				"": "0A.4E",
				"element": ["4F.4G"]
			}
		}))
		var data = {
			ref: {
				CUR: 1
			},
			array: [{
				ref4: {
					CUR: 1
				}
			}, {
				ref4: {
					CUR: 2
				}
			}],
			ref2: {
				array2: [{
					element: 3
				}, {
					element: 4
				}],
				ref3: {
					CUR: 5
				}
			}
		};
		var converted = helpersTool.convert(data, map);
		console.log("ZZ " + JSON.stringify(converted))
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": {
				"B": 1,
				"D": [{
					"C": 1
				}, {
					"C": 2
				}],
				"C": 5,
				"E": [{
					"F": {
						"G": 3
					}
				}, {
					"F": {
						"G": 4
					}
				}]
			}
		}), "Conversion to jsxml, condition ref.CUR=1")
		var data = {
			ref2: {
				array2: [{
					element: 3
				}, {
					element: 4
				}],
				ref3: {
					CUR: 5
				}
			},
			array: [{
				ref4: {
					CUR: 1
				}
			}, {
				ref4: {
					CUR: 2
				}
			}],
			ref: {
				CUR: 7
			}
		};
		var converted = helpersTool.convert(data, map);
		console.log("ZZ " + JSON.stringify(converted))
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": {
				"B": 7,
				"D": [{
					"L": 1
				}, {
					"L": 2
				}],
				"C": 5,
				"E": [{
					"F": {
						"G": 3
					}
				}, {
					"F": {
						"G": 4
					}
				}]
			}
		}), "Conversion to jsxml, condition ref.CUR <> 1")

		var map = helpersTool.preprocessMapping(_, mappings, false, diags, prototype);
		console.log("VORH 22")
		strictEqual(JSON.stringify(map), JSON.stringify({
			"": {
				"toXML": 0,
				"depth": 2
			},
			"A.B": ["ref.CUR"],
			"A.D": {
				"": "array",
				"C": ["ref4.CUR"],
				"L": ["ref4.CUR"]
			},
			"A.C": ["ref2.ref3.CUR"],
			"A.E": {
				"": "ref2.array2",
				"F.G": ["element"]
			}
		}), "Map with references, toXML")
		console.log("MAP " + JSON.stringify(map));
		console.log("kkk " + JSON.stringify({
			"": {
				"toXML": 0,
				"depth": 2
			},
			"A.B": ["ref.CUR"],
			"A.D": {
				"": "array",
				"C": ["ref4.CUR"],
				"L": ["ref4.CUR"]
			},
			"A.C": ["ref2.ref3.CUR"],
			"A.E": {
				"": "ref2.array2",
				"F.G": ["element"]
			}
		}))
		var converted = helpersTool.convert(converted, map);
		console.log("ZZ2 " + JSON.stringify(converted))
		strictEqual(JSON.stringify(converted), JSON.stringify(data), "Conversion to JSON")

	})


	it('different mappings test', function(_) {
		var mappings = [{
			xml: "A.B",
			json: "u"
		}, {
			xml: "A.B",
			json: "v"
		}, {
			xml: "A.B",
			json: "w"
		}]
		var diags = [];
		var map = helpersTool.preprocessMapping(_, mappings, false, diags);
		strictEqual(JSON.stringify(map), JSON.stringify({
			"": {
				"toXML": 0,
				"depth": 1
			},
			"A.B": [
				["u", "v", "w"]
			]
		}), "Double mapping of JSON path")
		strictEqual(diags.length, 1, "Double mapping of JSON path: 1 warning")
		var converted = helpersTool.convert({
			A: {
				B: 7
			}
		}, map)
		strictEqual(JSON.stringify(converted), JSON.stringify({
				"u": 7,
				"v": 7,
				"w": 7
			}))
			// wrong conditions
		_testError(_, [{
			xml: "A.C",
			json: "u"
		}, {
			xml: "A.B",
			json: "u",
			condition: "a = 5"
		}], "FULLCHANGE", true)
		_testError(_, [{
			xml: "A.C",
			json: "u$"
		}], "INCORRECTJSON", true)
		_testError(_, [{
			xml: "A.C,",
			json: "u"
		}], "INCORRECTXML", true)
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: "abcde"
		}], "WRONGCONDFORMAT", true)
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: "a..b = 5"
		}], "WRONGCONDVAR", true)
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: ".a.b = 5"
		}], "WRONGCONDVAR", true)
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: "a <> 5a"
		}], "WRONGCONDCONST", true)
		_testError(_, [{
				xml: "A.B[0..n].C",
				json: "u.v",
				condition: "u.x >< 5a"
			}], "WRONGCONDOP", true)
			/*	_testError(_, [{
					xml: "A.B[0..n].C",
					json: "u.v",
					condition: "a = 5"
				}], "WRONGCONDVAR", true)
			*/
			// operators test
		var mappings = [{
			xml: "A.B",
			json: "u",
			condition: "v = 5 or v eq 5 or v = '5' or v eq '5' or v > 5 or v gt 5 or v > '5' or v gt '5' or v lt 5 or v < 5 or v lt '5' or v lt '5' or v <> 5 or v != 5 or v ne 5 or v <> '5' or v != '5' or v ne '5' or v >= 5 or v ge 5 or v >= '5' or v ge '5' or v <= 5 or v le 5 or v <= '5' or v le '5'"
		}]
		var map = helpersTool.preprocessMapping(_, mappings, true, diags);
		strictEqual(JSON.stringify(map), JSON.stringify({
			"": {
				"toXML": 1,
				"depth": 1
			},
			"u": ["0A.0B", "0", null, [0, "v", 9, 5, 0, 6, 0, "v", 9, 5, 0, 12, 0, "v", 1, "5", 0, 18, 0, "v", 1, "5", 0, 24, 0, "v", 10, 5, 0, 30, 0, "v", 10, 5, 0, 36, 0, "v", 2, "5", 0, 42, 0, "v", 2, "5", 0, 48, 0, "v", 15, 5, 0, 54, 0, "v", 15, 5, 0, 60, 0, "v", 7, "5", 0, 66, 0, "v", 7, "5", 0, 72, 0, "v", 13, 5, 0, 78, 0, "v", 13, 5, 0, 84, 0, "v", 13, 5, 0, 90, 0, "v", 5, "5", 0, 96, 0, "v", 5, "5", 0, 102, 0, "v", 5, "5", 0, 108, 0, "v", 11, 5, 0, 114, 0, "v", 11, 5, 0, 120, 0, "v", 3, "5", 0, 126, 0, "v", 3, "5", 0, 132, 0, "v", 14, 5, 0, 138, 0, "v", 14, 5, 0, 144, 0, "v", 6, "5", 0, 150, 0, "v", 6, "5", 0, 0]]
		}), "all operators")
		var map = helpersTool.preprocessMapping(_, [{
			xml: "A.B",
			json: "u",
			condition: "a == -7"
		}], true);

		strictEqual(JSON.stringify(map), JSON.stringify({
			"": {
				"toXML": 1,
				"depth": 1
			},
			"u": ["0A.0B", "0", null, [0, "a", 9, -7, 0, 0]]
		}), "equality 2");
		var map = helpersTool.preprocessMapping(_, [{
			xml: "A.B",
			json: "u",
			type: "maxLength:10",
			condition: "a le 'ab\\'cd'"
		}, {
			xml: "A.C",
			json: "u",
			condition: 'a gt "ab\\"cd"'
		}, {
			xml: "A.D",
			json: "u",
			condition: "a ge 'abcd'"
		}], true);
		strictEqual(JSON.stringify(map), JSON.stringify({
			"": {
				"toXML": 1,
				"depth": 1
			},
			"u": ["0A.0B", "10", null, [0, "a", 6, "ab'cd", 0, 0], "0A.1C", "0", null, [0, "a", 2, 'ab"cd', 0, 0], "0A.2D", "0", null, [0, "a", 3, "abcd", 0, 0]]
		}), "several");
		var map = helpersTool.preprocessMapping(_, [{
			xml: "A.B",
			json: "u",
			type: "maxLength:10",
			condition: "a < 5"
		}, {
			xml: "A.C",
			json: "u",
			condition: 'a > 5'
		}, {
			xml: "A.D",
			json: "u",
			condition: "a >= 5"
		}], true);

		// convert with condition
		var converted = helpersTool.convert({
			u: "12345678901234567",
			a: 5

		}, map);
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": {
				"D": "12345678901234567"
			}
		}), "numerical comparison, a = 5")
		var converted = helpersTool.convert({
			u: "12345678901234567",
			a: 10

		}, map);
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": {
				"C": "12345678901234567",
				"D": "12345678901234567"
			}
		}), "numerical comparison, a = 10")
		var converted = helpersTool.convert({
			u: "12345678901234567",
			a: 3

		}, map);
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": {
				"B": "1234567890"
			}
		}), "numerical comparison, a = 3")

		var map = helpersTool.preprocessMapping(_, [{
			xml: "A.B",
			json: "u",
			type: "maxLength:10",
			condition: "a > '5'"
		}, {
			xml: "A.C",
			json: "u",
			condition: "a < '5'"
		}, {
			xml: "A.D",
			json: "u",
			condition: "a <= '5'"
		}], true);

		// convert with condition
		var converted = helpersTool.convert({
			u: "12345678901234567",
			a: 5

		}, map);
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": {
				"D": "12345678901234567"
			}
		}), "string comparison, a = 5")
		var converted = helpersTool.convert({
			u: "12345678901234567",
			a: 10

		}, map);
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": {
				"C": "12345678901234567",
				"D": "12345678901234567"
			}
		}), "string comparison, a = 10")
		var converted = helpersTool.convert({
			u: "12345678901234567",
			a: 6
		}, map);
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": {
				"B": "1234567890"
			}
		}), "string comparison, a = 6")


		var mappings = [{
			xml: "A.B",
			json: "u",
			condition: "v eq '\"\\'\\\\'",
		}, {
			xml: "A.C",
			json: "u",
			condition: 'v eq "\'\\"\\\\"'
		}]
		var map = helpersTool.preprocessMapping(_, mappings, true, diags);
		var converted = helpersTool.convert({
			u: "xyz",
			v: '"\'\\'
		}, map)
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": {
				"B": "xyz"
			}
		}), "quotation marks 1")
		var converted = helpersTool.convert({
			u: "xyz",
			v: "'\"\\"
		}, map)
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": {
				"C": "xyz"
			}
		}), "quotation marks 2")


	})


	it('preprocess test', function(_) {
		_testError(_, [], "NOMAPPING")
		var mappings = [{
			xml: "A.L",
			json: "u",
			type: "base:xs:string,maxLength:50"
		}, {
			xml: "A.B.C[0..n].D",
			json: "v.w",
			type: "base:xs:string"
		}, {
			xml: "A.B.C[0..n].DE",
			json: "v.x",
			type: "base:xs:decimal"
		}, {
			xml: "A.F[0..n].G.H",
			json: "y.z"
		}, {
			xml: "A.F[0..n].I[0..n].J",
			json: "y.t.s"
		}];

		var r1 = helpersTool.preprocessMapping(_, mappings)
		strictEqual(JSON.stringify(r1), JSON.stringify({
			"": {
				toXML: 0,
				depth: 3
			},
			"A.L": ["u", "50"],
			"A.B.C": {
				"": "v",
				"D": ["w"],
				"DE": ["x", "0", "decimal"]
			},
			"A.F": {
				"": "y",
				"G.H": ["z"],
				"I": {
					"": "t",
					"J": ["s"]
				}
			}
		}), "Transformation to JSON mapping")
		mappings.push({}); // add empty mapping (should not change anything)
		var r1 = helpersTool.preprocessMapping(_, mappings, true)
		strictEqual(JSON.stringify(r1), JSON.stringify({
			"": {
				toXML: 1,
				depth: 1
			},
			"u": ["0A.0L", "50"],
			"v": {
				"": "0A.1B.1C",
				"w": ["1D"],
				"x": ["2DE", "0", "decimal"]
			},
			"y": {
				"": "0A.3F",
				"z": ["3G.3H"],
				"t": {
					"": "4I",
					"s": ["4J"]
				}
			}
		}), "Transformation to XML mapping")
		console.log(JSON.stringify(r1));
		_testError(_, [{
			xml: "A"
		}], "EMPTYJSON")
		_testError(_, [{
			json: "A"
		}], "EMPTYXML")
		_testError(_, [{
			json: "",
			xml: "A"
		}], "EMPTYJSON")
		_testError(_, [{
			json: "A",
			xml: ""
		}], "EMPTYXML")
		_testError(_, [{}], "NOMAPPING")
		_testError(_, [{
			xml: "A.B[0..n][0..m].C",
			json: "u.v.w"
		}], "INCORRECTXML");
		_testError(_, [{
			xml: "A.B[0..n].B[0..m]",
			json: "u.v.w"
		}], "INCORRECTXML");
		_testError(_, [{
			xml: "A.B[0..n].B[0..m].C",
			json: "u.v."
		}], "INCORRECTJSON")
		_testError(_, [{
			xml: "A.B[0..n].B[0..m].C",
			json: "u..v."
		}], "INCORRECTJSON")
		_testError(_, [{
			xml: "A.B[0..n].B[0..m].C",
			json: "u.vw"
		}], "DESTLESSGROUPS")
		_testError(_, [{
			xml: "A.B[0..n].B[0..m].C",
			json: "u.v.w.x"
		}], "DESTMOREGROUPS")
		_testError(_, [{
			xml: "A.B",
			json: "u"
		}, {
			xml: "A.B[0..n].B",
			json: "u.v"
		}], "FULLTOGROUP")
		_testError(_, [{
			xml: "A.B[0..n].B",
			json: "u.v"
		}, {
			xml: "A.B",
			json: "u"
		}], "GROUPTOFULL")
		_testError(_, [{
			xml: "A.B[0..n].B",
			json: "u.v"
		}, {
			xml: "A.B[0..n].C",
			json: "v.v"
		}], "GROUPCHANGE")
		_testError(_, [{
			xml: "B",
			json: "u"
		}, {
			xml: "A",
			json: "u"
		}], "ROOTDIFFERENT", true)
		_testError(_, [{
			xml: "A.C",
			json: "u"
		}, {
			xml: "A.C.D",
			json: "v"
		}], "CONTAINS");
		_testError(_, [{
			xml: "A.C.D",
			json: "u"
		}, {
			xml: "A.C",
			json: "v"
		}], "CONTAINED");
		_testError(_, [{
			xml: "A[0..n].B",
			json: "u.v"
		}], "ROOTREPETITION");
		_testError(_, [{
			xml: "A.B[0..n].B",
			json: "u.v"
		}, {
			xml: "AA.B[0..n].B",
			json: "w.v"
		}], "ROOTDIFFERENT");

	});

	it('converter test', function(_) {
		// empty XML
		var map = helpersTool.preprocessMapping(_, [{
			xml: "A.B[0..n].C",
			json: "u.v"
		}], true);
		var converted = helpersTool.convert({
			w: 2
		}, map);
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": ""
		}), "empty XML")

		var mappings = [{
			xml: "A.L",
			json: "u",
			type: "base:xs:string,maxLength:10"
		}, {
			xml: "A.B.C[0..n].D",
			json: "v.w",
			type: "base:xs:string"
		}, {
			xml: "A.B.C[0..n].DE",
			json: "v.x",
			type: "base:xs:decimal"
		}, {
			xml: "A.F[0..n].G.H",
			json: "y.z"
		}, {
			xml: "A.F[0..n].I[0..n].J",
			json: "y.t.s"
		}];
		var map = helpersTool.preprocessMapping(_, mappings, true);
		var converted = helpersTool.convert({
				u: "abcdefghijklmnop",
				nothing: 5,
				nil: {},
				v: {
					w: "a",
					x: 1.5
				},
				y: [{
					z: 1
				}, {
					z: 2,
					t: {
						s: 20
					}
				}]
			}, map)
			// string will be truncated!
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": {
				"L": "abcdefghij",
				"B": {
					"C": [{
						"D": "a",
						"DE": "1.5",
					}]
				},
				"F": [{
					"G": {
						"H": 1
					}
				}, {
					"G": {
						"H": 2
					},
					"I": [{
						"J": 20
					}]
				}],
			}
		}), "Conversion to jsxml")
		var map2 = helpersTool.preprocessMapping(_, mappings);
		var convertedback = helpersTool.convert(converted, map2);
		// string will be truncated!
		strictEqual(JSON.stringify(convertedback), JSON.stringify({
			y: [{
				z: 1
			}, {
				t: [{
					s: 20
				}],
				z: 2,
			}],
			v: [{
				x: 1.5,
				w: "a",
			}],
			u: "abcdefghij"
		}), "Conversion from jsxml")
		var A = {
			A: undefined
		};
		A.A = A;
		var convertedrec = helpersTool.convert(A, map2);
		strictEqual(JSON.stringify(convertedrec), '{}', "recursive structure")
		var A = {
			F: [{
				A: undefined
			}]
		};
		A.F[0].A = A;
		var convertedrec = helpersTool.convert(A, map2);
		strictEqual(JSON.stringify(convertedrec), '{}', "recursive structure 2")
			// test with type conversions
		var mappings = [{
			xml: "A.A",
			json: "a",
			type: "base:xs:integer"
		}, {
			xml: "A.B",
			json: "b",
			type: "base:xs:decimal"
		}, {
			xml: "A.C",
			json: "c",
			type: "base:xs:date"
		}, {
			xml: "A.D",
			json: "d",
			type: "base:xs:dateTime"
		}, {
			xml: "A.E",
			json: "e",
			type: "base:xs:boolean"
		}];
		var map = helpersTool.preprocessMapping(_, mappings, true);
		var converted = helpersTool.convert({
			a: 1,
			b: 1.5,
			c: "2011-10-10Z",
			d: new Date("2011-10-10T05:05Z"),
			e: true
		}, map);
		strictEqual(JSON.stringify(converted), '{"A":{"A":"1","B":"1.5","C":"2011-10-10","D":"2011-10-10T05:05:00Z","E":"true"}}', "type example 1")
		var converted = helpersTool.convert({
			a: "1.5",
			b: +0,
			c: new Date("2011-10-10Z"),
			d: "2011-10-10T05:05:05Z",
			e: "false"
		}, map);
		strictEqual(JSON.stringify(converted), '{"A":{"A":"1","B":"0","C":"2011-10-10","D":"2011-10-10T05:05:05Z","E":"false"}}', "type example 2")
		var map = helpersTool.preprocessMapping(_, mappings, false);
		var converted = helpersTool.convert({
			A: {
				A: "1",
				B: "+1.5E2",
				C: "2011-10-10Z",
				D: "2011-10-10T05:05:05Z",
				E: "1"
			}
		}, map);
		strictEqual(converted.e, true, "conversion from XML: boolean 1")
		strictEqual(converted.d.getTime(), new Date("2011-10-10T05:05:05.000Z").getTime(), "conversion from XML: datetime 1")
		strictEqual(converted.c.getTime(), new Date("2011-10-10Z").getTime(), "conversion from XML: date 1")
		strictEqual(converted.b, 150, "conversion from XML: decimal 1")
		strictEqual(converted.a, 1, "conversion from XML: integer 1")
		var converted = helpersTool.convert({
			A: {
				A: "-15",
				B: "-1.5",
				C: "2011-10-10Z",
				D: "2011-10-10T05:05:05Z",
				E: "true"
			}
		}, map);
		strictEqual(converted.e, true, "conversion from XML: boolean 2")
		strictEqual(converted.d.getTime(), new Date("2011-10-10T05:05:05.000Z").getTime(), "conversion from XML: datetime 2")
		strictEqual(converted.c.getTime(), new Date("2011-10-10Z").getTime(), "conversion from XML: date 2")
		strictEqual(converted.b, -1.5, "conversion from XML: decimal 2")
		strictEqual(converted.a, -15, "conversion from XML: integer 2")
	})
	it('fine points about conditions', function(_) {
		// tests conditions in other paths and correct repetition groups
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: "v.w < 0"
		}], "CONDVARNOTUNIQUE", true)
		_testError(_, [{
			xml: "A.B[0..n].C[0..n].D",
			json: "u.v.w",
			condition: "u.w.y = 0"
		}], "CONDVARNOTUNIQUE", true)


		var mappings = [{
			xml: "A.B[0..n].C[0..n].D",
			json: "u.v.s",
			condition: "z = 1"
		}, {
			xml: "A.B[0..n].C[0..n].E",
			json: "u.v.x",
			condition: "u.w = 1"
		}, {
			xml: "A.B[0..n].C[0..n].F",
			json: "u.v.y",
			condition: "u.v.t = 1"
		}]
		var map = helpersTool.preprocessMapping(_, mappings, true);
		strictEqual(JSON.stringify(map), JSON.stringify({
			"": {
				"toXML": 1,
				"depth": 1
			},
			"u": {
				"": "0A.0B",
				"v": {
					"": "0C",
					"s": ["0D", "0", null, [0, "z", 9, 1, 0, 0]],
					"x": ["1E", "0", null, [1, "w", 9, 1, 0, 0]],
					"y": ["2F", "0", null, [2, "t", 9, 1, 0, 0]]
				}
			}
		}), "process map")
		var converted = helpersTool.convert({
			z: 1,
			u: [{
				w: 1,
				v: [{
					t: 1,
					y: "yes because t=1",
					x: "yes because w=1",
					s: "always1"
				}, {
					t: 2,
					y: "no because t<>1",
					x: "yes because w=1",
					s: "always2"
				}]
			}, {
				w: 2,
				v: [{
					t: 1,
					y: "yes because t=1",
					x: "no because w<>1",
					s: "always3"
				}, {
					t: 2,
					y: "no because t<>1",
					x: "no because w<>1",
					s: "always4"
				}]
			}]
		}, map)
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": {
				"B": [{
					"C": [{
						"D": "always1",
						"E": "yes because w=1",
						"F": "yes because t=1"
					}, {
						"D": "always2",
						"E": "yes because w=1"
					}]
				}, {
					"C": [{
						"D": "always3",
						"F": "yes because t=1"
					}, {
						"D": "always4"
					}]
				}]
			}
		}), "process conditions")

		// more complicated conditions
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: "v < 0 and"
		}], "WRONGCONDEND", true)
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: "or v < 0"
		}], "WRONGCONDOP", true)
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: "v < 0 w = 0"
		}], "WRONGCONDCOND", true)
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: "()"
		}], "WRONGCONDBRACKCLOSE", true)
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: ")"
		}], "WRONGCONDBRACKCLOSE", true)
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: "(and)"
		}], "WRONGCONDOP", true)
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: "(v = 0) or"
		}], "WRONGCONDEND", true)
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: "(v = 0) (w = 0)"
		}], "WRONGCONDBRACKOPEN", true)
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: "v = 0& or"
		}], "WRONGCONDOP", true)
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: "(v = 0))"
		}], "CONDBRACKETS", true)
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: "((v=0)"
		}], "CONDBRACKETS2", true)
		_testError(_, [{
			xml: "A.B",
			json: "u",
			condition: "(v=0"
		}], "CONDBRACKETS2", true)
		var map = helpersTool.preprocessMapping(_, [{
			xml: "A.B[0..n].A",
			json: "u.v",
			condition: "u.a = 2 & u.b = 3 | u.d=4 & u.e = 5 & u.f = 6 | u.g = 7"
		}], true);
		strictEqual(JSON.stringify(map), JSON.stringify({
			"": {
				"toXML": 1,
				"depth": 1
			},
			"u": {
				"": "0A.0B",
				"v": ["0A", "0", null, [1, "a", 9, 2, 6, 12, 1, "b", 9, 3, 0, 12, 1, "d", 9, 4, 18, 30, 1, "e", 9, 5, 24, 30, 1, "f", 9, 6, 0, 30, 1, "g", 9, 7, 0, 0]]
			}
		}), "condition without brackets")
		var converted = helpersTool.convert({
			u: [{
				v: "F1",
				a: 2
			}, {
				v: "T1",
				a: 2,
				b: 3
			}, {
				v: "F2",
				a: 3,
				b: 3
			}, {
				v: "T2",
				a: 2,
				g: 7
			}, {
				v: "F3",
				d: 4,
				e: 5,
				a: 2,
				b: 4,
				f: 7,
				g: 8
			}, {
				v: "F4",
				d: 5,
				e: 4,
				a: 3,
				b: 3,
				f: 6,
				g: 8
			}]
		}, map)
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": {
				"B": [{
					"A": "T1"
				}, {
					"A": "T2"
				}]
			}
		}), "conversion")
		var map = helpersTool.preprocessMapping(_, [{
			xml: "A.B[0..n].A",
			json: "u.v",
			condition: "(((u.a = 2 & u.b = 3)) | (((u.d=4 & u.e = 5) & u.f = 6) | (((u.g = 7)))))"
		}], true);
		strictEqual(JSON.stringify(map), JSON.stringify({
				"": {
					"toXML": 1,
					"depth": 1
				},
				"u": {
					"": "0A.0B",
					"v": ["0A", "0", null, [1, "a", 9, 2, 6, 12, 1, "b", 9, 3, 0, 12, 1, "d", 9, 4, 18, 30, 1, "e", 9, 5, 24, 30, 1, "f", 9, 6, 0, 30, 1, "g", 9, 7, 0, 0]]
				}
			}), "equivalent condition with brackets")
			//												    {"":{"toXML":true,"depth":1},"u":{"":"A.B","v":["A","0",null,[1,"a",9,2,6,0,1,"b",9,3,0,0,1,"d",9,4,18,0,1,"e",9,5,24,0,1,"f",9,6,0,0,1,"g",9,7,0,0]]}}
		var map = helpersTool.preprocessMapping(_, [{
			xml: "A.B[0..n].A",
			json: "u.v",
			condition: "(u.a = 2 or u.b = 3) and (u.c = 4 or u.d = 5) or u.e = 6"
		}], true);
		strictEqual(JSON.stringify(map), JSON.stringify({
			"": {
				"toXML": 1,
				"depth": 1
			},
			"u": {
				"": "0A.0B",
				"v": ["0A", "0", null, [1, "a", 9, 2, 12, 6, 1, "b", 9, 3, 12, 24, 1, "c", 9, 4, 0, 18, 1, "d", 9, 5, 0, 24, 1, "e", 9, 6, 0, 0]]
			}
		}), "second condition with brackets")
		var converted = helpersTool.convert({
			u: [{
				v: "F1",
				a: 2
			}, {
				v: "F2",
				a: 2,
				b: 3
			}, {
				v: "T1",
				b: 3,
				c: 4
			}, {
				v: "T2",
				a: 4,
				b: 3,
				c: 1,
				d: 1,
				e: 6
			}, {
				v: "T3",
				a: 2,
				c: 5,
				d: 5,
				e: 9
			}, {
				v: "F3",
				a: 2,
				c: 5,
				d: 4,
				e: 9
			}]
		}, map)
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": {
				"B": [{
					"A": "T1"
				}, {
					"A": "T2"
				}, {
					A: "T3"
				}]
			}
		}), "conversion")

		var map = helpersTool.preprocessMapping(_, [{
			xml: "A.B[0..n].A",
			json: "u.v",
			condition: "u.e = 6 or (u.c = 4 or u.d = 5) and (u.a = 2 or u.b = 3)"
		}], true);
		strictEqual(JSON.stringify(map), JSON.stringify({
			"": {
				"toXML": 1,
				"depth": 1
			},
			"u": {
				"": "0A.0B",
				"v": ["0A", "0", null, [1, "e", 9, 6, 0, 6, 1, "c", 9, 4, 18, 12, 1, "d", 9, 5, 18, 0, 1, "a", 9, 2, 0, 24, 1, "b", 9, 3, 0, 0]]
			}
		}), "second condition with brackets, shifted")
		var converted = helpersTool.convert({
			u: [{
				v: "F1",
				a: 2
			}, {
				v: "F2",
				a: 2,
				b: 3
			}, {
				v: "T1",
				b: 3,
				c: 4
			}, {
				v: "T2",
				a: 4,
				b: 3,
				c: 1,
				d: 1,
				e: 6
			}, {
				v: "T3",
				a: 2,
				c: 5,
				d: 5,
				e: 9
			}, {
				v: "F3",
				a: 2,
				c: 5,
				d: 4,
				e: 9
			}]
		}, map)
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": {
				"B": [{
					"A": "T1"
				}, {
					"A": "T2"
				}, {
					A: "T3"
				}]
			}
		}), "conversion")
		var map = helpersTool.preprocessMapping(_, [{
			xml: "A.B[0..n].A",
			json: "u.v",
			condition: "u.e = 6 or (u.a = 2 or u.b = 3) and (u.c = 4 or u.d = 5)"
		}], true);
		strictEqual(JSON.stringify(map), JSON.stringify({
			"": {
				"toXML": 1,
				"depth": 1
			},
			"u": {
				"": "0A.0B",
				"v": ["0A", "0", null, [1, "e", 9, 6, 0, 6, 1, "a", 9, 2, 18, 12, 1, "b", 9, 3, 18, 0, 1, "c", 9, 4, 0, 24, 1, "d", 9, 5, 0, 0]]
			}
		}), "second condition with brackets, shifted again")
		var converted = helpersTool.convert({
			u: [{
				v: "F1",
				a: 2
			}, {
				v: "F2",
				a: 2,
				b: 3
			}, {
				v: "T1",
				b: 3,
				c: 4
			}, {
				v: "T2",
				a: 4,
				b: 3,
				c: 1,
				d: 1,
				e: 6
			}, {
				v: "T3",
				a: 2,
				c: 5,
				d: 5,
				e: 9
			}, {
				v: "F3",
				a: 2,
				c: 5,
				d: 4,
				e: 9
			}]
		}, map)
		strictEqual(JSON.stringify(converted), JSON.stringify({
			"A": {
				"B": [{
					"A": "T1"
				}, {
					"A": "T2"
				}, {
					A: "T3"
				}]
			}
		}), "conversion")

		var map = helpersTool.preprocessMapping(_, [{
			xml: "A.B[0..n].A",
			json: "u.v",
			condition: "u.a = 1 or u.b = 2 and u.c = 3 and u.d = 4 or u.e = 5 and u.f = 6 and u.g = 7 or u.h = 8"
		}], true);
		strictEqual(JSON.stringify(map), JSON.stringify({
				"": {
					"toXML": 1,
					"depth": 1
				},
				"u": {
					"": "0A.0B",
					"v": ["0A", "0", null, [1, "a", 9, 1, 0, 6, 1, "b", 9, 2, 12, 24, 1, "c", 9, 3, 18, 24, 1, "d", 9, 4, 0, 24, 1, "e", 9, 5, 30, 42, 1, "f", 9, 6, 36, 42, 1, "g", 9, 7, 0, 42, 1, "h", 9, 8, 0, 0]]
				}
			}),
			"AND condition with more than 2 operators")



	})

	it('ordering in XML output', function(_) {
		var mappings = [{
			xml: "A.B0",
			json: "u0",
		}, {
			xml: "A.B1",
			json: "u1",
		}, {
			xml: "A.B2",
			json: "u2",
		}, {
			xml: "A.B3",
			json: "u3",
		}, {
			xml: "A.B4",
			json: "u4",
		}, {
			xml: "A.B5",
			json: "u5",
		}, {
			xml: "A.B6",
			json: "u6",
		}, {
			xml: "A.B7",
			json: "u7",
		}, {
			xml: "A.B8",
			json: "u8",
		}, {
			xml: "A.B9",
			json: "u9",
		}]
		var map = helpersTool.preprocessMapping(_, mappings, true);
		strictEqual(JSON.stringify(map), JSON.stringify({
				"": {
					"toXML": 1,
					"depth": 1
				},
				"u0": ["0A.0B0"],
				"u1": ["0A.1B1"],
				"u2": ["0A.2B2"],
				"u3": ["0A.3B3"],
				"u4": ["0A.4B4"],
				"u5": ["0A.5B5"],
				"u6": ["0A.6B6"],
				"u7": ["0A.7B7"],
				"u8": ["0A.8B8"],
				"u9": ["0A.9B9"]
			}),
			"10 mappings")
		var mappings = [{
			xml: "A.B0",
			json: "u0",
		}, {
			xml: "A.B1",
			json: "u1",
		}, {
			xml: "A.B2",
			json: "u2",
		}, {
			xml: "A.B3",
			json: "u3",
		}, {
			xml: "A.B4",
			json: "u4",
		}, {
			xml: "A.B5",
			json: "u5",
		}, {
			xml: "A.B6",
			json: "u6",
		}, {
			xml: "A.B7",
			json: "u7",
		}, {
			xml: "A.B8",
			json: "u8",
		}, {
			xml: "A.B9",
			json: "u9",
		}, {
			xml: "A.Bx",
			json: "ux",
		}]
		var map = helpersTool.preprocessMapping(_, mappings, true);
		strictEqual(JSON.stringify(map), JSON.stringify({
				"": {
					"toXML": 2,
					"depth": 1
				},
				"u0": ["00A.00B0"],
				"u1": ["00A.01B1"],
				"u2": ["00A.02B2"],
				"u3": ["00A.03B3"],
				"u4": ["00A.04B4"],
				"u5": ["00A.05B5"],
				"u6": ["00A.06B6"],
				"u7": ["00A.07B7"],
				"u8": ["00A.08B8"],
				"u9": ["00A.09B9"],
				"ux": ["00A.10Bx"]
			}),
			"11 mappings")
		var json = {
			u1: 1,
			u2: 2,
			u3: 3,
			u7: 7
		}; // this JSON will be mapped with different orderings in the mappings array. The XML output must be different
		var converted = helpersTool.convert(json, map)
		strictEqual(JSON.stringify(converted), JSON.stringify({
				"A": {
					"B1": 1,
					"B2": 2,
					"B3": 3,
					"B7": 7
				}
			}),
			"XML output with first ordering")

		var map = helpersTool.preprocessMapping(_, mappings.reverse(), true);
		strictEqual(JSON.stringify(map), JSON.stringify({
				"": {
					"toXML": 2,
					"depth": 1
				},
				"ux": ["00A.00Bx"],
				"u9": ["00A.01B9"],
				"u8": ["00A.02B8"],
				"u7": ["00A.03B7"],
				"u6": ["00A.04B6"],
				"u5": ["00A.05B5"],
				"u4": ["00A.06B4"],
				"u3": ["00A.07B3"],
				"u2": ["00A.08B2"],
				"u1": ["00A.09B1"],
				"u0": ["00A.10B0"]
			}),
			"11 mappings reverted")
		var converted = helpersTool.convert(json, map)
		strictEqual(JSON.stringify(converted), JSON.stringify({
				"A": {
					"B7": 7,
					"B3": 3,
					"B2": 2,
					"B1": 1
				}
			}),
			"XML output with reverted ordering")
		var mappings = [{
			xml: "A.B0",
			json: "u0",
		}, {
			xml: "A.B6",
			json: "u6",
		}, {
			xml: "A.B3",
			json: "u3",
		}, {
			xml: "A.B7",
			json: "u7",
		}, {
			xml: "A.B8",
			json: "u8",
		}, {
			xml: "A.B1",
			json: "u1",
		}, {
			xml: "A.B4",
			json: "u4",
		}, {
			xml: "A.B5",
			json: "u5",
		}, {
			xml: "A.B2",
			json: "u2",
		}, {
			xml: "A.Bx",
			json: "ux",
		}, {
			xml: "A.B9",
			json: "u9",
		}]
		var map = helpersTool.preprocessMapping(_, mappings, true);
		strictEqual(JSON.stringify(map), JSON.stringify({
				"": {
					"toXML": 2,
					"depth": 1
				},
				"u0": ["00A.00B0"],
				"u6": ["00A.01B6"],
				"u3": ["00A.02B3"],
				"u7": ["00A.03B7"],
				"u8": ["00A.04B8"],
				"u1": ["00A.05B1"],
				"u4": ["00A.06B4"],
				"u5": ["00A.07B5"],
				"u2": ["00A.08B2"],
				"ux": ["00A.09Bx"],
				"u9": ["00A.10B9"]
			}),
			"11 mappings different ordering")
		console.log("LKLKLKL", JSON.stringify(map))
		var converted = helpersTool.convert(json, map)
		strictEqual(JSON.stringify(converted), JSON.stringify({
				"A": {
					"B3": 3,
					"B7": 7,
					"B1": 1,
					"B2": 2
				}
			}),
			"XML output with different ordering")

		var mappings = [{
			json: "ETCC_EBPD.CENTCOD",
			xml: "Facturae.Parties.BuyerParty.AdministrativeCentres.AdmiknistrativeCentre[0..n].CentreCode"
		}]
		var map = helpersTool.preprocessMapping(_, mappings, true);
		var jsonxml = helpersTool.convert({
			ETCC_EBPD: [{
				CENTCOD: "COD1"
			}, {
				CENTCOD: "COD2"
			}, {
				CENTCOD: "COD2"
			}]
		}, map);
		strictEqual(jsxml.stringify(jsonxml, {
			indent: '\t'
		}), "<Facturae>\n\t<Parties>\n\t\t<BuyerParty>\n\t\t\t<AdministrativeCentres>\n\t\t\t\t<AdmiknistrativeCentre>\n\t\t\t\t\t<CentreCode>COD1</CentreCode>\n\t\t\t\t</AdmiknistrativeCentre>\n\t\t\t\t<AdmiknistrativeCentre>\n\t\t\t\t\t<CentreCode>COD2</CentreCode>\n\t\t\t\t</AdmiknistrativeCentre>\n\t\t\t\t<AdmiknistrativeCentre>\n\t\t\t\t\t<CentreCode>COD2</CentreCode>\n\t\t\t\t</AdmiknistrativeCentre>\n\t\t\t</AdministrativeCentres>\n\t\t</BuyerParty>\n\t</Parties>\n</Facturae>", "Test example 1");
		console.log("XXXXXXXXXXXXXXXX", jsxml.stringify(jsonxml, {
			indent: '\t'
		}));
		var mappings = [{
			xml: "Facturae.Parties.BuyerParty.LegalEntity.CorporateName",
			json: "BPCORDNAM",
			condition: 'PERSONTYPBU eq "J"'
		}];
		var map = helpersTool.preprocessMapping(_, mappings, true);
		var jsonxml = helpersTool.convert({
			BPCORDNAM: "toto",
			PERSONTYPBU: "J"
		}, map);
		strictEqual(jsxml.stringify(jsonxml, {
			indent: '\t'
		}), "<Facturae>\n\t<Parties>\n\t\t<BuyerParty>\n\t\t\t<LegalEntity>\n\t\t\t\t<CorporateName>toto</CorporateName>\n\t\t\t</LegalEntity>\n\t\t</BuyerParty>\n\t</Parties>\n</Facturae>", "Test example 2");
		console.log("XXXXXXXXXXXXXXXX", jsxml.stringify(jsonxml, {
			indent: '\t'
		}));


	})

	it('init test environment ', function(_) {
		endpoint = testAdmin.modifyCollaborationEndpoint(dbName);
		db = dataModel.getOrm(_, _getModel(), endpoint.datasets[dbName]);
		EdiEntity.dropAllEdiCacheEntity(_, {
			db: db
		});
		EdiProcess.removeAllEdiProcess(_, {
			db: db
		});
	});
	it('parser fixed size ', function(_) {

		var fileBuff = {};
		fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFAC", 'utf-8', _).replace(/\r\n/g, "\n");;

		var seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
		var prototype = JSON.parse(fs.readFile(_defDataDir + "context/BadProto.json", 'utf-8', _));


		var configParser = createContextParser(seqFile, sqMap);

		var res = parser.mapParse["fixedLength"](_, {
			input: fileBuff,
			configParser: configParser,
			prototype: prototype
		});

		strictEqual(JSON.stringify(res), "{}", "generate instance json from LINFAC (with not all field  value), good seqFile and bad prototype");

		fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFAC1", 'utf-8', _).replace(/\r\n/g, "\n");;

		seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
		prototype = JSON.parse(fs.readFile(_defDataDir + "context/BadProto.json", 'utf-8', _));

		res = parser.mapParse["fixedLength"](_, {
			input: sortInput(fileBuff, configParser),
			configParser: configParser,
			prototype: prototype
		});
		strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","SIVTYP":"FAC","ACCDAT":"2014-02-24"}}', "generate instance json from LINFAC (with not all field  value) and CABFAC, good seqFile and bad prototype");
		seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
		prototype = JSON.parse(fs.readFile(_defDataDir + "context/fakePrototype.json", 'utf-8', _));

		res = parser.mapParse["fixedLength"](_, {
			input: sortInput(fileBuff, configParser),
			configParser: configParser,
			prototype: prototype
		});
		strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24","ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}]}}', "generate instance json from LINFAC (with not all field  value) and CABFAC, good seqFile and good prototype (not describe all properties)");
		prototype = JSON.parse(fs.readFile(_defDataDir + "context/fullPrototype.json", 'utf-8', _));

		res = parser.mapParse["fixedLength"](_, {
			input: sortInput(fileBuff, configParser),
			configParser: configParser,
			prototype: prototype
		});

		strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24","ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}]}}', "generate instance json from LINFAC (with not all field  value) and CABFAC, good seqFile and full prototype");

		fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFACIncomplete.txt", 'utf-8', _).replace(/\r\n/g, "\n");;

		res = parser.mapParse["fixedLength"](_, {
			input: sortInput(fileBuff, configParser),
			configParser: configParser,
			prototype: prototype
		});

		strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}]}}', "generate instance json from LINFAC  and CABFAC (incomplete), good seqFile and good prototype");


		fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACIncomplete.txt", 'utf-8', _).replace(/\r\n/g, "\n");;

		res = parser.mapParse["fixedLength"](_, {
			input: sortInput(fileBuff, configParser),
			configParser: configParser,
			prototype: prototype
		});

		strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000}]}}', "generate instance json from LINFAC (with not all field  value) and CABFAC (incomplete), good seqFile and good prototype");

		fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACIncomplete2.txt", 'utf-8', _).replace(/\r\n/g, "\n");;

		res = parser.mapParse["fixedLength"](_, {
			input: sortInput(fileBuff, configParser),
			configParser: configParser,
			prototype: prototype
		});
		strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000}]}}', "generate instance json from LINFAC (with not all field value version 2) and CABFAC (incomplete), good seqFile and good prototype");

		prototype = JSON.parse(fs.readFile(_defDataDir + "context/fakePrototype.json", 'utf-8', _));

		res = parser.mapParse["fixedLength"](_, {
			input: sortInput(fileBuff, configParser),
			configParser: configParser,
			prototype: prototype
		});

		strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","QTY":2,"GROPRI":1000000}]}}', "generate instance json from LINFAC (with not all field  value) and CABFAC (incomplete), good seqFile and good prototype");

		res = parser.mapParse["fixedLength"](_, {
			input: sortInput(fileBuff, configParser),
			configParser: configParser,
			prototype: prototype
		});

		strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","QTY":2,"GROPRI":1000000}]}}', "add to an existent instance json from LINFAC (with not all field  value) and CABFAC (incomplete), good seqFile and good prototype ");


		// test array of object or array
		fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACSCOL.txt", 'utf-8', _).replace(/\r\n/g, "\n");;
		seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIHArray.json", 'utf-8', _));
		var mmFile = JSON.parse(fs.readFile(_defDataDir + "context/messageMappingSOHREal_sep_field.json", 'utf-8', _));

		prototype = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1SCOL_$details.json", 'utf-8', _));

		var configParser = createContextParser(seqFile, sqMap);
		res = parser.mapParse["fixedLength"](_, {
			input: sortInput(fileBuff, configParser),
			configParser: configParser,
			prototype: prototype
		});

		strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000,"SCOL":[{"TEST":"VALT"}]},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000,"SCOL":[{"TEST":"VALY"}]}]}}', " parse object of array of object or array ok");

		fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFACMultiple.txt", 'utf-8', _);
		fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACMultiple.txt", 'utf-8', _);
		res = parser.mapParse["fixedLength"](_, {
			input: sortInput(fileBuff, configParser),
			configParser: configParser,
			prototype: prototype
		});


		strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24","ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}]},"FCC11014VEN00000012":{"NUM":"FCC11014VEN00000012","BPR":"ESP0002","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24","ESIH1SID":[{"NUM":"FCC11014VEN00000012","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000},{"NUM":"FCC11014VEN00000012","SIDLIN":1000,"ITMREF":"CDROM2","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM2","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}]}}', " parse multiple object in 1 header file and 1 body file");

		fileBuff["CABFAC1"] = fs.readFile(_defDataDir + "ediFiles/CABFACMultiple1.txt", 'utf-8', _).replace(/\r\n/g, "\n");;
		fileBuff["CABFAC2"] = fs.readFile(_defDataDir + "ediFiles/CABFACMultiple2.txt", 'utf-8', _).replace(/\r\n/g, "\n");;

		fileBuff["LINFAC1"] = fs.readFile(_defDataDir + "ediFiles/LINFACMultiple1.txt", 'utf-8', _).replace(/\r\n/g, "\n");;
		fileBuff["LINFAC32"] = fs.readFile(_defDataDir + "ediFiles/LINFACMultiple2.txt", 'utf-8', _).replace(/\r\n/g, "\n");;
		res = parser.mapParse["fixedLength"](_, {
			input: sortInput(fileBuff, configParser),
			configParser: configParser,
			prototype: prototype
		});

		strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24","ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}]},"FCC11014VEN00000012":{"NUM":"FCC11014VEN00000012","BPR":"ESP0002","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24","ESIH1SID":[{"NUM":"FCC11014VEN00000012","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000},{"NUM":"FCC11014VEN00000012","SIDLIN":1000,"ITMREF":"CDROM2","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM2","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}]}}', " parse multiple object in multiple header file and multiple line file");

		var mmFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSORDERFlagFixedLength.json", 'utf-8', _));
		var prototype = JSON.parse(fs.readFile(_defDataDir + "context/protoSORDERTenor.json", 'utf-8', _));

		var configParser = createContextParser(mmFile, sqMap);
		var fileBuff = {};
		fileBuff["SORDERTENOR.edi"] = fs.readFile(_defDataDir + "ediFiles/SORDERTERNOR.edi", 'utf-8', _).replace(/\r\n/g, "\n");;
		res = parser.mapParse["fixedLength"](_, {
			input: fileBuff,
			configParser: configParser,
			prototype: prototype
		});

		strictEqual(JSON.stringify(res), '{"":{"BLANK":"250","CUSORDREF":"00243060","EDISOHTYP":"0","EDIFUNCTION":"9","CUR":"EU","EDIDLVDAT":"R2015040","EDIDLVTIME":"7","EDIBPCCOD":"3020400233805","EXCEDICOD":"3011005400105","EDIBPCINV":"3020400233805","SOHR_NOTES":[{"TXTID":"GEN","TEXT":"ATTENTION : IL EST IMPERATIF DE RESPECTER L\'HORAIRE DE LIVRAISON. TOUT MANQUANT OU RETARD OCCASIONNERONT DES PENALITES."}],"SOHR_SOP":[{"EANCOD":"9999999999999","EDISAU":"PCE","DEMDLVDATLIN":"2015-04-25"},{"EANCOD":"9999999999999","EDISAU":"PCE","DEMDLVDATLIN":"2015-04-25"}],"SOHSOP":[{"ITMDES":"CARGO TABLE GRIS ORAGE","QTY":2},{"ITMDES":"CARGO TABLE PIMENT","QTY":1}]}}', " parse fixed length file with flag for line");
	});
	it('serialized fixed size ', function(_) {


		var json = {
			"ESIH1SID": [{
				"NUM": "FCC11014VEN00000014",
				"SIDLIN": 1000,
				"ITMREF": "CDROM",
				"ITMDES": "CD-ROM 16X",
				"SAU": "Un",
				"QTY": 3,
				"GROPRI": 1000000,
				"NETPRI": 1000000,
				"AMTLIN": 30000
			}, {
				"NUM": "FCC11014VEN00000014",
				"SIDLIN": 2000,
				"ITMREF": "CDROM1",
				"ITMDES": "CD-ROM1 16X",
				"SAU": "Un",
				"QTY": 2,
				"GROPRI": 1000000,
				"NETPRI": 1000000,
				"AMTLIN": 20000
			}],
			"NUM": "FCC11014VEN00000014",
			"BPR": "ESP0001",
			"CPY": "110",
			"FCY": "C110",
			"BPAPAY": "A01",
			"CUR": "EUR",
			"PTE": "CHEQ100COMPTANT",
			"AMTATI": 75880,
			"AMTNOT": 66000,
			"SIVTYP": "FAC",
			"ACCDAT": "2014-02-24"
		};
		var seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
		var configParser = createContextSerializer(seqFile, sqMap, {
			C: "CABFAC",
			L: "LINFAC"
		});

		var fileBuff = {};
		var prototype = JSON.parse(fs.readFile(_defDataDir + "context/fullPrototype.json", 'utf-8', _));

		fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFAC", 'utf-8', _).replace(/\r\n/g, "\n").replace(/\r\n/g, "\n");;

		fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFAC", 'utf-8', _).replace(/\r\n/g, "\n").replace(/\r\n/g, "\n");;

		var res = serializer.mapSerialize["fixedLength"](_, {
			json: json,
			configSerializer: configParser,
			prototype: prototype
		});
		strictEqual(res !== null, true, "with correct json and good proto,  generate string for files ok ");

		strictEqual(res["CABFAC"], fileBuff["CABFAC"], "with correct json and good proto,  generate cabfac ok") // space at the end are remove automatically on certains IDE;
		strictEqual(res["LINFAC"], fileBuff["LINFAC"], "with correct json and good proto,  generate cabfac ok") // space at the end are remove automatically on certains IDE;


		var json = {
			"ESIH1SID": [{
				"NUM": "FCC11014VEN00000014",
				"SIDLIN": 1000,
				"ITMREF": "CDROM",
				"ITMDES": "CD-ROM 16X",
				"SAU": "Un",
				"QTY": 3,
				"GROPRI": 1000000,
				"NETPRI": 1000000,
				"AMTLIN": 30000
			}, {
				"NUM": "FCC11014VEN00000014",
				"SIDLIN": 2000,
				"ITMREF": "CDROM1",
				"ITMDES": "CD-ROM1 16X",
				"SAU": "Un",
				"QTY": 2,
				"GROPRI": 1000000,
				"NETPRI": 1000000,
				"AMTLIN": 20000
			}, {
				"NUM": "",
				"SIDLIN": "",
				"ITMREF": "",
				"ITMDES": "",
				"SAU": "",
				"QTY": "",
				"GROPRI": "",
				"NETPRI": "",
				"AMTLIN": ""
			}],
			"NUM": "FCC11014VEN00000014",
			"BPR": "ESP0001",
			"CPY": "110",
			"FCY": "C110",
			"BPAPAY": "A01",
			"CUR": "EUR",
			"PTE": "CHEQ100COMPTANT",
			"AMTATI": 75880,
			"AMTNOT": 66000,
			"SIVTYP": "FAC",
			"ACCDAT": "2014-02-24"
		};
		var res = serializer.mapSerialize["fixedLength"](_, {
			json: json,
			configSerializer: configParser,
			prototype: prototype
		});
		strictEqual(res !== null, true, "with correct json and good proto,  generate string for files ok with empty line ");

		strictEqual(res["CABFAC"], fileBuff["CABFAC"], "with correct json and good proto,  generate cabfac ok with empty line ") // space at the end are remove automatically on certains IDE;


		strictEqual(res["LINFAC"], fileBuff["LINFAC"], "with correct json and good proto,  generate linfac ok with empty line ") // space at the end are remove;

		var json = {
			"ESIH1SID": [{
				"NUM": "FCC11014VEN00000014",
				"SIDLIN": 1000,
				"ITMREF": "CDROM",
				"ITMDES": "CD-ROM 16X",
				"SAU": "Un",
				"QTY": 3,
				"GROPRI": 1000000,
				"NETPRI": 1000000,
				"AMTLIN": 30000,
				"SCOL": [{
					"TEST": "VALT"
				}]
			}, {
				"NUM": "FCC11014VEN00000014",
				"SIDLIN": 2000,
				"ITMREF": "CDROM1",
				"ITMDES": "CD-ROM1 16X",
				"SAU": "Un",
				"QTY": 2,
				"GROPRI": 1000000,
				"NETPRI": 1000000,
				"AMTLIN": 20000,
				"SCOL": [{
					"TEST": "VALY"
				}]
			}],
			"NUM": "FCC11014VEN00000014",
			"BPR": "ESP0001",
			"CPY": "110",
			"FCY": "C110",
			"BPAPAY": "A01",
			"CUR": "EUR",
			"PTE": "CHEQ100COMPTANT",
			"AMTATI": 75880,
			"AMTNOT": 66000,
			"SIVTYP": "FAC",
			"ACCDAT": "2014-02-24"
		};
		var prototype = JSON.parse(fs.readFile(_defDataDir + "context/BadProto.json", 'utf-8', _));
		try {
			var res = serializer.mapSerialize["fixedLength"](_, {
				json: json,
				configSerializer: configParser,
				prototype: prototype
			});
			ok(false, "ERROR CASE : can't serialize , some properties doesn't match prototype ");
		} catch (e) {
			ok(true, "ERROR CASE : can't serialize , some properties doesn't match prototype  mess:" + e.message);

		}
		prototype = JSON.parse(fs.readFile(_defDataDir + "context/fullPrototype.json", 'utf-8', _));
		json.NONEXISTPROP = "test";
		var res = serializer.mapSerialize["fixedLength"](_, {
			json: json,
			configSerializer: configParser,
			prototype: prototype
		});
		strictEqual(res !== null, true, "with correct json and good proto,  generate string for files ok ");

		strictEqual(res["CABFAC"], fileBuff["CABFAC"], "with non exists property json and good proto,  generate cabfac ok") // space at the end are remove automatically on certains IDE;
		strictEqual(res["LINFAC"], fileBuff["LINFAC"], "with non exists property json and good proto,  generate cabfac ok") // space at the end are remove automatically on certains IDE;


		fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACSCOL.txt", 'utf-8', _).replace(/\r\n/g, "\n");;
		seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIHArray.json", 'utf-8', _));
		prototype = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1SCOL_$details.json", 'utf-8', _));

		var configParser = createContextSerializer(seqFile, sqMap, {
			C: "CABFAC",
			L: "LINFAC"
		});
		var res = serializer.mapSerialize["fixedLength"](_, {
			json: json,
			configSerializer: configParser,
			prototype: prototype
		});

		console.log("LINFAC  '" + res["LINFAC"] + "'");
		strictEqual(res["CABFAC"], fileBuff["CABFAC"], "with CABFAC object or array of object of array ok") // space at the end are remove automatically on certains IDE;
		strictEqual(res["LINFAC"], fileBuff["LINFAC"], "with LINFAC object or array of object of array ok") // space at the end are remove automatically on certains IDE;

	});
	it('serialize import file ', function(_) {

		var json = JSON.parse(fs.readFile(_defDataDir + "context/jsonImport.json", 'utf-8', _));


		var messageMapping = JSON.parse(fs.readFile(_defDataDir + "context/messageMappingSOH.json", 'utf-8', _));

		var configParser = createContextSerializer(messageMapping, mmMap, {}, true);

		var prototype = JSON.parse(fs.readFile(_defDataDir + "context/fullPrototypeImport.json", 'utf-8', _));
		var res = serializer.mapSerialize["delimited"](_, {
			json: json,
			configSerializer: configParser,
			prototype: prototype
		});

		var result = '"ASN","CDE-2010-0491","LS","20100921","","ASN","EUR",""\n' +
			'"CD100","Camion semi remorque rouge","Un","300000"\n' +
			'"ARTICLE2","Dsignation article 2","Un",""\n' +
			'"ARTICLE2","Dsignation article 2","Un",""\n' +
			'"ARTICLE4","ARTICLE4","Un",""\n';


		strictEqual(res[configParser.fileName], result, "serialize SOH in delimited file ok");

		res = serializer.mapSerialize["sepField"](_, {
			json: json,
			configSerializer: configParser,
			prototype: prototype
		});
		result = "ASN,CDE-2010-0491,LS,20100921,ASN,EUR,CD100,Camion semi remorque rouge,Un,300000ARTICLE2,Dsignation article 2,Un,ARTICLE2,Dsignation article 2,Un,ARTICLE4,ARTICLE4,Un,";

		strictEqual(res[configParser.fileName], result, " serialize SOH with sepField ok ");

		res = serializer.mapSerialize["sepRecord"](_, {
			json: json,
			configSerializer: configParser,
			prototype: prototype
		});
		result = "ASN,CDE-2010-0491,LS,20100921,ASN,EUR\nCD100,Camion semi remorque rouge,Un,300000\nARTICLE2,Dsignation article 2,Un,\nARTICLE2,Dsignation article 2,Un,\nARTICLE4,ARTICLE4,Un,\n";

		strictEqual(res[configParser.fileName], result, " serialize SOH with sepRecord ok ");


	});

	it('parser', function(_) {
		_initPrototypeCache(_, db);
		// store in mongodb all needed to perform the test
		var seqFileJson = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));

		var configParser = createContextParser(seqFileJson, sqMap);
		var fileBuff = {};
		fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFAC", 'utf-8', _).replace(/\r\n/g, "\n");;
		fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFAC", 'utf-8', _).replace(/\r\n/g, "\n");;
		var jsonSIH = {
			"NUM": "FCC11014VEN00000014",
			"BPR": "ESP0001",
			"CPY": "110",
			"FCY": "C110",
			"BPAPAY": "A01",
			"CUR": "EUR",
			"PTE": "CHEQ100COMPTANT",
			"AMTATI": 75880,
			"AMTNOT": 66000,
			"SIVTYP": "FAC",
			"ACCDAT": "2014-02-24",
			"ESIH1SID": [{
				"NUM": "FCC11014VEN00000014",
				"SIDLIN": 1000,
				"ITMREF": "CDROM",
				"ITMDES": "CD-ROM 16X",
				"SAU": "Un",
				"QTY": 3,
				"GROPRI": 1000000,
				"NETPRI": 1000000,
				"AMTLIN": 30000
			}, {
				"NUM": "FCC11014VEN00000014",
				"SIDLIN": 2000,
				"ITMREF": "CDROM1",
				"ITMDES": "CD-ROM1 16X",
				"SAU": "Un",
				"QTY": 2,
				"GROPRI": 1000000,
				"NETPRI": 1000000,
				"AMTLIN": 20000
			}]
		};
		var protocolJson = JSON.parse(fs.readFile(_defDataDir + "context/protocol.json", 'utf-8', _));



		var res = parser.parse(_, {
			configParser: configParser,
			prototype: prototype_EDISIH1,
			input: fileBuff,
			db: db
		});
		strictEqual(JSON.stringify(res.FCC11014VEN00000014), JSON.stringify(jsonSIH), "parse ok ");

		var seqFileJsonReal = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIHReal.json", 'utf-8', _)); // for some reasons the collection name in prototype is not the same as we have in the decribe we manage both case.

		var configParser = createContextParser(seqFileJsonReal, sqMap);



		res = parser.parse(_, {
			configParser: configParser,
			prototype: prototype_EDISIH1,
			input: fileBuff,
			db: db
		});
		var jsonSIH = {
			"NUM": "FCC11014VEN00000014",
			"BPR": "ESP0001",
			"CPY": "110",
			"FCY": "C110",
			"BPAPAY": "A01",
			"CUR": "EUR",
			"PTE": "CHEQ100COMPTANT",
			"AMTATI": 75880,
			"AMTNOT": 66000,
			"SIVTYP": "FAC",
			"ACCDAT": "2014-02-24"
		};
		strictEqual(JSON.stringify(res.FCC11014VEN00000014), JSON.stringify(jsonSIH), "parse with seqFile that describe collection that not correspond to the prototype ok ");


	});

	it(' serialize edi file', function(_) {
		_initPrototypeCache(_, db);
		// store in mongodb all needed to perform the test
		var seqFileJson = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));

		var configParser = createContextSerializer(seqFileJson, sqMap, {
			C: "CABFAC",
			L: "LINFAC"
		}, false);
		var protocolJson = JSON.parse(fs.readFile(_defDataDir + "context/protocol.json", 'utf-8', _));
		var fileBuff = {};
		fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFAC", 'utf-8', _).replace(/\r\n/g, "\n");;
		fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFAC", 'utf-8', _).replace(/\r\n/g, "\n");;

		var jsonSIH = {
			"NUM": "FCC11014VEN00000014",
			"BPR": "ESP0001",
			"CPY": "110",
			"FCY": "C110",
			"BPAPAY": "A01",
			"CUR": "EUR",
			"PTE": "CHEQ100COMPTANT",
			"AMTATI": 75880,
			"AMTNOT": 66000,
			"SIVTYP": "FAC",
			"ACCDAT": "2014-02-24",
			"ESIH1SID": [{
				"NUM": "FCC11014VEN00000014",
				"SIDLIN": 1000,
				"ITMREF": "CDROM",
				"ITMDES": "CD-ROM 16X",
				"SAU": "Un",
				"QTY": 3,
				"GROPRI": 1000000,
				"NETPRI": 1000000,
				"AMTLIN": 30000
			}, {
				"NUM": "FCC11014VEN00000014",
				"SIDLIN": 2000,
				"ITMREF": "CDROM1",
				"ITMDES": "CD-ROM1 16X",
				"SAU": "Un",
				"QTY": 2,
				"GROPRI": 1000000,
				"NETPRI": 1000000,
				"AMTLIN": 20000
			}]
		};


		var res = serializer.serialize(_, {
			configSerializer: configParser,
			prototype: prototype_EDISIH1,
			json: jsonSIH,
			action: "edi",
			db: db
		});

		strictEqual(Object.keys(res).length, 2, "number of file ok");
		strictEqual(res["CABFAC"], fileBuff["CABFAC"], "cabfac ok ");
		strictEqual(res["LINFAC"], fileBuff["LINFAC"], "linfac ok ");



		try {
			var res = serializer.serialize(_, {
				configSerializer: configParser,
				json: jsonSIH,
				action: "edi",
				db: db
			});
			ok(false, "ERROR CASE : serialize on a non exists representation");

		} catch (e) {
			ok(true, "ERROR CASE : serialize on a non exists representation mess:" + e.stack);
		}




	});

	it(' serialize import files', function(_) {
		_initPrototypeCache(_, db);

		// store in mongodb all needed to perform the test
		var messageMappingJson = JSON.parse(fs.readFile(_defDataDir + "context/messageMappingSOH.json", 'utf-8', _));

		var configParser = createContextSerializer(messageMappingJson, mmMap, {
			C: "CABFAC",
			L: "LINFAC"
		}, true);
		var protocolJson = JSON.parse(fs.readFile(_defDataDir + "context/protocol.json", 'utf-8', _));
		var fileBuff = fs.readFile(_defDataDir + "context/importSOH.csv", 'utf-8', _).replace(/\r\n/g, "\n");;

		var jsonSOH = JSON.parse(fs.readFile(_defDataDir + "context/jsonImport.json", 'utf-8', _));


		var res = serializer.serialize(_, {
			configSerializer: configParser,
			json: jsonSOH,
			prototype: prototype_EDIS0H2,
			action: "import",
			db: db
		});
		strictEqual(res !== null, true, "serialization ok ");

		strictEqual(res[Object.keys(res)[0]], fileBuff, "import file content ok");


		try {
			var res = serializer.serialize(_, {
				configSerializer: configParser,
				json: jsonSOH,
				action: "import",
				db: db
			});
			ok(false, "ERROR CASE : serialize on a non exists representation");

		} catch (e) {
			ok(true, "ERROR CASE : serialize on a non exists representation mess:" + e.message);
		}

	});

	it('parse xml file', function(_) {

		// store in mongodb all needed to perform the test
		var xmlFile = JSON.parse(fs.readFile(_defDataDir + "context/xmlFileTest1.json", 'utf-8', _));
		var input = {
			"FACTURAE.xml": fs.readFile(_defDataDir + "ediFiles/xmltest.xml", 'utf-8', _)
		};
		var option = EdiProcess.createContextParserXmlFile(_, {
			xmlFile: xmlFile
		})


		// parse
		var res = parser.parse(_, {
			configParser: option.configParser,
			input: input,
			prototype: prototype_EDISIH1FACTURA,
			db: db
		});

		strictEqual(JSON.stringify(res[Object.keys(res)[0]]), '{"item":[{"price":"123.45"}],"personne":"str1234","orderId":"str1234"}', "generation sample json ok");

		var option = EdiProcess.createContextSerializerXmlFile(_, {
			xmlFile: xmlFile,
			fileNames: "FACTURAE.xml"

		});

		// serialize
		var res = serializer.serialize(_, {
			configSerializer: option.configSerializer,
			json: res[Object.keys(res)[0]],
			prototype: prototype_EDISIH1FACTURA,
			db: db
		});

		strictEqual(res && res["FACTURAE.xml"], '<shiporder orderid="str1234">\n\t<item>\n\t\t<price>123.45</price>\n\t</item>\n\t<orderperson>str1234</orderperson>\n</shiporder>', " xml generated ok");

		var xmlFile = JSON.parse(fs.readFile(_defDataDir + "context/xmlFileTest2.json", 'utf-8', _));

		var option = EdiProcess.createContextParserXmlFile(_, {
			xmlFile: xmlFile
		})

		// parse
		var res = parser.parse(_, {
			configParser: option.configParser,
			input: input,
			prototype: prototype_EDISIH1FACTURA,
			db: db
		});
		strictEqual(JSON.stringify(res[Object.keys(res)[0]]), '{"item":[{"price":"123.45","quantity":"745","note":"str1234","title":"str1234"}],"personne":"str1234","orderId":"str1234"}', "generation sample json ok");


		var option = EdiProcess.createContextSerializerXmlFile(_, {
			xmlFile: xmlFile,
			fileNames: "FACTURAE.xml"

		});

		// serialize
		var res = serializer.serialize(_, {
			configSerializer: option.configSerializer,
			json: res[Object.keys(res)[0]],
			prototype: prototype_EDISIH1FACTURA,
			db: db
		});

		strictEqual(res && res["FACTURAE.xml"], '<shiporder orderid="str1234">\n\t<item>\n\t\t<price>123.45</price>\n\t\t<quantity>745</quantity>\n\t\t<title>str1234</title>\n\t\t<note>str1234</note>\n\t</item>\n\t<orderperson>str1234</orderperson>\n</shiporder>', " xml generated ok");

		var input = {
			"FACTURAE.xml": fs.readFile(_defDataDir + "ediFiles/xmltest2.xml", 'utf-8', _)
		};


		var xmlFile = JSON.parse(fs.readFile(_defDataDir + "context/xmlFileTest2.json", 'utf-8', _));

		var option = EdiProcess.createContextParserXmlFile(_, {
			xmlFile: xmlFile
		})

		// parse
		var res = parser.parse(_, {
			configParser: option.configParser,
			input: input,
			prototype: prototype_EDISIH1FACTURA,
			db: db
		});

		strictEqual(JSON.stringify(res[Object.keys(res)[0]]), '{"item":[{"price":"123.45","quantity":"745","note":"str1234","title":"str1234"},{"price":"123.46","quantity":"746","note":"str1235","title":"str1235"},{"price":"123.47","quantity":"748","note":"str1237","title":"str1237"},{"price":"123.48","quantity":"748","note":"str1238","title":"str1238"}],"personne":"str1234","orderId":"str1234"}', "generation sample json ok");


		var option = EdiProcess.createContextSerializerXmlFile(_, {
			xmlFile: xmlFile,
			fileNames: "FACTURAE.xml"

		});

		// serialize
		var res = serializer.serialize(_, {
			configSerializer: option.configSerializer,
			json: res[Object.keys(res)[0]],
			prototype: prototype_EDISIH1FACTURA,
			db: db
		});

		strictEqual(res && res["FACTURAE.xml"], '<shiporder orderid="str1234">\n\t<item>\n\t\t<price>123.45</price>\n\t\t<quantity>745</quantity>\n\t\t<title>str1234</title>\n\t\t<note>str1234</note>\n\t</item>\n\t<item>\n\t\t<price>123.46</price>\n\t\t<quantity>746</quantity>\n\t\t<title>str1235</title>\n\t\t<note>str1235</note>\n\t</item>\n\t<item>\n\t\t<price>123.47</price>\n\t\t<quantity>748</quantity>\n\t\t<title>str1237</title>\n\t\t<note>str1237</note>\n\t</item>\n\t<item>\n\t\t<price>123.48</price>\n\t\t<quantity>748</quantity>\n\t\t<title>str1238</title>\n\t\t<note>str1238</note>\n\t</item>\n\t<orderperson>str1234</orderperson>\n</shiporder>', " xml generated ok");

		var input = {
			"FACTURAE.xml": fs.readFile(_defDataDir + "ediFiles/xmltest3.xml", 'utf-8', _)
		};
		var option = EdiProcess.createContextParserXmlFile(_, {
			xmlFile: xmlFile
		})


		// parse
		var res = parser.parse(_, {
			configParser: option.configParser,
			input: input,
			prototype: prototype_EDISIH1FACTURA,
			db: db
		});

		strictEqual(JSON.stringify(res[Object.keys(res)[0]]), '{"item":[{"price":"123.45","quantity":"745","note":"str1234","title":"str1234"},{"price":"123.46","quantity":"746","note":"str1235","title":"str1235"},{"price":"123.47","quantity":"748","note":"str1237","title":"str1237"},{"price":"","quantity":"748","note":"str1238","title":"str1238"}],"personne":"str1234","orderId":"str1234"}', "generation sample json ok");


		var option = EdiProcess.createContextSerializerXmlFile(_, {
			xmlFile: xmlFile,
			fileNames: "FACTURAE.xml"

		});

		// serialize
		var res = serializer.serialize(_, {
			configSerializer: option.configSerializer,
			json: res[Object.keys(res)[0]],
			prototype: prototype_EDISIH1FACTURA,
			db: db
		});

		strictEqual(res && res["FACTURAE.xml"], '<shiporder orderid="str1234">\n\t<item>\n\t\t<price>123.45</price>\n\t\t<quantity>745</quantity>\n\t\t<title>str1234</title>\n\t\t<note>str1234</note>\n\t</item>\n\t<item>\n\t\t<price>123.46</price>\n\t\t<quantity>746</quantity>\n\t\t<title>str1235</title>\n\t\t<note>str1235</note>\n\t</item>\n\t<item>\n\t\t<price>123.47</price>\n\t\t<quantity>748</quantity>\n\t\t<title>str1237</title>\n\t\t<note>str1237</note>\n\t</item>\n\t<item>\n\t\t<price></price>\n\t\t<quantity>748</quantity>\n\t\t<title>str1238</title>\n\t\t<note>str1238</note>\n\t</item>\n\t<orderperson>str1234</orderperson>\n</shiporder>', " xml generated ok");
		console.log("ZXZXZ", '<shiporder orderid="str1234">\n\t<item>\n\t\t<price>123.45</price>\n\t\t<quantity>745</quantity>\n\t\t<title>str1234</title>\n\t\t<note>str1234</note>\n\t</item>\n\t<item>\n\t\t<price>123.46</price>\n\t\t<quantity>746</quantity>\n\t\t<title>str1235</title>\n\t\t<note>str1235</note>\n\t</item>\n\t<item>\n\t\t<price>123.47</price>\n\t\t<quantity>748</quantity>\n\t\t<title>str1237</title>\n\t\t<note>str1237</note>\n\t</item>\n\t<item>\n\t\t<price></price>\n\t\t<quantity>748</quantity>\n\t\t<title>str1238</title>\n\t\t<note>str1238</note>\n\t</item>\n</shiporder>'.replace(/\t/g, "|").replace(/\n/g, "#"))
		console.log("ZXZXy", res && res["FACTURAE.xml"].replace(/\t/g, "|").replace(/\n/g, "#"))
		var input = {
			"FACTURAE.xml": fs.readFile(_defDataDir + "ediFiles/xmltest4.xml", 'utf-8', _)
		};
		var xmlFile = JSON.parse(fs.readFile(_defDataDir + "context/xmlFileTestAllType.json", 'utf-8', _));

		var option = EdiProcess.createContextParserXmlFile(_, {
			xmlFile: xmlFile
		})


		// parse
		var res = parser.parse(_, {
			configParser: option.configParser,
			input: input,
			prototype: prototype_EDISIH1FACTURA,
			db: db
		});

		strictEqual(JSON.stringify(res[Object.keys(res)[0]]), '{"item":[{"price":123.45,"fullDate":"2012-12-13T12:12:12.000Z","date":"2012-12-13T00:00:00.000Z","quantity":745,"note":"str1234","title":"str1234"},{"price":123.45,"fullDate":"2012-12-13T12:12:12.000Z","date":"2012-12-13T00:00:00.000Z","quantity":745,"note":"str1234","title":""}],"personne":"str1234","orderId":"str1234"}', "generation sample json ok");
		var option = EdiProcess.createContextSerializerXmlFile(_, {
			xmlFile: xmlFile,
			fileNames: "FACTURAE.xml"

		});

		// serialize
		var res = serializer.serialize(_, {
			configSerializer: option.configSerializer,
			json: res[Object.keys(res)[0]],
			prototype: prototype_EDISIH1FACTURA,
			db: db
		});

		console.log("res ", res && res["FACTURAE.xml"]);
		strictEqual(res && res["FACTURAE.xml"], '<shiporder orderid="str1234">\n\t<item>\n\t\t<price>123.45</price>\n\t\t<quantity>745</quantity>\n\t\t<title>str1234</title>\n\t\t<note>str1234</note>\n\t\t<date>2012-12-13</date>\n\t\t<fullDate>2012-12-13T12:12:12Z</fullDate>\n\t</item>\n\t<item>\n\t\t<price>123.45</price>\n\t\t<quantity>745</quantity>\n\t\t<title></title>\n\t\t<note>str1234</note>\n\t\t<date>2012-12-13</date>\n\t\t<fullDate>2012-12-13T12:12:12Z</fullDate>\n\t</item>\n\t<orderperson>str1234</orderperson>\n</shiporder>', " xml generated ok");

		// serialized
	});


	it("Test with namespaces", function(_) {
		console.log(1112222)
		var xml = '<W><abc:A xmlns:abc="http://test.test">R</abc:A><B>S</B></W>';
		var jsonxml = jsxml.parse(xml);
		var map = helpersTool.preprocessMapping(_, [{
			xml: "W.A",
			json: "u",
		}, {
			xml: "W.abc:B",
			json: "v"
		}], false, null, null, {
			ignoreNS: true
		});
		console.log(11122223)
		var result = helpersTool.convert(jsonxml, map);
		strictEqual(JSON.stringify(result), '{"v":"S","u":"R"}', "Mapping with ignored namespaces")
	})
	
	it('clean edi entity mongodb', function(_) {
		EdiEntity.dropAllEdiCacheEntity(_, {
			db: db
		});
		EdiProcess.removeAllEdiProcess(_, {
			db: db
		});
	});
});