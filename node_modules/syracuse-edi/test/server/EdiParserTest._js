"use strict";
/* jshint -W079 */
/* jshint unused: false */
/* global QUnit: false, asyncTest: false, test: false, strictEqual: false, ok: false, start: false, stop: false */

/*global QUnit, start, ok*/
var syracuse = require('syracuse-main/lib/syracuse');
var helpers = require('syracuse-core/lib/helpers');
var streams = require("streamline/lib/streams/streams");
var sys = require("util");
var config = require('config'); // must be first syracuse require
var adminHelper = require("syracuse-collaboration/lib/helpers").AdminHelper;
var parser = require("syracuse-edi/lib/tool/parser");
var serializer = require("syracuse-edi/lib/tool/serializer");
var EdiProcess = require("syracuse-edi/lib/ediProcess");
var EdiEntity = require("syracuse-edi/lib/ediEntity");
var EdiType = require("syracuse-edi/lib/enumType").EdiType;
var adminTestFixtures = require("syracuse-collaboration/test/fixtures/adminTestFixtures");
var mongodb = require('streamline-mongodb');
var dataModel = require("syracuse-orm/lib/dataModel");
var registry = require("syracuse-sdata/lib/sdataRegistry");
var fs = require("streamline-fs");
var sqMap = require("syracuse-edi/lib/helpers").seqentialFilePropertyMap;
var mmMap = require("syracuse-edi/lib/helpers").messageMappingPropertyMap;
var SEQFILE_LIB = require('syracuse-edi/lib/enumType').SEQFILE_LIB;
var IMPORTFILE_LIB = require('syracuse-edi/lib/enumType').IMPORTFILE_LIB;
var ediDataFormat = require("syracuse-edi/lib/enumType").EDIDATEFORMAT;

var upath = require('path');
var dbName = "unit_test";
var traces = false;
// activate traces
if (traces) {
	var level = "error";
	var option = {
		name: "edi",
		enabled: true,
		level: level,
		transport: "console",
		mod: {
			name: "parser",
			enabled: true,
			level: level
		}
	};
	adminTestFixtures.setTracesOn("edi.parser", option);

	option.mod.name = "serializer";
	adminTestFixtures.setTracesOn("edi.serializer", option);
}

var globals = require('streamline/lib/globals');
var _defDataDir = upath.join(__dirname, "../server/data/");

function _getModel() {
	return dataModel.make(registry.applications.syracuse.contracts.collaboration, dbName);
}

var endpointTest = {
	dataset: function(_) {
		return "GX3APP";
	},
	getModel: function(_) {
		return {
			getEntity: function(_, nameEntity, facet) {
				return {
					name: nameEntity,
					getPrototype: function(_, name, facet) {
						return JSON.parse(fs.readFile(_defDataDir + "context/" + name + "_" + facet + ".json", 'utf-8', _));
					}
				};
			}
		};
	}
};


function retrieveCommonPrefix(exp1, exp2) {
	var prefix = "";
	for (var i = 0; i < exp1.length && exp2.length && exp1[i] === exp2[i]; i++) {
		prefix += exp1[i];
	}
	return prefix[prefix.length - 1] === "." ? prefix.substring(0, prefix.length - 1) : prefix;
};

function createContextParser(seqFile, sqMap) {
	var mapFilesCode = {};
	var keyByFileCode = {};
	seqFile[sqMap.filesDescription] && seqFile[sqMap.filesDescription].forEach(function(item) {
		mapFilesCode[item[sqMap.filesDescriptions.fileId]] = item[sqMap.filesDescriptions.fileName];

		keyByFileCode[item[sqMap.filesDescriptions.fileName]] = {
			primary: item[sqMap.filesDescriptions.primarykey],
			foreign: item[sqMap.filesDescriptions.foreignkey],
			fatherFileId: item[sqMap.filesDescriptions.fatherFileId]
		};
	});
	var elems = [];
	var prefixExp = {};
	seqFile[sqMap.elem].forEach(function(item, idx, arr) {
		var classInstname = seqFile[sqMap.classInstance] || null;
		var exp = item[sqMap.elems.expression];

		var fileName = mapFilesCode[item[sqMap.elems.fileId]];
		prefixExp[fileName] = prefixExp[fileName] == null ? exp : retrieveCommonPrefix(prefixExp[fileName], exp); // get common path for the file id
		var element = {
			offset: item[sqMap.elems.offset] - 1,
			length: item[sqMap.elems.length],
			expression: exp,
			flag: item[sqMap.elems.flag],
			idLineElem: item[sqMap.elems.idLine],
			isEnd: item[sqMap.elems.isEnd],
			fileName: fileName,
			fileId: item[sqMap.elems.fileId]
		};

		elems.push(element);
	});
	var configParser = {
		parser: SEQFILE_LIB[seqFile[sqMap.fileType]],
		sepDecimal: seqFile[sqMap.decimalSep],
		sepField: seqFile[sqMap.fieldSep],
		sepRecord: "\n", // TODO the one in the context
		delimField: seqFile[sqMap.fieldDelimiter],
		elems: elems,
		linkKey: keyByFileCode, // primary and foreign key for the element
		exppressionPrefix: prefixExp,
		dateFormat: seqFile[sqMap.dateFormat] ? ediDataFormat[seqFile[sqMap.dateFormat]] : null

	};
	return configParser;
}

function createContextSerializer(mm, mapField, mapFilesCode, isImport) {
	// create map between file name and file code

	var serializerMethod;
	if (!isImport) {
		serializerMethod = SEQFILE_LIB[mm[mapField.fileType]];
	} else {
		serializerMethod = IMPORTFILE_LIB[mm[mapField.fileType]];
	}
	var elems = [];
	mm && mm[mapField.elem] && mm[mapField.elem].forEach(function(item, idx, arr) {
		var classInstname = mm[mapField.classInstance];
		var exp = item[mapField.elems.expression];

		elems.push({
			offset: item[mapField.elems.offset] - 1,
			length: item[mapField.elems.length],
			expression: exp, // remove the classe instance if it exists to have the property name that correspond tot he prototype arborescence
			flag: item[mapField.elems.flag],
			isEnd: item[mapField.elems.isEnd],
			fileName: mapFilesCode[item[mapField.elems.fileId]],
			level: item[mapField.elems.level],
			isMandatory: item[mapField.elems.isMandatory] === 2 ? true : false
		});
	});
	var configSerializer = {
		serializer: serializerMethod,
		sepDecimal: mm[mapField.decimalSep],
		sepField: mm[mapField.fieldSep],
		sepRecord: "\n",
		delimField: mm[mapField.fieldDelimiter],
		elems: elems,
		fileName: isImport ? "importTest_" + (new Date().getTime()) + ".csv" : null,
		dateFormat: mm[mapField.dateFormat] ? ediDataFormat[mm[mapField.dateFormat]] : null

	};
	return configSerializer;
}



globals.context = globals.context || {};
globals.context.session = {
	id: helpers.uuid.generate(),
	getUserLogin: function(_) {
		return "admin";
	},
	getUserProfile: function(_) {
		return {
			selectedLocale: function(_) {
				var db = adminHelper.getCollaborationOrm(_);

				// the metamodel is associated to the orm
				var model = db.model;

				var entity = db.model.getEntity(_, "localePreference");
				return db.fetchInstance(_, entity, {
					jsonWhere: {
						code: "en-US"
					}
				});
			},
			user: function(_) {
				// getting the administration ORM
				var db = adminHelper.getCollaborationOrm(_);

				// the metamodel is associated to the orm
				var model = db.model;

				var entity = db.model.getEntity(_, "user");
				// fetchInstance(callback, entity, filter)
				return db.fetchInstance(_, entity, {
					jsonWhere: {
						login: "admin"
					}
				});

			}
		};
	},
	getSecurityProfile: function(_) {
		return null;
	}
};
var doStop = false;
QUnit.module(module.id, {
	setup: function() {},
	teardown: function() {
		if (doStop) {
			setTimeout(function() {
				process.kill(process.pid);
			}, 100);
		}
	}
});
var endpoint, db;
var prototype_EDISIH1;
var prototype_EDISIH1SCOL;
var prototype_EDIS0H2;
var prototype_EDISIH1FACTURA;

function _initPrototypeCache(_, database) {
	EdiEntity.dropAllEdiCacheEntity(_, {
		db: database
	});
	EdiProcess.removeAllEdiProcess(_, {
		db: database
	});
	prototype_EDISIH1 = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1_$details.json", 'utf-8', _));
	prototype_EDISIH1SCOL = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1SCOL_$details.json", 'utf-8', _));
	prototype_EDIS0H2 = JSON.parse(fs.readFile(_defDataDir + "context/EDISOH2_$details.json", 'utf-8', _));
	prototype_EDISIH1FACTURA = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1FACTURA_$details.json", 'utf-8', _));

}

function sortInput(input, opt) {
	var sortInput = {};
	Object.keys(opt.linkKey).forEach(function(filenamePattern) {
		// looking for the right file
		var found = null;
		var regexp = new RegExp(filenamePattern);

		for (var i = 0; i < Object.keys(input).length && !found; i++) {
			found = regexp.test(Object.keys(input)[i]) ? Object.keys(input)[i] : null;
		}
		// add found data
		if (found) {
			sortInput[found] = input[found];
		}
	});
	return sortInput;

}
var uuidJSonSOH;
asyncTest("init test environment ", function(_) {
	endpoint = adminTestFixtures.modifyCollaborationEndpoint(dbName);
	db = dataModel.getOrm(_, _getModel(), endpoint.datasets[dbName]);
	EdiEntity.dropAllEdiCacheEntity(_, {
		db: db
	});
	EdiProcess.removeAllEdiProcess(_, {
		db: db
	});
	start();
});
asyncTest("parser fixed size ", function(_) {

	var fileBuff = {};
	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFAC", 'utf-8', _).replace(/\r\n/g, "\n");;

	var seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
	var prototype = JSON.parse(fs.readFile(_defDataDir + "context/BadProto.json", 'utf-8', _));


	var configParser = createContextParser(seqFile, sqMap);

	var res = parser.mapParse["fixedLength"](fileBuff, configParser, prototype);

	strictEqual(JSON.stringify(res), "{}", "generate instance json from LINFAC (with not all field  value), good seqFile and bad prototype");

	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFAC1", 'utf-8', _).replace(/\r\n/g, "\n");;

	seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/BadProto.json", 'utf-8', _));

	res = parser.mapParse["fixedLength"](sortInput(fileBuff, configParser), configParser, prototype);
	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","SIVTYP":"FAC","ACCDAT":"2014-02-24"}}', "generate instance json from LINFAC (with not all field  value) and CABFAC, good seqFile and bad prototype");
	seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/fakePrototype.json", 'utf-8', _));

	res = parser.mapParse["fixedLength"](sortInput(fileBuff, configParser), configParser, prototype);
	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24","ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}]}}', "generate instance json from LINFAC (with not all field  value) and CABFAC, good seqFile and good prototype (not describe all properties)");
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/fullPrototype.json", 'utf-8', _));

	res = parser.mapParse["fixedLength"](sortInput(fileBuff, configParser), configParser, prototype);

	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24","ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}]}}', "generate instance json from LINFAC (with not all field  value) and CABFAC, good seqFile and full prototype");

	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFACIncomplete.txt", 'utf-8', _).replace(/\r\n/g, "\n");;

	res = parser.mapParse["fixedLength"](sortInput(fileBuff, configParser), configParser, prototype);

	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}]}}', "generate instance json from LINFAC  and CABFAC (incomplete), good seqFile and good prototype");


	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACIncomplete.txt", 'utf-8', _).replace(/\r\n/g, "\n");;

	res = parser.mapParse["fixedLength"](sortInput(fileBuff, configParser), configParser, prototype);

	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000}]}}', "generate instance json from LINFAC (with not all field  value) and CABFAC (incomplete), good seqFile and good prototype");

	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACIncomplete2.txt", 'utf-8', _).replace(/\r\n/g, "\n");;

	res = parser.mapParse["fixedLength"](sortInput(fileBuff, configParser), configParser, prototype);

	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000}]}}', "generate instance json from LINFAC (with not all field value version 2) and CABFAC (incomplete), good seqFile and good prototype");

	prototype = JSON.parse(fs.readFile(_defDataDir + "context/fakePrototype.json", 'utf-8', _));

	res = parser.mapParse["fixedLength"](sortInput(fileBuff, configParser), configParser, prototype);

	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","QTY":2,"GROPRI":1000000}]}}', "generate instance json from LINFAC (with not all field  value) and CABFAC (incomplete), good seqFile and good prototype");

	res = parser.mapParse["fixedLength"](sortInput(fileBuff, configParser), configParser, prototype, res);

	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","QTY":2,"GROPRI":1000000}]}}', "add to an existent instance json from LINFAC (with not all field  value) and CABFAC (incomplete), good seqFile and good prototype ");


	// test array of object or array
	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACSCOL.txt", 'utf-8', _).replace(/\r\n/g, "\n");;
	seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIHArray.json", 'utf-8', _));
	var mmFile = JSON.parse(fs.readFile(_defDataDir + "context/messageMappingSOHREal_sep_field.json", 'utf-8', _));

	prototype = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1SCOL_$details.json", 'utf-8', _));

	var configParser = createContextParser(seqFile, sqMap);
	res = parser.mapParse["fixedLength"](sortInput(fileBuff, configParser), configParser, prototype);

	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000,"SCOL":[{"TEST":"VALT"}]},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000,"SCOL":[{"TEST":"VALY"}]}]}}', " parse object of array of object or array ok");

	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFACMultiple.txt", 'utf-8', _);
	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACMultiple.txt", 'utf-8', _);
	res = parser.mapParse["fixedLength"](sortInput(fileBuff, configParser), configParser, prototype);


	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24","ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}]},"FCC11014VEN00000012":{"NUM":"FCC11014VEN00000012","BPR":"ESP0002","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24","ESIH1SID":[{"NUM":"FCC11014VEN00000012","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000},{"NUM":"FCC11014VEN00000012","SIDLIN":1000,"ITMREF":"CDROM2","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM2","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}]}}', " parse multiple object in 1 header file and 1 body file");

	fileBuff["CABFAC1"] = fs.readFile(_defDataDir + "ediFiles/CABFACMultiple1.txt", 'utf-8', _).replace(/\r\n/g, "\n");;
	fileBuff["CABFAC2"] = fs.readFile(_defDataDir + "ediFiles/CABFACMultiple2.txt", 'utf-8', _).replace(/\r\n/g, "\n");;

	fileBuff["LINFAC1"] = fs.readFile(_defDataDir + "ediFiles/LINFACMultiple1.txt", 'utf-8', _).replace(/\r\n/g, "\n");;
	fileBuff["LINFAC32"] = fs.readFile(_defDataDir + "ediFiles/LINFACMultiple2.txt", 'utf-8', _).replace(/\r\n/g, "\n");;
	res = parser.mapParse["fixedLength"](sortInput(fileBuff, configParser), configParser, prototype);

	strictEqual(JSON.stringify(res), '{"FCC11014VEN00000014":{"NUM":"FCC11014VEN00000014","BPR":"ESP0001","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24","ESIH1SID":[{"NUM":"FCC11014VEN00000014","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000014","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}]},"FCC11014VEN00000012":{"NUM":"FCC11014VEN00000012","BPR":"ESP0002","CPY":"110","FCY":"C110","BPAPAY":"A01","CUR":"EUR","PTE":"CHEQ100COMPTANT","AMTATI":75880,"AMTNOT":66000,"SIVTYP":"FAC","ACCDAT":"2014-02-24","ESIH1SID":[{"NUM":"FCC11014VEN00000012","SIDLIN":1000,"ITMREF":"CDROM","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM1","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000},{"NUM":"FCC11014VEN00000012","SIDLIN":1000,"ITMREF":"CDROM2","ITMDES":"CD-ROM 16X","SAU":"Un","QTY":3,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":30000},{"NUM":"FCC11014VEN00000012","SIDLIN":2000,"ITMREF":"CDROM2","ITMDES":"CD-ROM1 16X","SAU":"Un","QTY":2,"GROPRI":1000000,"NETPRI":1000000,"AMTLIN":20000}]}}', " parse multiple object in multiple header file and multiple line file");

	var mmFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSORDERFlagFixedLength.json", 'utf-8', _));
	var prototype = JSON.parse(fs.readFile(_defDataDir + "context/protoSORDERTenor.json", 'utf-8', _));

	var configParser = createContextParser(mmFile, sqMap);
	var fileBuff = {};
	fileBuff["SORDERTENOR.edi"] = fs.readFile(_defDataDir + "ediFiles/SORDERTERNOR.edi", 'utf-8', _).replace(/\r\n/g, "\n");;
	var res = parser.mapParse["fixedLength"](fileBuff, configParser, prototype);

	strictEqual(JSON.stringify(res), '{"":{"BLANK":"250","SOHR_SOP":[{"EANCOD":"9999999999999","EDISAU":"PCE","DEMDLVDATLIN":"2015-04-25"}],"SOHSOP":[{"ITMDES":"CARGO TABLE PIMENT","QTY":1}]}}', " parse fixed length file with flag for line");
	start();
});
asyncTest("serialized fixed size ", function(_) {


	var json = {
		"ESIH1SID": [{
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 1000,
			"ITMREF": "CDROM",
			"ITMDES": "CD-ROM 16X",
			"SAU": "Un",
			"QTY": 3,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 30000
		}, {
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 2000,
			"ITMREF": "CDROM1",
			"ITMDES": "CD-ROM1 16X",
			"SAU": "Un",
			"QTY": 2,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 20000
		}],
		"NUM": "FCC11014VEN00000014",
		"BPR": "ESP0001",
		"CPY": "110",
		"FCY": "C110",
		"BPAPAY": "A01",
		"CUR": "EUR",
		"PTE": "CHEQ100COMPTANT",
		"AMTATI": 75880,
		"AMTNOT": 66000,
		"SIVTYP": "FAC",
		"ACCDAT": "2014-02-24"
	};
	var seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));
	var configParser = createContextSerializer(seqFile, sqMap, {
		C: "CABFAC",
		L: "LINFAC"
	});

	var fileBuff = {};
	var prototype = JSON.parse(fs.readFile(_defDataDir + "context/fullPrototype.json", 'utf-8', _));

	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFAC", 'utf-8', _).replace(/\r\n/g, "\n").replace(/\r\n/g, "\n");;

	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFAC", 'utf-8', _).replace(/\r\n/g, "\n").replace(/\r\n/g, "\n");;

	var res = serializer.mapSerialize["fixedLength"](json, configParser, prototype);
	strictEqual(res !== null, true, "with correct json and good proto,  generate string for files ok ");

	strictEqual(res["CABFAC"], fileBuff["CABFAC"], "with correct json and good proto,  generate cabfac ok") // space at the end are remove automatically on certains IDE;
	strictEqual(res["LINFAC"], fileBuff["LINFAC"], "with correct json and good proto,  generate cabfac ok") // space at the end are remove automatically on certains IDE;


	/*var json = {
		"ESIH1SID": [{
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 1000,
			"ITMREF": "CDROM",
			"ITMDES": "CD-ROM 16X",
			"SAU": "Un",
			"QTY": 3,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 30000
		}, {
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 2000,
			"ITMREF": "CDROM1",
			"ITMDES": "CD-ROM1 16X",
			"SAU": "Un",
			"QTY": 2,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 20000
		},{
			"NUM": "",
			"SIDLIN": "",
			"ITMREF": "",
			"ITMDES": "",
			"SAU": "",
			"QTY": "",
			"GROPRI": "",
			"NETPRI": "",
			"AMTLIN": ""
		}],
		"NUM": "FCC11014VEN00000014",
		"BPR": "ESP0001",
		"CPY": "110",
		"FCY": "C110",
		"BPAPAY": "A01",
		"CUR": "EUR",
		"PTE": "CHEQ100COMPTANT",
		"AMTATI": 75880,
		"AMTNOT": 66000,
		"SIVTYP": "FAC",
		"ACCDAT": "2014-02-24"
	};
	var res = serializer.mapSerialize["fixedLength"](json, configParser, prototype);
	strictEqual(res !== null, true, "with correct json and good proto,  generate string for files ok with empty line ");

	strictEqual(res["CABFAC"], fileBuff["CABFAC"], "with correct json and good proto,  generate cabfac ok with empty line ") // space at the end are remove automatically on certains IDE;
	console.log("LINFAC '"+res["LINFAC"]+"'" );
	console.log("LINFAC '"+fileBuff["LINFAC"]+"'" );

	strictEqual(res["LINFAC"], fileBuff["LINFAC"], "with correct json and good proto,  generate cabfac ok with empty line ") // space at the end are remove*/

	var json = {
		"ESIH1SID": [{
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 1000,
			"ITMREF": "CDROM",
			"ITMDES": "CD-ROM 16X",
			"SAU": "Un",
			"QTY": 3,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 30000,
			"SCOL": [{
				"TEST": "VALT"
			}]
		}, {
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 2000,
			"ITMREF": "CDROM1",
			"ITMDES": "CD-ROM1 16X",
			"SAU": "Un",
			"QTY": 2,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 20000,
			"SCOL": [{
				"TEST": "VALY"
			}]
		}],
		"NUM": "FCC11014VEN00000014",
		"BPR": "ESP0001",
		"CPY": "110",
		"FCY": "C110",
		"BPAPAY": "A01",
		"CUR": "EUR",
		"PTE": "CHEQ100COMPTANT",
		"AMTATI": 75880,
		"AMTNOT": 66000,
		"SIVTYP": "FAC",
		"ACCDAT": "2014-02-24"
	};
	var prototype = JSON.parse(fs.readFile(_defDataDir + "context/BadProto.json", 'utf-8', _));
	try {
		var res = serializer.mapSerialize["fixedLength"](json, configParser, prototype);
		ok(false, "ERROR CASE : can't serialize , some properties doesn't match prototype ");
	} catch (e) {
		ok(true, "ERROR CASE : can't serialize , some properties doesn't match prototype  mess:" + e.message);

	}
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/fullPrototype.json", 'utf-8', _));
	json.NONEXISTPROP = "test";
	var res = serializer.mapSerialize["fixedLength"](json, configParser, prototype);
	strictEqual(res !== null, true, "with correct json and good proto,  generate string for files ok ");

	strictEqual(res["CABFAC"], fileBuff["CABFAC"], "with non exists property json and good proto,  generate cabfac ok") // space at the end are remove automatically on certains IDE;
	strictEqual(res["LINFAC"], fileBuff["LINFAC"], "with non exists property json and good proto,  generate cabfac ok") // space at the end are remove automatically on certains IDE;


	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFACSCOL.txt", 'utf-8', _).replace(/\r\n/g, "\n");;
	seqFile = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIHArray.json", 'utf-8', _));
	prototype = JSON.parse(fs.readFile(_defDataDir + "context/EDISIH1SCOL_$details.json", 'utf-8', _));

	var configParser = createContextParser(seqFile, sqMap);
	var res = serializer.mapSerialize["fixedLength"](json, configParser, prototype);

	strictEqual(res["CABFAC"], fileBuff["CABFAC"], "with CABFAC object or array of object of array ok") // space at the end are remove automatically on certains IDE;
	strictEqual(res["LINFAC"], fileBuff["LINFAC"], "with LINFAC object or array of object of array ok") // space at the end are remove automatically on certains IDE;
	start();

});
asyncTest("serialize import file ", function(_) {

	var json = JSON.parse(fs.readFile(_defDataDir + "context/jsonImport.json", 'utf-8', _));


	var messageMapping = JSON.parse(fs.readFile(_defDataDir + "context/messageMappingSOH.json", 'utf-8', _));

	var configParser = createContextSerializer(messageMapping, mmMap, {}, true);

	var prototype = JSON.parse(fs.readFile(_defDataDir + "context/fullPrototypeImport.json", 'utf-8', _));
	var res = serializer.mapSerialize["delimited"](json, configParser, prototype);

	var result = '"ASN","CDE-2010-0491","LS","20100921","","ASN","EUR",""\n' +
		'"CD100","Camion semi remorque rouge","Un","300000"\n' +
		'"ARTICLE2","Désignation article 2","Un",""\n' +
		'"ARTICLE2","Désignation article 2","Un",""\n' +
		'"ARTICLE4","ARTICLE4","Un",""';


	strictEqual(res[configParser.fileName], result, "serialize SOH in delimited file ok");

	res = serializer.mapSerialize["sepField"](json, configParser, prototype);
	result = "ASN,CDE-2010-0491,LS,20100921,ASN,EUR,CD100,Camion semi remorque rouge,Un,300000ARTICLE2,Désignation article 2,Un,ARTICLE2,Désignation article 2,Un,ARTICLE4,ARTICLE4,Un,";

	strictEqual(res[configParser.fileName], result, " serialize SOH with sepField ok ");

	res = serializer.mapSerialize["sepRecord"](json, configParser, prototype);
	result = "ASN,CDE-2010-0491,LS,20100921,ASN,EUR,CD100,Camion semi remorque rouge,Un,300000\nARTICLE2,Désignation article 2,Un,\nARTICLE2,Désignation article 2,Un,\nARTICLE4,ARTICLE4,Un,";
	strictEqual(res[configParser.fileName], result, " serialize SOH with sepRecord ok ");


	start();
});

asyncTest("parser", function(_) {
	_initPrototypeCache(_, db);
	// store in mongodb all needed to perform the test
	var seqFileJson = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));

	var configParser = createContextParser(seqFileJson, sqMap);
	var fileBuff = {};
	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFAC", 'utf-8', _).replace(/\r\n/g, "\n");;
	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFAC", 'utf-8', _).replace(/\r\n/g, "\n");;
	var jsonSIH = {
		"NUM": "FCC11014VEN00000014",
		"BPR": "ESP0001",
		"CPY": "110",
		"FCY": "C110",
		"BPAPAY": "A01",
		"CUR": "EUR",
		"PTE": "CHEQ100COMPTANT",
		"AMTATI": 75880,
		"AMTNOT": 66000,
		"SIVTYP": "FAC",
		"ACCDAT": "2014-02-24",
		"ESIH1SID": [{
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 1000,
			"ITMREF": "CDROM",
			"ITMDES": "CD-ROM 16X",
			"SAU": "Un",
			"QTY": 3,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 30000
		}, {
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 2000,
			"ITMREF": "CDROM1",
			"ITMDES": "CD-ROM1 16X",
			"SAU": "Un",
			"QTY": 2,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 20000
		}]
	};
	var protocolJson = JSON.parse(fs.readFile(_defDataDir + "context/protocol.json", 'utf-8', _));



	var res = parser.parse(_, {
		configParser: configParser,
		prototype: prototype_EDISIH1,
		input: fileBuff,
		db: db
	});
	strictEqual(JSON.stringify(res.FCC11014VEN00000014), JSON.stringify(jsonSIH), "parse ok ");

	var seqFileJsonReal = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIHReal.json", 'utf-8', _)); // for some reasons the collection name in prototype is not the same as we have in the decribe we manage both case.

	var configParser = createContextParser(seqFileJsonReal, sqMap);



	res = parser.parse(_, {
		configParser: configParser,
		prototype: prototype_EDISIH1,
		input: fileBuff,
		db: db
	});
	var jsonSIH = {
		"NUM": "FCC11014VEN00000014",
		"BPR": "ESP0001",
		"CPY": "110",
		"FCY": "C110",
		"BPAPAY": "A01",
		"CUR": "EUR",
		"PTE": "CHEQ100COMPTANT",
		"AMTATI": 75880,
		"AMTNOT": 66000,
		"SIVTYP": "FAC",
		"ACCDAT": "2014-02-24"
	};
	strictEqual(JSON.stringify(res.FCC11014VEN00000014), JSON.stringify(jsonSIH), "parse with seqFile that describe collection that not correspond to the prototype ok ");

	var seqFileJsonDelim = JSON.parse(fs.readFile(_defDataDir + "context/seqFileFactureFailed.json", 'utf-8', _)); // for some reasons the collection name in prototype is not the same as we have in the decribe we manage both case.

	var configParser = createContextParser(seqFileJsonDelim, sqMap);
	//  Case of the prototype collection correspond to the expression define by applicative team and the other one following the rules implement by the supervisor


	fileBuff = {};
	fileBuff["FACTURA"] = fs.readFile(_defDataDir + "ediFiles/FACTURA.txt", 'utf-8', _).replace(/\r\n/g, "\n");;


	try {
		res = parser.parse(_, {
			configParser: configParser,
			prototype: prototype_EDISIH1FACTURA,
			input: fileBuff,
			db: db
		});
		ok(false, "ERROR CASE : can't serialize property.$type not compatible with data read in file");

	} catch (e) {
		ok(true, "ERROR CASE : can't serialize property.$type not compatible with data read in file mess:" + e.message);
	}

	start();
});

asyncTest(" serialize edi file", function(_) {
	_initPrototypeCache(_, db);
	// store in mongodb all needed to perform the test
	var seqFileJson = JSON.parse(fs.readFile(_defDataDir + "context/seqFileSIH.json", 'utf-8', _));

	var configParser = createContextSerializer(seqFileJson, sqMap, {
		C: "CABFAC",
		L: "LINFAC"
	}, false);
	var protocolJson = JSON.parse(fs.readFile(_defDataDir + "context/protocol.json", 'utf-8', _));
	var fileBuff = {};
	fileBuff["CABFAC"] = fs.readFile(_defDataDir + "ediFiles/CABFAC", 'utf-8', _).replace(/\r\n/g, "\n");;
	fileBuff["LINFAC"] = fs.readFile(_defDataDir + "ediFiles/LINFAC", 'utf-8', _).replace(/\r\n/g, "\n");;

	var jsonSIH = {
		"NUM": "FCC11014VEN00000014",
		"BPR": "ESP0001",
		"CPY": "110",
		"FCY": "C110",
		"BPAPAY": "A01",
		"CUR": "EUR",
		"PTE": "CHEQ100COMPTANT",
		"AMTATI": 75880,
		"AMTNOT": 66000,
		"SIVTYP": "FAC",
		"ACCDAT": "2014-02-24",
		"ESIH1SID": [{
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 1000,
			"ITMREF": "CDROM",
			"ITMDES": "CD-ROM 16X",
			"SAU": "Un",
			"QTY": 3,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 30000
		}, {
			"NUM": "FCC11014VEN00000014",
			"SIDLIN": 2000,
			"ITMREF": "CDROM1",
			"ITMDES": "CD-ROM1 16X",
			"SAU": "Un",
			"QTY": 2,
			"GROPRI": 1000000,
			"NETPRI": 1000000,
			"AMTLIN": 20000
		}]
	};


	var res = serializer.serialize(_, {
		configSerializer: configParser,
		prototype: prototype_EDISIH1,
		json: jsonSIH,
		action: "edi",
		db: db
	});

	strictEqual(Object.keys(res).length, 2, "number of file ok");
	strictEqual(res["CABFAC"], fileBuff["CABFAC"], "cabfac ok ");
	strictEqual(res["LINFAC"], fileBuff["LINFAC"], "linfac ok ");



	try {
		var res = serializer.serialize(_, {
			configSerializer: configParser,
			json: jsonSIH,
			action: "edi",
			db: db
		});
		ok(false, "ERROR CASE : serialize on a non exists representation");

	} catch (e) {
		ok(true, "ERROR CASE : serialize on a non exists representation mess:" + e.stack);
	}




	start();
});

asyncTest(" serialize import files", function(_) {
	_initPrototypeCache(_, db);

	// store in mongodb all needed to perform the test
	var messageMappingJson = JSON.parse(fs.readFile(_defDataDir + "context/messageMappingSOH.json", 'utf-8', _));

	var configParser = createContextSerializer(messageMappingJson, mmMap, {
		C: "CABFAC",
		L: "LINFAC"
	}, true);
	var protocolJson = JSON.parse(fs.readFile(_defDataDir + "context/protocol.json", 'utf-8', _));
	var fileBuff = fs.readFile(_defDataDir + "context/importSOH.csv", 'utf-8', _).replace(/\r\n/g, "\n");;

	var jsonSOH = JSON.parse(fs.readFile(_defDataDir + "context/jsonImport.json", 'utf-8', _));


	var res = serializer.serialize(_, {
		configSerializer: configParser,
		json: jsonSOH,
		prototype: prototype_EDIS0H2,
		action: "import",
		db: db
	});
	strictEqual(res !== null, true, "serialization ok ");

	strictEqual(res[Object.keys(res)[0]], fileBuff, "import file content ok");


	try {
		var res = serializer.serialize(_, {
			configSerializer: configParser,
			json: jsonSOH,
			action: "import",
			db: db
		});
		ok(false, "ERROR CASE : serialize on a non exists representation");

	} catch (e) {
		ok(true, "ERROR CASE : serialize on a non exists representation mess:" + e.message);
	}

	start();
});


asyncTest("clean edi entity mongodb", 0, function(_) {
	EdiEntity.dropAllEdiCacheEntity(_, {
		db: db
	});
	EdiProcess.removeAllEdiProcess(_, {
		db: db
	});

	start();
});

asyncTest("stop  tests", 0, function(_) {
	doStop = true;
	start();
});