"use strict";

var helpers = require('syracuse-core').helpers;
var adminHelper = require("syracuse-collaboration/lib/helpers").AdminHelper;
var parser = require("./tool/parser");
var serializer = require("./tool/serializer");
var datetime = require('syracuse-core').types.datetime;
var ediProcessTracer = {
	info: console.log,
	debug: console.log,
	error: console.log
}; //require('syracuse-core').getTracer("edi.process");
var sqMap = require('./helpers').seqentialFilePropertyMap;
var xmlMap = require('./helpers').xmlFilePropertyMap;

var mmMap = require('./helpers').messageMappingPropertyMap;
var encodingMenulocalMap = require('./helpers').encodingMenuLocalMap;
var helpersTool = require('./tool/helpers');

var protoMap = require('./helpers').protocolPropertyMap;
var SEQFILE_LIB = require('./enumType').SEQFILE_LIB;
var IMPORTFILE_LIB = require('./enumType').IMPORTFILE_LIB;
var ediDataFormat = require('./enumType').EDIDATEFORMAT;
var parseHelp = require('./tool/helpers');
var jsxml = require('js-xml');
var xsdValidator = require("libxml-xsd");
var fs = require("streamline-fs");

var config = require('config'); // must be first syracuse require
var configEdi = config.edi || {};
var ediClass = require('./helpers').EdiClass;
var PROTOCOL = require('./enumType').PROTOCOL;
var LIB_ENCODING = require('./enumType').LIB_ENCODING;
var locale = require('streamline-locale');

var EdiEntity = require("./edi_Entity");
var sa = require("syracuse-orm/lib/storageArea");


var protocolHanler = {
	2: { // protocol type directory
		module: "./protocolHandler/directoryProtocol",
		receipt: {
			method: "getReceiptFiles",
			archive: "mvReceiptArchiveFiles"
		},
		issue: {
			method: "writeIssueFiles",
			archive: ""
		}
	}
};
/*
 * cache the running process. if it already exists, we override the information
 */
function _createEdiProcess(_, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _createEdiProcess idProcess " + opt.idProcess);
	try {
		var klass = new ediClass(_, opt && opt.db, 'ediProcess');
		var ediCache = klass.getInstance(_, {
			"sdataWhere": "idProcess eq '" + opt.idProcess + "'"
		});
		if (!ediCache) {
			ediCache = klass.createInstance(_);
		}
		ediCache.idProcess(_, opt.idProcess);

		ediCache.folder(_, opt.folder); // set the folder to allow the entity to get the endpoint link before setting idMessageMapping etc.. that need the endpoint
		ediCache.x3RepName(_, opt.repName);

		// if messageMapping sequentialFile and protocol are directly passe as a object, it's not necessary to get it from cache
		if (typeof opt.messageMapping === "object") {
			ediCache._messageMapping = opt.messageMapping;
		} else {
			ediCache.idMessageMapping(_, opt.messageMapping);
		}
		if (typeof opt.sequentialFile === "object") {
			ediCache._sequentialFile = opt.sequentialFile;
		} else {
			ediCache.idSequentialFile(_, opt.sequentialFile);
		}
		if (typeof opt.protocol === "object") {
			ediCache._protocol = opt.protocol;
		} else {
			ediCache.idProtocol(_, opt.protocol);
		}
		if (typeof opt.flow === "object") {
			ediCache._flow = opt.flow;
		} else {
			ediCache.idFlow(_, opt.flow);
		}
		if (typeof opt.xmlFile === "object") {
			ediCache._xmlFile = opt.xmlFile;
		} else {
			ediCache.idXmlFile(_, opt.xmlFile);
		}
		var timeout = (configEdi.process && configEdi.process.timeout) ? configEdi.process.timeout : 3600000;
		var stampExpiration = (new Date().getTime()) + timeout;
		ediCache.expiration(_, datetime.fromJsDate(new Date(stampExpiration)));

		ediCache.save(_);

		if (opt.endpoint) { // define another endpoint instead of take the one association to the folder (especially for offline unit test)
			ediCache.endPoint(_, opt.endpoint);
		}
		return ediCache;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error("_createEdiProcess message " + e + " stack " + e.stack);

		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _createEdiProcess done ");

	}
}


function _getEdiProcess(_, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _getEdiProcess idProcess " + opt.idProcess);
	try {
		var ediCache = new ediClass(_, opt && opt.db, "ediProcess").getInstance(_, {
			"sdataWhere": "idProcess eq '" + opt.idProcess + "'"
		});

		return ediCache;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error("_getEdiProcess message " + e + " stack " + e.stack);

		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _getEdiProcess done");
	}

}

function _removeEdiProcess(_, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _removeEdiProcess idProcess " + opt.idProcess);
	try {
		return new ediClass(_, opt && opt.db, "ediProcess").deleteInstance(_, {
			"sdataWhere": "idProcess eq '" + opt.idProcess + "'"
		});
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error("_removeEdiProcess message " + e + " stack " + e.stack);

		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _removeEdiProcess done");
	}
}

function _removeAllEdiProcess(_, opt) {
	return new ediClass(_, opt && opt.db, "ediProcess").dropAllInstance(_);
}


// for unit test
exports.createEdiProcess = _createEdiProcess;
exports.getEdiProcess = _getEdiProcess;
exports.removeEdiProcess = _removeEdiProcess;
exports.removeAllEdiProcess = _removeAllEdiProcess;

exports.$exported = true;



function _checkEDIVolume(_) {
	var db = adminHelper.getCollaborationOrm(_);
	var vols = db.db.collection("StorageVolume", _).find({
		code: "EDI"
	}).toArray(_);
	if (!vols || !vols.length) {
		// create std volume
		var vol = db.model.getEntity(_, "storageVolume").factory.createInstance(_, null, db);
		vol.code(_, "EDI");
		vol.description(_, {
			"default": "EDI storage volume",
			"en-US": "EDI storage volume",
			"fr-FR": "Volume EDI"
		});
		vol.storageType(_, "db_file");
		vol.save(_);
		//
	}
}


function _getPrefix(jsXsd) {
	var schemaPropName = null;
	for (var i = 0; i < Object.keys(jsXsd).length && !schemaPropName; i++) {
		if (Object.keys(jsXsd)[i].indexOf("schema") !== -1) {
			schemaPropName = Object.keys(jsXsd)[i];
		}
	}
	//console.log("schemaPropName "+schemaPropName);

	// check all name space declared
	var listAttr = jsXsd[schemaPropName].$ && Object.keys(jsXsd[schemaPropName].$);
	var prefix = "";

	for (var i = 0; i < listAttr.length && !prefix; i++) {
		var attr = listAttr[i];
		//console.log("attr "+JSON.stringify(jsXsd[schemaPropName].$[attr]));

		if (jsXsd[schemaPropName].$[attr] === "http://www.w3.org/2001/XMLSchema") {
			if (attr !== "targetNameSpace") {
				prefix = attr.substring(6);
				prefix = prefix ? prefix + ":" : prefix;
			}
		}
	}
	return prefix;
}



/// !doc
/// ## var result = parseXsd(_,opt) :
/// This function parse an xsd file and store the xml path result into a entity in mongodb. it can be use for create or update the entity that containt the xmlpath. On update if the entity doesn't exists we automatically create a new entity
/// opt : contains all the element to parse the xsd in order to generate the xml path and create or update the result
/// result : contains the uuid of the edi cache entity create that contain the xml path
///
/// result = "uuid of the json store in cache",
///
///
/// ```javascript
/// var option =
///    xsdUuid : ["uuid1","uuid2"], //list of uuid of xsd file store in storage area
///    uuid : "uuid of already generate entity",
///    id : "id of the edi process"
/// };
/// ```
///

function _retrieveCommonPrefix(exp1, exp2) {
	var prefix = "";
	for (var i = 0; i < exp1.length && exp2.length && exp1[i] === exp2[i]; i++) {
		prefix += exp1[i];
	}
	return prefix[prefix.length - 1] === "." ? prefix.substring(0, prefix.length - 1) : prefix;
}

exports.createContextParserXmlFile = function(_, option) {
	var xmlFile = option.xmlFile;
	var mapFilesCode;
	xmlFile[xmlMap.filesDescription] && xmlFile[xmlMap.filesDescription].forEach(function(item) {
		mapFilesCode = item[xmlMap.filesDescriptions.fileName];
	});
	option.fileNames = mapFilesCode;
	var res = _createContextXmlFile(_, option);
	option.configParser = {
		parser: "xml",
		elems: res.elems,
	};
	return option;
}

function _createContextParserRawFile(option) {
	var seqFile = option.seqFile;

	var mapFilesCode = {};
	var keyByFileCode = {};
	seqFile[sqMap.filesDescription] && seqFile[sqMap.filesDescription].forEach(function(item) {
		mapFilesCode[item[sqMap.filesDescriptions.fileId]] = item[sqMap.filesDescriptions.fileName];

		keyByFileCode[item[sqMap.filesDescriptions.fileName]] = {
			primary: item[sqMap.filesDescriptions.primarykey],
			foreign: item[sqMap.filesDescriptions.foreignkey],
			fatherFileId: item[sqMap.filesDescriptions.fatherFileId]
		};
	});
	var elems = [];
	var prefixExp = {};
	var currentFilename = "";

	seqFile[sqMap.elem].forEach(function(item, idx, arr) {
		var classInstname = seqFile[sqMap.classInstance] || null;
		var exp = item[sqMap.elems.expression];

		var fileName = mapFilesCode[item[sqMap.elems.fileId]];
		prefixExp[fileName] = !keyByFileCode[fileName].foreign || prefixExp[fileName] == null ? "" : _retrieveCommonPrefix(prefixExp[fileName], exp); // get common path for the file id
		var element = {
			isStart: currentFilename !== fileName,
			offset: item[sqMap.elems.offset] - 1,
			length: item[sqMap.elems.length],
			expression: exp,
			flag: item[sqMap.elems.flag],
			isEnd: item[sqMap.elems.isEnd],
			fileName: fileName,
			fileId: item[sqMap.elems.fileId],
			level: item[sqMap.elems.level],
			isMandatory: (item[sqMap.elems.isMandatory] === 2),
			idLineElem: item[sqMap.elems.idLine]
		};
		currentFilename = fileName;
		elems.push(element);
	});

	option.configParser = {
		parser: SEQFILE_LIB[seqFile[sqMap.fileType]],
		sepDecimal: seqFile[sqMap.decimalSep],
		sepField: seqFile[sqMap.fieldSep],
		sepRecord: "\r\n",
		delimField: seqFile[sqMap.fieldDelimiter],
		elems: elems,
		linkKey: keyByFileCode, // primary and foreign key for the element
		exppressionPrefix: prefixExp,
		dateFormat: seqFile[sqMap.dateFormat] ? ediDataFormat[seqFile[sqMap.dateFormat]] : null
	};
	return option;
}




/// ## validateMapping(_, opt) :
/// this fucntion allow to validate if the mapping define in the xmlFile is correct and supported by the javscript api or not. If the mapping is not supported this function raise an exception.
/// idProcess : the edi process identifiant defined in x3
/// opt : contain the element xmlFile that can be a uuid or directly the structure in order to validate if the mapping is ok.
///
/// opt = {
///     xmlFile : "uuid",
///		prototype :"uuid"
/// }
///
/// or
///
/// opt = {
///     xmlFile : {...}
///		prototype :{...}
/// }

exports.validateMapping = function(_, opt) {
	function getFromCache(_, val) {
		var cacheEdi = EdiEntity.getEdiCacheEntity(_, {
			filter: {
				jsonWhere: {
					$uuid: val,
				}
			},
			db: opt.db
		});
		return cacheEdi && cacheEdi.json(_);
	}

	if (opt && typeof opt.xmlFile === "string") {
		opt.xmlFile = getFromCache(_, opt.xmlFile)
	}

	if (opt && typeof opt.prototype === "string") {
		opt.prototype = getFromCache(_, opt.prototype)
	}

	var option = exports.createContextParserXmlFile(_, opt);
	var diags = {};
	Object.keys(option.configParser.elems).forEach_(_, function(_, fileName) {
		helpersTool.preprocessMapping(_, option.configParser.elems[fileName], diags, true, opt.prototype);
		helpersTool.preprocessMapping(_, option.configParser.elems[fileName], diags, false, opt.prototype);
	})
}

function _validateXml(_, input, xsdFilePath) {
	var errors = [];
	var schema = xsdValidator.parseFile(xsdFilePath, _);
	input && schema && Object.keys(input).forEach_(_, function(_, key) {
		var validationErrors = schema.validate(input[key], _);
		if (validationErrors) {
			ediProcessTracer.error && ediProcessTracer.error('xsd path : ' + xsdFilePath + ' xml : ', input[key]);
			console.error("error validation xml used ", input[key], "xsd used ", xsdFilePath);
			errors.push("xsd validation failed \n" + validationErrors);
		}
	});
	if (errors.length > 0)
		throw new Error(errors.join(";"));
}
/// ## var result = decodeEdiFiles(_,idProcess, opt) :
/// This function decode the edi partnet data and store in mongodb the json object corresponding to the data to load in a syraucse instance.
/// idProcess : the edi process identifiant defined in x3
/// opt : json object that provide all the needed element to let the sfyracuse server to retrieve his context and process the decoding
/// result : the object that contains the uuid and the key  of the edi entity that contain the json object store.
///
/// result = {
///    uuid :"uuid of the json store in cache",
///    key :"value of the field identified as a key by the context"
/// }
///
/// ```javascript
/// var option = {
///    messageMapping : "uuid", //id of messageMapping
///    sequentialFile : "uuid", // id of sequentialFile
///    xmlFile : "uuid", // id of sequentialFile
///    protocol : "uuid", // id of flow
///    flow : "uuid", // id of protocol
///    prototype : "uuid", // json that represent the prototype of the representation
///    repName : "EDISIH1", // id fo the x3 class
///    folder : "GX3APP",
///    keepCache : true,
///	   moveEnd : true
///    test : true
/// };
///
/// or
///
/// var option = {
///    messageMapping : {...}, //a Json object that represent the messageMapping
///    sequentialFile : {...}, //a Json object that represent the sequential File
///    flow : {...}, // json of the flow
///    protocol : {...}, //a Json object that represent the protocol
///    prototype : {...}, // json that represent the prototype of the representation
///    repName : "EDISIH1", // id fo the x3 class
///    folder : "GX3APP",
///    keepCache : true
///	   moveEnd : true
///    test : true
/// };
///
/// ```
///
exports.decodeEdiFiles = function(_, idProcess, opt) {




	var configParser;
	ediProcessTracer.debug && ediProcessTracer.debug(" decodeEdiFiles idProcess = " + idProcess);
	var cachedEdi;
	var states = [];
	try {
		opt.sadfsq = opt.sadfsq || {};
		opt.sadfsq.user = opt && opt.sadfsq && opt.sadfsq.user || (config.edi && config.edi.user);
		opt.sadfsq.password = opt && opt.sadfsq && opt.sadfsq.password || (config.edi && config.edi.password);
		// store in the cache the context (env) received
		opt.idProcess = idProcess;

		cachedEdi = _getEdiProcess(_, opt) || _createEdiProcess(_, opt);

		states = cachedEdi.states(_) && JSON.parse(cachedEdi.states(_)) || [];

		// read files
		var protocol = cachedEdi.protocol(_);
		var seqFile = cachedEdi.sequentialFile(_);
		var xmlFile = cachedEdi.xmlFile(_);

		if ((!seqFile || Object.keys(seqFile).length === 0) && (!xmlFile || Object.keys(xmlFile).length === 0)) { // no SeqFile or xmlFile
			if (opt.sequentialFile) throw new Error(locale.format(module, "noSeqFile", cachedEdi.idSequentialFile(_)));
			else throw new Error(locale.format(module, "noXMLFile", opt.xmlFile));
		}
		var protocolhandler = protocolHanler[protocol && protocol.PTCTYP ? protocol.PTCTYP : 2]; // default directory protocol (TODO must raise an excpetion when we'll manage different protocol
		var option = opt;

		var sFile;
		var sMap;
		var xsdFilePath;
		if (seqFile) {
			sFile = seqFile;
			sMap = sqMap;
			option.seqFile = sFile;
			option = _createContextParserRawFile(option);

		} else {
			sFile = xmlFile;
			sMap = xmlMap; //TODO map for xml
			var xmlPathId = xmlFile[xmlMap.cacheUuid]
			opt.edicacheXsdPath = EdiEntity.getEdiCacheEntity(_, {
				uuid: xmlPathId
			});
			if (!opt.edicacheXsdPath) {
				throw new Error(locale.format(module, "cantFindXmlPath", xmlPathId));
			}
			xsdFilePath = opt.edicacheXsdPath.getMainXsdFilePath(_);
			option.xmlFile = xmlFile;
			option = exports.createContextParserXmlFile(_, option);
			//TODO xsdFiles
		}
		option.input = protocolhandler && require(protocolhandler.module)[protocolhandler.receipt.method](_, protocol, sFile, sMap, cachedEdi.endPoint(_), opt);
		if (Object.keys(option.input).length === 0) {
			throw new Error(locale.format(module, "fileNotFound"))
		}
		//input = _getReceiptFiles(_, protocol, seqFile, cachedEdi.endPoint(_), opt);
		//}
		if (xsdFilePath) { // validation of xml

			_validateXml(_, option.input, xsdFilePath);
		}

		// construct context  for the parse
		if (typeof opt.prototype === "string") {
			option.prototype = EdiEntity.getEdiCacheJson(_, {
				uuid: opt.prototype,
				db: opt.db
			});
		} else {
			option.prototype = opt.prototype;
		}
		var mapJson = parser.parse(_, option); // generate a map of json with id of the instance in key
		ediProcessTracer.debug && ediProcessTracer.debug('mapJson : ' + mapJson);

		// return array of uuid and id of each document
		// [{uuid : "uuid", id :"id"}, {...}]
		var result = [];
		var extIdProperty = sFile[sMap.extId];
		Object.keys(mapJson).forEach_(_, function(_, key) {
			var json = mapJson[key];

			function getExtId(extIdProp) {
				var listProp = [extIdProp];
				var extId = json;
				if (extIdProp && extIdProp.indexOf(".") !== -1) { // not in the first level
					listProp = extIdProp.split(".");
				}
				for (var i = 0; i < listProp.length && extId; i++) {
					if (Array.isArray(extId) && extId.length === 1) {
						extId = extId[0];
					}
					extId = extId[listProp[i]];
				}
				if (!extId) {
					ediProcessTracer.error && ediProcessTracer.error("can't find extId from property " + extIdProperty);
				}
				return extId;
			}
			var uuid = EdiEntity.createEdiCacheEntity(_, {
				type: idProcess,
				id: key,
				json: json,
				db: opt.db
			});
			// set the extId specific for EDI for each json file
			result.push({
				uuid: uuid,
				id: key,
				extId: extIdProperty && getExtId(extIdProperty)
			});
		});

		// move to the edi archive directory all the file
		if (opt.moveEnd && !opt.test) {
			protocolhandler && require(protocolhandler.module)[protocolhandler.receipt.archive](_, protocol, option.input, cachedEdi.endPoint(_), opt);
		}
		return result;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error("decodeEdiFiles message " + e + " stack " + e.stack);
		states && states.push({ // TODO manage severity warning
			$diagnoses: [{
				$message: e.message || e,
				$stackTrace: e.stack,
				$severity: "ERROR"
			}]
		});
		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" decodeEdiFiles done");
		// remove ediProcess
		_removeEdiProcess(_, {
			idProcess: idProcess
		});
		cachedEdi && cachedEdi.states(_, JSON.stringify(states));
		//cachedEdi.save(_);
	}
};

function _createContextXmlFile(_, opt) {
	var elems = [];
	var xmlFile = opt.xmlFile;
	var ediCacheXsdPath = opt.edicacheXsdPath;
	var mapFilesCode = opt.fileNames;
	// get cache uuid
	var lines = ediCacheXsdPath && _getXmlPathFile(_, ediCacheXsdPath);

	var listRootNameSpace = {}
	xmlFile[xmlMap.elem].forEach(function(item, idx, arr) {
		var classInstname = xmlFile[xmlMap.classInstance] || null;
		var fullxmlpath = null;
		if (lines && lines.length) {
			var idLine = item[xmlMap.elems.idXmlPath] - 1;
			if (!lines[idLine])
				throw new Error(locale.format(module, "xmlpathNotFound", idLine));
			lines[idLine] = typeof lines[idLine] === "string" ? JSON.parse(lines[idLine]) : lines[idLine];
			var rootPath = fullxmlpath = lines[idLine].path;
			if (fullxmlpath.indexOf(".")) // TODO manage property name space regading the type should be done during generation of xml depending of the type
				rootPath = fullxmlpath.split(".")[0];
			listRootNameSpace[rootPath] = lines[idLine].namespace;

		}

		var fileName = mapFilesCode;
		var element = {
			json: item[xmlMap.elems.expression],
			fileName: fileName,
			xml: fullxmlpath || item[xmlMap.elems.xmlPath], // TODO get the xmlpath from the
			id: item[xmlMap.elems.idXmlPath] - 1,
			type: item[xmlMap.elems.type],
			condition: item[xmlMap.elems.condition]
		};
		elems[fileName] = elems[fileName] || [];
		elems[fileName].push(element);
	});

	// path a generate in the reverse order of the xsd. we reorder the mapping in order to generate the correct xml for xsd validation
	return {
		elems: elems,
		namespace: listRootNameSpace
	};
}

exports.createContextSerializerXmlFile = function(_, opt) {


	var res = _createContextXmlFile(_, opt);
	opt.configSerializer = {
		serializer: "xml",
		elems: res.elems,
		namespace: res.namespace
	};
	return opt;
}

function _generateFiles(_, idProcess, opt) {


	function _createContextSerializerRawFile(opt) {
		var encodingContext = opt.encodingContext;
		var mapFilesCode = opt.mapFilesCode;
		var mapField, serializerMethod;
		if (opt.action === "edi") {
			mapField = sqMap;
			serializerMethod = SEQFILE_LIB[encodingContext[mapField.fileType]];

		} else {
			mapField = mmMap;
			serializerMethod = IMPORTFILE_LIB[encodingContext[mapField.fileType]];
		}


		var elems = [];
		var filenameImport = null;
		if (opt.action === "import") {
			filenameImport = opt.fileName ? opt.fileName : "import";
		}
		encodingContext && encodingContext[mapField.elem] && encodingContext[mapField.elem].forEach(function(item, idx, arr) {
			var classInstname = encodingContext[mapField.classInstance];
			var exp = item[mapField.elems.expression];
			/*if (classInstname && exp && exp.indexOf(classInstname) === 0) { // first elem is the class inst
			 exp = exp.substring(exp.indexOf(".") + 1);
			 }*/
			elems.push({
				offset: item[mapField.elems.offset] - 1,
				length: item[mapField.elems.length],
				expression: exp, // remove the classe instance if it exists to have the property name that correspond tot he prototype arborescence
				flag: item[mapField.elems.flag],
				isEnd: item[mapField.elems.isEnd],
				fileName: opt.fileNames && opt.fileNames[item[mapField.elems.fileId]] || filenameImport,
				level: item[mapField.elems.level],
				isMandatory: (item[mapField.elems.isMandatory] === 2)
			});
		});
		var option = opt;

		option.configSerializer = {
			serializer: serializerMethod,
			sepDecimal: encodingContext[mapField.decimalSep],
			sepField: encodingContext[mapField.fieldSep],
			sepRecord: '\r\n',
			delimField: encodingContext[mapField.fieldDelimiter],
			elems: elems,
			fileName: filenameImport,
			dateFormat: encodingContext[mapField.dateFormat] ? ediDataFormat[encodingContext[mapField.dateFormat]] : null

		};
		return option;
	}


	ediProcessTracer.debug && ediProcessTracer.debug(" _generateFiles idProcess = " + idProcess + ", action = " + opt.action);
	var states = [];
	var cachedEdi;
	var excep;
	try {
		if (!opt.uuid || !opt.sequentialFile && !opt.messageMapping && !opt.xmlFile || !opt.folder || !opt.protocol) {
			throw new Error("can't process generateFile, missing context element, please check api documentation");
		}
		// hack for sadfsq
		opt.sadfsq = opt.sadfsq || {};
		opt.sadfsq.user = opt && opt.sadfsq && opt.sadfsq.user || (config.edi && config.edi.user);
		opt.sadfsq.password = opt && opt.sadfsq && opt.sadfsq.password || (config.edi && config.edi.password);

		// get possibly already generate document for that process
		var generatedDoc = EdiEntity.getSADocument(_, idProcess);
		var document = {};
		if (generatedDoc && generatedDoc.length) {
			generatedDoc.forEach_(_, function(_, doc) {
				document[doc.fileName(_)] = {
					uuid: doc.$uuid,
					doc: doc,
					output: sa.readAll(_, {
						jsonWhere: {
							$uuid: doc.$uuid
						}
					})
				};
			});
		}
		var fileNames;


		opt.idProcess = idProcess;
		cachedEdi = _getEdiProcess(_, opt) || _createEdiProcess(_, opt);

		states = cachedEdi.states(_) && JSON.parse(cachedEdi.states(_)) || [];
		var protocol = cachedEdi.protocol(_);
		// get list of uuid already treated if it's the case


		var uuids = opt.uuid || [];

		uuids = !Array.isArray(uuids) ? [uuids] : uuids;
		if (states && states.length) {
			uuids = uuids.filter(function(v, i) {
				i >= states.length || (states[i].uuid === uuids[i] && states[i].$diagnoses); // TODO check only if  severity ERROR
			});
		}

		var output = {};
		var option, encodingContext, mapField;
		// create map between file name and file code


		var mandatoryFile = {};

		var xsdFilePath;
		if (uuids.length > 0) {
			//TODO
			var seqFile = cachedEdi.sequentialFile(_);
			var mmFile = cachedEdi.messageMapping(_);
			var xmlFile = cachedEdi.xmlFile(_);
			if (!xmlFile) {
				if (opt.action === "edi") {
					encodingContext = seqFile;
					mapField = sqMap;
				} else {
					encodingContext = mmFile;
					mapField = mmMap;
				}
				opt.encodingContext = encodingContext;
				if (!encodingContext) {
					// Avoid can't aces TYPEFIL of null. This bug occurs when Edi Syracuse cached are out of synch with X3
					// The error "cantCreate" is not handled by 4GL so the process continues to run with wrong setup
					// To fix it the end user has to edit/save 'Sequential File' entity (Christian Jimenez) and launch the process again
					throw new Error(locale.format(module, "badEncodingContext"));
				}
				option = _createContextSerializerRawFile(opt);
			} else {
				encodingContext = xmlFile;
				mapField = xmlMap;
				opt.xmlFile = xmlFile;
				var xmlPathId = xmlFile[xmlMap.cacheUuid]
				opt.edicacheXsdPath = EdiEntity.getEdiCacheEntity(_, {
					uuid: xmlPathId
				});
				if (!opt.edicacheXsdPath) {
					throw new Error(locale.format(module, "cantFindXmlPath", xmlPathId));
				}
				xsdFilePath = opt.edicacheXsdPath.getMainXsdFilePath(_);
				option = exports.createContextSerializerXmlFile(_, opt);

			}
			encodingContext[mapField.filesDescription] && encodingContext[mapField.filesDescription].forEach(function(fileDescr) {
				mandatoryFile[fileDescr[mapField.filesDescriptions.fileName]] = fileDescr[mapField.filesDescriptions.mandatory];
			});
			// generate for all non used json or failed
			uuids.forEach_(_, function(_, uuid) {
				try {
					// read files
					option.uuid = uuid;
					option.process = cachedEdi;
					option.json = EdiEntity.getEdiCacheJson(_, option);

					// construct context  for the parse
					if (typeof opt.prototype === "string") {
						option.prototype = EdiEntity.getEdiCacheJson(_, {
							uuid: opt.prototype,
							db: opt.db
						});
					} else {
						option.prototype = opt.prototype;
					}

					opt.encoding = opt.encoding || LIB_ENCODING[encodingContext[mapField.encoding]];
					var res = serializer.serialize(_, option);

					// check if the files generated are correct xsd validation
					if (xsdFilePath) { // validation of xml

						_validateXml(_, res, xsdFilePath);
					}

					if (res && opt.signature) {
						var sign = require('syracuse-xml/lib/helpers').sign;
						opt.signature.utf8 = true; // do not transform
						Object.keys(res).forEach_(_, function(_, filename) {
							res[filename] = sign(_, res[filename], opt.signature.path, opt.signature.certificate, opt.signature);
						});
					}
					// concat current res to the final output  (concat file if it's necessary
					if (res) {
						Object.keys(res).forEach_(_, function(_, filename) {
							if (document && document[filename]) { //concat the content of filename to this existing one with new line
								document[filename].output += "\r\n" + res[filename];
							} else { // new file
								document[filename] = {
									doc: EdiEntity.createSADocument(_, idProcess, filename),
									output: res[filename]
								};
							}
							EdiEntity.updateSADocument(_, document[filename], opt.encoding);
						});

						var sta = { // TODO manage severity warning
							uuid: uuid,
							fileNames: Object.keys(document)
						};
						// purge json in cache
						if (!opt.keepCache) {
							ediProcessTracer.debug && ediProcessTracer.debug(" purge cache uuid entity = " + uuid);
							EdiEntity.removeEdiCacheEntity(_, {
								uuid: uuid
							});
							sta.purgeCache = true;
						}
						states.push(sta);
					}
				} catch (e) {
					// error raise during serialization - don't stop the process and continu with the next one
					states.push({ // TODO manage severity warning
						uuid: uuid,
						$diagnoses: [{
							$message: e.message,
							$stackTrace: e.stack,
							$severity: "ERROR"
						}]
					});
					throw e;
				}
			});
		}

		// close docs
		// _closeSADocument(_, document);

		// construct output by file to write on sadfsq
		var out = {};
		Object.keys(document).forEach_(_, function(_, filename) {
			// manage don't write non mandatory file that are empty
			out[filename] = out[filename] || {};
			out[filename].content = document[filename].output;
			var match = false;

			for (var i = 0; i < Object.keys(mandatoryFile).length && !match; i++) {
				var patternFile = Object.keys(mandatoryFile)[i];
				match = new RegExp(patternFile).test(filename);
				if (match) {
					out[filename].mandatory = mandatoryFile[patternFile];
				}
			}
		});

		if (!opt.noWrite) {
			var protocolhandler = protocolHanler[protocol && protocol.PTCTYP ? protocol.PTCTYP : 2]; // default directory protocol (TODO must raise an excpetion when we'll manage different protocol
			protocolhandler && require(protocolhandler.module)[protocolhandler.issue.method](_, protocol, encodingContext, cachedEdi.endPoint(_), out, opt, mapField);
		}
		//_writeIssueFiles(_, protocol, encodingContext, cachedEdi.endPoint(_), out, opt, mapField);

		// delete document if no error occurs during write issue file
		EdiEntity.removeSADocument(_, idProcess);
		return states;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error("_generateFiles message " + e + " stack " + e.stack);
		states.push({ // TODO manage severity warning
			$diagnoses: [{
				$message: e.message || e,
				$stackTrace: e.stack,
				$severity: "ERROR"
			}]
		});
		excep = e;
		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _generateFiles done");
		// save ediCache context
		if (!excep) { // remove the ediProcess only if no exception. if it never it will be expire automatically
			_removeEdiProcess(_, {
				idProcess: idProcess
			});
			cachedEdi && cachedEdi.states(_, JSON.stringify(states));

		}
		//cachedEdi &&  cachedEdi.save(_);
	}
}

/// ## var result = generateEdiFiles(_,idProcess, opt) :
/// This function generate the edi partnet data regarding stored in mongodb the json object corresponding to syraucse instance.
/// idProcess : the edi process identifiant defined in x3
/// opt : json object that provide all the needed element to let the syracuse server to retrieve his context in order to process the generation
/// result : the list object composed by uuid of representation loaded, the filename is it was generated or the error in case of failure.
///
///  result = [{
///    filename : "CABAC",
///    uuid : "uuid1",
///    cachePurge :  true // if the cache object identify by uuid was purge by x3
///  },{
///    uuid : "uuid2"
///    $diagnoses : [{
///      "$message": "error message",
///      "$severity":  'ERROR', => can be ERROR, WARN ..etc
///      "$stackTrace":  "stack trace of the error in syracuse"
///    }]
///  }]
///
///
///
/// ```javascript
/// var opt = {
///    messageMapping : "uuid", //id of messageMapping
///    sequentialFile : "uuid", // id of sequentialFile
///    protocol : "uuid", // id of protocol
///    xmlFile : "uuid", // id of xmlFile
///    flow : "uuid", // id of flow
///    prototype : "uuid",
///    repName : "EDISIH1", // id fo the x3 representation used for generation
///    folder : "GX3APP",
///    uuid :  ["uuid of the json file generate that representaiton the representation",..],
///    encoding : "utf8",
///    fileNames : {...}, list of file name  link to filecode in order to know the file to generate
///    keepCache : true, // set keepCache at true if you want syracuse to don't purge cache for representation generate
///    signature: {...} // optional information for digital XML file signature, see below
/// }
///
/// or
///
/// var opt = {
///    messageMapping : {...}, //a Json object that represent the messageMapping
///    sequentialFile : {...}, //a Json object that represent the sequential File
///    xmlFile : {...}, //a Json object that represent the xml File
///    protocol : {...}, //a Json object that represent the protocol
///    flow : {..}, //a Json object that represent the protocol
///    prototype : {...}, // json that represent the prototype of the representation
///    repName : "EDISIH1", // id fo the x3 representation used for generation
///    folder : "GX3APP",
///    uuid :  ["uuid of the json file generate that representaiton the representation",...],
///    encoding : "utf8",
///    keepCache : true, // set keepCache at true if you want syracuse to don't purge cache for representation generate
///    signature: {...} // optional information for digital XML file signature, see below
/// }
///
/// Signature information (see also description of function "sign" in XML signature functions API)
/// {
///    certificate: "certname", // name of certificate instance for signing (must als have private key), obligatory
///    path: [...], // paths in XML file which must be signed, e. g. [""] for signing the whole file except signature
///    signatureAlgorithm: "...", // optional signature algorithm (default: "RSA-SHA256")
///    includeKeyInfo: true, // (optional boolean): include key info into signature with certificate and details of public key
///    prefix: "ds", // (optional): prefix for signature namespace
///    canonicalizationAlgorithm: "...", // optional canonicalization algorithm (default: "http://www.w3.org/2001/10/xml-exc-c14n#"); currently no other algorithm supported 
///    xades: {...} // optional information about XADeS (see description of function "sign" in XML signature functions API)
/// }
/// ```
///
exports.generateEdiFiles = function(_, idProcess, opt) {
	opt.action = "edi";
	// override encoding of it's defined in the context

	return _generateFiles(_, idProcess, opt);
};

/// ## var result = generateImportFiles(_,idProcess, opt) :
/// This function generate the import file regarding  stored in mongodb the json object corresponding to syraucse instance.
/// idProcess : the edi process identifiant defined in x3
/// opt : json object that provide all the needed element to let the syracuse server to retrieve his context in order to process the generation
/// result : the list object composed by uuid of representation loaded, the filename is it was generated or the error in case of failure.
///
///  result = [{
///    filename : "CABAC",
///    uuid : "uuid1",
///    purgeCache : true // if the cached json was purge by syracuse
///  },{
///    uuid : "uuid2"
///    $diagnoses : [{
///      "$message": "error message",
///      "$severity":  'ERROR', => can be ERROR, WARN ..etc
///      "$stackTrace":  "stack trace of the error in syracuse"
///    }]
///  }]
///
/// ```javascript
/// var opt = {
///    messageMapping : "uuid", //id of messageMapping
///    sequentialFile : "uuid", // id of sequentialFile
///    flow : "uuid", //a Json object that represent the protocol
///    protocol : "test", // id of protocol
///    repName : "EDISIH1", // id of the representation
///    folder : "GX3APP",
///    uuid :  ["uuid of the json file generate that representaiton the representation",...],
///    prototype : "uuid",
///    encoding : "utf8",
///    fileName : "name of the file with extension to create",
///    keepCache : true
///    test : true
/// }
///
/// or
///
/// var opt = {
///    messageMapping : {...}, //a Json object that represent the messageMapping
///    sequentialFile : {...}, //a Json object that represent the sequential File
///    protocol : {...}, //a Json object that represent the protocol
///    prototype : {...}, // json that represent the prototype of the representation
///    flow : {..}, //a Json object that represent the protocol
///    repName : "EDISIH1", // id of the representation
///    folder : "GX3APP",
///    uuid :  ["uuid of the json file generate that representaiton the representation",...],
///    encoding : "utf8",
///    fileName : "name of the file with extension to create",
///    keepCache : true
///    test : true
/// }
///
/// ```
///
exports.generateImportFiles = function(_, idProcess, opt) {
	opt.action = "import";
	return _generateFiles(_, idProcess, opt);
};



function _createOrderedSchemaList(listXsd, jsonXsd, xsdFiles, elem) {
	if (elem) { // add schema dependency
		var nameSpace = Object.keys(elem.listNameSpace);
		for (var i = 0; i < nameSpace.length; i++) {
			var nmmspace = elem.listNameSpace[nameSpace[i]];
			var item = listXsd[nmmspace];
			if (item && !item.treated) {
				item.treated = true;
				_createOrderedSchemaList(listXsd, jsonXsd, xsdFiles, item);
			}
		}
		xsdFiles.push({
			fileName: elem.fileName,
			uuid: elem.uuid,
			targetNameSpace: elem.targetNameSpace
		})
		jsonXsd.push(elem.schema);

	} else {
		for (var i = 0; listXsd && i < Object.keys(listXsd).length; i++) {
			var current = listXsd[Object.keys(listXsd)[i]];
			if (current && jsonXsd && jsonXsd.indexOf(current.schema) === -1 && !current.treated) {
				current.treated = true;
				_createOrderedSchemaList(listXsd, jsonXsd, xsdFiles, current);
			}
		}
	}
}
/// ## var result = parseXsd(_,opt) :
/// This function parse an xsd file and store the xml path result into a entity in mongodb. it can be use for create or update the entity that containt the xmlpath. On update if the entity doesn't exists we automatically create a new entity
/// opt : contains all the element to parse the xsd in order to generate the xml path and create or update the result
/// result : contains the uuid of the edi cache entity create that contain the xml path
///
/// result = {uuid : "uuid of the json store in cache"},
///
///
/// ```javascript
/// var option =
///    xsdUuid : ["uuid1","uuid2"], //list of uuid of xsd file store in storage area
///    uuid : "uuid of already generate entity",
///    id : "id of the edi process"
/// };
/// ```
///
exports.parseXsd = function(_, opt) {


	try {

		// retrieve list of xsd to read in storage area
		var jsonXsd = [];
		var docs = [];

		opt.xsdUuid && Array.isArray(opt.xsdUuid) && opt.xsdUuid.forEach_(_, function(_, uuid) {

			var doc = sa.getDocumentInstance(_, {
				jsonWhere: {
					$uuid: uuid
				}
			});
			doc.rawContent = sa.readAll(_, {
				jsonWhere: {
					$uuid: uuid
				}
			}).toString('utf8');
			doc.content = jsxml.parse(doc.rawContent);
			doc.filename = doc.fileName(_);
			doc.uuid = uuid;
			docs.push(doc);
		});

		// sort jsxsd file in ordr to have the imported file before
		var listXsd = {};
		var xsdFiles = []
		docs && docs.forEach(function(doc) {
			var pref = EdiEntity.getPrefix(doc.content);
			var schema = doc.content[pref + "schema"];
			var listNameSpace = {};
			Object.keys(schema.$).forEach(function(attr) {
				if (attr !== "xmlns" &&  attr !== "targetNamespace" && attr.indexOf("xmlns:") !== -1 && schema.$[attr] !== "http://www.w3.org/2001/XMLSchema") {
					listNameSpace[attr] = schema.$[attr];
				}
			});

			listXsd[schema.$.targetNamespace ||  schema.$.xmlns ||  "default"] = {
				pref: pref,
				schema: doc.content,
				rawContent: doc.rawContent,
				listNameSpace: listNameSpace,
				fileName: doc.filename,
				uuid: doc.uuid,
				targetNameSpace: schema.$.targetNamespace ||  schema.$.xmlns
			};


		});

		_createOrderedSchemaList(listXsd, jsonXsd, xsdFiles);
		xsdFiles.reverse();
		// create Document that store the xsd merged files


		var entity = EdiEntity.getEdiCacheEntity(_, opt);

		var docuuid = EdiEntity.executeParseXsd(_, opt, jsonXsd);

		if (!entity) {
			entity = EdiEntity.createEdiEntity(_, {
				id: opt.id,
				type: "xmlType"
			});
		} else {
			// delete old document
			var docinst = sa.getDocumentInstance(_, {
				jsonWhere: {
					$uuid: entity.xmlPathId(_)
				}
			}, 'EDI');
			docinst && docinst.deleteSelf(_);
		}
		entity.xmlPathId(_, docuuid);
		entity.xsdFiles(_, JSON.stringify(xsdFiles));
		//_updateEdiCacheEntity(_, opt)

		/*
		 comment remove of document xsd
		 docs && docs.forEach_(_, function(_, doc) {
		 doc.deleteSelf(_);
		 });*/
		entity.save(_);
		return {
			uuid: entity.$uuid
		};
	} catch (e) {
		console.error(e.stack);
		throw e;
	}
};

/// ## var result = removeXmlPath(_,opt) :
///
///

exports.removeXmlPath = function(_, opt) {
	var edicache = EdiEntity.getEdiCacheEntity(_, opt);
	var docuuid = edicache && edicache.xmlPathId(_);
	if (docuuid) {
		sa.remove(_, {
			jsonWhere: {
				$uuid: docuuid
			}
		});
	}
	edicache && edicache.deleteSelf(_);
};
/// ```javascript
/// var option =
///    uuid : "uuid1", //list of uuid of xsd file store in storage area
///    startIndex : 1, //startIndex of the page
///    count : 20, // number of element  by page
/// };
/// ```
///
///

function _getXmlPathFile(_, edicache) {
	// check if the entity contain th xmlpath doc id
	var docuuid = edicache && edicache.xmlPathId(_);

	if (docuuid) {
		// the metamodel is associated to the orm
		//// read the file and return the
		var content = docuuid && sa.readAll(_, {
			jsonWhere: {
				$uuid: docuuid
			}
		}).toString('utf8') || null;
		return content && content.split("\n");
	}
	return null;
}

exports.getXmlPath = function(_, opt) {
	var edicache = EdiEntity.getEdiCacheEntity(_, opt);

	var lines = _getXmlPathFile(_, edicache);
	if (lines) {
		var startIndex = opt.startIndex && opt.startIndex > 0 ? opt.startIndex - 1 : 0;
		var count = opt.count && opt.count > 0 ? opt.count : 20;
		var k = 0;
		var list = [];
		for (var i = startIndex; i < lines.length && i < count + startIndex; i++) {
			var json = JSON.parse(lines[i]);
			list.push({
				id: k + opt.startIndex,
				path: json.path,
				type: json.type,
				restriction: json.restriction
			});
			k++;
		}

		return {
			startIndex: opt.startIndex,
			count: count,
			elems: list,
			totalResult: lines.length
		};
	} else {

		throw Error("can't find document link to edi entity " + (opt.uuid));
	}




};