"use strict";

var helpers = require('syracuse-core/lib/helpers');
var adminHelper = require("syracuse-collaboration/lib/helpers").AdminHelper;
var parser = require("./tool/parser");
var serializer = require("./tool/serializer");
var datetime = require("syracuse-core/lib/types/datetime");
var ediProcessTracer = require("syracuse-trace/lib/helper").getTracer("edi.process");
var sqMap = require("syracuse-edi/lib/helpers").seqentialFilePropertyMap;
var mmMap = require("syracuse-edi/lib/helpers").messageMappingPropertyMap;
var encodingMenulocalMap = require('syracuse-edi/lib/helpers').encodingMenuLocalMap;
var protoMap = require("syracuse-edi/lib/helpers").protocolPropertyMap;
var SEQFILE_LIB = require('syracuse-edi/lib/enumType').SEQFILE_LIB;
var IMPORTFILE_LIB = require('syracuse-edi/lib/enumType').IMPORTFILE_LIB;
var ediDataFormat = require("syracuse-edi/lib/enumType").EDIDATEFORMAT;
var parseHelp = require('syracuse-edi/lib/tool/helpers');

var adminHelper = require("syracuse-collaboration/lib/helpers").AdminHelper;
var config = require('syracuse-main/lib/nodeconfig').config; // must be first syracuse require
var configEdi = config.edi || {};
var EdiClass = require('./helpers').EdiClass;
var PROTOCOL = require('./enumType').PROTOCOL;
var LIB_ENCODING = require('./enumType').LIB_ENCODING;
var locale = require("syracuse-core/lib/locale");

var EdiEntity = require("./edi_Entity");
var sa = require("syracuse-orm/lib/storageArea");


var protocolHanler = {
	2: { // protocol type directory
		module: "./protocolHandler/directoryProtocol",
		receipt: {
			method: "getReceiptFiles",
			archive: "mvReceiptArchiveFiles"
		},
		issue: {
			method: "writeIssueFiles",
			archive: ""
		}
	}
};
/*
 * cache the running process. if it already exists, we override the information
 */
function _createEdiProcess(_, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _createEdiProcess idProcess " + opt.idProcess);
	try {
		var klass = new EdiClass(_, opt && opt.db, 'ediProcess');
		var ediCache = klass.getInstance(_, {
			"sdataWhere": "idProcess eq '" + opt.idProcess + "'"
		});
		if (!ediCache) {
			ediCache = klass.createInstance(_);
		}
		ediCache.idProcess(_, opt.idProcess);

		ediCache.folder(_, opt.folder); // set the folder to allow the entity to get the endpoint link before setting idMessageMapping etc.. that need the endpoint
		ediCache.x3RepName(_, opt.repName);

		// if messageMapping sequentialFile and protocol are directly passe as a object, it's not necessary to get it from cache
		if (typeof opt.messageMapping === "object") {
			ediCache._messageMapping = opt.messageMapping;
		} else {
			ediCache.idMessageMapping(_, opt.messageMapping);
		}
		if (typeof opt.sequentialFile === "object") {
			ediCache._sequentialFile = opt.sequentialFile;
		} else {
			ediCache.idSequentialFile(_, opt.sequentialFile);
		}
		if (typeof opt.protocol === "object") {
			ediCache._protocol = opt.protocol;
		} else {
			ediCache.idProtocol(_, opt.protocol);
		}
		if (typeof opt.flow === "object") {
			ediCache._flow = opt.flow;
		} else {
			ediCache.idFlow(_, opt.flow);
		}
		var timeout = (configEdi.process && configEdi.process.timeout) ? configEdi.process.timeout : 3600000;
		var stampExpiration = (new Date().getTime()) + timeout;
		ediCache.expiration(_, datetime.fromJsDate(new Date(stampExpiration)));

		ediCache.save();

		if (opt.endpoint) // define another endpoint instead of take the one association to the folder (especially for offline unit test)
			ediCache.endPoint(_, opt.endpoint);

		return ediCache;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);

		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _createEdiProcess done ");

	}
}


function _getEdiProcess(_, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _getEdiProcess idProcess " + opt.idProcess);
	try {
		var ediCache = new EdiClass(_, opt && opt.db, "ediProcess").getInstance(_, {
			"sdataWhere": "idProcess eq '" + opt.idProcess + "'"
		});
		ediCache && ediCache.endPoint(_, adminHelper.getEndpoint(_, {
			dataset: ediCache.folder(_)
		}));
		return ediCache;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);

		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _getEdiProcess done");
	}

}

function _removeEdiProcess(_, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _removeEdiProcess idProcess " + opt.idProcess);
	try {
		return new EdiClass(_, opt && opt.db, "ediProcess").deleteInstance(_, {
			"sdataWhere": "idProcess eq '" + opt.idProcess + "'"
		});
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);

		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _removeEdiProcess done");
	}
}

function _removeAllEdiProcess(_, opt) {
	return new EdiClass(_, opt && opt.db, "ediProcess").dropAllInstance(_);
}


// for unit test
exports.createEdiProcess = _createEdiProcess;
exports.getEdiProcess = _getEdiProcess;
exports.removeEdiProcess = _removeEdiProcess;
exports.removeAllEdiProcess = _removeAllEdiProcess;

exports.$exported = true;







function _checkEDIVolume(_) {
	var db = adminHelper.getCollaborationOrm();
	var vols = db.db.collection("StorageVolume", _).find({
		code: "EDI"
	}).toArray(_);
	if (!vols || !vols.length) {
		// create std volume
		var vol = db.model.getEntity(_, "storageVolume").factory.createInstance(_, null, db);
		vol.code(_, "EDI");
		vol.description(_, {
			"default": "EDI storage volume",
			"en-US": "EDI storage volume",
			"fr-FR": "Volume EDI"
		});
		vol.storageType(_, "db_file");
		vol.save(_);
		//
	}
}


/// !doc
/// ## var result = decodeEdiFiles(_,idProcess, opt) :
/// This function decode the edi partnet data and store in mongodb the json object corresponding to the data to load in a syraucse instance.
/// idProcess : the edi process identifiant defined in x3
/// opt : json object that provide all the needed element to let the syracuse server to retrieve his context and process the decoding
/// result : the object that contains the uuid and the key  of the edi entity that contain the json object store.
///
/// result = {
///    uuid :"uuid of the json store in cache",
///    key :"value of the field identified as a key by the context"
/// }
///
/// ```javascript
/// var option = {
///    messageMapping : "uuid", //id of messageMapping
///    sequentialFile : "uuid", // id of sequentialFile
///    protocol : "uuid", // id of flow
///    flow : "uuid", // id of protocol
///    prototype : "uuid", // json that represent the prototype of the representation
///    repName : "EDISIH1", // id fo the x3 class
///    folder : "GX3APP",
///    keepCache : true,
///	   moveEnd : true
///    test : true
/// };
///
/// or
///
/// var option = {
///    messageMapping : {...}, //a Json object that represent the messageMapping
///    sequentialFile : {...}, //a Json object that represent the sequential File
///    flow : {...}, // json of the flow
///    protocol : {...}, //a Json object that represent the protocol
///    prototype : {...}, // json that represent the prototype of the representation
///    repName : "EDISIH1", // id fo the x3 class
///    folder : "GX3APP",
///    keepCache : true
///	   moveEnd : true
///    test : true
/// };
///
/// ```
///
exports.decodeEdiFiles = function(_, idProcess, opt) {


	function retrieveCommonPrefix(exp1, exp2) {
		var prefix = "";
		for (var i = 0; i < exp1.length && exp2.length && exp1[i] === exp2[i]; i++) {
			prefix += exp1[i];
		}
		return prefix[prefix.length - 1] === "." ? prefix.substring(0, prefix.length - 1) : prefix;
	}

	var configParser;
	ediProcessTracer.debug && ediProcessTracer.debug(" decodeEdiFiles idProcess = " + idProcess);
	var cachedEdi;
	var states = [];
	try {
		opt.sadfsq = opt.sadfsq || {};
		opt.sadfsq.user = opt && opt.sadfsq && opt.sadfsq.user || (config.edi && config.edi.user);
		opt.sadfsq.password = opt && opt.sadfsq && opt.sadfsq.password || (config.edi && config.edi.password);
		// store in the cache the context (env) received
		opt.idProcess = idProcess;

		cachedEdi = _getEdiProcess(_, opt) || _createEdiProcess(_, opt);


		states = cachedEdi.states(_) && JSON.parse(cachedEdi.states(_)) || [];

		// read files
		var protocol = cachedEdi.protocol(_);
		var seqFile = cachedEdi.sequentialFile(_);
		if (!seqFile || Object.keys(seqFile).length === 0) {
			throw new Error(locale.format(module, "noSeqFile", cachedEdi.idSequentialFile(_)));
		}
		var protocolhandler = protocolHanler[protocol && protocol.PTCTYP ? protocol.PTCTYP : 2]; // default directory protocol (TODO must raise an excpetion when we'll manage different protocol
		var option = opt;

		option.input = protocolhandler && require(protocolhandler.module)[protocolhandler.receipt.method](_, protocol, seqFile, cachedEdi.endPoint(_), opt);
		//input = _getReceiptFiles(_, protocol, seqFile, cachedEdi.endPoint(_), opt);
		//}

		// construct context  for the parse
		if (typeof opt.prototype === "string") {
			option.prototype = EdiEntity.getEdiCacheJson(_, {
				uuid: opt.prototype,
				db: opt.db
			});
		} else {
			option.prototype = opt.prototype;
		}
		var mapFilesCode = {};
		var keyByFileCode = {};
		seqFile[sqMap.filesDescription] && seqFile[sqMap.filesDescription].forEach(function(item) {
			mapFilesCode[item[sqMap.filesDescriptions.fileId]] = item[sqMap.filesDescriptions.fileName];

			keyByFileCode[item[sqMap.filesDescriptions.fileName]] = {
				primary: item[sqMap.filesDescriptions.primarykey],
				foreign: item[sqMap.filesDescriptions.foreignkey],
				fatherFileId: item[sqMap.filesDescriptions.fatherFileId]
			};
		});
		var elems = [];
		var prefixExp = {};

		var currentIdLine = {};
		var currentFilename = "";
		seqFile[sqMap.elem].forEach(function(item, idx, arr) {
			var classInstname = seqFile[sqMap.classInstance] || null;
			var exp = item[sqMap.elems.expression];



			var fileName = mapFilesCode[item[sqMap.elems.fileId]];
			prefixExp[fileName] = !keyByFileCode[fileName].foreign || prefixExp[fileName] == null ? "" : retrieveCommonPrefix(prefixExp[fileName], exp); // get common path for the file id
			var element = {
				isStart: currentFilename !== fileName,
				offset: item[sqMap.elems.offset] - 1,
				length: item[sqMap.elems.length],
				expression: exp,
				flag: item[sqMap.elems.flag],
				isEnd: item[sqMap.elems.isEnd],
				fileName: fileName,
				fileId: item[sqMap.elems.fileId],
				level: item[sqMap.elems.level],
				isMandatory: item[sqMap.elems.isMandatory] === 2 ? true : false,
				idLineElem: item[sqMap.elems.idLine]
			};
			currentFilename = fileName;
			elems.push(element);
		});
		// TODO add elem id line
		option.configParser = {
			parser: SEQFILE_LIB[seqFile[sqMap.fileType]],
			sepDecimal: seqFile[sqMap.decimalSep],
			sepField: seqFile[sqMap.fieldSep],
			sepRecord: "\r\n",
			delimField: seqFile[sqMap.fieldDelimiter],
			elems: elems,
			linkKey: keyByFileCode, // primary and foreign key for the element
			exppressionPrefix: prefixExp,
			dateFormat: seqFile[sqMap.dateFormat] ? ediDataFormat[seqFile[sqMap.dateFormat]] : null
		};
		var mapJson = parser.parse(_, option); // generate a map of json with id of the instance in key


		// return array of uuid and id of each document
		// [{uuid : "uuid", id :"id"}, {...}]
		var result = [];
		var extIdProperty = seqFile[sqMap.extId];
		Object.keys(mapJson).forEach_(_, function(_, key) {
			var json = mapJson[key];

			function getExtId() {
				var listProp = [extIdProperty];
				var extId = json;
				if (extIdProperty && extIdProperty.indexOf(".") !== -1) { // not in the first level
					listProp = extIdProperty.split(".");
				}
				for (var i = 0; i < listProp.length && extId; i++) {
					if (Array.isArray(extId) && extId.length === 1) {
						extId = extId[0];
					}
					extId = extId[listProp[i]];
				}
				if (!extId) {
					ediProcessTracer.error && ediProcessTracer.error("can't find extId from property " + extIdProperty);
				}
				return extId;
			}
			var uuid = EdiEntity.createEdiCacheEntity(_, {
				type: idProcess,
				id: key,
				json: json,
				db: opt.db
			});
			// set the extId specific for EDI for each json file
			result.push({
				uuid: uuid,
				id: key,
				extId: getExtId()
			});
		});

		// move to the edi archive directory all the file
		if (opt.moveEnd && !opt.test) {
			protocolhandler && require(protocolhandler.module)[protocolhandler.receipt.archive](_, protocol, option.input, cachedEdi.endPoint(_), opt);
		}
		return result;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);
		states && states.push({ // TODO manage severity warning
			$diagnoses: [{
				$message: e.message,
				$stackTrace: e.stack,
				$severity: "ERROR"
			}]
		});
		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" decodeEdiFiles done");
		// remove ediProcess
		_removeEdiProcess(_, {
			idProcess: idProcess
		});
		cachedEdi && cachedEdi.states(_, JSON.stringify(states));
		//cachedEdi.save(_);
	}
};


function _generateFiles(_, idProcess, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _generateFiles idProcess = " + idProcess + ", action = " + opt.action);
	var states = [];
	var cachedEdi;
	try {
		if (!opt.uuid || !opt.saquentialFile && !opt.messageMapping || !opt.folder || !opt.protocol) {
			throw new Error("can't process generateFile, missing context element, please check api documentation");
		}
		// hack for sadfsq
		opt.sadfsq = opt.sadfsq || {};
		opt.sadfsq.user = opt && opt.sadfsq && opt.sadfsq.user || (config.edi && config.edi.user);
		opt.sadfsq.password = opt && opt.sadfsq && opt.sadfsq.password || (config.edi && config.edi.password);

		// get possibly already generate document for that process
		var generatedDoc = _getSADocument(_, idProcess);
		var document = {};
		if (generatedDoc && generatedDoc.length) {
			generatedDoc.forEach_(_, function(_, doc) {
				document[doc.fileName(_)] = {
					uuid: doc.$uuid,
					doc: doc,
					output: sa.readAll(_, {
						jsonWhere: {
							$uuid: doc.$uuid
						}
					})
				};
			});
		}
		var fileNames;


		opt.idProcess = idProcess;
		cachedEdi = _getEdiProcess(_, opt) || _createEdiProcess(_, opt);

		states = cachedEdi.states(_) && JSON.parse(cachedEdi.states(_)) || [];
		var protocol = cachedEdi.protocol(_);
		// get list of uuid already treated if it's the case


		var uuids = opt.uuid || [];

		uuids = !Array.isArray(uuids) ? [uuids] : uuids;
		if (states && states.length) {
			uuids = uuids.filter(function(v, i) {
				i >= states.length || (states[i].uuid === uuids[i] && states[i].$diagnoses); // TODO check only if  severity ERROR
			});
		}

		var output = {};
		if (uuids.length > 0) {
			var encodingContext, mapField, serializerMethod;
			if (opt.action === "edi") {
				mapField = sqMap;
				encodingContext = cachedEdi.sequentialFile(_);
				serializerMethod = SEQFILE_LIB[encodingContext[mapField.fileType]];

			} else {
				mapField = mmMap;
				encodingContext = cachedEdi.messageMapping(_);
				serializerMethod = IMPORTFILE_LIB[encodingContext[mapField.fileType]];
			}
			// create map between file name and file code
			var mapFilesCode = opt.fileNames;

			var mandatoryFile = {};
			encodingContext[mapField.filesDescription] && encodingContext[mapField.filesDescription].forEach(function(fileDescr) {
				mandatoryFile[fileDescr[mapField.filesDescriptions.fileName]] = fileDescr[mapField.filesDescriptions.mandatory];
			});

			var elems = [];
			var filenameImport = null;
			if (opt.action === "import") {
				filenameImport = opt.fileName ? opt.fileName : "import";
			}
			encodingContext && encodingContext[mapField.elem] && encodingContext[mapField.elem].forEach(function(item, idx, arr) {
				var classInstname = encodingContext[mapField.classInstance];
				var exp = item[mapField.elems.expression];
				/*if (classInstname && exp && exp.indexOf(classInstname) === 0) { // first elem is the class inst
                 exp = exp.substring(exp.indexOf(".") + 1);
                 }*/
				elems.push({
					offset: item[mapField.elems.offset] - 1,
					length: item[mapField.elems.length],
					expression: exp, // remove the classe instance if it exists to have the property name that correspond tot he prototype arborescence
					flag: item[mapField.elems.flag],
					isEnd: item[mapField.elems.isEnd],
					fileName: mapFilesCode && mapFilesCode[item[mapField.elems.fileId]] || filenameImport,
					level: item[mapField.elems.level],
					isMandatory: item[mapField.elems.isMandatory] === 2 ? true : false
				});
			});
			var option = opt;

			option.configSerializer = {
				serializer: serializerMethod,
				sepDecimal: encodingContext[mapField.decimalSep],
				sepField: encodingContext[mapField.fieldSep],
				sepRecord: '\r\n',
				delimField: encodingContext[mapField.fieldDelimiter],
				elems: elems,
				fileName: filenameImport,
				dateFormat: encodingContext[mapField.dateFormat] ? ediDataFormat[encodingContext[mapField.dateFormat]] : null

			};
			// generate for all non used json or failed
			uuids.forEach_(_, function(_, uuid) {
				try {
					// read files
					option.uuid = uuid;
					option.process = cachedEdi;
					option.json = EdiEntity.getEdiCacheJson(_, option);

					// construct context  for the parse
					if (typeof opt.prototype === "string") {
						option.prototype = EdiEntity.getEdiCacheJson(_, {
							uuid: opt.prototype,
							db: opt.db
						});
					} else {
						option.prototype = opt.prototype;
					}

					opt.encoding = opt.encoding || LIB_ENCODING[encodingContext[mapField.encoding]];
					var res = serializer.serialize(_, option);
					// concat current res to the final output  (concat file if it's necessary
					if (res) {
						Object.keys(res).forEach_(_, function(_, filename) {
							if (document && document[filename]) { //concat the content of filename to this existing one with new line
								document[filename].output += "\r\n" + res[filename];
							} else { // new file
								document[filename] = {
									doc: _createSADocument(_, idProcess, filename),
									output: res[filename]
								};
							}
							_updateSADocument(_, document[filename], opt.encoding);
						});

						var sta = { // TODO manage severity warning
							uuid: uuid,
							fileNames: Object.keys(document)
						};
						// purge json in cache
						if (!opt.keepCache) {
							ediProcessTracer.debug && ediProcessTracer.debug(" purge cache uuid entity = " + uuid);
							EdiEntity.removeEdiCacheEntity(_, {
								uuid: uuid
							});
							sta.purgeCache = true;
						}
						states.push(sta);
					}
				} catch (e) {
					// error raise during serialization - don't stop the process and continu with the next one
					states.push({ // TODO manage severity warning
						uuid: uuid,
						$diagnoses: [{
							$message: e.message,
							$stackTrace: e.stack,
							$severity: "ERROR"
						}]
					});
				}
			});
		}


		// construct output by file to write on sadfsq
		var out = {};
		Object.keys(document).forEach_(_, function(_, filename) {
			// manage don't write non mandatory file that are empty
			out[filename] = out[filename] || {};
			out[filename].content = document[filename].output;
			var match = false;

			for (var i = 0; i < Object.keys(mandatoryFile).length && !match; i++) {
				var patternFile = Object.keys(mandatoryFile)[i];
				match = new RegExp(patternFile).test(filename);
				if (match) {
					out[filename].mandatory = mandatoryFile[patternFile];
				}
			}
		});

		var protocolhandler = protocolHanler[protocol && protocol.PTCTYP ? protocol.PTCTYP : 2]; // default directory protocol (TODO must raise an excpetion when we'll manage different protocol

		protocolhandler && require(protocolhandler.module)[protocolhandler.issue.method](_, protocol, encodingContext, cachedEdi.endPoint(_), out, opt, mapField);

		//_writeIssueFiles(_, protocol, encodingContext, cachedEdi.endPoint(_), out, opt, mapField);

		// delete document if no error occurs during write issue file
		_removeSADocument(_, idProcess);
		return states;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);
		states.push({ // TODO manage severity warning
			$diagnoses: [{
				$message: e.message,
				$stackTrace: e.stack,
				$severity: "ERROR"
			}]
		});
		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _generateFiles done");
		// save ediCache context
		_removeEdiProcess(_, {
			idProcess: idProcess
		});

		cachedEdi && cachedEdi.states(_, JSON.stringify(states));
		//cachedEdi &&  cachedEdi.save(_);
	}
}

/// ## var result = generateEdiFiles(_,idProcess, opt) :
/// This function generate the edi partnet data regarding stored in mongodb the json object corresponding to syraucse instance.
/// idProcess : the edi process identifiant defined in x3
/// opt : json object that provide all the needed element to let the syracuse server to retrieve his context in order to process the generation
/// result : the list object composed by uuid of representation loaded, the filename is it was generated or the error in case of failure.
///
///  result = [{
///    filename : "CABAC",
///    uuid : "uuid1",
///    cachePurge :  true // if the cache object identify by uuid was purge by x3
///  },{
///    uuid : "uuid2"
///    $diagnoses : [{
///      "$message": "error message",
///      "$severity":  'ERROR', => can be ERROR, WARN ..etc
///      "$stackTrace":  "stack trace of the error in syracuse"
///    }]
///  }]
///
///
///
/// ```javascript
/// var opt = {
///    messageMapping : "uuid", //id of messageMapping
///    sequentialFile : "uuid", // id of sequentialFile
///    protocol : "uuid", // id of protocol
///    flow : "uuid", // id of flow
///    prototype : "uuid",
///    repName : "EDISIH1", // id fo the x3 representation used for generation
///    folder : "GX3APP",
///    uuid :  ["uuid of the json file generate that representaiton the representation",..],
///    encoding : "utf8",
///    keepCache : true // set keepCache at true if you want syracuse to don't purge cache for representation generate
/// }
///
/// or
///
/// var opt = {
///    messageMapping : {...}, //a Json object that represent the messageMapping
///    sequentialFile : {...}, //a Json object that represent the sequential File
///    protocol : {...}, //a Json object that represent the protocol
///    flow : {..}, //a Json object that represent the protocol
///    prototype : {...}, // json that represent the prototype of the representation
///    repName : "EDISIH1", // id fo the x3 representation used for generation
///    folder : "GX3APP",
///    uuid :  ["uuid of the json file generate that representaiton the representation",...],
///    encoding : "utf8",
///    keepCache : true // set keepCache at true if you want syracuse to don't purge cache for representation generate
/// }
///
/// ```
///
exports.generateEdiFiles = function(_, idProcess, opt) {
	opt.action = "edi";
	// override encoding of it's defined in the context

	return _generateFiles(_, idProcess, opt);
};

/// ## var result = generateImportFiles(_,idProcess, opt) :
/// This function generate the import file regarding  stored in mongodb the json object corresponding to syraucse instance.
/// idProcess : the edi process identifiant defined in x3
/// opt : json object that provide all the needed element to let the syracuse server to retrieve his context in order to process the generation
/// result : the list object composed by uuid of representation loaded, the filename is it was generated or the error in case of failure.
///
///  result = [{
///    filename : "CABAC",
///    uuid : "uuid1",
///    purgeCache : true // if the cached json was purge by syracuse
///  },{
///    uuid : "uuid2"
///    $diagnoses : [{
///      "$message": "error message",
///      "$severity":  'ERROR', => can be ERROR, WARN ..etc
///      "$stackTrace":  "stack trace of the error in syracuse"
///    }]
///  }]
///
/// ```javascript
/// var opt = {
///    messageMapping : "uuid", //id of messageMapping
///    sequentialFile : "uuid", // id of sequentialFile
///    flow : "uuid", //a Json object that represent the protocol
///    protocol : "test", // id of protocol
///    repName : "EDISIH1", // id of the representation
///    folder : "GX3APP",
///    uuid :  ["uuid of the json file generate that representaiton the representation",...],
///    prototype : "uuid",
///    encoding : "utf8",
///    fileName : "name of the file with extension to create",
///    keepCache : true
///    test : true
/// }
///
/// or
///
/// var opt = {
///    messageMapping : {...}, //a Json object that represent the messageMapping
///    sequentialFile : {...}, //a Json object that represent the sequential File
///    protocol : {...}, //a Json object that represent the protocol
///    prototype : {...}, // json that represent the prototype of the representation
///    flow : {..}, //a Json object that represent the protocol
///    repName : "EDISIH1", // id of the representation
///    folder : "GX3APP",
///    uuid :  ["uuid of the json file generate that representaiton the representation",...],
///    encoding : "utf8",
///    fileName : "name of the file with extension to create",
///    keepCache : true
///    test : true
/// }
///
/// ```
///
exports.generateImportFiles = function(_, idProcess, opt) {
	opt.action = "import";
	return _generateFiles(_, idProcess, opt);
};

function _createSADocument(_, idprocess, filename) {
	_checkEDIVolume(_); //create EDI volume
	var doc = {};
	doc.properties = {
		description: idprocess,
		content: {
			contentType: "application/text",
			fileName: filename,
		}
	};
	doc.dd = sa.open(_, null, {
		volume: "EDI"
	});
	return doc;
}

function _updateSADocument(_, d, encoding) {
	sa.write(_, d.doc.dd, d.doc.properties, new Buffer(d.output, encoding), true);

}

function _removeSADocument(_, name) {
	var doc = sa.listDocuments(_, {
		sdataWhere: "description eq '" + name + "'"
	});
	doc.forEach_(_, function(_, d) {
		d.deleteSelf(_);
	});
}

function _getSADocument(_, name) {
	var list = [];
	sa.listDocuments(_, {
		sdataWhere: "description eq '" + name + "'"
	}).forEach_(_, function(_, doc) {
		var filter = {
			jsonWhere: {
				$uuid: doc.$uuid
			}
		};
		doc.properties = {
			description: name,
			content: {
				contentType: "application/text",
				fileName: doc.fileName(_),
			}
		};
		doc.dd = sa.open(_, filter);
		list.push(doc);
	});
}