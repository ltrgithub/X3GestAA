"use strict";

var helpers = require('syracuse-core/lib/helpers');
var adminHelper = require("syracuse-collaboration/lib/helpers").AdminHelper;
var Sadfsq = require("syracuse-x3/lib/clients/sadfsq/sadfsqClient").SadFsqClient;
var parser = require("./tool/parser");
var serializer = require("./tool/serializer");
var datetime = require("syracuse-core/lib/types/datetime");
var ediProcessTracer = require("syracuse-trace/lib/helper").getTracer("edi.process");
var sqMap = require("syracuse-edi/lib/helpers").seqentialFilePropertyMap;
var mmMap = require("syracuse-edi/lib/helpers").messageMappingPropertyMap;
var encodingMenulocalMap = require('syracuse-edi/lib/helpers').encodingMenuLocalMap;
var protoMap = require("syracuse-edi/lib/helpers").protocolPropertyMap;
var SEQFILE_LIB = require('syracuse-edi/lib/enumType').SEQFILE_LIB;
var IMPORTFILE_LIB = require('syracuse-edi/lib/enumType').IMPORTFILE_LIB;

var parseHelp = require('syracuse-edi/lib/tool/helpers');

var adminHelper = require("syracuse-collaboration/lib/helpers").AdminHelper;
var config = require('syracuse-main/lib/nodeconfig').config; // must be first syracuse require
var configEdi = config.edi;
var trace = configEdi && configEdi.cache && configEdi.cache.trace;
var EDIClass = require('./helpers').EDIClass;
var PROTOCOL = require('./enumType').PROTOCOL;
var LIB_ENCODING = require('./enumType').LIB_ENCODING;
var locale = require("syracuse-core/lib/locale");

var EdiEntity = require("./ediEntity");
var sa = require("syracuse-orm/lib/storageArea");

/*
 * cache the running process. if it already exists, we override the information
 */
function _createEdiProcess(_, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _createEdiProcess idProcess " + opt.idProcess);
	try {
		var klass = new EDIClass(_, opt && opt.db, 'ediProcess');
		var ediCache = klass.getInstance(_, {
			"sdataWhere": "idProcess eq '" + opt.idProcess + "'"
		});
		if (!ediCache) {
			ediCache = klass.createInstance(_);
		}
		ediCache.idProcess(_, opt.idProcess);

		ediCache.folder(_, opt.folder); // set the folder to allow the entity to get the endpoint link before setting idMessageMapping etc.. that need the endpoint
		ediCache.x3RepName(_, opt.repName);

		// if messageMapping sequentialFile and protocol are directly passe as a object, it's not necessary to get it from cache
		if (typeof opt.messageMapping === "object") {
			ediCache._messageMapping = opt.messageMapping;
		} else {
			ediCache.idMessageMapping(_, opt.messageMapping);
		}
		if (typeof opt.sequentialFile === "object") {
			ediCache._sequentialFile = opt.sequentialFile;
		} else {
			ediCache.idSequentialFile(_, opt.sequentialFile);
		}
		if (typeof opt.protocol === "object") {
			ediCache._protocol = opt.protocol;
		} else {
			ediCache.idProtocol(_, opt.protocol);
		}
		if (typeof opt.flow === "object") {
			ediCache._flow = opt.flow;
		} else {
			ediCache.idFlow(_, opt.flow);
		}
		var timeout = (configEdi.process && configEdi.process.timeout) ? configEdi.process.timeout : 3600000;
		var stampExpiration = (new Date().getTime()) + timeout;
		ediCache.expiration(_, datetime.fromJsDate(new Date(stampExpiration)));

		ediCache.save();

		if (opt.endpoint) // define another endpoint instead of take the one association to the folder (especially for offline unit test)
			ediCache.endPoint(_, opt.endpoint);

		return ediCache;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);

		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _createEdiProcess done ");

	}
}


function _getEdiProcess(_, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _getEdiProcess idProcess " + opt.idProcess);
	try {
		var ediCache = new EDIClass(_, opt && opt.db, "ediProcess").getInstance(_, {
			"sdataWhere": "idProcess eq '" + opt.idProcess + "'"
		});
		ediCache && ediCache.endPoint(_, adminHelper.getEndpoint(_, {
			dataset: ediCache.folder(_)
		}));
		return ediCache;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);

		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _getEdiProcess done");
	}

}

function _removeEdiProcess(_, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _removeEdiProcess idProcess " + opt.idProcess);
	try {
		return new EDIClass(_, opt && opt.db, "ediProcess").deleteInstance(_, {
			"sdataWhere": "idProcess eq '" + opt.idProcess + "'"
		});
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);

		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _removeEdiProcess done");
	}
}

function _removeAllEdiProcess(_, opt) {
	return new EDIClass(_, opt && opt.db, "ediProcess").dropAllInstance(_);
}


// for unit test
exports.createEdiProcess = _createEdiProcess;
exports.getEdiProcess = _getEdiProcess;
exports.removeEdiProcess = _removeEdiProcess;
exports.removeAllEdiProcess = _removeAllEdiProcess;

exports.$exported = true;

// retrieve EDI process context in X3 (manage with cache mechanism to prevent to generate always the data

function _getEndpoint(_, protocol, ep, opt) {
	var endpoint;
	if (protocol && protocol.$actxFolder) {
		endpoint = adminHelper.getEndpoint(_, {
			dataset: protocol.$actxFolder // take the folder define in the protocol or folder by default sent by x3
		});
	} else {
		endpoint = ep;
	}
	//hack
	var user = opt && opt.sadfsq && opt.sadfsq.user;
	var pass = opt && opt.sadfsq && opt.sadfsq.password;
	if (endpoint === null) {
		throw new Error(locale.format(module, "noEndpoint"));
	}
	return endpoint;
}

function _getSadFsq(_, endpoint, opt) {
	// hack
	var user = opt && opt.sadfsq && opt.sadfsq.user;
	var pass = opt && opt.sadfsq && opt.sadfsq.password;

	return new Sadfsq(_, endpoint.x3server(_).serverHost(_), endpoint.x3server(_).serverPort(_), user, pass, true, (opt.sadfsq && opt.sadfsq.recOptions) || {});

}

function _writeIssueFiles(_, protocol, seqFile, ep, files, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _writeIssueFiles protocol = " + (protocol && protocol.PTCCOD) + ", endpoint = " + (ep && ep.dataset(_)) + ", files = " + JSON.stringify(Object.keys(files)));
	try {
		var sadFsq = _getSadFsq(_, _getEndpoint(_, protocol, ep, opt), opt);
		files && Object.keys(files).forEach_(_, function(_, filename) {
			var items = protocol && protocol[protoMap.listDirectory] && protocol[protoMap.listDirectory].filter(function(item) {
				return item && item[protoMap.listDirectories.typeDirectory] === "DIRISSUE";
			});
			sadFsq.writeFile(_, {
					"path": (opt.path || items && items[0][protoMap.listDirectories.path]) + "/" + filename
				},
				files[filename], {
					flag: "a+",
					encoding: opt.encoding || (seqFile && encodingMenulocalMap[seqFile[sqMap.encoding]]) || "utf-8"
				}
			);

		});
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);

		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _writeIssueFiles done ");
	}
}


function _getReceiptFiles(_, protocol, seqFile, ep, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _getReceiptFiles protocol = " + (protocol && protocol.PTCCOD) + ", endpoint = " + (ep && ep.dataset(_)));

	function _checkPatternFileName(name, sf) {
		var fileid = null;
		for (var i = 0; sf && sf[sqMap.filesDescription] && i < sf[sqMap.filesDescription].length && !fileid; i++) { // se base sur le tableau qui decrit la liste des fichiers //TODO check pattern
			var item = sf[sqMap.filesDescription][i][sqMap.filesDescriptions.fileName];
			var regexp = item ? new RegExp(item) : null;
			if (regexp && regexp.test(name) !== -1) { // TODO check pattern
				fileid = item;
			}
		}
		return fileid;
	}
	try {

		var sadFsq = _getSadFsq(_, _getEndpoint(_, protocol, ep, opt), opt);

		// find the RECEIPT dir
		var items = protocol[protoMap.listDirectory] && protocol[protoMap.listDirectory].filter(function(item) {
			return item[protoMap.listDirectories.typeDirectory] === "DIRRECEIPT";
		});
		var path = items && items[0][protoMap.listDirectories.path];
		var listFile = sadFsq.readdir(_, {
			path: path
		});
		var fileBuff = {};
		for (var i = 0; i < listFile.length; i++) {
			var fileId = _checkPatternFileName(listFile[i], seqFile);
			if (fileId) {
				fileBuff[listFile[i].substring(0, listFile[i].lastIndexOf("."))] = sadFsq.readFile(_, {
					path: path + "/" + listFile[i]
				}, {
					flag: "r",
					encoding: (seqFile && encodingMenulocalMap[seqFile[sqMap.encoding]]) || "utf-8"
				});
			}
		}
		return fileBuff;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);
		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _getReceiptFiles done");
	}
}

exports.getReceiptFiles = _getReceiptFiles; // for unit test
exports.writeIssueFiles = _writeIssueFiles; // for unit test

/// !doc
/// ## var result = decodeEdiFiles(_,idProcess, opt) :
/// This function decode the edi partnet data and store in mongodb the json object corresponding to the data to load in a syraucse instance.
/// idProcess : the edi process identifiant defined in x3
/// opt : json object that provide all the needed element to let the syracuse server to retrieve his context and process the decoding
/// result : the object that contains the uuid and the key  of the edi entity that contain the json object store.
///
/// result = {
///    uuid :"uuid of the json store in cache",
///    key :"value of the field identified as a key by the context"
/// }
///
/// ```javascript
/// var option = {
///    messageMapping : "uuid", //id of messageMapping
///    sequentialFile : "uuid", // id of sequentialFile
///    protocol : "uuid", // id of flow
///    flow : "uuid", // id of protocol
///    prototype : "uuid", // json that represent the prototype of the representation
///    repName : "EDISIH1", // id fo the x3 class
///    folder : "GX3APP",
///    keepCache : true
/// };
///
/// or
///
/// var option = {
///    messageMapping : {...}, //a Json object that represent the messageMapping
///    sequentialFile : {...}, //a Json object that represent the sequential File
///    flow : {...}, // json of the flow
///    protocol : {...}, //a Json object that represent the protocol
///    prototype : {...}, // json that represent the prototype of the representation
///    repName : "EDISIH1", // id fo the x3 class
///    folder : "GX3APP",
///    keepCache : true
/// };
///
/// ```
///
exports.decodeEdiFiles = function(_, idProcess, opt) {


	function retrieveCommonPrefix(exp1, exp2) {
		var prefix = "";
		for (var i = 0; i < exp1.length && exp2.length && exp1[i] === exp2[i]; i++) {
			prefix += exp1[i];
		}
		return prefix[prefix.length - 1] === "." ? prefix.substring(0, prefix.length - 1) : prefix;
	}

	var configParser;
	ediProcessTracer.debug && ediProcessTracer.debug(" decodeEdiFiles idProcess = " + idProcess);
	var cachedEdi;
	var states = [];
	try {
		opt.sadfsq = opt.sadfsq || {};
		opt.sadfsq.user = opt && opt.sadfsq && opt.sadfsq.user || (config.edi && config.edi.user);
		opt.sadfsq.password = opt && opt.sadfsq && opt.sadfsq.password || (config.edi && config.edi.password);
		// store in the cache the context (env) received
		opt.idProcess = idProcess;

		cachedEdi = _getEdiProcess(_, opt) || _createEdiProcess(_, opt);


		states = cachedEdi.states(_) && JSON.parse(cachedEdi.states(_)) || [];

		// read files
		var protocol = cachedEdi.protocol(_);
		var seqFile = cachedEdi.sequentialFile(_);
		if (!seqFile || Object.keys(seqFile).length === 0) {
			throw new Error(locale.format(module, "noSeqFile", cachedEdi.idSequentialFile(_)));
		}
		var input;
		//if (protocol && protocol.PTCTYP === PROTOCOL.directory) {
		input = _getReceiptFiles(_, protocol, seqFile, cachedEdi.endPoint(_), opt);
		//}
		var option = opt;
		option.input = input;

		// construct context  for the parse
		if (typeof opt.prototype === "string") {
			option.prototype = EdiEntity.getEdiCacheJson(_, {
				uuid: opt.prototype,
				db: opt.db
			});
		} else {
			option.prototype = opt.prototype;
		}
		var mapFilesCode = {};
		var keyByFileCode = {};
		seqFile[sqMap.filesDescription] && seqFile[sqMap.filesDescription].forEach(function(item) {
			mapFilesCode[item[sqMap.filesDescriptions.fileId]] = item[sqMap.filesDescriptions.fileName];

			keyByFileCode[item[sqMap.filesDescriptions.fileName]] = {
				primary: item[sqMap.filesDescriptions.primarykey],
				foreign: item[sqMap.filesDescriptions.foreignkey],
				fatherFileId: item[sqMap.filesDescriptions.fatherFileId]
			};
		});
		var elems = [];
		var prefixExp = {};
		seqFile[sqMap.elem].forEach(function(item, idx, arr) {
			var classInstname = seqFile[sqMap.classInstance] || null;
			var exp = item[sqMap.elems.expression];
			if (classInstname && exp.indexOf(classInstname) === 0) { // first elem is the class inst
				exp = exp.substring(exp.indexOf(".") + 1);
			}
			var fileName = mapFilesCode[item[sqMap.elems.fileId]];
			prefixExp[fileName] = prefixExp[fileName] == null ? exp : retrieveCommonPrefix(prefixExp[fileName], exp); // get common path for the file id
			var element = {
				offset: item[sqMap.elems.offset] - 1,
				length: item[sqMap.elems.length],
				expression: exp,
				flag: item[sqMap.elems.flag],
				isEnd: item[sqMap.elems.isEnd],
				fileName: fileName,
				fileId: item[sqMap.elems.fileId]
			};

			elems.push(element);
		});
		option.configParser = {
			parser: SEQFILE_LIB[seqFile[sqMap.fileType]],
			sepDecimal: seqFile[sqMap.decimalSep],
			sepField: seqFile[sqMap.fieldSep],
			sepRecord: "\r\n", // TODO the one in the context
			delimField: seqFile[sqMap.fieldDelimiter],
			elems: elems,
			linkKey: keyByFileCode, // primary and foreign key for the element
			exppressionPrefix: prefixExp
		};
		var mapJson = parser.parse(_, option); // generate a map of json with id of the instance in key

		// return array of uuid and id of each document
		// [{uuid : "uuid", id :"id"}, {...}]
		var result = [];
		Object.keys(mapJson).forEach_(_, function(_, key) {
			var uuid = EdiEntity.createEdiCacheEntity(_, {
				type: idProcess,
				id: key,
				json: mapJson[key],
				db: opt.db
			});
			result.push({
				uuid: uuid,
				id: key
			});
		});


		return result;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);
		states && states.push({ // TODO manage severity warning
			$diagnoses: [{
				$message: e.message,
				$stackTrace: e.stack,
				$severity: "ERROR"
			}]
		});
		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" decodeEdiFiles done");
		cachedEdi && cachedEdi.states(_, JSON.stringify(states));
		//cachedEdi.save(_);
	}
};


function _generateFiles(_, idProcess, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _generateFiles idProcess = " + idProcess + ", action = " + opt.action);
	var states = [];
	var cachedEdi;
	try {
		if (!opt.uuid || !opt.saquentialFile && !opt.messageMapping || !opt.folder || !opt.protocol) {
			throw new Error("can't process generateFile, missing context element, please check api documentation");
		}
		// hack for sadfsq
		opt.sadfsq = opt.sadfsq || {};
		opt.sadfsq.user = opt && opt.sadfsq && opt.sadfsq.user || (config.edi && config.edi.user);
		opt.sadfsq.password = opt && opt.sadfsq && opt.sadfsq.password || (config.edi && config.edi.password);

		// get possibly already generate document for that process
		var generatedDoc = _getSADocument(_, idProcess);
		var document = {};
		if (generatedDoc && generatedDoc.length) {
			generatedDoc.forEach_(_, function(_, doc) {
				document[doc.fileName(_)] = {
					uuid: doc.$uuid,
					doc: doc,
					output: sa.readAll(_, {
						jsonWhere: {
							$uuid: doc.$uuid
						}
					})
				};
			});
		}
		var fileNames;


		opt.idProcess = idProcess;
		cachedEdi = _getEdiProcess(_, opt) || _createEdiProcess(_, opt);

		states = cachedEdi.states(_) && JSON.parse(cachedEdi.states(_)) || [];
		var protocol = cachedEdi.protocol(_);
		// get list of uuid already treated if it's the case


		var uuids = opt.uuid || [];

		uuids = !Array.isArray(uuids) ? [uuids] : uuids;
		if (states && states.length) {
			uuids = uuids.filter(function(v, i) {
				i >= states.length || (states[i].uuid === uuids[i] && states[i].$diagnoses); // TODO check only if  severity ERROR
			});
		}

		var output = {};
		if (uuids.length > 0) {
			var encodingContext, mapField, serializerMethod;
			if (opt.action === "edi") {
				mapField = sqMap;
				encodingContext = cachedEdi.sequentialFile(_);
				serializerMethod = SEQFILE_LIB[encodingContext[mapField.fileType]];

			} else {
				mapField = mmMap;
				encodingContext = cachedEdi.messageMapping(_);
				serializerMethod = IMPORTFILE_LIB[encodingContext[mapField.fileType]];
			}
			// create map between file name and file code
			var mapFilesCode = opt.fileNames;


			var elems = [];
			encodingContext && encodingContext[mapField.elem] && encodingContext[mapField.elem].forEach(function(item, idx, arr) {
				var classInstname = encodingContext[mapField.classInstance];
				var exp = item[mapField.elems.expression];
				if (classInstname && exp && exp.indexOf(classInstname) === 0) { // first elem is the class inst
					exp = exp.substring(exp.indexOf(".") + 1);
				}
				elems.push({
					offset: item[mapField.elems.offset] - 1,
					length: item[mapField.elems.length],
					expression: exp, // remove the classe instance if it exists to have the property name that correspond tot he prototype arborescence
					flag: item[mapField.elems.flag],
					isEnd: item[mapField.elems.isEnd],
					fileName: mapFilesCode[item[mapField.elems.fileId]],
					isMandatory: item[mapField.elems.isMandatory] === 2 ? true : false
				});
			});
			var option = opt;
			var filenameImport = null;
			if (opt.action === "import") {
				filenameImport = opt.fileName ? opt.fileName : "import";
			}

			option.configSerializer = {
				serializer: serializerMethod,
				sepDecimal: encodingContext[mapField.decimalSep],
				sepField: encodingContext[mapField.fieldSep],
				sepRecord: "\r\n",
				delimField: encodingContext[mapField.fieldDelimiter],
				elems: elems,
				fileName: filenameImport
			};
			// generate for all non used json or failed
			uuids.forEach_(_, function(_, uuid) {
				try {
					// read files
					option.uuid = uuid;
					option.process = cachedEdi;
					option.json = EdiEntity.getEdiCacheJson(_, option);

					// construct context  for the parse

					if (typeof opt.prototype === "string") {
						option.prototype = EdiEntity.getEdiCacheJson(_, {
							uuid: opt.prototype,
							db: opt.db
						});
					} else {
						option.prototype = opt.prototype;
					}

					opt.encoding = opt.encoding || LIB_ENCODING[encodingContext[mapField.encoding]];
					var res = serializer.serialize(_, option);
					// concat current res to the final output  (concat file if it's necessary
					if (res) {
						Object.keys(res).forEach_(_, function(_, filename) {
							if (document && document[filename]) { //concat the content of filename to this existing one with new line
								document[filename].output += "\r\n" + res[filename];
							} else { // new file
								document[filename] = {
									doc: _createSADocument(_, idProcess, filename),
									output: res[filename]
								};
							}
							_updateSADocument(_, document[filename], opt.encoding);
						});

						var sta = { // TODO manage severity warning
							uuid: uuid,
							fileNames: Object.keys(document)
						};
						// purge json in cache
						if (!opt.keepCache) {
							ediProcessTracer.debug && ediProcessTracer.debug(" purge cache uuid entity = " + uuid);
							EdiEntity.removeEdiCacheEntity(_, {
								uuid: uuid
							});
							sta.purgeCache = true;
						}
						states.push(sta);
					}
				} catch (e) {
					// error raise during serialization - don't stop the process and continu with the next one
					states.push({ // TODO manage severity warning
						uuid: uuid,
						$diagnoses: [{
							$message: e.message,
							$stackTrace: e.stack,
							$severity: "ERROR"
						}]
					});
				}
			});
		}


		// construct output by file to write on sadfsq
		var out = {};
		Object.keys(document).forEach_(_, function(_, filename) {
			out[filename] = document[filename].output;

		});
		_writeIssueFiles(_, protocol, encodingContext, cachedEdi.endPoint(_), out, opt);

		// delete document if no error occurs during write issue file
		_removeSADocument(_, idProcess);
		return states;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);
		states.push({ // TODO manage severity warning
			$diagnoses: [{
				$message: e.message,
				$stackTrace: e.stack,
				$severity: "ERROR"
			}]
		});
		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _generateFiles done");
		// save ediCache context
		cachedEdi && cachedEdi.states(_, JSON.stringify(states));
		//cachedEdi &&  cachedEdi.save(_);
	}
}

/// ## var result = generateEdiFiles(_,idProcess, opt) :
/// This function generate the edi partnet data regarding stored in mongodb the json object corresponding to syraucse instance.
/// idProcess : the edi process identifiant defined in x3
/// opt : json object that provide all the needed element to let the syracuse server to retrieve his context in order to process the generation
/// result : the list object composed by uuid of representation loaded, the filename is it was generated or the error in case of failure.
///
///  result = [{
///    filename : "CABAC",
///    uuid : "uuid1",
///    cachePurge :  true // if the cache object identify by uuid was purge by x3
///  },{
///    uuid : "uuid2"
///    $diagnoses : [{
///      "$message": "error message",
///      "$severity":  'ERROR', => can be ERROR, WARN ..etc
///      "$stackTrace":  "stack trace of the error in syracuse"
///    }]
///  }]
///
///
///
/// ```javascript
/// var opt = {
///    messageMapping : "uuid", //id of messageMapping
///    sequentialFile : "uuid", // id of sequentialFile
///    protocol : "uuid", // id of protocol
///    flow : "uuid", // id of flow
///    prototype : "uuid",
///    repName : "EDISIH1", // id fo the x3 representation used for generation
///    folder : "GX3APP",
///    uuid :  ["uuid of the json file generate that representaiton the representation",..],
///    encoding : "utf8",
///    keepCache : true // set keepCache at true if you want syracuse to don't purge cache for representation generate
/// }
///
/// or
///
/// var opt = {
///    messageMapping : {...}, //a Json object that represent the messageMapping
///    sequentialFile : {...}, //a Json object that represent the sequential File
///    protocol : {...}, //a Json object that represent the protocol
///    flow : {..}, //a Json object that represent the protocol
///    prototype : {...}, // json that represent the prototype of the representation
///    repName : "EDISIH1", // id fo the x3 representation used for generation
///    folder : "GX3APP",
///    uuid :  ["uuid of the json file generate that representaiton the representation",...],
///    encoding : "utf8",
///    keepCache : true // set keepCache at true if you want syracuse to don't purge cache for representation generate
/// }
///
/// ```
///
exports.generateEdiFiles = function(_, idProcess, opt) {
	opt.action = "edi";
	// override encoding of it's defined in the context

	return _generateFiles(_, idProcess, opt);
};

/// ## var result = generateImportFiles(_,idProcess, opt) :
/// This function generate the import file regarding  stored in mongodb the json object corresponding to syraucse instance.
/// idProcess : the edi process identifiant defined in x3
/// opt : json object that provide all the needed element to let the syracuse server to retrieve his context in order to process the generation
/// result : the list object composed by uuid of representation loaded, the filename is it was generated or the error in case of failure.
///
///  result = [{
///    filename : "CABAC",
///    uuid : "uuid1",
///    purgeCache : true // if the cached json was purge by syracuse
///  },{
///    uuid : "uuid2"
///    $diagnoses : [{
///      "$message": "error message",
///      "$severity":  'ERROR', => can be ERROR, WARN ..etc
///      "$stackTrace":  "stack trace of the error in syracuse"
///    }]
///  }]
///
/// ```javascript
/// var opt = {
///    messageMapping : "uuid", //id of messageMapping
///    sequentialFile : "uuid", // id of sequentialFile
///    flow : "uuid", //a Json object that represent the protocol
///    protocol : "test", // id of protocol
///    repName : "EDISIH1", // id of the representation
///    folder : "GX3APP",
///    uuid :  ["uuid of the json file generate that representaiton the representation",...],
///    prototype : "uuid",
///    encoding : "utf8",
///    path : "path where the import has to be create",
///    fileName : "name of the file with extension to create",
///    keepCache : true
/// }
///
/// or
///
/// var opt = {
///    messageMapping : {...}, //a Json object that represent the messageMapping
///    sequentialFile : {...}, //a Json object that represent the sequential File
///    protocol : {...}, //a Json object that represent the protocol
///    prototype : {...}, // json that represent the prototype of the representation
///    flow : {..}, //a Json object that represent the protocol
///    repName : "EDISIH1", // id of the representation
///    folder : "GX3APP",
///    uuid :  ["uuid of the json file generate that representaiton the representation",...],
///    encoding : "utf8",
///    path : "path where the import has to be create",
///    fileName : "name of the file with extension to create",
///    keepCache : true
/// }
///
/// ```
///
exports.generateImportFiles = function(_, idProcess, opt) {
	opt.action = "import";
	return _generateFiles(_, idProcess, opt);
};

function _createSADocument(_, idprocess, filename) {
	var doc = {};
	doc.properties = {
		description: idprocess,
		content: {
			contentType: "application/text",
			fileName: filename,
		}
	};
	doc.dd = sa.open(_, null, {
		volume: "EDI"
	});
	return doc;
}

function _updateSADocument(_, d, encoding) {
	sa.write(_, d.doc.dd, d.doc.properties, new Buffer(d.output, encoding), true);

}

function _removeSADocument(_, name) {
	var doc = sa.listDocuments(_, {
		sdataWhere: "description eq '" + name + "'"
	});
	doc.forEach_(_, function(_, d) {
		d.deleteSelf(_);
	});
}

function _getSADocument(_, name) {
	var list = [];
	sa.listDocuments(_, {
		sdataWhere: "description eq '" + name + "'"
	}).forEach_(_, function(_, doc) {
		var filter = {
			jsonWhere: {
				$uuid: doc.$uuid
			}
		};
		doc.properties = {
			description: name,
			content: {
				contentType: "application/text",
				fileName: doc.fileName(_),
			}
		};
		doc.dd = sa.open(_, filter);
		list.push(doc);
	});
}