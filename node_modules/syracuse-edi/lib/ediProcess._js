"use strict";

var helpers = require('syracuse-core/lib/helpers');
var adminHelper = require("syracuse-collaboration/lib/helpers").AdminHelper;
var parser = require("./tool/parser");
var serializer = require("./tool/serializer");
var datetime = require("syracuse-core/lib/types/datetime");
var ediProcessTracer = require("syracuse-trace/lib/helper").getTracer("edi.process");
var sqMap = require("syracuse-edi/lib/helpers").seqentialFilePropertyMap;
var mmMap = require("syracuse-edi/lib/helpers").messageMappingPropertyMap;
var encodingMenulocalMap = require('syracuse-edi/lib/helpers').encodingMenuLocalMap;
var protoMap = require("syracuse-edi/lib/helpers").protocolPropertyMap;
var SEQFILE_LIB = require('syracuse-edi/lib/enumType').SEQFILE_LIB;
var IMPORTFILE_LIB = require('syracuse-edi/lib/enumType').IMPORTFILE_LIB;
var ediDataFormat = require("syracuse-edi/lib/enumType").EDIDATEFORMAT;
var parseHelp = require('syracuse-edi/lib/tool/helpers');
var jsxml = require('jsxml');


var adminHelper = require("syracuse-collaboration/lib/helpers").AdminHelper;
var config = require('syracuse-main/lib/nodeconfig').config; // must be first syracuse require
var configEdi = config.edi || {};
var EdiClass = require('./helpers').EdiClass;
var PROTOCOL = require('./enumType').PROTOCOL;
var LIB_ENCODING = require('./enumType').LIB_ENCODING;
var locale = require("syracuse-core/lib/locale");

var EdiEntity = require("./ediEntity");
var sa = require("syracuse-orm/lib/storageArea");


var protocolHanler = {
	2: { // protocol type directory
		module: "./protocolHandler/directoryProtocol",
		receipt: {
			method: "getReceiptFiles",
			archive: "mvReceiptArchiveFiles"
		},
		issue: {
			method: "writeIssueFiles",
			archive: ""
		}
	}
};
/*
 * cache the running process. if it already exists, we override the information
 */
function _createEdiProcess(_, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _createEdiProcess idProcess " + opt.idProcess);
	try {
		var klass = new EdiClass(_, opt && opt.db, 'ediProcess');
		var ediCache = klass.getInstance(_, {
			"sdataWhere": "idProcess eq '" + opt.idProcess + "'"
		});
		if (!ediCache) {
			ediCache = klass.createInstance(_);
		}
		ediCache.idProcess(_, opt.idProcess);

		ediCache.folder(_, opt.folder); // set the folder to allow the entity to get the endpoint link before setting idMessageMapping etc.. that need the endpoint
		ediCache.x3RepName(_, opt.repName);

		// if messageMapping sequentialFile and protocol are directly passe as a object, it's not necessary to get it from cache
		if (typeof opt.messageMapping === "object") {
			ediCache._messageMapping = opt.messageMapping;
		} else {
			ediCache.idMessageMapping(_, opt.messageMapping);
		}
		if (typeof opt.sequentialFile === "object") {
			ediCache._sequentialFile = opt.sequentialFile;
		} else {
			ediCache.idSequentialFile(_, opt.sequentialFile);
		}
		if (typeof opt.protocol === "object") {
			ediCache._protocol = opt.protocol;
		} else {
			ediCache.idProtocol(_, opt.protocol);
		}
		if (typeof opt.flow === "object") {
			ediCache._flow = opt.flow;
		} else {
			ediCache.idFlow(_, opt.flow);
		}
		var timeout = (configEdi.process && configEdi.process.timeout) ? configEdi.process.timeout : 3600000;
		var stampExpiration = (new Date().getTime()) + timeout;
		ediCache.expiration(_, datetime.fromJsDate(new Date(stampExpiration)));

		ediCache.save();

		if (opt.endpoint) // define another endpoint instead of take the one association to the folder (especially for offline unit test)
			ediCache.endPoint(_, opt.endpoint);

		return ediCache;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);

		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _createEdiProcess done ");

	}
}


function _getEdiProcess(_, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _getEdiProcess idProcess " + opt.idProcess);
	try {
		var ediCache = new EdiClass(_, opt && opt.db, "ediProcess").getInstance(_, {
			"sdataWhere": "idProcess eq '" + opt.idProcess + "'"
		});
		ediCache && ediCache.endPoint(_, adminHelper.getEndpoint(_, {
			dataset: ediCache.folder(_)
		}));
		return ediCache;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);

		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _getEdiProcess done");
	}

}

function _removeEdiProcess(_, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _removeEdiProcess idProcess " + opt.idProcess);
	try {
		return new EdiClass(_, opt && opt.db, "ediProcess").deleteInstance(_, {
			"sdataWhere": "idProcess eq '" + opt.idProcess + "'"
		});
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);

		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _removeEdiProcess done");
	}
}

function _removeAllEdiProcess(_, opt) {
	return new EdiClass(_, opt && opt.db, "ediProcess").dropAllInstance(_);
}


// for unit test
exports.createEdiProcess = _createEdiProcess;
exports.getEdiProcess = _getEdiProcess;
exports.removeEdiProcess = _removeEdiProcess;
exports.removeAllEdiProcess = _removeAllEdiProcess;

exports.$exported = true;



function _checkEDIVolume(_) {
	var db = adminHelper.getCollaborationOrm();
	var vols = db.db.collection("StorageVolume", _).find({
		code: "EDI"
	}).toArray(_);
	if (!vols || !vols.length) {
		// create std volume
		var vol = db.model.getEntity(_, "storageVolume").factory.createInstance(_, null, db);
		vol.code(_, "EDI");
		vol.description(_, {
			"default": "EDI storage volume",
			"en-US": "EDI storage volume",
			"fr-FR": "Volume EDI"
		});
		vol.storageType(_, "db_file");
		vol.save(_);
		//
	}
}



function _executeParseXsd(jsXsds) {

	function parseSimpleType(elems, mapSimpleType) {
		if (elems && !Array.isArray(elems)) {
			elems = [elems];
		}
		elems && elems.forEach(function(elem) {
			var simpleTypes = elem["xs:simpleType"];
			if (simpleTypes && !Array.isArray(simpleTypes)) {
				simpleTypes = [simpleTypes];
			}
			simpleTypes && simpleTypes.forEach(function(simpleType) {
				var restriction = simpleType["xs:restriction"];

				var enumeration = [];
				restriction && restriction["xs:enumeration"] && restriction["xs:enumeration"].forEach(function(enume) {
					enumeration.push(enume.$.Value);
				});
				mapSimpleType[simpleType.$.name] = {
					$simple: true,
					$name: simpleType.$.name,
					$type: restriction.$.base,
					$restriction: {
						base: restriction.$.base,
						minInclusive: restriction["xs:minInclusive"] && restriction["xs:minInclusive"].$.value,
						maxInclusive: restriction["xs:maxInclusive"] && restriction["xs:maxInclusive"].$.value,
						pattern: restriction["xs:pattern"] && restriction["xs:pattern"].$.value,
						whiteSpace: restriction["xs:whiteSpace"] && restriction["xs:whiteSpace"].$.value,
						length: restriction["xs:length"] && restriction["xs:length"].$.value,
						minLength: restriction["xs:minLength"] && restriction["xs:minLength"].$.value,
						maxLength: restriction["xs:maxLength"] && restriction["xs:maxLength"].$.value
					}
				};
				if (enumeration.length) {
					mapSimpleType[simpleType.$.name].$restriction.enumeration = enumeration;
				}
			});

		});
	}

	function parseComplexType(name, elemComplexType, map) {
		var atts = elemComplexType["xs:attribute"] && elemComplexType["xs:attribute"];
		if (atts && !Array.isArray(atts)) {
			atts = [atts];
		}
		atts && atts.forEach(function(elem) {
			map[name] = map[name] || {};

			map[name][elem.$.name] = {
				$name: elem.$.name,
				$type: elem.$.type ||  elem.$.ref,
				$leafAttribute: true
			};
			map[name].$complex = true;
			map[name].$name = name;

		});
		var elems = elemComplexType["xs:sequence"] && elemComplexType["xs:sequence"]["xs:element"] && elemComplexType["xs:sequence"]["xs:element"];
		if (!elems) {
			elems = elemComplexType["xs:all"] && elemComplexType["xs:all"]["xs:element"] && elemComplexType["xs:all"]["xs:element"];

		}
		if (elems && !Array.isArray(elems)) {
			elems = [elems];
		}
		elems && elems.forEach(function(elem) {
			//console.log("elem "+JSON.stringify(elem));

			map[name] = map[name] || {};
			map[name][elem.$.name] = {
				$name: elem.$.name,
				$type: elem.$.type ||  elem.$.name,
				$leafElement: mapType[elem.$.type] && mapType[elem.$.type].$simple
			};
			map[name].$name = name;
			map[name].$complex = true;

			parseComplexTypeInElem(elem, map);

		});

	}
	// return if we have treated a complextype
	function parseComplexTypeInElem(jsXsd, mapComplexType) {
		var elements = jsXsd;
		if (elements && !Array.isArray(elements)) {
			elements = [elements];
		}
		elements && elements.forEach(function(element) {
			var firstComplexType = element["xs:complexType"];
			if (firstComplexType) { // treat the first complex type and manage all sons
				parseComplexType(element.$.name, firstComplexType, mapComplexType);
			}
		});

	}

	function parseElementsRoot(elems, mapComplexeType) {
		if (elems && !Array.isArray(elems)) {
			elems = [elems];
		}
		elems && elems.forEach(function(elem) {
			mapComplexeType[elem.$.name] = mapComplexeType[elem.$.name] || {
				$name: elem.$.name,
				$type: elem.$.type
			};
			if (mapComplexeType[elem.$.type])
				mapComplexeType[elem.$.type].$name = elem.$.name; // put the real for the root complexType
			mapComplexeType["root"] = mapComplexeType["root"] ||  [];
			mapComplexeType["root"].push(elem.$.name);
		});
	}

	function constructList(map, el) {
		var stack = [{
			map: map,
			elem: el,
		}];
		var list = [];
		var treated = [];
		while (stack.length) {
			var item = stack.pop();
			var mapType = item.map;
			var elem = item.elem;
			var father = item.father;
			var name = item.name;

			if (elem && treated.indexOf(elem.$name) === -1) {
				if (elem && elem.$leafAttribute) {
					//console.log("$leafAttribute " + JSON.stringify(elem));
					if (list[father] && list[father].elems && list[father].elems.length) {
						list[father].elems.forEach(function(item) {
							list["final"] = list["final"] || {};
							list["final"][item.path + ".$." + (name || elem.$name)] = {
								path: item.path + ".$." + (name || elem.$name),
								type: mapType[elem.$type] && mapType[elem.$type].$restriction.base || elem.$type,
								restriction: item.restriction = mapType[elem.$type] && mapType[elem.$type].$restriction
							};
						});
					}

				} else if (elem && (elem.$leafElement || (elem.$type && elem.$type.substring(0, 3) === "xs:"))) { // its  a simple type
					//console.log("$leafElement " + JSON.stringify(elem));

					if (list[father] && list[father].elems && list[father].elems.length) {
						list[father].elems.forEach(function(item) {
							list["final"] = list["final"] || {};
							list["final"][item.path + "." + (name || elem.$name)] = {
								path: item.path + "." + (name || elem.$name),
								type: mapType[elem.$type] && mapType[elem.$type].$restriction.base || elem.$type,
								restriction: item.restriction = mapType[elem.$type] && mapType[elem.$type].$restriction
							};
						});
					}
				} else if (elem && elem.$complex) { // it's a complex type
					//console.log("complex " + JSON.stringify(elem, null, 2));
					if (!father) { // create the list of the father for the first element
						//console.log("add father " + JSON.stringify(elem.$name));

						list[elem.$name] = list[elem.$name] || {
							elems: [],
							nbsons: 0
						};
						list[elem.$name].elems.push({
							path: elem.$name
						});
					}
					if (list[father] && list[father].elems && list[father].elems.length) {
						list[father].elems.forEach(function(itemFather) {
							//console.log("itemFather " + JSON.stringify(itemFather));
							list[elem.$name] = list[elem.$name] || {
								elems: [],
								nbsons: 0
							};
							list[elem.$name].elems.push({
								path: itemFather.path + "." + (name || elem.$name)
							});
							//console.log("path added "+itemFather.path + "." + elem.$name)
							//console.log("dump "+itemFather.path + "." +(name ||elem.$name));
						});
					}

					var nb = Object.keys(elem).length;
					Object.keys(elem) && Object.keys(elem).forEach(function(item) {
						if (["$complex", "$name", "$type"].indexOf(item) === -1) {
							//console.log("item " + JSON.stringify(item));
							stack.push({
								father: elem.$name,
								map: mapType,
								elem: mapType[item] || elem[item],
							});
							list[elem.$name].nbsons = nb - 1;
						}
					});
					// define that the current son is treated
					if (list[father]) {
						//console.log("nb of sons "+list[father].nbsons);
						list[father].nbsons--;
						if (!list[father].nbsons) // no more son so we delete the father context
							delete list[father];
					}
					treated.push(elem.$name);
				} else { // case we receive the name of the root
					//console.log("root " + JSON.stringify(elem));
					stack.push({
						father: father,
						map: mapType,
						elem: mapType[elem.$type] || mapType[elem.$type.substring(0, 3)],
						name: elem.$name,
					});
					//return elem && elem.$type && constructList(mapType, mapType[elem.$type]);
				}
			}
		}
		return list["final"];
	}


	var mapType = {};

	// retrieve list of complexe contain in the xsd

	if (!jsXsds) {
		return null;
	}

	if (!Array.isArray(jsXsds)) {
		jsXsds = [jsXsds];
	}

	jsXsds && jsXsds.forEach(function(jsXsd) {
		var listComplexType = jsXsd["xs:schema"]["xs:complexType"];
		if (listComplexType) { // case of complexType describe in the root of the schema
			if (!Array.isArray(listComplexType)) {
				listComplexType = [listComplexType];
			}
			listComplexType.forEach(function(complexType) {
				parseComplexType(complexType.$.name, complexType, mapType);
			});
		}
		parseComplexTypeInElem(jsXsd["xs:schema"]["xs:element"], mapType);

		parseSimpleType(jsXsd["xs:schema"], mapType);

		parseElementsRoot(jsXsd["xs:schema"]["xs:element"], mapType);

	});

	var listXmlPath = [];
	var i = 0;
	mapType.root && mapType.root.forEach(function(rootElem) { // generate for each root element the list of possibilities
		listXmlPath[rootElem] = rootElem;
	});

	//console.log("mapType " + JSON.stringify(mapType, null, 2));

	var list = {};
	mapType.root && mapType.root.forEach(function(root) {
		var l = constructList(mapType, mapType[root]);
		l && Object.keys(l).forEach(function(item) {
			list[item] = l[item];
		});
	});

	return list;
}

exports.executeParseXsd = _executeParseXsd;

/// ## var result = parseXSD(_,opt) :
/// This function parse an xsd file and store the xml path result into a entity in mongodb. it can be use for create or update the entity that containt the xmlpath. On update if the entity doesn't exists we automatically create a new entity
/// opt : contains all the element to parse the xsd in order to generate the xml path and create or update the result
/// result : the object that contains the uuid of the entity updated or create
///
/// result = {
///    uuid :"uuid of the json store in cache",
/// }
///
/// in creation mode

/// ```javascript
/// var option =
///    xsdUuid : ["uuid1","uuid2"], //list of uuid of xsd file store in storage area
///    idProcess : "id of the edi process"
/// };
/// ```
/// in update mode
///
///
/// ```javascript
/// var option = {
///    xsdUuid : ["uuid1","uuid2"], //list of uuid of xsd file store in storage area
///    uuid : "uuid", // uuid of the current entity that we want to update
///    idProcess : "id of the edi process"

/// };
///
/// ```
///
exports.parseXsd = function(_, opt) {
	// retrieve list of xsd to read in storage area
	var jsonXsd = [];
	var docs = [];

	opt.xsdUuid && Array.isArray(opt.xsdUuid) && opt.xsdUuid.forEach_(_, function(_, uuid) {

		var doc = sa.getDocumentInstance(_, {
			jsonWhere: {
				$uuid: uuid
			}
		});

		doc.content = jsxml.parse(sa.readAll(_, {
			jsonWhere: {
				$uuid: uuid
			}
		}).toString('utf8'));
		doc.filename = doc.fileName(_);

		docs.push(doc);
	});

	// sort jsxsd file in ordr to have the imported file before
	docs && docs.sort(function(a, b) {
		var schemaA = a.content["xs:schema"];
		var schemaA = b.content["xs:schema"];

		if (schemaA && !schemaA["xs:import"]) {
			return -1;
		}
		var importA = schemaA["xs:import"];
		if (!Array.isArray(importA)) {
			importA = [importA];
		}
		if (importA.indexOf(b.filename)) { // must treat a after b
			return 1;
		}
		return 0;
	}).forEach(function(doc) {
		jsonXsd.push(doc.content);
	});

	var entity = EdiEntity.getEdiCacheEntity(_, opt);

	if (entity) {
		console.log("update ");
		// update the current value
		var json = _executeParseXsd(jsonXsd);
		opt.json = JSON.parse(JSON.stringify(json).replace(/\./g, "[dot]"));
		EdiEntity.updateEdiCacheEntity(_, opt);
		return {
			uuid: opt.uuid,
			json: json
		};

	} else {
		// not exist we need to create it
		var json = _executeParseXsd(jsonXsd);
		var jsonMongo = JSON.parse(JSON.stringify(json).replace(/\./g, "[dot]"));

		return {
			uuid: EdiEntity.createEdiCacheEntity(_, {
				json: jsonMongo,
				id: opt.idProcess,
				type: "xmlType"
			}),
			json: json
		};
	}
	docs && docs.forEach_(_, function(_, doc) {
		doc.deleteSelf(_);
	});

};


/// !doc
/// ## var result = decodeEdiFiles(_,idProcess, opt) :
/// This function decode the edi partnet data and store in mongodb the json object corresponding to the data to load in a syraucse instance.
/// idProcess : the edi process identifiant defined in x3
/// opt : json object that provide all the needed element to let the syracuse server to retrieve his context and process the decoding
/// result : the object that contains the uuid and the key  of the edi entity that contain the json object store.
///
/// result = {
///    uuid :"uuid of the json store in cache",
///    key :"value of the field identified as a key by the context"
/// }
///
/// ```javascript
/// var option = {
///    messageMapping : "uuid", //id of messageMapping
///    sequentialFile : "uuid", // id of sequentialFile
///    protocol : "uuid", // id of flow
///    flow : "uuid", // id of protocol
///    prototype : "uuid", // json that represent the prototype of the representation
///    repName : "EDISIH1", // id fo the x3 class
///    folder : "GX3APP",
///    keepCache : true,
///	   moveEnd : true
///    test : true
/// };
///
/// or
///
/// var option = {
///    messageMapping : {...}, //a Json object that represent the messageMapping
///    sequentialFile : {...}, //a Json object that represent the sequential File
///    flow : {...}, // json of the flow
///    protocol : {...}, //a Json object that represent the protocol
///    prototype : {...}, // json that represent the prototype of the representation
///    repName : "EDISIH1", // id fo the x3 class
///    folder : "GX3APP",
///    keepCache : true
///	   moveEnd : true
///    test : true
/// };
///
/// ```
///
exports.decodeEdiFiles = function(_, idProcess, opt) {


	function retrieveCommonPrefix(exp1, exp2) {
		var prefix = "";
		for (var i = 0; i < exp1.length && exp2.length && exp1[i] === exp2[i]; i++) {
			prefix += exp1[i];
		}
		return prefix[prefix.length - 1] === "." ? prefix.substring(0, prefix.length - 1) : prefix;
	}

	var configParser;
	ediProcessTracer.debug && ediProcessTracer.debug(" decodeEdiFiles idProcess = " + idProcess);
	var cachedEdi;
	var states = [];
	try {
		opt.sadfsq = opt.sadfsq || {};
		opt.sadfsq.user = opt && opt.sadfsq && opt.sadfsq.user || (config.edi && config.edi.user);
		opt.sadfsq.password = opt && opt.sadfsq && opt.sadfsq.password || (config.edi && config.edi.password);
		// store in the cache the context (env) received
		opt.idProcess = idProcess;

		cachedEdi = _getEdiProcess(_, opt) || _createEdiProcess(_, opt);

		states = cachedEdi.states(_) && JSON.parse(cachedEdi.states(_)) || [];

		// read files
		var protocol = cachedEdi.protocol(_);
		var seqFile = cachedEdi.sequentialFile(_);
		if (!seqFile || Object.keys(seqFile).length === 0) {
			throw new Error(locale.format(module, "noSeqFile", cachedEdi.idSequentialFile(_)));
		}
		var protocolhandler = protocolHanler[protocol && protocol.PTCTYP ? protocol.PTCTYP : 2]; // default directory protocol (TODO must raise an excpetion when we'll manage different protocol
		var option = opt;

		option.input = protocolhandler && require(protocolhandler.module)[protocolhandler.receipt.method](_, protocol, seqFile, cachedEdi.endPoint(_), opt);
		//input = _getReceiptFiles(_, protocol, seqFile, cachedEdi.endPoint(_), opt);
		//}

		// construct context  for the parse
		if (typeof opt.prototype === "string") {
			option.prototype = EdiEntity.getEdiCacheJson(_, {
				uuid: opt.prototype,
				db: opt.db
			});
		} else {
			option.prototype = opt.prototype;
		}
		var mapFilesCode = {};
		var keyByFileCode = {};
		seqFile[sqMap.filesDescription] && seqFile[sqMap.filesDescription].forEach(function(item) {
			mapFilesCode[item[sqMap.filesDescriptions.fileId]] = item[sqMap.filesDescriptions.fileName];

			keyByFileCode[item[sqMap.filesDescriptions.fileName]] = {
				primary: item[sqMap.filesDescriptions.primarykey],
				foreign: item[sqMap.filesDescriptions.foreignkey],
				fatherFileId: item[sqMap.filesDescriptions.fatherFileId]
			};
		});
		var elems = [];
		var prefixExp = {};

		var currentIdLine = {};

		seqFile[sqMap.elem].forEach(function(item, idx, arr) {
			var classInstname = seqFile[sqMap.classInstance] || null;
			var exp = item[sqMap.elems.expression];

			var fileName = mapFilesCode[item[sqMap.elems.fileId]];
			prefixExp[fileName] = !keyByFileCode[fileName].foreign || prefixExp[fileName] == null ? "" : retrieveCommonPrefix(prefixExp[fileName], exp); // get common path for the file id
			var element = {
				offset: item[sqMap.elems.offset] - 1,
				length: item[sqMap.elems.length],
				expression: exp,
				flag: item[sqMap.elems.flag],
				isEnd: item[sqMap.elems.isEnd],
				fileName: fileName,
				fileId: item[sqMap.elems.fileId],
				level: item[sqMap.elems.level],
				isMandatory: item[sqMap.elems.isMandatory] === 2 ? true : false,
				idLineElem: item[sqMap.elems.idLine]
			};

			elems.push(element);
		});
		var sepRecord = null;
		try {
			var sepRecord = eval(seqFile[sqMap.recordSep]);
		} catch (e) {
			sepRecord = "\r\n";
			ediProcessTracer.warn && ediProcessTracer.warn(" _generateFiles no record separator available - used default record separator");
		}
		// TODO add elem id line
		option.configParser = {
			parser: SEQFILE_LIB[seqFile[sqMap.fileType]],
			sepDecimal: seqFile[sqMap.decimalSep],
			sepField: seqFile[sqMap.fieldSep],
			sepRecord: sepRecord || "\r\n",
			delimField: seqFile[sqMap.fieldDelimiter],
			elems: elems,
			linkKey: keyByFileCode, // primary and foreign key for the element
			exppressionPrefix: prefixExp,
			dateFormat: seqFile[sqMap.dateFormat] ? ediDataFormat[seqFile[sqMap.dateFormat]] : null
		};
		var mapJson = parser.parse(_, option); // generate a map of json with id of the instance in key


		// return array of uuid and id of each document
		// [{uuid : "uuid", id :"id"}, {...}]
		var result = [];
		var extIdProperty = seqFile[sqMap.extId];
		Object.keys(mapJson).forEach_(_, function(_, key) {
			var json = mapJson[key];

			function getExtId() {
				var listProp = [extIdProperty];
				var extId = json;
				if (extIdProperty && extIdProperty.indexOf(".") !== -1) { // not in the first level
					listProp = extIdProperty.split(".");
				}
				for (var i = 0; i < listProp.length && extId; i++) {
					if (Array.isArray(extId) && extId.length === 1) {
						extId = exitId[0];
					}
					extId = extId[listProp[i]];
				}
				if (!extId) {
					ediProcessTracer.error && ediProcessTracer.error("can't find extId from property " + extIdProperty);
				}
				return extId;
			}
			var uuid = EdiEntity.createEdiCacheEntity(_, {
				type: idProcess,
				id: key,
				json: json,
				db: opt.db
			});
			// set the extId specific for EDI for each json file
			result.push({
				uuid: uuid,
				id: key,
				extId: getExtId()
			});
		});

		// move to the edi archive directory all the file
		if (opt.moveEnd && !opt.test) {
			protocolhandler && require(protocolhandler.module)[protocolhandler.receipt.archive](_, protocol, option.input, cachedEdi.endPoint(_), opt);
		}
		return result;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);
		states && states.push({ // TODO manage severity warning
			$diagnoses: [{
				$message: e.message,
				$stackTrace: e.stack,
				$severity: "ERROR"
			}]
		});
		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" decodeEdiFiles done");
		// remove ediProcess
		_removeEdiProcess(_, {
			idProcess: idProcess
		});
		cachedEdi && cachedEdi.states(_, JSON.stringify(states));
		//cachedEdi.save(_);
	}
};


function _generateFiles(_, idProcess, opt) {
	ediProcessTracer.debug && ediProcessTracer.debug(" _generateFiles idProcess = " + idProcess + ", action = " + opt.action);
	var states = [];
	var cachedEdi;
	try {
		if (!opt.uuid || !opt.saquentialFile && !opt.messageMapping || !opt.folder || !opt.protocol) {
			throw new Error("can't process generateFile, missing context element, please check api documentation");
		}
		// hack for sadfsq
		opt.sadfsq = opt.sadfsq || {};
		opt.sadfsq.user = opt && opt.sadfsq && opt.sadfsq.user || (config.edi && config.edi.user);
		opt.sadfsq.password = opt && opt.sadfsq && opt.sadfsq.password || (config.edi && config.edi.password);

		// get possibly already generate document for that process
		var generatedDoc = _getSADocument(_, idProcess);
		var document = {};
		if (generatedDoc && generatedDoc.length) {
			generatedDoc.forEach_(_, function(_, doc) {
				document[doc.fileName(_)] = {
					uuid: doc.$uuid,
					doc: doc,
					output: sa.readAll(_, {
						jsonWhere: {
							$uuid: doc.$uuid
						}
					})
				};
			});
		}
		var fileNames;


		opt.idProcess = idProcess;
		cachedEdi = _getEdiProcess(_, opt) || _createEdiProcess(_, opt);

		states = cachedEdi.states(_) && JSON.parse(cachedEdi.states(_)) || [];
		var protocol = cachedEdi.protocol(_);
		// get list of uuid already treated if it's the case


		var uuids = opt.uuid || [];

		uuids = !Array.isArray(uuids) ? [uuids] : uuids;
		if (states && states.length) {
			uuids = uuids.filter(function(v, i) {
				i >= states.length || (states[i].uuid === uuids[i] && states[i].$diagnoses); // TODO check only if  severity ERROR
			});
		}

		var output = {};
		if (uuids.length > 0) {
			var encodingContext, mapField, serializerMethod;
			if (opt.action === "edi") {
				mapField = sqMap;
				encodingContext = cachedEdi.sequentialFile(_);
				serializerMethod = SEQFILE_LIB[encodingContext[mapField.fileType]];

			} else {
				mapField = mmMap;
				encodingContext = cachedEdi.messageMapping(_);
				serializerMethod = IMPORTFILE_LIB[encodingContext[mapField.fileType]];
			}
			// create map between file name and file code
			var mapFilesCode = opt.fileNames;

			var mandatoryFile = {};
			encodingContext[mapField.filesDescription] && encodingContext[mapField.filesDescription].forEach(function(fileDescr) {
				mandatoryFile[fileDescr[mapField.filesDescriptions.fileName]] = fileDescr[mapField.filesDescriptions.mandatory];
			});

			var elems = [];
			var filenameImport = null;
			if (opt.action === "import") {
				filenameImport = opt.fileName ? opt.fileName : "import";
			}
			encodingContext && encodingContext[mapField.elem] && encodingContext[mapField.elem].forEach(function(item, idx, arr) {
				var classInstname = encodingContext[mapField.classInstance];
				var exp = item[mapField.elems.expression];
				/*if (classInstname && exp && exp.indexOf(classInstname) === 0) { // first elem is the class inst
                 exp = exp.substring(exp.indexOf(".") + 1);
                 }*/
				elems.push({
					offset: item[mapField.elems.offset] - 1,
					length: item[mapField.elems.length],
					expression: exp, // remove the classe instance if it exists to have the property name that correspond tot he prototype arborescence
					flag: item[mapField.elems.flag],
					isEnd: item[mapField.elems.isEnd],
					fileName: mapFilesCode && mapFilesCode[item[mapField.elems.fileId]] || filenameImport,
					level: item[mapField.elems.level],
					isMandatory: item[mapField.elems.isMandatory] === 2 ? true : false
				});
			});
			var option = opt;

			var sepRecord = null;
			try {
				var sepRecord = eval(encodingContext[mapField.recordSep]);
			} catch (e) {
				sepRecord = "\r\n";
				ediProcessTracer.warn && ediProcessTracer.warn(" _generateFiles no record separator available - used default record separator");
			}
			option.configSerializer = {
				serializer: serializerMethod,
				sepDecimal: encodingContext[mapField.decimalSep],
				sepField: encodingContext[mapField.fieldSep],
				sepRecord: sepRecord || '\r\n',
				delimField: encodingContext[mapField.fieldDelimiter],
				elems: elems,
				fileName: filenameImport,
				dateFormat: encodingContext[mapField.dateFormat] ? ediDataFormat[encodingContext[mapField.dateFormat]] : null

			};
			// generate for all non used json or failed
			uuids.forEach_(_, function(_, uuid) {
				try {
					// read files
					option.uuid = uuid;
					option.process = cachedEdi;
					option.json = EdiEntity.getEdiCacheJson(_, option);

					// construct context  for the parse
					if (typeof opt.prototype === "string") {
						option.prototype = EdiEntity.getEdiCacheJson(_, {
							uuid: opt.prototype,
							db: opt.db
						});
					} else {
						option.prototype = opt.prototype;
					}

					opt.encoding = opt.encoding || LIB_ENCODING[encodingContext[mapField.encoding]];
					var res = serializer.serialize(_, option);
					// concat current res to the final output  (concat file if it's necessary
					if (res) {
						Object.keys(res).forEach_(_, function(_, filename) {
							if (document && document[filename]) { //concat the content of filename to this existing one with new line
								document[filename].output += "\r\n" + res[filename];
							} else { // new file
								document[filename] = {
									doc: _createSADocument(_, idProcess, filename),
									output: res[filename]
								};
							}
							_updateSADocument(_, document[filename], opt.encoding);
						});

						var sta = { // TODO manage severity warning
							uuid: uuid,
							fileNames: Object.keys(document)
						};
						// purge json in cache
						if (!opt.keepCache) {
							ediProcessTracer.debug && ediProcessTracer.debug(" purge cache uuid entity = " + uuid);
							EdiEntity.removeEdiCacheEntity(_, {
								uuid: uuid
							});
							sta.purgeCache = true;
						}
						states.push(sta);
					}
				} catch (e) {
					// error raise during serialization - don't stop the process and continu with the next one
					states.push({ // TODO manage severity warning
						uuid: uuid,
						$diagnoses: [{
							$message: e.message,
							$stackTrace: e.stack,
							$severity: "ERROR"
						}]
					});
				}
			});
		}


		// construct output by file to write on sadfsq
		var out = {};
		Object.keys(document).forEach_(_, function(_, filename) {
			// manage don't write non mandatory file that are empty
			out[filename] = out[filename] || {};
			out[filename].content = document[filename].output;
			var match = false;

			for (var i = 0; i < Object.keys(mandatoryFile).length && !match; i++) {
				var patternFile = Object.keys(mandatoryFile)[i];
				match = new RegExp(patternFile).test(filename);
				if (match) {
					out[filename].mandatory = mandatoryFile[patternFile];
				}
			}
		});

		var protocolhandler = protocolHanler[protocol && protocol.PTCTYP ? protocol.PTCTYP : 2]; // default directory protocol (TODO must raise an excpetion when we'll manage different protocol

		protocolhandler && require(protocolhandler.module)[protocolhandler.issue.method](_, protocol, encodingContext, cachedEdi.endPoint(_), out, opt, mapField);

		//_writeIssueFiles(_, protocol, encodingContext, cachedEdi.endPoint(_), out, opt, mapField);

		// delete document if no error occurs during write issue file
		_removeSADocument(_, idProcess);
		return states;
	} catch (e) {
		// log exception
		ediProcessTracer.error && ediProcessTracer.error(" message " + e.message + " stack " + e.stack);
		states.push({ // TODO manage severity warning
			$diagnoses: [{
				$message: e.message,
				$stackTrace: e.stack,
				$severity: "ERROR"
			}]
		});
		throw e;
	} finally {
		ediProcessTracer.debug && ediProcessTracer.debug(" _generateFiles done");
		// save ediCache context
		_removeEdiProcess(_, {
			idProcess: idProcess
		});

		cachedEdi && cachedEdi.states(_, JSON.stringify(states));
		//cachedEdi &&  cachedEdi.save(_);
	}
}

/// ## var result = generateEdiFiles(_,idProcess, opt) :
/// This function generate the edi partnet data regarding stored in mongodb the json object corresponding to syraucse instance.
/// idProcess : the edi process identifiant defined in x3
/// opt : json object that provide all the needed element to let the syracuse server to retrieve his context in order to process the generation
/// result : the list object composed by uuid of representation loaded, the filename is it was generated or the error in case of failure.
///
///  result = [{
///    filename : "CABAC",
///    uuid : "uuid1",
///    cachePurge :  true // if the cache object identify by uuid was purge by x3
///  },{
///    uuid : "uuid2"
///    $diagnoses : [{
///      "$message": "error message",
///      "$severity":  'ERROR', => can be ERROR, WARN ..etc
///      "$stackTrace":  "stack trace of the error in syracuse"
///    }]
///  }]
///
///
///
/// ```javascript
/// var opt = {
///    messageMapping : "uuid", //id of messageMapping
///    sequentialFile : "uuid", // id of sequentialFile
///    protocol : "uuid", // id of protocol
///    flow : "uuid", // id of flow
///    prototype : "uuid",
///    repName : "EDISIH1", // id fo the x3 representation used for generation
///    folder : "GX3APP",
///    uuid :  ["uuid of the json file generate that representaiton the representation",..],
///    encoding : "utf8",
///    keepCache : true // set keepCache at true if you want syracuse to don't purge cache for representation generate
/// }
///
/// or
///
/// var opt = {
///    messageMapping : {...}, //a Json object that represent the messageMapping
///    sequentialFile : {...}, //a Json object that represent the sequential File
///    protocol : {...}, //a Json object that represent the protocol
///    flow : {..}, //a Json object that represent the protocol
///    prototype : {...}, // json that represent the prototype of the representation
///    repName : "EDISIH1", // id fo the x3 representation used for generation
///    folder : "GX3APP",
///    uuid :  ["uuid of the json file generate that representaiton the representation",...],
///    encoding : "utf8",
///    keepCache : true // set keepCache at true if you want syracuse to don't purge cache for representation generate
/// }
///
/// ```
///
exports.generateEdiFiles = function(_, idProcess, opt) {
	opt.action = "edi";
	// override encoding of it's defined in the context

	return _generateFiles(_, idProcess, opt);
};

/// ## var result = generateImportFiles(_,idProcess, opt) :
/// This function generate the import file regarding  stored in mongodb the json object corresponding to syraucse instance.
/// idProcess : the edi process identifiant defined in x3
/// opt : json object that provide all the needed element to let the syracuse server to retrieve his context in order to process the generation
/// result : the list object composed by uuid of representation loaded, the filename is it was generated or the error in case of failure.
///
///  result = [{
///    filename : "CABAC",
///    uuid : "uuid1",
///    purgeCache : true // if the cached json was purge by syracuse
///  },{
///    uuid : "uuid2"
///    $diagnoses : [{
///      "$message": "error message",
///      "$severity":  'ERROR', => can be ERROR, WARN ..etc
///      "$stackTrace":  "stack trace of the error in syracuse"
///    }]
///  }]
///
/// ```javascript
/// var opt = {
///    messageMapping : "uuid", //id of messageMapping
///    sequentialFile : "uuid", // id of sequentialFile
///    flow : "uuid", //a Json object that represent the protocol
///    protocol : "test", // id of protocol
///    repName : "EDISIH1", // id of the representation
///    folder : "GX3APP",
///    uuid :  ["uuid of the json file generate that representaiton the representation",...],
///    prototype : "uuid",
///    encoding : "utf8",
///    fileName : "name of the file with extension to create",
///    keepCache : true
///    test : true
/// }
///
/// or
///
/// var opt = {
///    messageMapping : {...}, //a Json object that represent the messageMapping
///    sequentialFile : {...}, //a Json object that represent the sequential File
///    protocol : {...}, //a Json object that represent the protocol
///    prototype : {...}, // json that represent the prototype of the representation
///    flow : {..}, //a Json object that represent the protocol
///    repName : "EDISIH1", // id of the representation
///    folder : "GX3APP",
///    uuid :  ["uuid of the json file generate that representaiton the representation",...],
///    encoding : "utf8",
///    fileName : "name of the file with extension to create",
///    keepCache : true
///    test : true
/// }
///
/// ```
///
exports.generateImportFiles = function(_, idProcess, opt) {
	opt.action = "import";
	return _generateFiles(_, idProcess, opt);
};

function _createSADocument(_, idprocess, filename) {
	_checkEDIVolume(_); //create EDI volume
	var doc = {};
	doc.properties = {
		description: idprocess,
		content: {
			contentType: "application/text",
			fileName: filename,
		}
	};
	doc.dd = sa.open(_, null, {
		volume: "EDI"
	});
	return doc;
}

function _updateSADocument(_, d, encoding) {
	sa.write(_, d.doc.dd, d.doc.properties, new Buffer(d.output, encoding), true);

}

function _removeSADocument(_, name) {
	var doc = sa.listDocuments(_, {
		sdataWhere: "description eq '" + name + "'"
	});
	doc.forEach_(_, function(_, d) {
		d.deleteSelf(_);
	});
}

function _getSADocument(_, name) {
	var list = [];
	sa.listDocuments(_, {
		sdataWhere: "description eq '" + name + "'"
	}).forEach_(_, function(_, doc) {
		var filter = {
			jsonWhere: {
				$uuid: doc.$uuid
			}
		};
		doc.properties = {
			description: name,
			content: {
				contentType: "application/text",
				fileName: doc.fileName(_),
			}
		};
		doc.dd = sa.open(_, filter);
		list.push(doc);
	});
}