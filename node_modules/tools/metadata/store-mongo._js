"use strict";

var mongodb = require('streamline-mongodb');

exports.newStore = function(config, files, readFile) {
	var trace = config.trace;
	var jsondir = config.output;

	var mongoConfig = config.mongo || {};
	var server = new mongodb.Server(mongoConfig.host || "localhost", mongoConfig.port || 27017, {});
	var db = new mongodb.Db(mongoConfig.database || "x3meta", server, {
		w: 1//"majority"
	});

	var DATE_ZERO = new Date("1599-12-31T00:00:00Z");

	function defValue(col) {
		switch (col.CODTYP_0) {
		case 'M':
		case 'L':
			return 0;
		case 'D':
		case 'ATDATIM':
			return DATE_ZERO;
		default:
			return ""; // for now - types not exported yet - need them to get type and length
		}
	}

	function colValue(col, i, data) {
		var v = data[col.CODZONE_0 + '_' + i];
		if (v === undefined) return defValue(col);
		switch (col.CODTYP_0) {
		case 'D':
		case 'ATDATIM':
			return new Date(v);
		}
		return v;
	}
	
	function expandColumn(withType) {
		return function(col) {
			var s = "";
			var dim = col.DIME_0 || 1; // TODO get dim from activity code if missing here
			for (var i = 0; i < dim; i++) s += (s ? "," : "") + col.CODZONE_0 + "_" + i + (withType ? " " + sqlType(col) : "");
			return s;
		};
	}

	function cleanupData(data) {
		// TODO use metadata dimension to decided between array and non array.
		return Array.isArray(data) ? data.map(cleanupData) : Object.keys(data).reduce(function(r, k) {
			var i = k.lastIndexOf('_');
			var v = data[k];
			if (v && typeof v === "object")
				r[k] = cleanupData(v);
			else if (i > 0) {
				var ind = parseInt(k.substring(i + 1));
				k = k.substring(0, i);
				if (ind > 0) {
					r[k] = r[k] || [];
					r[k][ind] = data[k]
				} else {
					r[k] = v;
				}
			} else {
				r[k] =  v;
			}
			return r;
		}, {});
	}

	return {
		open: function(_) {
			db.open(_);
			return this;		
		},
		createTables: function(_) {
			trace && trace("dropping old collections ...");
			var t0 = Date.now();
			var tableNames = db.collectionNames(_).map(function(o) {
				return o.name.substring(o.name.lastIndexOf('.') + 1);
			}).filter(function(s) {
				console.log("s=" + s);
				return files.TABLES[s]
			}); //Object.keys(files.TABLES);
			tableNames.forEach_(_, function(_, name) {
				console.log("dropping " + name);
				db.dropCollection(name, _);
			});
			trace && trace(tableNames.length + " collections dropped in " + Math.round((Date.now() - t0) / 1000) + " seconds");
		},
		fillTables: function(_, entity) {
			trace && trace("inserting " + entity.title + " metadata ...");
			var t0 = Date.now();
			var meta = readFile(_, files.TABLES[entity.tableName]);
			var names = Object.keys(files[entity.subdir] || {});
			var coln = db.collection(entity.tableName, _);
			names.forEach_(_, function(_, name) {
				var data = readFile(_, files[entity.subdir][name]);
				data = cleanupData(data);
				coln.insert(data, _);
			});
			trace && trace(entity.title + ": " + names.length + " resources created in " + Math.round((Date.now() - t0) / 1000) + " seconds");
		},
		fillTexts: function(_) {
			trace && trace("inserting texts ...");
			var t0 = Date.now();
			var names = files.TEXTS;
			var colnATEXTE = db.collection("ATEXTE", _);
			var colnATEXTRA = db.collection("ATEXTRA", _);
			names.forEach_(_, function(_, name) {
				var data = readFile(_, name);
				data = cleanupData(data);
				if (data.TEXTS) colnATEXTRA.insert(data.TEXTS, _);
				else if (Array.isArray(data)) colnATEXTE.insert(data, _);
				else console.log("bad text file: " + name);
			});
			var colnAPLSTD = db.collection("APLSTD", _);
			files.MENUS.forEach_(_, function(_, name) {
				var data = readFile(_, name);
				data = cleanupData(data);
				colnAPLSTD.insert(data, _);
			})
			trace && trace("ATEXTE: " + names.length + " resources created in " + Math.round((Date.now() - t0) / 1000) + " seconds");
		},
		readInstance: function(_, entity, key) {
			var filter = {}
			filter[entity.primaryKey] = key;
			return db.collection(entity.tableName, _).find(filter, _).toArray(_)[0];
		},		
	}
};
