"use strict";
var fs = require('streamline-fs');
var fsp = require("path");
var sys = require("util");
var helpers = require("syracuse-core/lib/helpers");
var flows = require("streamline/lib/util/flows");
var adminHelper = require("syracuse-collaboration/lib/helpers").AdminHelper;
var locale = require("syracuse-core/lib/locale");
var config = require('syracuse-main/lib/nodeconfig').config; // must be first

var traceFilePrefix = "C:\\trace\\";
var chapterDotnet = 10041;
var chapterAdmin = 10036;
var chapterSyracuse = 10031;
var fetchCountX3 = 10000;
var aplStdMaxLength = 123;
var maxLength = aplStdMaxLength - 13;
var maxTotalLength = 123;
var maxNbRecords = 1999;

var isoToX3LangMap = {
	"de-de": "GER",
	"en-us": "ENG",
	"en-gb": "BRI",
	"es-es": "SPA",
	"fr-fr": "FRA",
	"it-it": "ITA",
	"pl-pl": "POL",
	"pt-pt": "POR",
	"pt-br": "BRA",
	"ru-ru": "RUS",
	"zh-cn": "CHI"
}

var chapterBoundings = 5;

var tracer = null;
//var tracer = console.log;

config.session = config.session || {};
config.session.auth = "basic";

helpers.pageFileStorage = false;

var rootpath = fsp.dirname(process.cwd());



function get_tracer(fileName) {
	var internalFileName = traceFilePrefix + fileName;
	var options = {
		flag: 'a+'
	};
	return function(text) {
		var strn = str + "\n";
		fs.appendFileSync(f, new Buffer(strn, 'utf8'), options);
	};
}

function readIndex(_, indexpath, diags, fsModule){
	tracer && tracer("indexpath: " + indexpath);
	var fsModule = fsModule || fs;
	var exists = fsModule.existsSync(indexpath);
	var data = "";
	var fd;
	var index;
	if (exists) {
		data = fsModule.readFile(indexpath, "utf8", _);
	}
	if (data === "") {
		index = {
			count: 0
		};
		tracer && tracer("data is empty ");
	} else {
		try {
			index = JSON.parse(data);
			tracer && tracer("index data " + JSON.stringify(index, null, 2));
		} catch (e) {
			if (diags) diags.push({
				$severity: "error",
				$message: locale.format(module, "incorrectJsonFormat", indexpath)
			});
			//else instance.$addDiagnose('error', locale.format(module, "incorrectJsonFormat", indexpath));
			return null;
		}
	}

	return index;
}

function _splitMessage(message, chunks) {
	var length = message.length;
	var end;
	var beg = 0;
	if (length <= maxTotalLength) {
		end = length;
		chunks.push(message);
	} else {
		end = maxLength;

		var substr = message.substring(beg, end);
		tracer && tracer("substr " + substr);
		var len = end - 1;

		while (!(/\s/.exec(substr[len])) && len > 0) len--;
		chunks.push(message.substring(beg, len + 1));
		if (len === 0 && (!(/\s/.exec(substr[len])))) tracer && tracer("Can not be splitted correctly. Long chunck without white spaces: " + message);
		substr = message.substring(len + 1, length);
		_splitMessage(substr, chunks);

	}

}

function _findMessage(_, coll, lanchp, lannum, chunks) {
	var msg = "";
	tracer && tracer("_findMessage: " + lanchp + ' , ' + lannum);

	coll.some_(_, function(_, item) {
		var num = item.LANNUM(_);
		var chp = item.LANCHP(_);
		if (num && num === lannum && chp && chp === lanchp) {
			var text = item.LANMES(_);
			var match = /&>(([0-9]+)\.)?([0-9]+)$/.exec(text);
			if (match) {
				chunks.push(item.LANMES(_));
				//var line = match[0];
				var chapter = (match[2]) ? parseInt(match[2], 10) : item.LANCHP(_);
				var linenumber = parseInt(match[3], 10);
				tracer && tracer("chapter: " + chapter);
				tracer && tracer("linenumber: " + linenumber);
				var next = _findMessage(_, coll, chapter, linenumber, chunks);
				msg += text.replace(/&>(([0-9]+)\.)?([0-9]+)$/, next);

			} else {
				msg += item.LANMES(_);
				if (chunks) chunks.push(msg);
			}
			return true;
		}
		return false;
	});
	tracer && tracer("chunks: " + JSON.stringify(chunks, null, 2));
	//tracer && tracer("find message returns :  "+msg) ;
	return msg;
}

//provisoire
exports.deleteAll = function(_, instance, options) {
	var chaptersToDelete = [chapterDotnet, chapterAdmin, chapterSyracuse];



	options = options || {};



	chaptersToDelete.forEach_(_, function(_, chapter) {
		var x3Records = db.fetchInstances(_, entity, {
			sdataWhere: "lanchp eq " + chapter + " and LANNUM ne 0 and LANNUM gt 81"
		}); //and LAN eq 'ENG'

		tracer && tracer("x3Records: " + x3Records.length);
		x3Records.forEach_(_, function(_, rec) {
			rec.deleteSelf(_);
		});
	});
};

function _getLanguages(_, x3endpoint) {
	tracer && tracer("_getLanguages");
	var db = adminHelper.getCollaborationOrm(_);
	var localePrefs = db.fetchInstances(_, db.model.getEntity(_, "localePreference"));
	var isoCodesStr = "";
	localePrefs.forEach_(_, function(_, e, idx) {
		isoCodesStr += " '" + e.code(_);
		if (idx < localePrefs.length - 1) isoCodesStr += "', ";
		else isoCodesStr += "' ";
	});

	var isoCodes = localePrefs.map_(_, function(_, e) {
		return e.code(_);
	});
	tracer && tracer("ISO CODES: " + sys.inspect(isoCodes));

	var entity = db.getEntity(_, 'TABLAN', "$query");
	var where = "LANISO in  (";
	isoCodes.forEach_(_, function(_, code, idx) {
		if (idx === 0) where += '"' + code + '"';
		else {
			where += ', ';
			where += '"' + code + '"';
		}

	});
	where += ")";

	tracer && tracer("WHERE: " + where);

	var dbX3 = x3endpoint.getOrm(_);
	var langs = dbX3.fetchInstances(_, entity, {
		sdataWhere: where
	});
	var x3langs = {};
	langs.forEach_(_, function(_, e) {
		tracer && tracer(e.LAN(_) + '  : ' + e.LANISO(_));
		x3langs[e.LAN(_)] = e.LANISO(_).toLowerCase();
	});

	tracer && tracer("X3LANGS: " + sys.inspect(x3langs));

	return x3langs;
}

function _hasErrors(_, inst) {
	return inst.getAllDiagnoses(_).some(function(d) {
		return d.severity === "error";
	});
}

function _injectLongMessage(_, endpoint, message, idxcount, firstChapter, isoLangCode) {
	isoLangCode = isoLangCode || "en-us";
	var x3LangCode = isoToX3LangMap[isoLangCode];
	//
	tracer && tracer("inject long message 1st chp: " + firstChapter);
	tracer && tracer("Splitting long message: " + message);
	var chunks = [];
	_splitMessage(message, chunks);
	tracer && tracer("Chunks: " + sys.inspect(chunks));
	var nbChunks = chunks.length;
	var nbCreatedChuncks = 0;
	var i;
	for (i = 0; i < nbChunks; i++) {
		// id = index.count+1+i ;
		var id = idxcount + i + 1;
		var nextId = id + 1;
		var chp = firstChapter + Math.floor(id / (maxNbRecords + 1));
		var nextChp = firstChapter + Math.floor(nextId / (maxNbRecords + 1));
		if (id % maxNbRecords === 0) id = maxNbRecords;
		else id = id % maxNbRecords;
		if (nextId % maxNbRecords === 0) nextId = maxNbRecords;
		else nextId = nextId % maxNbRecords;

		var chunk;
		if (i === nbChunks - 1) // the last chunk does not contain marker
		chunk = chunks[i];
		else {
			if (nextChp !== chp) chunk = chunks[i] + "&>" + nextChp + '.' + nextId;
			else chunk = chunks[i] + "&>" + nextId;
		}

		tracer && tracer("_createEntry chunk: " + chunk);
		tracer && tracer("_createEntry id: " + id);
		tracer && tracer("_createEntry chapter: " + chp);
		var success = _createEntry(_, endpoint, chp, id, chunk, isoLangCode);
		if (success) nbCreatedChuncks++;
	}

	tracer && tracer("nbCreatedChuncks: " + nbCreatedChuncks);
	return nbCreatedChuncks;
}

function _createEntry(_, endpoint, chapter, id, message, isoLangCode) {
	isoLangCode = isoLangCode || "en-us";
	var x3LangCode = isoToX3LangMap[isoLangCode];
	//
	tracer && tracer("_createEntry chapter:" + chapter + " id:" + id + ' text:' + message);
	tracer && tracer("endpoint " + endpoint.dataset(_));
	try {
		var db = endpoint.getOrm(_);
		var entity = db.getEntity(_, "APLSTD", "$edit");

		var msg = entity.createInstance(_, db);
		msg.LANCHP(_, chapter);
		msg.LANNUM(_, id);
		msg.LAN(_, x3LangCode);
		msg.LANMES(_, message);
		var diags = [];
		msg.save(_);

		msg.getAllDiagnoses(_, diags);
		if (_hasErrors(_, msg)) {
			tracer && tracer("id: " + id);
			tracer && tracer("diagnose after save : " + sys.inspect(diags));
			return false;
		}
		tracer && tracer("success");

	} catch (e) {
		tracer && tracer(e.message ? e.message : e);
		return false;

	}
	return true;
}

function getX3Records(_, db, whereClause, x3Langs, addDiagnoseCallback) {
	var x3Records = {};
	var x3Chunks = {};
	var ancestors = {};
	var entity = db.getEntity(_, "APLSTD", "$query");
	var records = db.fetchInstances(_, entity, {
		count: fetchCountX3,
		sdataWhere: whereClause
	});

	records.forEach_(_, function(_, inst) {
		var match;
		var line;
		var chapter;
		var linenumber;
		tracer && tracer("next record: " + JSON.stringify(inst.serializeInstance(_), null, 2));
		if (!inst.LANNUM(_)) {
			tracer && tracer("ERROR: incorrect record,lannum is missing");
			return addDiagnoseCallback && addDiagnoseCallback("warning", locale.format(module, "incorrectRecord", inst.LANMES(_)));
		}
		// fill an array of translated languages
		if (x3Langs && (x3Langs.indexOf(inst.LAN(_) < 0))) x3Langs.push(inst.LAN(_));

		tracer && tracer("RECORD ID : " + inst.LANNUM(_));
		tracer && tracer("RECORD CHP : " + inst.LANCHP(_));
		tracer && tracer("RECORD LAN : " + inst.LAN(_));
		if (!x3Chunks[inst.LANCHP(_)]) x3Chunks[inst.LANCHP(_)] = {};
		if (!x3Chunks[inst.LANCHP(_)][inst.LAN(_)]) x3Chunks[inst.LANCHP(_)][inst.LAN(_)] = [];
		if (!x3Records[inst.LANCHP(_)]) x3Records[inst.LANCHP(_)] = {};

		tracer && tracer("x3Chunks : " + JSON.stringify(x3Chunks, null, 2));


		var text = inst.LANMES(_);
		match = /&>(([0-9]+)\.)?([0-9]+)$/.exec(text);
		if (match) {
			tracer && tracer("matches : " + match[0]);
			line = match[0];
			chapter = match[2] ? parseInt(match[2], 10) : inst.LANCHP(_);
			linenumber = parseInt(match[3], 10);
			tracer && tracer("chapter: " + chapter);
			tracer && tracer("linenumber: " + match[3]);
			if (!x3Chunks[chapter]) x3Chunks[chapter] = {};
			if (!x3Chunks[chapter][inst.LAN(_)]) x3Chunks[chapter][inst.LAN(_)] = [];
			x3Chunks[chapter][inst.LAN(_)].push(linenumber);
			tracer && tracer("x3Chunks[" + chapter + "][" + inst.LAN(_) + "].push " + linenumber);

			if (!ancestors[chapter]) ancestors[chapter] = {};
			if (!ancestors[chapter][inst.LAN(_)]) ancestors[chapter][inst.LAN(_)] = {};
			text = text.replace(line, "");
			ancestors[chapter][inst.LAN(_)][linenumber] = {
				chapter: inst.LANCHP(_),
				lang: inst.LAN(_),
				id: inst.LANNUM(_),
				text: text
			};

		}

		if (x3Chunks[inst.LANCHP(_)][inst.LAN(_)].indexOf(inst.LANNUM(_)) === -1) {
			if (!x3Records[inst.LANCHP(_)][inst.LANNUM(_)]) x3Records[inst.LANCHP(_)][inst.LANNUM(_)] = {};
			if (!match) x3Records[inst.LANCHP(_)][inst.LANNUM(_)][inst.LAN(_)] = inst.LANMES(_);

		} else if (!match) { // (x3Chunks[inst.LANCHP(_)][inst.LAN(_)].indexOf(inst.LANNUM(_)) !== -1) {
			var ancestor = ancestors[inst.LANCHP(_)][inst.LAN(_)][inst.LANNUM(_)];
			tracer && tracer("last chunk text" + text);
			tracer && tracer("ancestor" + sys.inspect(ancestor));

			var root;
			while (ancestor) {
				root = ancestor;

				//tracer && tracer("ancestors: " + JSON.stringify(ancestors,null,2));
				text = ancestor.text + text;
				//text=ancestor.text ;
				ancestor = ancestors[ancestor.chapter] && ancestors[ancestor.chapter][inst.LAN(_)] && ancestors[ancestor.chapter][inst.LAN(_)][ancestor.id];
				tracer && tracer("ancestor" + sys.inspect(ancestor));
			}
			tracer && tracer("end while");
			x3Records[root.chapter][root.id][inst.LAN(_)] = text;
			tracer && tracer("x3Records[" + root.chapter + "][" + root.id + "]=" + JSON.stringify(x3Records[root.chapter][root.id], null, 2));

		}

	});
	tracer && tracer("X3RECORDS: " + JSON.stringify(x3Records, null, 2));
	return x3Records;
}

function _updateEntry(_, endPoint, key, text, firstChapter, chp, lannum, chunks, idxcount, isoLangCode) {

	tracer && tracer("_updateEntry " + lannum + ' new value: ' + text);

	isoLangCode = isoLangCode || "en-us";
	var x3LangCode = isoToX3LangMap[isoLangCode];
	var db = endPoint.getOrm(_);

	var entity = db.getEntity(_, "APLSTD", "$edit");
	var msg = db.fetchInstance(_, entity, {
		sdataWhere: "LANCHP eq " + chp + " and LANNUM eq " + lannum + " and LAN eq '" + x3LangCode + "'"
	});
	tracer && tracer("old value: " + msg.LANMES(_));
	var incr = 0;
	var diags;
	if (text.length > maxTotalLength) {
		var oldChunks = chunks;
		tracer && tracer("old chunks " + JSON.stringify(oldChunks, null, 2));
		var newChunks = [];
		_splitMessage(text, newChunks);
		tracer && tracer("new chunks " + JSON.stringify(newChunks, null, 2));
		var i;
		var newValue;

		for (i = 0; i < (newChunks.length - 1); i++) {
			tracer && tracer("i: " + i);
			if (oldChunks[i]) {
				var match = /&>(([0-9]+)\.)?([0-9]+)$/.exec(oldChunks[i]);
				if (match) {
					var line = match[0];
					var chapter = match[2] ? parseInt(match[2], 10) : msg.LANCHP(_);
					var linenumber = parseInt(match[3], 10);
					tracer && tracer("chapter: " + chapter);
					tracer && tracer("linenumber: " + linenumber);

					newValue = newChunks[i] + line;
					msg.LANMES(_, newValue);
					msg.save(_);

					msg = db.fetchInstance(_, entity, {
						sdataWhere: "LANCHP eq " + chapter + " and LAN eq '" + x3LangCode + "' and LANNUM eq " + linenumber
					});
					tracer && tracer("old value: " + msg.LANMES(_));
				} else { // last oldChunk
					tracer && tracer("last old chunck: ");

					var nextid = idxcount + incr + 1;
					var nextchapter = firstChapter + Math.floor(nextid / (maxNbRecords + 1));
					tracer && tracer("nextid: " + nextid);

					if (nextid % maxNbRecords === 0) nextid = maxNbRecords;
					else nextid = nextid % maxNbRecords;
					tracer && tracer("nextid: " + nextid);
					tracer && tracer("nextchapter: " + nextchapter);

					var nextmsg = entity.createInstance(_, db /*, {LANCHP : nextchapter, LANNUM : nextid, LAN : "ENG" , LANMES : " " }*/ );
					nextmsg.LANCHP(_, nextchapter);
					nextmsg.LANNUM(_, nextid);
					nextmsg.LAN(_, x3LangCode);
					nextmsg.LANMES(_, " ");
					diags = [];
					nextmsg.save(_);

					tracer && tracer("nxtmsg: " + JSON.stringify(nextmsg.serializeInstance(_), null, 2));
					nextmsg.getAllDiagnoses(_, diags);

					//tracer && tracer("diags for nxtmsg: "+sys.inspect(diags)) ;
					if (_hasErrors(_, nextmsg)) {
						tracer && tracer("id: " + nextid);
						tracer && tracer("diagnose after create next message: " + JSON.stringify(diags, null, 2));
						return -1;
					}
					incr++;
					tracer && tracer("success next message");

					if (nextchapter > chp) newValue = newChunks[i] + "&>" + nextchapter + "." + nextid;
					else newValue = newChunks[i] + "&>" + nextid;
					oldChunks.push("");
					tracer && tracer("oldChunks: " + sys.inspect(oldChunks));
					msg.LANMES(_, newValue);
					msg.save(_);

					diags = [];
					msg.getAllDiagnoses(_, diags);
					if (_hasErrors(_, msg)) {
						tracer && tracer("id: " + lannum);
						tracer && tracer("updateEntry: diagnose after save : " + sys.inspect(diags));
						return -1;
					} else tracer && tracer("update success for id " + lannum);

					msg = nextmsg;

				}
			}
		} //for

		//last chunk

		var last = newChunks.length - 1;
		tracer && tracer("last chunk: " + last);
		tracer && tracer("last chunk: " + newChunks[last]);
		if (msg) {
			msg.LANMES(_, newChunks[last]);
			msg.save(_);
			diags = [];
			msg.getAllDiagnoses(_, diags);
			if (_hasErrors(_, msg)) {
				tracer && tracer("id: " + lannum);
				tracer && tracer("updateEntry: diagnose after save : " + sys.inspect(diags));
				return -1;
			} else tracer && tracer("success for id " + last);
		}
	} else { //short messages
		msg.LANMES(_, text);
		msg.save(_);
		diags = [];
		msg.getAllDiagnoses(_, diags);
		if (_hasErrors(_, msg)) {
			tracer && tracer("id: " + lannum);
			tracer && tracer("updateEntry: diagnose after save : " + sys.inspect(diags));
			return -1;
		} else tracer && tracer("success for id " + lannum);
	}

	//ckeckDiagnoses(result) ;

	return incr;
}

/**************************TRANSLATION OF TEXTS IN JSON FILES IN THE RESOURCE FOLDERS********************/

//Syracuse->X3
exports.extractResources = function(_, instance, options, context) {
	var self = this;
	self.context = context;
	//tracer=trace ;
	//tracer && tracer("parameters: " + sys.inspect(options));

	function extract(_, file) {

		function _checkEntry(_, key, message) {
			var incr = 0;
			tracer && tracer("_checkEntry key: " + key);
			var relpath = fsp.relative(rootpath, fpath);
			var dirkey = relpath.replace(/\\/g, '\/');
			tracer && tracer("_checkEntry dirkey: " + dirkey);
			//tracer && tracer("index: "+JSON.stringify(index,null,2)) ;
			var success = false;
			var seg = index[dirkey];

			var chunks;
			var chp;
			var id;

			if (seg && seg[key]) {
				var el = seg[key];
				tracer && tracer("index[" + dirkey + "][" + key + "]=" + index[dirkey][key]);
				tracer && tracer("looking for id: " + index[dirkey][key].id);
				tracer && tracer("looking for chp: " + index[dirkey][key].chp);
				chunks = [];
				var x3message = _findMessage(_, x3Records, el.chp, el.id, chunks);
				if (x3message !== "") {
					tracer && tracer("x3message " + x3message);
					if (message !== el.text) {
						tracer && tracer("modifyed in Syracuse" + seg + ' ' + el.text);
						if (x3message !== index[dirkey][key].text) {
							tracer && tracer(" update conflict for " + dirkey + ":" + key);
							if (options && options.$diagnoses) options.$diagnoses.push({
								severity: "warning",
								message: locale.format(module, "updateConflict", dirkey + ":" + key, x3message)
							});
							else instance.$addDiagnose("warning", locale.format(module, "updateConflict", dirkey + ":" + key, x3message));
						} else {
							tracer && tracer("update entry");
							el.text = message;
							id = seg[key].id;
							var nb = _updateEntry(_, endPoint, key, message, chapterSyracuse, seg[key].chp, id, chunks, index.count);
							index.count += nb;

						}
					}
				} else {
					// this situation should not happen. It means some records has been deleted from X3 since the last extraction
					// while testing it is better to delete the index file when emptiing the X3 chapters
					if (options && options.$diagnoses) options.$diagnoses.push({
						severity: 'error',
						message: locale.format(module, "indexMess", dirkey, key)
					});
					else instance.$addDiagnose('error', locale.format(module, "indexMess", dirkey, key));
				}

			} else {
				if (typeof message !== "string") {
					if (options && options.$diagnoses) options.$diagnoses.push({
						severity: 'error',
						message: locale.format(module, "incorrectType", dirkey, key)
					});
					else instance.$addDiagnose('error', locale.format(module, "incorrectType", dirkey, key));
					tracer && tracer("Value is not a string ; Christie should fix the format");
					tracer && tracer(sys.inspect(message));
					return;
				}
				tracer && tracer("new message: " + message);
				tracer && tracer("length: " + message.length);
				if ((index.count + 1) % maxNbRecords === 0) id = maxNbRecords;
				else id = (index.count + 1) % maxNbRecords;
				chp = chapterSyracuse + Math.floor((index.count + 1) / (maxNbRecords + 1));
				if (chp > chapterSyracuse + chapterBoundings) {
					if (options && options.$diagnoses) options.$diagnoses.push({
						severity: "error",
						message: locale.format(module, "chapterFull", chapterSyracuse + chapterBoundings, "syracuse texts")
					});
					else instance.$addDiagnose('error', module, "chapterFull", chapterSyracuse + chapterBoundings, "syracuse texts");

					return;
				}

				if (message.length > maxTotalLength) incr = _injectLongMessage(_, instance.endpoint(_), message, index.count, chapterSyracuse);
				else {
					tracer && tracer("inject message " + dirkey + ":" + key);
					try {

						success = _createEntry(_, instance.endpoint(_), chp, id, message);
						if (success) incr++;
					} catch (ex) {
						if (options && options.$diagnoses) options.$diagnoses.push({
							severity: 'error',
							message: locale.format(module, "x3error")
						});

						tracer && tracer(_, "exception in createEntry: " + ex.stack);
					}
				}

				if (!index[dirkey]) index[dirkey] = {};

				if (!index[dirkey][key]) { //add to the index
					tracer && tracer("index.count:  " + index.count);
					index[dirkey][key] = {
						chp: chapterSyracuse + Math.floor((index.count + 1) / (maxNbRecords + 1)),
						id: id, // (index.count + 1)%maxNbRecords,
						text: message
					};
					index.count += incr;
				}
			}
		}

		var pos = file.indexOf("-en.json");
		var parsed;
		if (pos !== -1) {
			var fpath = fsp.join(dir, "resources", file);
			// console.log("fpath: " + fpath);
			var input = fs.readFile(fpath, "utf8", _);
			try {
				parsed = JSON.parse(input);
			} catch (e) {
				if (options && options.$diagnoses) options.$diagnoses.push({
					severity: 'error',
					message: locale.format(module, "incorrectJsonFormat", fpath)
				});
				else instance.$addDiagnose(module, "incorrectJsonFormat", fpath);
				return;
			}

			//tracer && tracer("PARSED: " + JSON.stringify(parsed,null,2));
			flows.eachKey(_, parsed, _checkEntry);
		}
	}

	function walk(_, file) {
		var path = fsp.join(dir, file); // dir + '\\' + file;
		//tracer && tracer("walk PATH "+path) ;
		var stat = fs.stat(path, _);
		var dircontent;
		if (stat.isDirectory()) {
			if (file === "resources") {
				dircontent = fs.readdir(path, _);
				tracer && tracer("call extract " + sys.inspect(dircontent));
				dircontent.forEach_(_, extract);
			} else {
				dircontent = fs.readdir(path, _);
				var temp = dir;
				dir = path;
				dircontent.forEach_(_, walk);
				dir = temp;
			}
		}
	}

	tracer && tracer("extract texts");

	var endPoint = instance.endpoint(_);

	options = options || {};
	maxNbRecords = options.maxNbRecords || maxNbRecords;

	var db = endPoint.getOrm(_);
	var entity;
	entity = db.getEntity(_, "APLSTD", "$bulk");

	var whereClause = "LANCHP ge " + chapterSyracuse + " and LANCHP le " + (chapterSyracuse + 4) + " and LANNUM ne 0";

	var x3Records = db.fetchInstances(_, entity, {
		count: fetchCountX3,
		sdataWhere: whereClause
	});
	if (x3Records.length >= fetchCountX3) {
		throw new Error("Error: Maximum records to read is " + fetchCountX3 + " and this amount of records has been fetched. Aborting since some records may not be processed otherwise!");
	}
	tracer && tracer("x3Records read: " + x3Records.length);

	var dir;
	if (options.dir) dir = fsp.join(__dirname, "../../", options.dir);
	else dir = fsp.join(__dirname, "../../", "");
	var indexdir;


	// default index dir is translation-indexes; if indexdir is given by options, it has to be a full path
	//if (options.indexdir) indexdir = fsp.join(__dirname, "../../", options.indexdir);
	//else indexdir = fsp.join(__dirname, "../lib");
	indexdir = options.indexdir || fsp.join(__dirname, "../../../translation-indexes");

	var indexpath = fsp.join(indexdir, "index.json");
	var diags=options && options.$diagnoses ;
	var index= readIndex(_, indexpath, diags, options.indexFiler);


	var dircontent = fs.readdir(dir, _);
	dircontent.forEach_(_, walk);
	var fd = fs.open(indexpath, "w+", "0666", _);

	fs.writeFile(indexpath, JSON.stringify(index, null, "\t"), "utf8", _);
	fs.close(fd, _);
};

//X3->Syracuse
exports.updateResources = function(_, instance, options, context) {
	function updFile(_, k) {
		tracer && tracer("updFile: " + k);

		function saveData(_, rec, dataBuffers, filePaths) {

			tracer && tracer("save data filePaths: " + JSON.stringify(filePaths));
			flows.eachKey(_, filePaths, function(_, lang, file) {

				try {
					tracer && tracer("write to file: " + file + " content: " + JSON.stringify(dataBuffers[lang]));
					fs.writeFile(file, JSON.stringify(dataBuffers[lang], null, "\t"), "utf8", _);
					//fs.close(fd, _);
				} catch (ex) {
					tracer && tracer("Error writing in file " + file);
					tracer && tracer("stack " + ex.stack);
				}
			});
		}

		function updData(_, key, el) {
			tracer && tracer("updData: " + key + ' ' + JSON.stringify(el, null, 2));

			function loadLocalData(_, rec, dataBuffers) {
				tracer && tracer("loadLocalData for rec: " + JSON.stringify(rec, null, 2));
				flows.eachKey(_, rec, function(_, lang) {
					if (dataBuffers[lang]) return;

					var file;
					var exists;
					var data;

					if (langFname[lang] === "en-us") file = fsp.join(rootpath, dirname, base + "-en" + ".json");
					else file = fsp.join(rootpath, dirname, base + "-" + langFname[lang] + ".json");

					exists = fs.existsSync(file);
					if (exists) {
						filePaths[lang] = file;
						data = fs.readFile(file, "utf8", _);
						try {
							dataBuffers[lang] = JSON.parse(data);
						} catch (e) {
							if (options && options.$diagnoses) options.$diagnoses.push({
								severity: "error",
								message: locale.format(module, "incorrectJsonFormat", file)
							});
							else instance.$addDiagnose("error", locale.format(module, "incorrectJsonFormat", file));
							tracer && tracer("incorrectJsonFormat " + file);
							return;
						}
					} else {

						if (lang === "ENG") {
							tracer && tracer("resources file deleted or moved: " + file);
							if (options && options.$diagnoses) options.$diagnoses.push({
								severity: "warning",
								message: locale.format(module, "missingFile", file)
							});
							else instance.$addDiagnose("warning", locale.format(module, "missingFile", file));
							dataBuffers[lang] = null;
							//return;
						} else dataBuffers[lang] = {};
					}

				});
				tracer && tracer("loadLocalData dataBuffers: " + JSON.stringify(dataBuffers, null, 2));
			}

			var chapter = chapterSyracuse + Math.floor(el.id / (maxNbRecords + 1));
			var rec = x3Records[chapter] && x3Records[chapter][el.id];
			if (rec) {
				tracer && tracer("loadLocalData for record" + sys.inspect(rec));
				loadLocalData(_, rec, dataBuffers);
				flows.eachKey(_, langFname, function(_, lang) {
					if (rec[lang]) {
						tracer && tracer("rec[" + lang + "]: " + sys.inspect(rec[lang]));
						if (!dataBuffers[lang]) // file delete or moved
						return;
						if (!filePaths[lang]) {
							tracer && tracer("!filePaths[lang]");
							var file;
							if (lang === 'ENG') file = fsp.join(rootpath, dirname, base + "-en" + ".json");
							else file = fsp.join(rootpath, dirname, base + "-" + langFname[lang] + ".json");

							filePaths[lang] = file;
							tracer && tracer("filePaths[" + lang + "]=" + filePaths[lang]);
						}
						if (lang !== 'ENG') {
							tracer && tracer("lang !== 'ENG'");

							dataBuffers[lang][key] = rec[lang];
						} else if (rec[lang] !== el.text) {
							tracer && tracer("modifyed in X3 " + k + ' ' + key + ' old value: ' + el.text + " new value: " + k + ' ' + key + ' txt: ' + rec[lang]);
							if (!dataBuffers[lang][key]) {
								if (options && options.$diagnoses) options.$diagnoses.push({
									severity: "error",
									message: locale.format(module, "missingReference", k, key)
								});
								else instance.$addDiagnose("error", locale.format(module, "missingReference", k, +key));
								return;
							}
							tracer && tracer("****lang: " + lang + "  key: " + key);
							tracer && tracer("dataBuffers lang: " + lang + ' ' + JSON.stringify(dataBuffers, null, 2));

							//if (dataBuffers[lang][key] !== index[k][key].text) {
							if (dataBuffers[lang][key] !== el.text) {
								tracer && tracer(" update conflict for " + k + ":" + key);
								if (options && options.$diagnoses) options.$diagnoses.push({
									severity: "warning",
									message: locale.format(module, "updateConflict", k + ":" + key, rec[lang])
								});
								else instance.$addDiagnose("warning", locale.format(module, "updateConflict", k + ":" + key, rec[lang]));
							} else {
								tracer && tracer("update record lang: " + lang + "key: " + key);
								dataBuffers[lang][key] = rec[lang];
							}
						} else {
							tracer && tracer(rec[lang] + " ==  " + el.text);
						}
					} else {
						tracer && tracer("!rec[" + lang + "]");
					}
				});
				tracer && tracer("data buffers: " + sys.inspect(dataBuffers));
				saveData(_, rec, dataBuffers, filePaths /*, fileHandlers*/ );
			}
		} // updData

		var base = fsp.basename(k, "-en.json").replace(/\//g, fsp.sep);
		var dirname = fsp.dirname(k).replace(/\//g, fsp.sep);
		//var fileHandlers = {};
		var filePaths = {};
		var dataBuffers = {};
		tracer && tracer("index[" + k + "]=" + JSON.stringify(index[k], null, 2));
		if (k === "count") return;

		flows.eachKey(_, index[k], updData);

	}

	//tracer=trace_update ;
	tracer && tracer("update resources");
	var self = this;
	self.context = context;
	options = options || {};

	var endPoint = instance.endpoint(_);
	var db = endPoint.getOrm(_);

	tracer && tracer("endPoint name " + endPoint.dataset(_));

	var langFname = _getLanguages(_, instance.endpoint(_));
	tracer && tracer("languages: " + JSON.stringify(langFname));
	var index;

	var whereClause = "LANCHP ge " + chapterSyracuse + " and LANCHP le " + (chapterSyracuse + 4) + " and LANNUM ne 0";
	tracer && tracer("whereClause: " + whereClause);
	var x3Records = getX3Records(_, db, whereClause);
	tracer && tracer("X3Records: " + JSON.stringify(x3Records, null, 2));

	var dir;
	var indexdir;
	if (options.dir) dir = fsp.join(__dirname, "../../", options.dir);
	else dir = fsp.join(__dirname, "../../", "");

	// default index dir is translation-indexes; if indexdir is given by options, it has to be a full path
	//if (options.indexdir) indexdir = fsp.join(__dirname, "../../", options.indexdir);
	//else indexdir = fsp.join(__dirname, "../lib");
	indexdir = options.indexdir || fsp.join(__dirname, "../../../translation-indexes");

	var indexpath = fsp.join(indexdir, "/index.json");
	tracer && tracer("indexpath: " + indexpath);

	var diags=options && options.$diagnoses ;
	var index=readIndex(_, indexpath, diags, options.indexFiler) ; 
	if (!index) return ;

	flows.eachKey(_, index, updFile);

};

/**************************TRANSLATION OF SYRACUSE ADMIN RESSOURCES********************/

//Syracuse->X3
exports.extractAdminResources = function(_, instance, options, context) {
	//tracer=trace_extract_admin ;

	function _extractAllLang(_, fpath, fname, fsModule) {
		tracer && tracer("_extract path: " + fpath);
		var contentStr = (fsModule || fs).readFile(fpath, "utf8", _);
		try {
			var jsonContent = JSON.parse(contentStr);
			tracer && tracer("index data " + JSON.stringify(index, null, 2));
		} catch (e) {
			return _addDiagnose('error', locale.format(module, "incorrectJsonFormat", fpath));
		}
		
		Object.keys(jsonContent.$localization || {}).filter(function(lang) {
			return options.extractAllLanguages || (lang.toLowercase() === "en-us");
		}).forEach_(_, function(_, lang) {
			if (!isoToX3LangMap[lang]) return _addDiagnose("error", locale.format(module, "unknownLangMap", lang));
			//
			var indexpath = fsp.join(indexdir, "indexAdmin" + "-" + lang + ".json");
			var diags = options && options.$diagnoses ;
			index = readIndex(_, indexpath, diags, options.indexFiler) ; 
			if (!index) return ;
			//
			var entity = db.getEntity(_, "APLSTD", "$bulk");
			var whereClause = "LANCHP ge " +chapterAdmin+ " and LANCHP le "+ (chapterAdmin + 4)+ " and LANNUM ne 0 and LAN eq \"" + isoToX3LangMap[lang] + "\"";
			x3Records = db.fetchInstances(_, entity, {
				count: fetchCountX3,
				sdataWhere: whereClause
			});
			tracer && tracer("x3Records read: " + x3Records.length);
			if (x3Records.length >= fetchCountX3) {
				throw new Error("Error: Maximum records to read is " + fetchCountX3 + " and this amount of records has been fetched. Aborting since some records may not be processed otherwise!");
			}
			//
			_extract(_, jsonContent.$localization[lang], fname, lang);
			//
			(options.indexFiler || fs).writeFile(indexpath, JSON.stringify(index, null, "\t"), "utf8", _);
		});
	}
	function _extract(_, localizationRef, fname, isoLangCode) {
		var isoLangCode = isoLangCode || "en-us";
		var success = false;

		flows.eachKey(_, localizationRef, function(_, key, val) {
			if (val && (options.longMessagesStrategy === "truncate") && (val.length > aplStdMaxLength)) {
				val = val.substring(0, aplStdMaxLength);
				_addDiagnose("warning", locale.format(module, "msgTooLong", fname, key, aplStdMaxLength, val));
			}
			if (index[fname] && index[fname][key]) {
				var el = index[fname][key];
				var x3message = _findMessage(_, x3Records, index[fname][key].chp, index[fname][key].id);
				if (x3message !== "") {
					tracer && tracer("_checkEntry message " + x3message);
					tracer && tracer("localizationRef[key] :" + localizationRef[key]);
					tracer && tracer("index[" + fname + "][" + key + "].text :" + index[fname][key].text);
					if (localizationRef[key] !== index[fname][key].text) {
						tracer && tracer("modifyed in Syracuse " + index[fname][key].text + ' ' + localizationRef[key]);
						if (x3message !== index[fname][key].text) {
							tracer && tracer(" update conflict for " + key);
							_addDiagnose("warning", locale.format(module, "updateConflict", fname + ":" + key, x3message));
						} else {
							tracer && tracer("update entry");
							el.text = localizationRef[key];
							var chunks = [];
							var nb = _updateEntry(_, endPoint, key, localizationRef[key], chapterAdmin, chapterAdmin, el.id, chunks, index.count, isoLangCode);
							index.count += nb;
						}
					}
				} else {
					// this situation should not happen. It means some records has been deleted from X3 since the last extraction
					// while testing it is better to delete the index file when emptiing the X3 chapters
					_addDiagnose('error', locale.format(module, "indexMess", fname, key));
				}
			} else {
				var id;
				var incr = 0;
				var chp;
				tracer && tracer("inject message " + key);
				
				chp = chapterAdmin + Math.floor((index.count + 1) / (maxNbRecords + 1));
				if (chp>chapterAdmin+chapterBoundings) {
					return _addDiagnose('error',module, "chapterFull", chapterAdmin+chapterBoundings, "admin resources");
				}
				if ((index.count + 1) % maxNbRecords === 0) 
					id = maxNbRecords;
				else 
					id = (index.count + 1) % maxNbRecords;

				if (val && (val.length > aplStdMaxLength)) 
					incr = _injectLongMessage(_, endPoint, val, index.count, chapterAdmin, isoLangCode);
				else {
					success = _createEntry(_, endPoint, chp, id, val, isoLangCode);
					if (success) 
						incr += 1;
					else {
						return _addDiagnose('error', locale.format(module, "createEntryfail", key, fname));
					}
				}
				if (!index[fname]) index[fname] = {};

				if (!index[fname][key]) { //add to the index
					index[fname][key] = {
						chp: chp,
						id: id,
						text: val
					};
					index.count += incr;
				}
			}
		});
	}

	options = options || {};
	var _addDiagnose = (options.$diagnoses || !instance) ? function(severity, message) {
		options.$diagnoses && options.$diagnoses.push({
			$severity: severity,
			$message: message
		});
	} : (instance && instance.$addDiagnoses);
	//
	var self = this;
	self.context = context;

	var endPoint = options.endpoint || (instance && instance.endpoint(_));
	if (!endPoint) throw new Error(locale.format(module, "noSourceEndpoint"));
	var db = endPoint.getOrm(_);

	var index;
	var x3Records;
	
	tracer && tracer("extract admin resources: ");
	var dir;
	var indexdir;
	if (options.dir) dir = options.dir;
	else dir = fsp.join(__dirname, "../../", "");
	// default index dir is translation-indexes; if indexdir is given by options, it has to be a full path
	//if (options.indexdir) indexdir = fsp.join(__dirname, "../../", options.indexdir);
	//else indexdir = fsp.join(__dirname, "../lib");
	indexdir = options.indexdir || fsp.join(__dirname, "../../../translation-indexes");

	var path;
	if (options.exportFile) {
		path = dir;

		_extractAllLang(_, fsp.join(path, options.exportFile), options.exportFile, options.inputFiler);
	} else {
		path = fsp.join(__dirname, "../../../import");
		var stat = fs.stat(path, _);
		if (stat.isDirectory()) {
			var dircontent = fs.readdir(path, _);

			dircontent.forEach_(_, function(_, fnam) {
				_extractAllLang(_, fsp.join(path, fnam), fnam, options.inputFiler);

			});
		}
	}
};

//X3->Syracuse
exports.updateAdminResources = function(_, instance, options, context) {
	//tracer = trace_update_admin;

	function _update(_, fname) {

		var fpath = fsp.join(path, fname);
		tracer && tracer("-update fpath: " + fpath);
		var fsModule = (options.dataFiler || fs);
		var contentStr = fsModule.readFile(fpath, "utf8", _);

		try {
			var jsonContent = JSON.parse(contentStr);
			tracer && tracer("index data " + JSON.stringify(index, null, 2));
		} catch (e) {
			return _addDiagnose('error', locale.format(module, "incorrectJsonFormat", fpath));
		}


		var localization = jsonContent.$localization;

		var langFname = _getLanguages(_, endPoint);
		tracer && tracer("LANGS: " + sys.inspect(langFname));

		flows.eachKey(_, index[fname], function(_, locCode, el) {

			if (locCode === 'count') return;
			/*
			var chapter = chapterAdmin + Math.floor(el.id / (maxNbRecords + 1));
			var rec = x3Records[chapter] && x3Records[chapter][el.id];
			*/
			var rec = x3Records[el.chp][el.id];
			if (rec) {
				flows.eachKey(_, langFname, function(_, lang, isolang) {
					if (rec[lang]) {
						tracer && tracer("update " + localization[isolang][locCode] + " with " + rec[lang]);
						if (!localization[isolang]) localization[isolang] = {};
						localization[isolang][locCode] = rec[lang];
					}
				});
			}
		});
		fsModule.writeFile(fpath, JSON.stringify(jsonContent, null, "\t"), "utf8", _);
	}

	tracer && tracer("update Admin resources");
	var self = this;
	self.context = context;
	options = options || {};
	var _addDiagnose = (options.$diagnoses || !instance) ? function(severity, message) {
		options.$diagnoses && options.$diagnoses.push({
			$severity: severity,
			$message: message
		});
	} : (instance && instance.$addDiagnoses);
	//
	var x3Langs = [];

	var endPoint = options.endpoint || (instance && instance.endpoint(_));
	var db = endPoint.getOrm(_);

	var whereClause = "LANCHP ge " +chapterAdmin+ " and LANCHP le "+ (chapterAdmin + 4)+ " and LANNUM ne 0";
	
	var x3Records = getX3Records(_, db, whereClause, x3Langs, _addDiagnose);
	tracer && tracer("X3Records: " + JSON.stringify(x3Records, null, 2));

	var exclude = ["syracuse-admin-demo.json", "syracuse-sprint1-demo.json"];
	var dir;
	// default index dir is translation-indexes; if indexdir is given by options, it has to be a full path !!!
	//if (options.indexdir) indexdir = fsp.join(__dirname, "../../", options.indexdir);
	//else indexdir = fsp.join(__dirname, "../lib");
	var indexdir = options.indexdir || fsp.join(__dirname, "../../../translation-indexes");
	var index;
	if (options.dir) dir = options.dir;
	else dir = fsp.join(__dirname, "../../");

	// start from en-us index
	var indexpath = fsp.join(indexdir, "/indexAdmin-en-us.json");
	tracer && tracer("indexpath: " + indexpath);
	index = readIndex(_, indexpath, options.$diagnoses, options.indexFiler);

	var path;
	if (options.exportFile) {
		path = dir;

		_update(_, options.exportFile);
	} else {

		path = fsp.join(__dirname, "../../../import");

		var stat = fs.stat(path, _);

		if (stat.isDirectory()) {
			var dircontent = fs.readdir(path, _);
			dircontent.filter(function(elt) {
				if (exclude.indexOf(elt) === -1) return true;
				else return false;
			});
			dircontent.forEach_(_, _update);
		}
	}
};

/**************************TRANSLATION OF DOTNET RESSOURCES ********************/

//Syracuse->X3
exports.extractDotnetResources = function(_, instance, options, context) {
	var self = this;
	self.context = context;
	//tracer = trace_dotnet_extract;
	tracer && tracer("parameters: " + sys.inspect(options));
	var fd;

	function extract(_, file) {

		function _checkEntry(_, key, message, fpath) {
			var relpath = fsp.relative(rootpath, fpath);
			var dirkey = relpath.replace(/\\/g, '\/');
			var success = false;
			var seg = index[dirkey];
			var incr = 0;
			var chunks;
			tracer && tracer("extract : " + dirkey + ' ' + key);
			tracer && tracer("index[dirkey] : " + JSON.stringify(index[dirkey], null, 2));
			if (seg && seg[key]) {
				var el = seg[key];
				tracer && tracer("index[" + dirkey + "][" + key + "]=" + el.id);
				chunks = [];

				var x3message = _findMessage(_, x3Records, el.chp, el.id, chunks);
				if (x3message !== "") {
					tracer && tracer("index message: " + seg[key].text);
					tracer && tracer("x3message:     " + x3message);
					tracer && tracer("syra message:  " + message);
					//  
					if (message !== el.text) {
						tracer && tracer("modifyed in Syracuse" + key + ' ' + el.text);
						if (x3message !== el.text) {
							tracer && tracer("conflict for " + dirkey + ":" + key);
							_addDiagnose("warning", locale.format(module, "updateConflict", dirkey + ":" + key, x3message));
						} else {

							el.text = message;
							var nb = _updateEntry(_, endPoint, key, message, chapterDotnet, el.chp, el.id, chunks, index.count);
							/*if (index.count<=maxNbRecords && index.count+nb>maxNbRecords)
								currentChapter++ ;*/
							index.count += nb;
							if (nb >= 0) success = true;

						}
					}
				} else {

					tracer && tracer("inject message " + dirkey + ":" + key);
					try {

						success = _createEntry(_, endPoint, el.chp, el.id, message);
						if (success) incr += 1;
					} catch (ex) {
						tracer && tracer(" exception in createEntry: " + ex.stack);
						
						(options.indexFiler || fs).writeFile(indexpath, JSON.stringify(index, null, "\t"), "utf8", _);
					}
				}
			} else {
				if (typeof message !== "string") {
					_addDiagnose('error', locale.format(module, "incorrectType", dirkey, key));

					tracer && tracer("Value is not a string ; Christie should fix the format");
					tracer && tracer(sys.inspect(message));
					return;
				}

				var id;
				var chp;

				if ((index.count + 1) % maxNbRecords === 0) id = maxNbRecords;
				else id = (index.count + 1) % maxNbRecords;
				chp = chapterDotnet + Math.floor((index.count + 1) / (maxNbRecords + 1));

				if (chp>chapterDotnet+chapterBoundings) {
					return _addDiagnose('error',module, "chapterFull", chapterDotnet+chapterBoundings, "dotnet resources");
				}

				if (message.length > maxTotalLength) {
					incr = _injectLongMessage(_, endPoint, message, index.count, chapterDotnet);
					if (incr >= 0) success = true;
				} else {

					tracer && tracer("inject message " + dirkey + ":" + key);
					tracer && tracer("inject message id" + id + " chp: " + chp);
					try {
						success = _createEntry(_, endPoint, chp, id, message);
						if (success) incr += 1;
					} catch (ex) {
						tracer && tracer(_, "exception in createEntry: " + ex.stack);
					}
				}
				if (success) {
					if (!index[dirkey]) index[dirkey] = {};

					if (!index[dirkey][key]) { //add to the index
						index[dirkey][key] = {
							chp: chp,
							id: id,
							text: message
						};
						index.count += incr;
					}
				}
			}
		}

		if (fsp.extname(file) !== ".resx") return;

		tracer && tracer("testing file : " + file);
		var basename = fsp.basename(file, ".resx");
		var langext = fsp.extname(basename);
		if (langext !== "") {
			tracer && tracer("rejected file : " + file);
			return;
		}

		var fpath = fsp.join(dir, file);
		tracer && tracer("process file : " + fpath);
		var xml;
		xml = (options.inputFiler || fs).readFile(fpath, _).toString("utf8"); //fs.readFile(fpath, "utf8", _);

		// remove xml comments
		xml = xml.replace(/<!--([\s\S]*?)-->/gm, "");

		var regex = /<data*\sname="([\s\S]*?)"([\s\S]*?)<value>([\s\S]*?)<\/value>([\s\S]*?)<\/data>/gm;
		//var matches = [];
		var match;
		while (match = regex.exec(xml)) {
			var line = match[0];
			var key = match[1];
			var text = match[3];

			// only string type information has to be processed
			if (!(line.match(/<data[\s\S]*\stype=[\s\S]*<\/data>/) || //
			line.match(/<data[\s\S]*\smimetype=[\s\S]*<\/data>/) || //
			key.match(/^&gt;&gt;/))) {
				var obj = {
					key: key,
					text: text
				};
				tracer && tracer("OBJ: " + JSON.stringify(obj, null, 2));
				//matches.push(obj);

				_checkEntry(_, key, text, fpath);

			}
		}
		//tracer && tracer("matches: " + JSON.stringify(matches, null, 2));

	}

	function walk(_, file) {
		var path = fsp.join(dir, file); // dir + '\\' + file;

		var stat = fs.stat(path, _);

		if (stat.isDirectory()) {
			var dircontent = fs.readdir(path, _);
			var temp = dir;
			dir = path;
			dircontent.forEach_(_, walk);
			dir = temp;
		} else {
			extract(_, file);
		}
	}

	var endPoint = options.endpoint || instance.endpoint(_);
	var index;
	options = options || {};
	var _addDiagnose = (options.$diagnoses || !instance) ? function(severity, message) {
		options.$diagnoses && options.$diagnoses.push({
			$severity: severity,
			$message: message
		});
	} : (instance && instance.$addDiagnoses);
	var db = endPoint.getOrm(_);

	var entity;
	entity = db.getEntity(_, "APLSTD", "$bulk");
	tracer && tracer("extract dotnet ressources ");
	var x3Records = db.fetchInstances(_, entity, {
		count: fetchCountX3,
		sdataWhere: "LANCHP eq " + chapterDotnet + " and LAN eq 'ENG' and LANNUM ne 0"
	});
	tracer && tracer("x3Records read: " + x3Records.length);
	tracer && x3Records.forEach_(_, function(_, r) {
		tracer("x3Record: " + JSON.stringify(r.serializeInstance(_), null, 2));
	});
	if (x3Records.length >= fetchCountX3) {
		throw new Error("Error: Maximum records to read is " + fetchCountX3 + " and this amount of records has been fetched. Aborting since some records may not be processed otherwise!");
	}

	var dir;
	var indexdir;
	dir = options.dir || fsp.join(__dirname, "../../../dotnet");

	// default index dir is translation-indexes; if indexdir is given by options, it has to be a full path
	//if (options.indexdir) indexdir = fsp.join(__dirname, "../../", options.indexdir);
	//else indexdir = fsp.join(__dirname, "../lib");
	indexdir = options.indexdir || fsp.join(__dirname, "../../../translation-indexes");
	tracer && tracer("INDEXDIR: " + indexdir);

	var indexpath = fsp.join(indexdir, "indexDotnet.json");
	tracer && tracer("indexpath: " + indexpath);
	index = readIndex(_, indexpath, options.$diagnoses, options.indexFiler);
	
	if (options.exportFile) {
		extract(_, options.exportFile);
	} else {
		//var currentChapter=chapterDotnet+ Math.floor( (index.count+1) / maxNbRecords )  ;
		var dircontent = fs.readdir(dir, _);
		dircontent.forEach_(_, walk);
	}	

	(options.indexFiler || fs).writeFile(indexpath, JSON.stringify(index, null, "\t"), "utf8", _);
};

//X3->Syracuse
exports.updateDotnetResources = function(_, instance, options, context) {
	function _getReference(input) {
		var xml = input.replace(/<!--([\s\S]*?)-->/gm, "");
		var regex = /<data*\sname="([\s\S]*?)"([\s\S]*?)<value>([\s\S]*?)<\/value>([\s\S]*?)<\/data>/gm;
		var matches = {};
		var match;
		while (match = regex.exec(xml)) {
			var line = match[0];
			var key = match[1];
			var text = match[3];

			// only string type information has to be processed
			if (!(line.match(/<data[\s\S]*\stype=[\s\S]*<\/data>/) || //
			line.match(/<data[\s\S]*\smimetype=[\s\S]*<\/data>/) || //
			key.match(/^&gt;&gt;/))) {
				matches[key] = text;
				//tracer && tracer("OBJ: "+JSON.stringify(obj,null,2)) ;   
			}
		}
		tracer && tracer("matches: " + JSON.stringify(matches, null, 2));
		return matches;

	}

	//tracer = trace_update_dotnet;
	tracer && tracer("update dotnet resources");
	var self = this;
	self.context = context;
	options = options || {};

	var endPoint = instance.endpoint(_);
	var db = endPoint.getOrm(_);

	tracer && tracer("endPoint name " + endPoint.dataset(_));

	var langFname = _getLanguages(_, instance.endpoint(_));
	tracer && tracer("languages: " + JSON.stringify(langFname));
	var index;

	var whereClause = "LANCHP ge " + chapterDotnet + " and LANCHP le " + (chapterDotnet + 4) + " and LANNUM ne 0";

	var x3Records = getX3Records(_, db, whereClause);

	var dir;
	var indexdir;
	if (options.dir) dir = fsp.join(__dirname, "../../", options.dir);
	else dir = fsp.join(__dirname, "../../", "");

	// default index dir is translation-indexes; if indexdir is given by options, it has to be a full path
	//if (options.indexdir) indexdir = fsp.join(__dirname, "../../", options.indexdir);
	//else indexdir = fsp.join(__dirname, "../lib");
	indexdir = options.indexdir || fsp.join(__dirname, "../../../translation-indexes");

	var indexpath = fsp.join(indexdir, "/indexDotnet.json");
	tracer && tracer("indexpath: " + indexpath);
	index = readIndex(_, indexpath, options.$diagnoses, options.indexFiler);

	flows.eachKey(_, index, function(_, k) {
		function loadLocalData(_) {
			var exists;
			var file;
			file = fsp.join(rootpath, dirname, base + ".resx");
			exists = fs.existsSync(file);
			if (!exists) {
				tracer && tracer("global resources file deleted or moved: " + file);
				if (options && options.$diagnoses) options.$diagnoses.push({
					severity: "warning",
					message: locale.format(module, "missingFile", file)
				});
				else instance.$addDiagnose("warning", locale.format(module, "missingFile", file));
				return;
			}
			var input = fs.readFile(file, "utf8", _);
			return input;
		}

		function _updateProjectFile(_, langExt, base, dirname) {
			var module = fsp.basename(dirname);
			var projPath = fsp.join(rootpath, dirname, module + ".csproj");
			var exists = fs.existsSync(projPath);
			if (!exists) return;
			var content = fs.readFile(projPath, "utf8", _);
			var toAdd = '<EmbeddedResource Include="' + base + '.' + langExt + '.resx"><DependentUpon>' + base + '.cs</DependentUpon></EmbeddedResource>';
			var s = '<EmbeddedResource[ ]+Include="' + base + '.resx">.*[^<]*<DependentUpon>[^<]*' + base + '.cs.*[^<]*' + '</DependentUpon>[\\s\\S]*?</EmbeddedResource>';

			var regex = new RegExp(s);
			var match = regex.exec(content);
			var txt = match[0] + toAdd;

			if (match[0]) {
				content = content.replace(match[0], txt);

				fs.writeFile(projPath, content, "utf8", _);
			}
		}

		function _saveChanges(_, dataBuffers, input, base, dirname) {
			var file;

			// If there is not a single translation for a language,
			// add an empty object to dataBuffer for the language to have the
			// resource file generated.
			flows.eachKey(_, langFname, function(_, lang) {
				if (!dataBuffers[lang]) dataBuffers[lang] = {};
			});
			flows.eachKey(_, dataBuffers, function(_, lang, replacevalues) {

				tracer && tracer("lang: " + lang);
				//tracer && tracer("BUFFER: " + JSON.stringify(replacevalues, null, 2));
				var mainfile;
				var parts;
				if (lang === "global") {
					file = fsp.join(rootpath, dirname, base + ".resx");
					tracer && tracer("global ressource file : " + file);
				} else {
					file = fsp.join(rootpath, dirname, base + "." + langFname[lang] + ".resx");
					tracer && tracer(" file to update : " + file);
					parts = langFname[lang].split('-');
					mainfile = fsp.join(rootpath, dirname, base + "." + parts[0] + ".resx");
					tracer && tracer(" main file to update : " + mainfile);
				}

				flows.eachKey(_, replacevalues, function(_, key, value) {
					tracer && tracer("KEY: " + key);
					tracer && tracer("value: " + value);
					key = key.replace('$', '[$]');
					var s = '<data[ ]+name="' + key + '".*>[^<]*<value>([^<]*)</value>[^<]*</data>';

					var regex = new RegExp(s);

					//var match = regex.exec(input, "gm");
					//tracer && tracer("MATCH: " + sys.inspect(match));

					input = input.replace(regex, function($0) {
						return ($0.replace(/<value>([\s\S]*?)<\/value>/, '<value>' + value + '<\/value>'));
					});
					//tracer && tracer("INPUT: " + input);
				});
				var exists = fs.existsSync(file);
				tracer && tracer("File exists: " + file + ": " + file);
				var fd = fs.open(file, "w+", "0666", _);

				fs.writeFile(file, input, "utf8", _);
				fs.close(fd, _);
				if (!exists && lang !== "global") _updateProjectFile(_, langFname[lang], base, dirname);

				if (mainfile) {
					exists = fs.existsSync(mainfile);

					fd = fs.open(mainfile, "w+", "0666", _);
					fs.writeFile(mainfile, input, "utf8", _);
					fs.close(fd, _);
					if (!exists && lang !== "global") _updateProjectFile(_, parts[0], base, dirname);
				}

			});
		}

		var base = fsp.basename(k, ".resx").replace(/\//g, fsp.sep);
		var dirname = fsp.dirname(k).replace(/\//g, fsp.sep);

		var dataBuffers = {};
		tracer && tracer("index[" + k + "]=" + JSON.stringify(index[k], null, 2));
		if (k === "count" || k === "minIdx") return;

		var fileObj = index[k];

		flows.eachKey(_, fileObj, function(_, key, el) {
			tracer && tracer("KEY: " + key);
			var rec = x3Records[el.chp] && x3Records[el.chp][el.id];
			if (!rec) {
				tracer && tracer("no x3  record:" + el.chp + "/" + el.id);
				return;
			}
			tracer && tracer("x3 record: " + JSON.stringify(rec, null, 2));
			var locData = loadLocalData(_, rec, dataBuffers);
			var reference = _getReference(locData);

			flows.eachKey(_, langFname, function(_, lang) {
				if (!rec[lang]) {
					return;
				}
				tracer && tracer("rec[" + lang + "]= " + sys.inspect(rec[lang]));

				if (lang === 'ENG') {
					tracer && tracer("index[" + k + "[" + key + "]=" + el.text);
					if (rec[lang] !== el.text) {
						tracer && tracer("modifyed in X3 " + k + ' ' + key + ' old value: ' + el.text + //
						" new value: " + k + ' ' + key + ' txt: ' + rec[lang]);
						//return;
					}
					if (reference[key] !== el.text) {
						tracer && tracer(" update conflict for " + k + ":" + key);
						if (options && options.$diagnoses) options.$diagnoses.push({
							severity: "warning",
							message: locale.format(module, "updateConflict", k + ":" + key, rec[lang])
						});
						else instance.$addDiagnose("warning", locale.format(module, "updateConflict", k + ":" + key, rec[lang]));
						return;
					}
					tracer && tracer("update record lang: " + lang + "key: " + key);
					dataBuffers.global = {};
					dataBuffers.global[key] = rec[lang];
				}
				if (!dataBuffers[lang]) dataBuffers[lang] = {};
				dataBuffers[lang][key] = rec[lang];
			});
			tracer && tracer("data buffers: " + sys.inspect(dataBuffers));
			_saveChanges(_, dataBuffers, locData, base, dirname);
			tracer && tracer("saved");
		});

	});
};
