"use strict";
var supervisor = require("etna-supervisor/lib/supervisor"),
	nodeLocalConfig = require('config'),
	gitWrapper = require('etna-etl/lib/gitWrapper'),
	path = require("path"),
	ez = require("ez-streams"),
	file = ez.devices.file,
	fs = require("streamline-fs"),
	gitWrapperInstance;


exports.newGenerator = function(_, config) {

	config.git = config.git || {};
	config.patch = config.patch || {};
	config.patch.langs = config.patch.langs || ["ENG", "FRA"]
	config.patch.comment = config.patch.comment || "test";
	config.patch.version = config.patch.version || 1;
	config.patch.product = config.patch.product || "X3";
	config.settingsTable = config.settingsTable || "_SETTINGS";

	// Normalize the meta folder
	config.metaSubFolder = path.join(config.metaSubFolder + "/").toLowerCase();
	var superv = supervisor.create(_, config);

	try {
		// Make sure the settings table exists
		superv.sqlDriver.getTableDef(_, superv.folderName, config.settingsTable);
	} catch (err) {
		console.log("ERROR : " + err);
		var tableDef = {
			schemaName: superv.folderName,
			tableName: config.settingsTable,
			columns: [{
				name: "GITSHA1",
				isNullable: true,
				type: "nvarchar",
				maxLength: 40
			}],
			indexes: [],
		};
		superv.sqlDriver.createTableFromTableDefinition(_, tableDef);
		config.trace && config.trace("Settings table '" + tableDef.tableName + "' was created.")
	}

	function _getGitWrapper() {
		if (!gitWrapperInstance) {
			var options = {
				folder: config.solutionPath,
				trace: config.git.trace
			};
			gitWrapperInstance = new gitWrapper.git(options);
		}
		return gitWrapperInstance;
	}

	function _parseJSONValue(key, val) {

		if (/^##\w+##$/.test(key)) {
			// Special tags : ##texts##, ##comments##, ...
			return {
				type: "extra",
				value: val
			};
		}
		var result = {};
		if (Array.isArray(val)) {
			result.value = [];
			result.type = "array";
			val.forEach(function(arrayItem, itemIdx) {
				result.value.push(_parseJSONValue(key + "[" + itemIdx + "]", arrayItem));
			});
		} else if ("string" === typeof(val)) {
			switch (val.charAt(0)) {
				case "S":
					var parts = /^S(\:[^|"]+)?\|(.*)$/.exec(val);
					if (parts) {
						// String : S|xxxxx
						// String with specific option (type option) : S:TF|xxxxxxxx
						result = {
							type: "string",
							value: parts[2]
						};
						if (" " === result.value)
							result.value = "";
						if (parts[1]) {
							if (parts[1].indexOf('T') != -1) {
								// This text is a formula, some characters must be mapped
								// Replace ',' with #254
								result.value = result.value.replace(/,/g, String.fromCharCode(255))
								// Replace #10 with #255
								result.value = result.value.replace(/\r/g, String.fromCharCode(254))
							}
						}
					} else
						throw new Error("Invalid string value : " + val);
					break;
				case "C":
					// Clobs
					result = {
						type: "clob",
						value: val.substring(val.indexOf("|") + 1)
					};
					break;
				case "N":
					// Decimals are stored as strings in json
					result = {
						type: "decimal",
						value: parseFloat(val.substring(val.indexOf("|") + 1))
					};
					break;
				case "D":
					// Date (without time part)
					// D:2009-12-31 -> 20091231
					val = val.substring(val.indexOf("|") + 1);
					result = {
						type: "date",
						value: val == "NULL" ? null : parseInt(val.replace(/\-/g, ""))
					};
					break;
				case "T":
					// Timestamp
					// T|2003-09-11T00:00:00.000Z -> 2003-09-11T00:00:00Z
					// just remove the millis
					val = val.substring(val.indexOf("|") + 1);
					result = {
						type: "timestamp",
						value: val.substring(0, val.lastIndexOf(".")) + "Z"
					};
					break;
				default:
					// should never happen
					throw new Error("Unknown value type : " + val);
					break;
			}
		} else if (isFinite(val)) {
			result = {
				type: "number",
				value: val
			};
			// Nothing to do : this is a number. Keep it as it.
		} else {
			// should never happen .. may be an object
		}
		return result;
	}

	function _processElement(_, writer, elt, eltConfig) {
		// Compute the title of the block
		var blockTitle;
		if (eltConfig.titleFunction) {
			blockTitle = _invokeTitleFunction(eltConfig.titleFunction, elt);
		} else {
			var pk = eltConfig.primaryKey || eltConfig.patchPK;
			if (!pk) {
				if (!eltConfig.orderBy)
					throw new Error("'orderBy' property is missing on element " + (eltConfig.title ? eltConfig.title : eltConfig.tableName));
				pk = eltConfig.orderBy.split(',')[0];
			}
			blockTitle = _parseJSONValue(pk, elt[pk]).value;
		}

		writer.write(_, "3,\"" + eltConfig.abbrev + "\"," + blockTitle + "\n");

		var allLines = {};

		function _formatValues(lineType, name, dimension, values, valueType) {
			var line = lineType + ',"' + name + '",' + dimension;
			if (25 === lineType) {
				// Clob
				line += "\r\n" + values.length + "\r\n" + values + "\r\n" + "**********";
			} else {
				if (!Array.isArray(values))
					values = [values];
				values.forEach(function(value) {
					line += ',';
					if (typeof(value) == "string") {
						if (value == " ")
							value = "";
						line += '"' + value + '"';
					} else {
						if ((4 === lineType) && valueType && ("date" === valueType) && !value) {
							// null dates are written as 000000
							value = "000000";
						}
						line += value;
					}
				});
			}
			return line;
		}

		function _enqueueItem(lineType, name, dimension, values, valueType) {
			allLines[name] = allLines[name] || [];
			allLines[name].push(_formatValues(lineType, name, dimension, values, valueType));
		}

		if (elt["##texts##"]) {
			var texts = elt["##texts##"];
			Object.keys(texts).forEach_(_, function(_, columnName) {
				if (!elt.hasOwnProperty(columnName))
					return;
				var textIds = elt[columnName];
				if (!Array.isArray(textIds))
					textIds = [textIds];

				// Some texts can have multiple dimensions (AWINDOW.INTMSK for instance)
				textIds.forEach_(_, function(_, textId, textDimension) {

					config.patch.langs.forEach_(_, function(_, langCode) {
						var valsToWrite = [
							texts[columnName][textDimension][langCode] || "",
							langCode,
							textId,
						];

						if (elt["##comments##"] && elt["##comments##"][columnName] && elt["##comments##"][columnName][textDimension] && elt["##comments##"][columnName][textDimension][langCode])
							valsToWrite.push(elt["##comments##"][columnName][textDimension][langCode]);
						else
							valsToWrite.push("");
						_enqueueItem(5, columnName, textDimension, valsToWrite);
					});

					_enqueueItem(5, columnName, textDimension, ["", "***"]);
				});

				delete(elt[columnName]);
			});
			delete(elt["##texts##"]);
			delete(elt["##comments##"]);
		}

		Object.keys(elt).forEach_(_, function(_, key) {
			if (/^##\w+##$/.test(key)) {
				// Special tags : ##texts##, ##comments##, ##extraTables##, ...
				return;
			}

			var val = _parseJSONValue(key, elt[key]);
			if ("array" == val.type) {
				val.value.forEach_(_, function(_, arrayItem, itemIdx) {
					_enqueueItem(4, key, itemIdx, arrayItem.value, arrayItem.type);
				});
			} else if ("clob" == val.type) {
				_enqueueItem(25, key, 0, val.value, val.type);
			} else {
				_enqueueItem(4, key, 0, val.value, val.type);
			}
		});

		Object.keys(allLines).sort().forEach_(_, function(_, lines) {
			allLines[lines].forEach_(_, function(_, line) {
				writer.write(_, line + "\n");
			});
		});

		if (elt["##extraTables##"] && elt["##extraTables##"].ATEXTRA) {
			var texts = elt["##extraTables##"].ATEXTRA;
			Object.keys(texts).forEach_(_, function(_, columnName) {
				var atLeastOneText = false;
				config.patch.langs.forEach_(_, function(_, langCode) {
					var valsToWrite = [
						texts[columnName][langCode] || "",
						langCode,
					];
					var textVals = texts[columnName];
					// Note : textVals is an object indexed by ATEXTRA.IDENT2_0.
					if (textVals) {
						// Here, we only consider the first ATEXTRA.IDENT2_0.
						var t = texts[columnName][Object.keys(texts[columnName])[0]];
						if (t[langCode]) {
							writer.write(_, _formatValues(9, columnName, 0, [t[langCode], langCode, "" + elt[eltConfig.primaryKey], Object.keys(texts[columnName])[0]]) + "\n");
							atLeastOneText = true;
						}
					}
				});
				if (atLeastOneText)
					writer.write(_, _formatValues(9, columnName, 0, ["", "***"]) + "\n");
			});
			delete(elt["##extraTables##"])
		}

		writer.write(_, "6,\"" + eltConfig.abbrev + "\"\n");
	}

	function _invokeTitleFunction(fct, elt) {
		var arg = {};
		Object.keys(elt).forEach(function(key) {
			arg[key] = _parseJSONValue(key, elt[key]).value;
		});
		var title = fct(arg);
		if (title && title["ENG"])
			title = title["ENG"];
		return title;
	}

	function _processMetaElement(_, writer, entityExportConfig, elt) {
		var title;
		if (elt["##texts##"]) {
			title = elt["##texts##"][entityExportConfig.textLinks[0]][0]["ENG"];
		} else {
			if (entityExportConfig.mainTitleFunction)
				title = _invokeTitleFunction(entityExportConfig.mainTitleFunction, elt);
			else
				throw new Error("No localized label are defined for element '" + entityExportConfig.title + "', you must provide a 'mainTitleFunction' function.")
		}
		var header = '"' + entityExportConfig.abbrev + '","' + _parseJSONValue(entityExportConfig.primaryKey, elt[entityExportConfig.primaryKey]).value + '","' + title + '"';
		writer.write(_, "2," + header + "\n");
		var children = [];
		if (entityExportConfig.children) {
			// The configuration describes some child-node, we have to keep them in a separate list.
			// They will be processed later.
			Object.keys(entityExportConfig.children).forEach(function(childName) {
				// For instance, in tables.js, childName == 'COLUMNS' or 'INDEXES'
				if (elt[childName]) {
					// note : elt[childName] is an array. Each item describes a child (i.e. one index or one column)
					elt[childName].forEach(function(c) {
						children.push({
							name: childName,
							node: c
						});
					});
					// We have to delete the child, otherwise it would be exposed as a value in the .dat file
					delete(elt[childName]);
				}
			});
		}
		_processElement(_, writer, elt, entityExportConfig);

		// Now, we can process the children
		children.forEach_(_, function(_, child) {
			_processElement(_, writer, child.node, entityExportConfig.children[child.name]);
		});

		writer.write(_, "7," + header + "\n");
	}

	/// returns whether a relative filename describes a .json meta file (relative to solutionFolder)
	function _isMetaFile(relativeFilename) {
		// Normalize the filename
		relativeFilename = path.join(relativeFilename).toLowerCase();
		if (!relativeFilename.substr(0, config.metaSubFolder.length) == config.metaSubFolder) {
			// This file is not a metadata file
			return false;
		}
		return /\.json$/.test(relativeFilename);
	}

	function _generatePatches(_, filesList, options) {


		function _openWriter(_, shortFilename) {
			var patchFilename = config.patchSubFolder + "/" + shortFilename + ".dat";
			filenames.push(patchFilename);
			var writer = file.text.writer(patchFilename, "utf8");
			config.trace && config.trace("\tGenerating patch file: " + path.join(config.solutionPath, patchFilename));

			writer.write(_, '1,"' + config.patch.comment + '","' + config.patch.langs.join("/") + '","' + config.patch.version + '","","' + config.patch.product + '","1",\n');
			return writer;
		}

		function _closeWriter(_, writer) {
			writer.write(_, '8,"' + config.patch.comment + '"\n');
			writer.write(_);
		}

		var filenames = [];
		var writer;

		// Note : the gitWrapper may have changed the current folder
		process.chdir(config.solutionPath);

		// clean the output folder
		config.trace && config.trace("Cleaning output folder : " + config.patchSubFolder);
		_cleanFolder(_, config.patchSubFolder);

		var patchFolder = path.join(config.solutionPath, config.patchSubFolder);
		if (!fs.exists(patchFolder, _)) {
			config.trace && config.trace("Create output folder " + patchFolder);
			try {
				fs.mkdir(patchFolder, _);
			} catch (err) {
				throw new Error("Could not create patch folder, reason = " + err.message);
			}
		}

		options = options || {};
		if (options.oneFile) {
			writer = _openWriter(_, "patch");
		}

		filesList.forEach_(_, function(_, filename) {
			// Normalize the filename
			filename = path.join(filename);
			// Note filename looks like "META_SUB_FOLDER/SUPERV/TABLES/ABANK.json"
			config.trace && config.trace("Processing file " + path.join(config.solutionPath, filename));
			if (!_isMetaFile(filename)) {
				// This file is not a metadata file
				return;
			}

			// Only keep SUPERV/TABLES/ABANK.json 
			// (Caution config.metaSubFolder may have more than one level)
			filename = filename.substr(config.metaSubFolder.length);
			var parts = filename.split(path.sep);

			// Note : the filename may also look like "META_SUB_FOLDER/CHAPTERS/AAS/PARAMETERS/AASAUTNUM.json" so we have
			// to read infos from the end of the array
			var moduleName = parts[parts.length - 3];
			var metaType = parts[parts.length - 2];
			var filenamePart = parts[parts.length - 1];

			filenamePart = filenamePart.substring(0, filenamePart.length - 5); // remove the '.json'

			var fullFileName = path.join(config.metaSubFolder, filename);
			var elt;
			try {
				elt = JSON.parse(fs.readFile(fullFileName, 'utf8', _));
			} catch (err) {
				throw new Error("Could not read file '" + fullFileName + "', reason = " + err.message);
			}
			if (!options.oneFile) {
				writer = _openWriter(_, metaType + "_" + filenamePart);
			}
			var entityExportConfig = require("etna-etl/lib/entities/" + metaType).entity;
			_processMetaElement(_, writer, entityExportConfig, elt);
			if (!options.oneFile) {
				_closeWriter(_, writer);
			}
		});
		if (options.oneFile) {
			_closeWriter(_, writer);
		}

		return filenames;
	}

	function _comparePatchFiles(_, filename1, filename2) {
		function _parseFile(_, filename) {
			var parts = {};
			var reader = ez.devices.file.text.reader(filename, "utf8").transform(ez.transforms.lines.parser());
			var currentBlockId;
			var currentBlockIdPrefix;
			while (true) {
				var line = reader.read(_);
				if (!line)
					break;
				switch (line.charAt(0)) {
					case "1":
						// Sth like 1,"test","ENG/FRA","1","","X3","1",
						// Start of a 1..8 block
						parts["HEADER"] = line;
						break;
					case "2":
						// Try to parse sth like 2,"ACLA","TCAWRKHISSUI","Workflow tracking archive"
						var result = /^2,\"(\w+)\",\"(\w+)\",\"(.+)\"/.exec(line);
						if (result) {
							// Start of a 2..7 block
							currentBlockIdPrefix = result[1] + "." + result[2];
							parts[currentBlockIdPrefix + ".ITEM_HEADER"] = line;
						}
						break;
					case "3":
						// Try to parse sth like 3,"ACLAF","ABROBJ"
						var result = /^3,\"(\w+)\",\"?([^\"]+)\"?/.exec(line);
						if (result) {
							// Start of a 3..6 block
							currentBlockId = currentBlockIdPrefix + "." + result[1] + ":" + result[2];
							parts[currentBlockId] = "";
						}
						break;
					case "6":
						// Try to parse sth like 6,"ACLA"
						// End of 3..6 block
						currentBlockId = null;
						break;
					case "7":
						// Try to parse sth like 7,"ACLA","TCAWRKHISSUI","Workflow tracking archive"
						// End of 2..7 block
						currentBlockIdPrefix = null;
						break;
					case "8":
						// End of 1..8 block
						// Nothing special to be done. should be the end of the file
						break;
					default:
						if (parts[currentBlockId].length)
							parts[currentBlockId] += "\n";
						parts[currentBlockId] += line;
				}

			}
			return parts;
		}

		function _compareParts(filename1, parts1, filename2, parts2) {
			Object.keys(parts1).forEach(function(key) {
				var part1 = parts1[key];
				var part2 = parts2[key];
				if (!part2)
					throw new Error("Could not find key " + key + " in file " + filename2);
				var lines1 = part1.split("\n");
				var lines2 = part2.split("\n");
				var same = lines1.length == lines2.length;
				same = same && !lines1.some(function(line1) {
					var idx2 = lines2.indexOf(line1);
					if (idx2 == -1) {
						config.trace && config.trace("Could not find string '" + line1 + "' from file " + filename2);
						return true;
					}
					return false;
				});

				if (!same) {
					config.trace && config.trace("------------- " + filename1);
					config.trace && config.trace(part1);
					config.trace && config.trace("------------- " + filename2);
					config.trace && config.trace(part2);
					config.trace && config.trace("-------------");
					throw new Error("Content mismatch : " + key);
				}
			});

		}
		var parts1 = _parseFile(_, filename1);
		var parts2 = _parseFile(_, filename2);
		_compareParts(filename1, parts1, filename2, parts2);
		_compareParts(filename2, parts2, filename1, parts1);
	}

	/// Stores the sha1 that was last synchronized
	function _setLastSyncdSha1(_, sha1) {
		try {
			superv.sqlDriver.withConnection(_, function(_, cnx) {
				superv.sqlDriver.execute(_, cnx, "delete from " + config.settingsTable);
				superv.sqlDriver.execute(_, cnx, "insert into " + config.settingsTable + " (GITSHA1) values (" + superv.sqlDriver.param(0) + ")", [sha1]);
			});
		} catch (err) {
			console.log("ERROR : " + err.message);
		}
		config.trace && config.trace("'" + sha1 + "' written as the last sync'd head.");
	}

	function _listModifiedFiles(_, fromSha1, toSha1) {
		var result;
		if (fromSha1) {
			// Return only the files that were modified in the range fromSha1..toSha1
			result = _getGitWrapper().diffStat(_, fromSha1, toSha1 || this.getGitHead(_));
		} else {
			// Retrieve all versionned files
			result = _getGitWrapper().diffStat(_);
		}
		return result.diffs.map(function(diff) {
			switch (diff.touch) {

				case 'A': // Add
				case 'M': // Modified
					return diff.filename;
				case 'D': // Deleted
					// STDEN : ignored for now
					return;
				default:
					// STDEN : ignored for now
					return;
			}
		}).filter(function(d) {
			// Remove 'undefined' entries
			return d;
		});
	}

	function _applyPatches(_, patchFilenames) {
		if (!patchFilenames.length)
			return;
		console.log("******* TODO ***********");
		console.log("apply the following patches : ");
		patchFilenames.forEach(function(patchFilename) {
			console.log("\t-" + patchFilename);
		})
	}

	function _remove(_, s) {
		if (!fs.exists(s, _))
			return;
		try {
			var stat = fs.stat(s, _);
			if (stat.isDirectory()) {
				fs.readdir(s, _).forEach_(_, function(_, f) {
					_remove(_, s + '/' + f);
				});
				fs.rmdir(s, _);
			} else {
				fs.unlink(s, _);
			}
		} catch (err) {
			throw new Error("Could not delete " + s + ", reason = " + err.message);
		}
	}

	function _cleanFolder(_, path) {
		try {
			fs.readdir(path, _).forEach_(_, function(_, name) {
				_remove(_, path + "/" + name);
			});
		} catch (err) {
			throw new Error("Could not clean folder " + path + ", reason = " + err.message);
		}

	}

	return {

		/// Returns the sha1 that was last synchronized
		getLastSyncdSha1: function(_) {
			var sha1;
			try {
				superv.sqlDriver.withConnection(_, function(_, cnx) {
					var row = superv.sqlDriver.reader(_, cnx, "select GITSHA1 from " + config.settingsTable).toArray(_)[0];
					if (!row) {
						return null;
					}
					sha1 = row.GITSHA1;
				});
			} catch (err) {
				console.log("ERROR : " + err.message);
			}
			return sha1;
		},

		getGitHead: function(_) {
			return _getGitWrapper().getHead(_);
		},

		generatePatches: function(_, filesList, options) {
			var results = _generatePatches(_, filesList, options);
			if (options.oneFile && options.x3PatchToCompare) {
				setTimeout(~_, 1000);
				config.trace && config.trace("Comparing generated file '" + results[0] + "' with reference file '" + options.x3PatchToCompare + "'");
				_comparePatchFiles(_, results[0], options.x3PatchToCompare);
			}
			return results;
		},


		synchronize: function(_, options) {
			options = options || {};

			if (undefined === options.oneFile)
				options.oneFile = true;

			if (config.trace) {
				var currentBranchResult = _getGitWrapper().command(_, "symbolic-ref", ["--short", "HEAD"]);
				if (0 === currentBranchResult.exitCode)
					config.trace("Current branch is [" + currentBranchResult.out + "]");
				else
					config.trace("Could not get the current branch, reason = " + currentBranchResult.err);
				config.trace("Working folder is : " + config.solutionPath);
			}

			// Run a git pull command to retreive all the new/updated json files
			config.trace && config.trace("Git pull...");
			var result = _getGitWrapper().pull(_);

			if (result.exitCode) {
				// Something went wrong ... maybe a conflict
				// For now, we can't do anything
				var msg = "The git-pull failed, reason = " + result.err;
				config.trace && config.trace(msg);
				throw new Error(msg);
			}

			var lastSyncdSha1;
			if (!options.full)
				lastSyncdSha1 = this.getLastSyncdSha1(_);
			if (config.trace) {
				if (lastSyncdSha1)
					config.trace("Last sync'd head = " + lastSyncdSha1);
				else
					config.trace("Last sync'd head = not set => full sync");
			}

			var gitHead = this.getGitHead(_);
			config.trace && config.trace("Git head = " + gitHead.sha1);

			// First : retrieve the files that have been updated (or created) between the two revisions			
			var files = _listModifiedFiles(_, lastSyncdSha1, gitHead.sha1).filter(_isMetaFile);

			if (files.length) {
				var patchFilenames = _generatePatches(_, files, options);
				_applyPatches(_, patchFilenames);

				// Store the current head in db so that next sync will be incremental
				_setLastSyncdSha1(_, gitHead.sha1);
			} else {
				config.trace && config.trace("Already up-to-date, no patch needed.")
			}
		},

		comparePatchFiles: function(_, filename1, filename2) {
			return _comparePatchFiles(_, filename1, filename2);
		},
	}
};
