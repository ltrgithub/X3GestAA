"use strict";
var supervisor = require("etna-supervisor/lib/supervisor"),
	nodeLocalConfig = require('config'),
	gitWrapper = require('etna-etl/lib/gitWrapper'),
	path = require("path"),
	ez = require("ez-streams"),
	file = ez.devices.file,
	fs = require("streamline-fs"),
	encodeValueToJsonString = require("etna-etl/lib/exporter").encodeValueToJsonString,
	decodeValueFromJsonString = require("etna-etl/lib/exporter").decodeValueFromJsonString,
	readAndMergeJsonFiles = require("etna-etl/lib/importer").readAndMergeJsonFiles,
	gitWrapperInstance;

var orderedTypes = [
	"ACV", "AML", "ELT", "BIA", "TXT", "EXE", "AHI", "ATN", "ADC", "ANG", "ADX", "TRT", "ETA", "ACS", "ANM", "ACT", "AFC", "ACL", "ASL", "ATYP", "AGB", "ACTX", "ACST", "ASU", "ATY", "ADV", "ADI", "ATB", "AVW", "AUR", "AMK", "ARP", "AOB", "AOP", "ADP", "AWI", "AOE", "AEN", "ACN", "PS1", "PS2", "TAB", "GAU", "AWM", "AWR", "AWA", "AWW", "ABT", "ABA", "ABG", "ACLA", "ASW", "ADZ", "ADO", "ADF", "ALH", "ALQ", "ALT", "ABF", "ABI", "ABM", "ABV", "ABO", "AHH", "AII", "ASY", "TFO", "APR", "AWE", "ANT", "AMC", "AY", "AYS", "ELX", "AYG", "AYD", "AYF", "AYM", "AYI", "AYE", "AYB", "AYO", "AYA", "AYL", "AYW", "AYC", "AYU", "IND"
];

/// !doc
/// # Patch generator
/// Tools to generate patch files from versionned (git) JSON files that contain metadata
/// Usage : 
/// ```
/// require("scm/lib/patchGenerator").newGenerator(_, config).synchonize(_);
/// ```
exports.newGenerator = function(_, config) {

	config.git = config.git || {};
	config.patch = config.patch || {};
	config.patch.langs = config.patch.langs || ["ENG", "FRA"]
	config.patch.comment = config.patch.comment || "test";
	config.patch.version = config.patch.version || 1;
	config.patch.product = config.patch.product || "X3";
	config.settingsTable = config.settingsTable || "_SETTINGS";
	if (undefined === config.oneFile)
		config.oneFile = true;


	// Normalize the meta folder
	config.metaSubFolder = path.join(config.metaSubFolder + "/").toLowerCase();
	var superv = supervisor.create(_, config);

	try {
		// Make sure the settings table exists
		superv.sqlDriver.getTableDef(_, superv.folderName, config.settingsTable);
	} catch (err) {
		var tableDef = {
			schemaName: superv.folderName,
			tableName: config.settingsTable,
			columns: [{
				name: "ID",
				isNullable: false,
				type: "nvarchar",
				maxLength: 100
			}, {
				name: "VALUE",
				isNullable: true,
				type: "clob",
			}],
			indexes: [],
		};
		superv.sqlDriver.createTableFromTableDefinition(_, tableDef);
		config.trace && config.trace("Settings table '" + tableDef.tableName + "' was created.")
	}

	function _getGitWrapper() {
		if (!gitWrapperInstance) {
			var options = {
				folder: config.gitFolder || config.solutionPath,
				trace: config.git.trace
			};
			gitWrapperInstance = new gitWrapper.git(options);
		}
		return gitWrapperInstance;
	}


	function _processElement(_, writer, elt, eltConfig) {
		// Compute the title of the block
		var blockTitle;
		if (eltConfig.titleFunction) {
			blockTitle = _invokeTitleFunction(eltConfig.titleFunction, elt);
		} else {
			var pk = eltConfig.primaryKey || eltConfig.patchPK;
			if (!pk) {
				if (!eltConfig.orderBy)
					throw new Error("'orderBy' property is missing on element " + (eltConfig.title ? eltConfig.title : eltConfig.tableName));
				pk = eltConfig.orderBy.split(',')[0];
			}
			blockTitle = decodeValueFromJsonString(pk, elt[pk]).value;
		}

		writer.write(_, "3,\"" + eltConfig.abbrev + "\"," + blockTitle + "\n");

		var allLines = {};

		function _formatValues(lineType, name, dimension, values, valueType) {
			var line = lineType + ',"' + name + '",' + dimension;
			if (25 === lineType) {
				// Clob
				line += "\r\n" + values.length + "\n" + values + "\n" + "**********";
			} else {
				if (!Array.isArray(values))
					values = [values];
				values.forEach(function(value) {
					line += ',';
					if (typeof(value) == "string") {
						if (value == " ")
							value = "";
						line += '"' + value + '"';
					} else {
						if ((4 === lineType) && valueType && ("date" === valueType) && !value) {
							// null dates are written as 000000
							value = "000000";
						}
						line += value;
					}
				});
			}
			return line;
		}

		function _enqueueItem(lineType, name, dimension, values, valueType) {
			allLines[name] = allLines[name] || [];
			allLines[name].push(_formatValues(lineType, name, dimension, values, valueType));
		}

		if (elt["##texts##"]) {
			var texts = elt["##texts##"];
			Object.keys(texts).forEach_(_, function(_, columnName) {
				if (!elt.hasOwnProperty(columnName))
					return;
				var textIds = elt[columnName];
				if (!Array.isArray(textIds))
					textIds = [textIds];

				// Some texts can have multiple dimensions (AWINDOW.INTMSK for instance)
				textIds.forEach_(_, function(_, textId, textDimension) {

					config.patch.langs.forEach_(_, function(_, langCode) {
						var valsToWrite = [
							texts[columnName][textDimension][langCode] || "",
							langCode,
							textId,
						];

						if (elt["##comments##"] && elt["##comments##"][columnName] && elt["##comments##"][columnName][textDimension] && elt["##comments##"][columnName][textDimension][langCode])
							valsToWrite.push(elt["##comments##"][columnName][textDimension][langCode]);
						else
							valsToWrite.push("");
						_enqueueItem(5, columnName, textDimension, valsToWrite);
					});

					_enqueueItem(5, columnName, textDimension, ["", "***"]);
				});

				delete(elt[columnName]);
			});
			delete(elt["##texts##"]);
			delete(elt["##comments##"]);
		}

		Object.keys(elt).forEach_(_, function(_, key) {
			if (/^##\w+##$/.test(key)) {
				// Special tags : ##texts##, ##comments##, ##extraTables##, ...
				return;
			}

			var val = decodeValueFromJsonString(key, elt[key]);
			if ("array" == val.type) {
				val.value.forEach_(_, function(_, arrayItem, itemIdx) {
					_enqueueItem(4, key, itemIdx, arrayItem.value, arrayItem.type);
				});
			} else if ("clob" == val.type) {
				_enqueueItem(25, key, 0, val.value, val.type);
			} else {
				_enqueueItem(4, key, 0, val.value, val.type);
			}
		});

		Object.keys(allLines).sort().forEach_(_, function(_, lines) {
			allLines[lines].forEach_(_, function(_, line) {
				writer.write(_, line + "\n");
			});
		});

		if (elt["##extraTables##"] && elt["##extraTables##"].ATEXTRA) {
			var texts = elt["##extraTables##"].ATEXTRA;
			Object.keys(texts).forEach_(_, function(_, columnName) {
				var atLeastOneText = false;
				config.patch.langs.forEach_(_, function(_, langCode) {
					var valsToWrite = [
						texts[columnName][langCode] || "",
						langCode,
					];
					var textVals = texts[columnName];
					// Note : textVals is an object indexed by ATEXTRA.IDENT2_0.
					if (textVals) {
						// Here, we only consider the first ATEXTRA.IDENT2_0.
						var t = texts[columnName][Object.keys(texts[columnName])[0]];
						if (t[langCode]) {
							writer.write(_, _formatValues(9, columnName, 0, [t[langCode], langCode, "" + elt[eltConfig.primaryKey], Object.keys(texts[columnName])[0]]) + "\n");
							atLeastOneText = true;
						}
					}
				});
				if (atLeastOneText)
					writer.write(_, _formatValues(9, columnName, 0, ["", "***"]) + "\n");
			});
			delete(elt["##extraTables##"])
		}

		writer.write(_, "6,\"" + eltConfig.abbrev + "\"\n");
	}

	function _invokeTitleFunction(fct, elt) {
		var arg = {};
		Object.keys(elt).forEach(function(key) {
			arg[key] = decodeValueFromJsonString(key, elt[key]).value;
		});
		var title = fct(arg);
		if (title && title["ENG"])
			title = title["ENG"];
		return title;
	}

	function _processMetaElement(_, writer, entityExportConfig, elt) {
		var title;
		if (elt["##texts##"]) {
			title = elt["##texts##"][entityExportConfig.textLinks[0]][0]["ENG"];
		} else {
			if (entityExportConfig.mainTitleFunction)
				title = _invokeTitleFunction(entityExportConfig.mainTitleFunction, elt);
			else
				throw new Error("No localized label are defined for element '" + entityExportConfig.title + "', you must provide a 'mainTitleFunction' function.")
		}
		var header = '"' + entityExportConfig.abbrev + '","' + decodeValueFromJsonString(entityExportConfig.primaryKey, elt[entityExportConfig.primaryKey]).value + '","' + title + '"';
		writer.write(_, "2," + header + "\n");
		var children = [];
		if (entityExportConfig.children) {
			// The configuration describes some child-node, we have to keep them in a separate list.
			// They will be processed later.
			Object.keys(entityExportConfig.children).forEach(function(childName) {
				// For instance, in tables.js, childName == 'COLUMNS' or 'INDEXES'
				if (elt[childName]) {
					// note : elt[childName] is an array. Each item describes a child (i.e. one index or one column)
					elt[childName].forEach(function(c) {
						children.push({
							name: childName,
							node: c
						});
					});
					// We have to delete the child, otherwise it would be exposed as a value in the .dat file
					delete(elt[childName]);
				}
			});
		}
		_processElement(_, writer, elt, entityExportConfig);

		// Now, we can process the children
		children.forEach_(_, function(_, child) {
			_processElement(_, writer, child.node, entityExportConfig.children[child.name]);
		});

		writer.write(_, "7," + header + "\n");
	}

	// returns whether an ABSOLUTE filename describes a .json meta file
	function _isMetaFile(absoluteFilename) {
		return /\.json$/.test(absoluteFilename);
	}

	// Generates a patch file from all the JSON files contained in jsonFilesList. 
	// jsonFilesList contains ABSOLUTE filenames
	// Depending on config.oneFile, the function will either generate a patch file per JSON file
	// or a unique patch file for all the JSON files.
	// This function returns the absolute filenames of all the generated path files
	function _generatePatches(_, jsonFilesList, options) {

		var filenames = [];
		var writer;

		// Convention for activity codes : 
		// null / undefined / [''] : process all the secondary files (xxx.activityCode.json)
		// [null] / [undefined] : process only the primary file (xxx.json)
		// ['yyy', 'zzz'] : process xxx.json, xxx.yyy.json, xxx.zzz.json (and skip all the other secondary files)
		if (!options.activityCodes) {
			// Process the primary files and all the secondary files
			options.activityCodes = [''];
		} else {
			if ((options.activityCodes.length == 1) && (!options.activityCodes[0])) {
				// Only process the primary files (xxx.json) and skip any secondary file (xxx.activityCode.json)
				options.activityCodes = undefined;
			}
		}

		function _openWriter(_, shortFilename) {
			var patchFilename = path.join(config.solutionPath, config.patchSubFolder, shortFilename + ".dat");
			filenames.push(patchFilename);
			writer = file.text.writer(patchFilename, "utf8");
			config.trace && config.trace("\tGenerating patch file: " + patchFilename);

			var header = '1,"' + config.patch.comment + '","' + config.patch.langs.join("/") + '","' + config.patch.version + '","';
			if (options.activityCode && options.activityCode.length && options.activityCode[0] !== '')
				header += options.activityCodes.sort().join('/');
			header += '","' + config.patch.product + '","1",\n';
			writer.write(_, header);
		}

		function _closeWriter(_, writer) {
			writer.write(_, '8,"' + config.patch.comment + '"\n');
			writer.end();
		}

		function _parseFilename(filename) {
			// Normalize the filename
			filename = path.join(filename);
			// Note filename looks like "META_SUB_FOLDER/SUPERV/TABLES/ABANK.json"

			var parts = filename.split(path.sep);

			// Note : we don't know the depth of the folder where the JSON files is, so we have
			// to read infos from the end of the array
			return {
				path: parts.slice(0, parts.length - 3).join(path.sep),
				module: parts[parts.length - 3],
				type: parts[parts.length - 2],
				shortFilename: parts[parts.length - 1],
			};
		}

		// Note : the gitWrapper may have changed the current folder
		process.chdir(config.solutionPath);

		// clean the output folder
		config.trace && config.trace("Cleaning output folder : " + config.patchSubFolder);
		_cleanFolder(_, config.patchSubFolder);

		var patchFolder = path.join(config.solutionPath, config.patchSubFolder);
		if (!fs.exists(patchFolder, _)) {
			config.trace && config.trace("Create output folder " + patchFolder);
			try {
				fs.mkdir(patchFolder, _);
			} catch (err) {
				throw new Error("Could not create patch folder, reason = " + err.message);
			}
		}

		if (config.oneFile)
			_openWriter(_, "patch");

		if (config.oneFile && jsonFilesList.length > 1) {
			// We will generate a single patch file from many json files. 
			// the json files must be ordered (for instance, activityCodes must be exported before classes)
			var typeAbbreviations = {};

			// Load all the entity configurations to be able to link an entity name to its abbreviation
			var resPath = path.join(__dirname, "../../etna-etl/lib/entities/");
			fs.readdir(resPath, _).forEach(function(filename) {
				var req = require(path.join(resPath, filename));
				typeAbbreviations[req.entity.subdir] = req.entity.abbrev;
			});

			jsonFilesList.sort(function(filename1, filename2) {
				var parts1 = _parseFilename(filename1);
				var parts2 = _parseFilename(filename2);
				var idx1 = orderedTypes.indexOf(typeAbbreviations[parts1.type]);
				var idx2 = orderedTypes.indexOf(typeAbbreviations[parts2.type]);
				return idx1 - idx2;
			});
		}

		var regExps;
		jsonFilesList.forEach_(_, function(_, filename) {
			// Normalize the filename
			filename = path.join(filename);
			// Note filename looks like "META_SUB_FOLDER/SUPERV/TABLES/ABANK.json"
			config.trace && config.trace("Processing file " + filename);
			if (!_isMetaFile(filename)) {
				// This file is not a metadata file
				return;
			}

			var parts = _parseFilename(filename);
			// parts.shortFilename has the following format xxxx[.activityCode].json (activityCode is optional)
			// We just keep the 'xxxx'
			parts.shortFilename = parts.shortFilename.substring(0, parts.shortFilename.indexOf('.'));

			var allFiles;
			if (options.activityCodes) {
				var includeAllActivityCodes = options.activityCodes.some(function(activityCode) {
					return "" === activityCode;
				});
				var fileFolder = path.dirname(filename);
				// We have to retrieve all the xxxx.activityCode.json files whose activityCode matched option.activityCodes
				allFiles = fs.readdir(fileFolder, _).filter(function(file) {
					var idx1 = file.indexOf('.');
					var idx2 = file.lastIndexOf('.');
					if (file.substring(0, idx1) != parts.shortFilename) {
						// This is a file for another entity
						return false;
					}
					if (idx1 === idx2) {
						// Primary file (xxxx.json)
						return true;
					}
					if (includeAllActivityCodes)
						return true;
					var fileActivityCode = file.substring(idx1 + 1, idx2);
					if (options.activityCodes.some(function(activityCode) {
						return (activityCode === fileActivityCode);
					}))
						return true;
					// Last chance, we can try to interpret the activityCodes as regular expressions
					if (!regExps) {
						regExps = options.activityCodes.map(function(activityCode) {
							return new RegExp(activityCode);
						});
					}
					return regExps.some(function(regex) {
						return regex.test(fileActivityCode);
					});
				}).map(function(file) {
					// use absolute filenames
					return path.join(fileFolder, file);
				});
				config.trace && config.trace("Will process file group : " + allFiles);
			} else {
				// Only process the primary files (xxx.json) and skip any secondary file (xxx.activityCode.json)
				allFiles = [filename];
			}

			var entityDescriptor = require("etna-etl/lib/entities/" + parts.type).entity;

			var elt;

			try {
				elt = readAndMergeJsonFiles(_, allFiles, entityDescriptor);
			} catch (err) {
				throw new Error("Could not read file '" + filename + "', reason = " + err.message);
			}

			if (!config.oneFile)
				_openWriter(_, parts.type + "_" + parts.shortFilename);
			_processMetaElement(_, writer, entityDescriptor, elt);
			if (!config.oneFile) {
				_closeWriter(_, writer);
			}
		});
		if (config.oneFile) {
			_closeWriter(_, writer);
		}

		return filenames;
	}

	// Stores the sha1 that was last synchronized
	function _setLastSyncdSha1(_, sha1) {
		try {
			superv.sqlDriver.withConnection(_, function(_, cnx) {
				superv.sqlDriver.execute(_, cnx, "delete from " + config.settingsTable + " where ID = " + superv.sqlDriver.param(0), ["PATCH.SYNC.LAST.GIT.HEAD"]);
				var valueToWrite = JSON.stringify({
					sha1: sha1,
					date: new Date().toISOString()
				});
				superv.sqlDriver.execute(_, cnx, "insert into " + config.settingsTable + " (ID, VALUE) values (" + superv.sqlDriver.param(0) + "," + superv.sqlDriver.param(1) + ")", ["PATCH.SYNC.LAST.GIT.HEAD", valueToWrite]);
			});
		} catch (err) {
			console.log("ERROR : " + err.message);
		}
		config.trace && config.trace("'" + sha1 + "' written as the last sync'd head.");
	}

	// Returns the ABSOLUTE filename of all the files that were modified between 2 sha1
	function _listModifiedFiles(_, fromSha1, toSha1) {
		var result;
		if (fromSha1) {
			// Return only the files that were modified in the range fromSha1..toSha1
			result = _getGitWrapper().diffStat(_, fromSha1, toSha1 || this.getGitHead(_));
		} else {
			// Retrieve all versionned files
			result = _getGitWrapper().diffStat(_);
		}
		return result.diffs.map(function(diff) {
			switch (diff.touch) {

				case 'A': // Add
				case 'M': // Modified
					return diff.filename;
				case 'D': // Deleted
					// STDEN : ignored for now
					return;
				default:
					// STDEN : ignored for now
					return;
			}
		}).filter(function(d) {
			// Remove 'undefined' entries
			return d;
		});
	}

	function _applyPatches(_, patchFilenames) {
		if (!patchFilenames.length)
			return;
		console.log("******* TODO ***********");
		console.log("apply the following patches : ");
		patchFilenames.forEach(function(patchFilename) {
			console.log("\t-" + patchFilename);
		})
	}

	function _remove(_, s) {
		if (!fs.exists(s, _))
			return;
		try {
			var stat = fs.stat(s, _);
			if (stat.isDirectory()) {
				fs.readdir(s, _).forEach_(_, function(_, f) {
					_remove(_, s + '/' + f);
				});
				fs.rmdir(s, _);
			} else {
				fs.unlink(s, _);
			}
		} catch (err) {
			throw new Error("Could not delete " + s + ", reason = " + err.message);
		}
	}

	function _cleanFolder(_, path) {
		try {
			fs.readdir(path, _).forEach_(_, function(_, name) {
				_remove(_, path + "/" + name);
			});
		} catch (err) {
			throw new Error("Could not clean folder " + path + ", reason = " + err.message);
		}

	}

	return {

		/// !doc
		/// ### getLastSyncdSha1(_)
		/// Returns the sha1 that was last synchronized
		getLastSyncdSha1: function(_) {
			var sha1;
			try {
				superv.sqlDriver.withConnection(_, function(_, cnx) {
					var row = superv.sqlDriver.reader(_, cnx, "select VALUE from " + config.settingsTable + " where ID = " + superv.sqlDriver.param(0), ["PATCH.SYNC.LAST.GIT.HEAD"]).toArray(_)[0];
					if (!row) {
						return null;
					}
					sha1 = JSON.parse(row.VALUE).sha1;
				});
			} catch (err) {
				console.log("ERROR : " + err.message);
			}
			return sha1;
		},

		/// !doc
		/// --------------------------
		/// ### getGitHead(_)
		/// Returns the current head of the local git repo
		/// ``` javascript
		/// { 
		///		sha1: xxxx,
		///		author: xxxx,
		///		email: xxxx,
		///		date: xxxx,
		///		subject: xxxx,
		/// }
		/// 
		/// ```
		getGitHead: function(_) {
			return _getGitWrapper().getHead(_);
		},

		/// !doc
		/// --------------------------
		/// ### generatePatches(_, jsonFilesList, options)
		/// Generates a patch file from all the JSON files contained in jsonFilesList. 
		/// jsonFilesList contains ABSOLUTE filenames
		/// Depending on config.oneFile, the function will either generate a patch file per JSON file
		/// or a unique patch file for all the JSON files.
		/// This function returns the absolute filenames of all the generated path files
		generatePatches: function(_, jsonFilesList, options) {
			options = options || {};
			return _generatePatches(_, jsonFilesList, options);
		},


		/// !doc
		/// --------------------------
		/// ### synchronize(_, options)
		/// Updates the metadata from a git repository.
		/// The local git repo will first be sync'd (git pull) and, if no errors occured,
		/// a patch file will be generated from all the updated/created JSON files.
		/// This patch file will then be sent to the server so that it can update its metadata.
		synchronize: function(_, options) {
			options = options || {};

			var gitFolder = _getGitWrapper().getFolder();
			if (config.trace) {
				var currentBranchResult = _getGitWrapper().command(_, "symbolic-ref", ["--short", "HEAD"]);
				if (0 === currentBranchResult.exitCode)
					config.trace("Current branch is [" + currentBranchResult.out + "]");
				else
					config.trace("Could not get the current branch, reason = " + currentBranchResult.err);
				config.trace("Local git folder : " + gitFolder);
			}

			// Run a git pull command to retreive all the new/updated json files
			config.trace && config.trace("Git pull...");
			var result = _getGitWrapper().pull(_);

			if (result.exitCode) {
				// Something went wrong ... maybe a conflict
				// For now, we can't do anything
				var msg = "The git-pull failed, reason = " + result.err;
				config.trace && config.trace(msg);
				throw new Error(msg);
			}

			var lastSyncdSha1;
			if (!options.full)
				lastSyncdSha1 = this.getLastSyncdSha1(_);
			if (config.trace) {
				if (lastSyncdSha1)
					config.trace("Last sync'd head = " + lastSyncdSha1);
				else
					config.trace("Last sync'd head = not set => full sync");
			}

			var gitHead = this.getGitHead(_);
			config.trace && config.trace("Git head = " + gitHead.sha1);

			// First : retrieve the files that have been updated (or created) between the two revisions			
			var jsonFilesList = _listModifiedFiles(_, lastSyncdSha1, gitHead.sha1).filter(_isMetaFile).filter(
				function(filename) {
					return _isMetaFile(filename);
				});

			if (jsonFilesList.length) {
				var patchFilenames = _generatePatches(_, jsonFilesList, options);
				_applyPatches(_, patchFilenames);

				// Store the current head in db so that next sync will be incremental
				_setLastSyncdSha1(_, gitHead.sha1);
			} else {
				config.trace && config.trace("Already up-to-date, no patch needed.")
			}
		},

		/// !doc
		/// --------------------------
		/// ### getOrderedTypes()
		/// Returns the order that should be used to export entities in a path file (for 
		/// instance, activityCodes must be exported before classes).
		/// Each entity type is described by the abbreviation of its table (ATABLE.ABRFIC).
		getOrderedTypes: function() {
			return orderedTypes;
		},

		resolveConflitcs: function(_, entity, jsonFile, options) {


			var inConflict = false;
			var inPreviousVersion = false;
			var currentVersion = "";
			var previousVersion = "";
			file.text.reader(jsonFile, "utf8").transform(ez.transforms.lines.parser()).forEach(_, function(_, line) {
				if (line[0] == '<') {
					inConflict = true;
					inPreviousVersion = true;
				} else if (line[0] === '=') {
					inPreviousVersion = false;
				} else if (line[0] == '>') {
					inConflict = false;
				} else {
					if (inConflict) {
						if (inPreviousVersion)
							previousVersion += line;
						else
							currentVersion += line;
					} else {
						previousVersion += line;
						currentVersion += line;
					}
				}
			});
			var writer = file.text.writer("c:\\out.xml", "utf8");
			writer.write(_, previousVersion);
			writer.write(_);
			var prevObj = JSON.parse(previousVersion);
			var currentObj = JSON.parse(currentVersion);
			var result = findDifferences(_, entity, "", "", prevObj, currentObj, options);
			console.log(JSON.stringify(result, undefined, "    "));
		}
	}


	function findDifferences(_, entity, propName, path, valLeft, valRight, options) {

		var localizedLabels = {};
		options = options || {};

		if (options.skipSpecials && ("##" === propName.slice(0, 2))) {
			// Skip special tags (##texts##, ##comments##, ...)
			return undefined;
		}



		function getLocalizedLabel(_, tableName, columnName) {
			if (!localizedLabels[tableName]) {
				// Load all the localized labels for this table
				var sql = "SELECT z.CODZONE_0 ZONE, t.TEXTE_0 TEXT FROM ATABZON z";
				sql += " LEFT JOIN ATEXTE t ON t.NUMERO_0 = z.NOLONG_0";
				sql += " WHERE z.CODFIC_0=" + superv.sqlDriver.param(0) + " AND t.LAN_0 = " + superv.sqlDriver.param(1);
				superv.sqlDriver.withConnection(_, function(_, cnx) {
					superv.sqlDriver.execute(_, cnx, sql, [tableName, options.langage || "FRA"]).forEach(function(row) {
						localizedLabels[tableName + "." + row.ZONE] = row.TEXT;
					});
				});
				localizedLabels[tableName] = tableName;
			}
			var key = tableName + '.' + columnName;
			var label = localizedLabels[key];
			if (!label)
				label = key;
			return label;
		}

		function getDistance(a, b) {
			if (a.length == 0) return b.length;
			if (b.length == 0) return a.length;

			var matrix = [];

			// increment along the first column of each row
			var i;
			for (i = 0; i <= b.length; i++) {
				matrix[i] = [i];
			}

			// increment each column in the first row
			var j;
			for (j = 0; j <= a.length; j++) {
				matrix[0][j] = j;
			}

			// Fill in the rest of the matrix
			for (i = 1; i <= b.length; i++) {
				for (j = 1; j <= a.length; j++) {
					if (b.charAt(i - 1) == a.charAt(j - 1)) {
						matrix[i][j] = matrix[i - 1][j - 1];
					} else {
						matrix[i][j] = Math.min(matrix[i - 1][j - 1] + 1, // substitution
							Math.min(matrix[i][j - 1] + 1, // insertion
								matrix[i - 1][j] + 1)); // deletion
					}
				}
			}

			return matrix[b.length][a.length];
		};

		function indexArray(entity, array) {
			var indexedArray = {};
			array.forEach(function(instance) {
				indexedArray[instance[getPK(entity)]] = instance;
			});
			return indexedArray;
		}

		function getPK(entity) {
			return entity.primaryKey || entity.patchPK || entity.orderBy;
		}


		var result = undefined;
		//console.log(path + " : compare " + valLeft + " / " + valRight);
		if (valLeft == valRight) {
			if (options.skipMatching)
				return undefined;
			return {
				label: getLocalizedLabel(_, entity.tableName, propName),
				path: path,
				status: "match",
				value: valLeft
			};
		}
		if (Array.isArray(valLeft)) {
			// Assume that valRight is also an array
			var subEntity;
			if (entity.children && entity.children.hasOwnProperty(propName)) {

				// This is a subObject
				subEntity = entity.children[propName];
				// We have to index all the items by their PK to be sure to compare the good pairs.
				// for instance, in a table, there will be a subObject named "COLUMNS" that will describe all the columns.
				// We can't be sure that the columns were serialized in the same order in the left and in the right object.
				var arrLeft = indexArray(subEntity, valLeft);
				var arrRight = indexArray(subEntity, valRight);
				result = findDifferences(_, subEntity, propName, path, arrLeft, arrRight, options);

			} else {
				// TODO !!!
				// Here, the items of the array can't be indexed, so we have no other choice than
				// assuming (or hoping...) that all the items are sorted the same way on the 2 arrays.
				// Might be improved later (maybe by using levenshtein distance based algo to identify the bast pairs)
				for (var i = 0; i < Math.min(valLeft.length, valRight.length); i++) {
					var subResult = findDifferences(_, entity, propName, path + "[" + i + "]", valLeft[i], valRight[i], options);
					if (subResult) {
						result = result || [];
						result.push(subResult);
					}
				}
				for (var i = Math.min(valLeft.length, valRight.length); i < valLeft.length; i++) {
					result.push({
						path: path + "[" + i + "]",
						status: "missing",
						left: valLeft[i],
					});
				}
				for (var i = Math.min(valLeft.length, valRight.length); i < valRight.length; i++) {
					result.push({
						path: path + "[" + i + "]",
						status: "missing",
						right: valRight[i],
					});
				}
			}

		} else if ("object" === typeof(valLeft)) {
			// Assume that valRight is also an object
			Object.keys(valLeft).forEach_(_, function(_, childPropName) {
				if (!valRight.hasOwnProperty(childPropName)) {
					result = result || {};
					result[childPropName] = {
						label: getLocalizedLabel(_, entity.tableName, childPropName),
						path: path + "/" + childPropName,
						status: "missing",
						left: valLeft[childPropName],
					};
					return;
				}
				var propVal1 = valLeft[childPropName];
				var propVal2 = valRight[childPropName];
				var subResult = findDifferences(_, entity, childPropName, path + "/" + childPropName, propVal1, propVal2, options);
				if (subResult) {
					result = result || {}
					result[childPropName] = subResult;
				}
				delete valRight[childPropName];
			});
			// Here, valRight only contains the properties that are not declared in valLeft
			Object.keys(valRight).forEach_(_, function(_, childPropName) {
				result = result || {};
				result[childPropName] = {
					label: getLocalizedLabel(_, entity.tableName, childPropName),
					path: path + "/" + childPropName,
					status: "missing",
					right: valRight[childPropName],
				};
			});
		} else {
			result = {
				label: getLocalizedLabel(_, entity.tableName, propName),
				path: path,
				status: "mismatch",
				left: valLeft,
				right: valRight,
			};
		}
		return result;
	}
};
