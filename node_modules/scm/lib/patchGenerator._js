"use strict";
var supervisor = require("etna-supervisor/lib/supervisor"),
	nodeLocalConfig = require('config'),
	gitWrapper = require('etna-etl/lib/gitWrapper'),
	path = require("path"),
	ez = require("ez-streams"),
	file = ez.devices.file,
	fs = require("streamline-fs"),
	gitWrapperInstance;

var orderedTypes = [
	"ACV", "AML", "ELT", "BIA", "TXT", "EXE", "AHI", "ATN", "ADC", "ANG", "ADX", "TRT", "ETA", "ACS", "ANM", "ACT", "AFC", "ACL", "ASL", "ATYP", "AGB", "ACTX", "ACST", "ASU", "ATY", "ADV", "ADI", "ATB", "AVW", "AUR", "AMK", "ARP", "AOB", "AOP", "ADP", "AWI", "AOE", "AEN", "ACN", "PS1", "PS2", "TAB", "GAU", "AWM", "AWR", "AWA", "AWW", "ABT", "ABA", "ABG", "ACLA", "ASW", "ADZ", "ADO", "ADF", "ALH", "ALQ", "ALT", "ABF", "ABI", "ABM", "ABV", "ABO", "AHH", "AII", "ASY", "TFO", "APR", "AWE", "ANT", "AMC", "AY", "AYS", "ELX", "AYG", "AYD", "AYF", "AYM", "AYI", "AYE", "AYB", "AYO", "AYA", "AYL", "AYW", "AYC", "AYU", "IND"
];

exports.newGenerator = function(_, config) {

	config.git = config.git || {};
	config.patch = config.patch || {};
	config.patch.langs = config.patch.langs || ["ENG", "FRA"]
	config.patch.comment = config.patch.comment || "test";
	config.patch.version = config.patch.version || 1;
	config.patch.product = config.patch.product || "X3";
	config.settingsTable = config.settingsTable || "_SETTINGS";
	if (undefined === config.oneFile)
		config.oneFile = true;


	// Normalize the meta folder
	config.metaSubFolder = path.join(config.metaSubFolder + "/").toLowerCase();
	var superv = supervisor.create(_, config);

	try {
		// Make sure the settings table exists
		superv.sqlDriver.getTableDef(_, superv.folderName, config.settingsTable);
	} catch (err) {
		console.log("ERROR : " + err);
		var tableDef = {
			schemaName: superv.folderName,
			tableName: config.settingsTable,
			columns: [{
				name: "GITSHA1",
				isNullable: true,
				type: "nvarchar",
				maxLength: 40
			}],
			indexes: [],
		};
		superv.sqlDriver.createTableFromTableDefinition(_, tableDef);
		config.trace && config.trace("Settings table '" + tableDef.tableName + "' was created.")
	}

	function _getGitWrapper() {
		if (!gitWrapperInstance) {
			var options = {
				folder: config.gitFolder || config.solutionPath,
				trace: config.git.trace
			};
			gitWrapperInstance = new gitWrapper.git(options);
		}
		return gitWrapperInstance;
	}

	function _parseJSONValue(key, val) {

		if (/^##\w+##$/.test(key)) {
			// Special tags : ##texts##, ##comments##, ...
			return {
				type: "extra",
				value: val
			};
		}
		var result = {};
		if (Array.isArray(val)) {
			result.value = [];
			result.type = "array";
			val.forEach(function(arrayItem, itemIdx) {
				result.value.push(_parseJSONValue(key + "[" + itemIdx + "]", arrayItem));
			});
		} else if ("string" === typeof(val)) {
			switch (val.charAt(0)) {
				case "S":
					var parts = /^S(\:[^|"]+)?\|(.*)$/.exec(val);
					if (parts) {
						// String : S|xxxxx
						// String with specific option (type option) : S:TF|xxxxxxxx
						result = {
							type: "string",
							value: parts[2]
						};
						if (" " === result.value)
							result.value = "";
						if (parts[1]) {
							if (parts[1].indexOf('T') != -1) {
								// This text is a formula, some characters must be mapped
								// Replace ',' with #254
								result.value = result.value.replace(/,/g, String.fromCharCode(255))
								// Replace #10 with #255
								result.value = result.value.replace(/\r/g, String.fromCharCode(254))
							}
						}
					} else
						throw new Error("Invalid string value : " + val);
					break;
				case "C":
					// Clobs
					result = {
						type: "clob",
						value: val.substring(val.indexOf("|") + 1)
					};
					break;
				case "N":
					// Decimals are stored as strings in json
					result = {
						type: "decimal",
						value: parseFloat(val.substring(val.indexOf("|") + 1))
					};
					break;
				case "D":
					// Date (without time part)
					// D:2009-12-31 -> 20091231
					val = val.substring(val.indexOf("|") + 1);
					result = {
						type: "date",
						value: val == "NULL" ? null : parseInt(val.replace(/\-/g, ""))
					};
					break;
				case "T":
					// Timestamp
					// T|2003-09-11T00:00:00.000Z -> 2003-09-11T00:00:00Z
					// just remove the millis
					val = val.substring(val.indexOf("|") + 1);
					result = {
						type: "timestamp",
						value: val.substring(0, val.lastIndexOf(".")) + "Z"
					};
					break;
				default:
					// should never happen
					throw new Error("Unknown value type : " + val);
					break;
			}
		} else if (isFinite(val)) {
			result = {
				type: "number",
				value: val
			};
			// Nothing to do : this is a number. Keep it as it.
		} else {
			// should never happen .. may be an object
		}
		return result;
	}

	function _processElement(_, writer, elt, eltConfig) {
		// Compute the title of the block
		var blockTitle;
		if (eltConfig.titleFunction) {
			blockTitle = _invokeTitleFunction(eltConfig.titleFunction, elt);
		} else {
			var pk = eltConfig.primaryKey || eltConfig.patchPK;
			if (!pk) {
				if (!eltConfig.orderBy)
					throw new Error("'orderBy' property is missing on element " + (eltConfig.title ? eltConfig.title : eltConfig.tableName));
				pk = eltConfig.orderBy.split(',')[0];
			}
			blockTitle = _parseJSONValue(pk, elt[pk]).value;
		}

		writer.write(_, "3,\"" + eltConfig.abbrev + "\"," + blockTitle + "\n");

		var allLines = {};

		function _formatValues(lineType, name, dimension, values, valueType) {
			var line = lineType + ',"' + name + '",' + dimension;
			if (25 === lineType) {
				// Clob
				line += "\r\n" + values.length + "\n" + values + "\n" + "**********";
			} else {
				if (!Array.isArray(values))
					values = [values];
				values.forEach(function(value) {
					line += ',';
					if (typeof(value) == "string") {
						if (value == " ")
							value = "";
						line += '"' + value + '"';
					} else {
						if ((4 === lineType) && valueType && ("date" === valueType) && !value) {
							// null dates are written as 000000
							value = "000000";
						}
						line += value;
					}
				});
			}
			return line;
		}

		function _enqueueItem(lineType, name, dimension, values, valueType) {
			allLines[name] = allLines[name] || [];
			allLines[name].push(_formatValues(lineType, name, dimension, values, valueType));
		}

		if (elt["##texts##"]) {
			var texts = elt["##texts##"];
			Object.keys(texts).forEach_(_, function(_, columnName) {
				if (!elt.hasOwnProperty(columnName))
					return;
				var textIds = elt[columnName];
				if (!Array.isArray(textIds))
					textIds = [textIds];

				// Some texts can have multiple dimensions (AWINDOW.INTMSK for instance)
				textIds.forEach_(_, function(_, textId, textDimension) {

					config.patch.langs.forEach_(_, function(_, langCode) {
						var valsToWrite = [
							texts[columnName][textDimension][langCode] || "",
							langCode,
							textId,
						];

						if (elt["##comments##"] && elt["##comments##"][columnName] && elt["##comments##"][columnName][textDimension] && elt["##comments##"][columnName][textDimension][langCode])
							valsToWrite.push(elt["##comments##"][columnName][textDimension][langCode]);
						else
							valsToWrite.push("");
						_enqueueItem(5, columnName, textDimension, valsToWrite);
					});

					_enqueueItem(5, columnName, textDimension, ["", "***"]);
				});

				delete(elt[columnName]);
			});
			delete(elt["##texts##"]);
			delete(elt["##comments##"]);
		}

		Object.keys(elt).forEach_(_, function(_, key) {
			if (/^##\w+##$/.test(key)) {
				// Special tags : ##texts##, ##comments##, ##extraTables##, ...
				return;
			}

			var val = _parseJSONValue(key, elt[key]);
			if ("array" == val.type) {
				val.value.forEach_(_, function(_, arrayItem, itemIdx) {
					_enqueueItem(4, key, itemIdx, arrayItem.value, arrayItem.type);
				});
			} else if ("clob" == val.type) {
				_enqueueItem(25, key, 0, val.value, val.type);
			} else {
				_enqueueItem(4, key, 0, val.value, val.type);
			}
		});

		Object.keys(allLines).sort().forEach_(_, function(_, lines) {
			allLines[lines].forEach_(_, function(_, line) {
				writer.write(_, line + "\n");
			});
		});

		if (elt["##extraTables##"] && elt["##extraTables##"].ATEXTRA) {
			var texts = elt["##extraTables##"].ATEXTRA;
			Object.keys(texts).forEach_(_, function(_, columnName) {
				var atLeastOneText = false;
				config.patch.langs.forEach_(_, function(_, langCode) {
					var valsToWrite = [
						texts[columnName][langCode] || "",
						langCode,
					];
					var textVals = texts[columnName];
					// Note : textVals is an object indexed by ATEXTRA.IDENT2_0.
					if (textVals) {
						// Here, we only consider the first ATEXTRA.IDENT2_0.
						var t = texts[columnName][Object.keys(texts[columnName])[0]];
						if (t[langCode]) {
							writer.write(_, _formatValues(9, columnName, 0, [t[langCode], langCode, "" + elt[eltConfig.primaryKey], Object.keys(texts[columnName])[0]]) + "\n");
							atLeastOneText = true;
						}
					}
				});
				if (atLeastOneText)
					writer.write(_, _formatValues(9, columnName, 0, ["", "***"]) + "\n");
			});
			delete(elt["##extraTables##"])
		}

		writer.write(_, "6,\"" + eltConfig.abbrev + "\"\n");
	}

	function _invokeTitleFunction(fct, elt) {
		var arg = {};
		Object.keys(elt).forEach(function(key) {
			arg[key] = _parseJSONValue(key, elt[key]).value;
		});
		var title = fct(arg);
		if (title && title["ENG"])
			title = title["ENG"];
		return title;
	}

	function _processMetaElement(_, writer, entityExportConfig, elt) {
		var title;
		if (elt["##texts##"]) {
			title = elt["##texts##"][entityExportConfig.textLinks[0]][0]["ENG"];
		} else {
			if (entityExportConfig.mainTitleFunction)
				title = _invokeTitleFunction(entityExportConfig.mainTitleFunction, elt);
			else
				throw new Error("No localized label are defined for element '" + entityExportConfig.title + "', you must provide a 'mainTitleFunction' function.")
		}
		var header = '"' + entityExportConfig.abbrev + '","' + _parseJSONValue(entityExportConfig.primaryKey, elt[entityExportConfig.primaryKey]).value + '","' + title + '"';
		writer.write(_, "2," + header + "\n");
		var children = [];
		if (entityExportConfig.children) {
			// The configuration describes some child-node, we have to keep them in a separate list.
			// They will be processed later.
			Object.keys(entityExportConfig.children).forEach(function(childName) {
				// For instance, in tables.js, childName == 'COLUMNS' or 'INDEXES'
				if (elt[childName]) {
					// note : elt[childName] is an array. Each item describes a child (i.e. one index or one column)
					elt[childName].forEach(function(c) {
						children.push({
							name: childName,
							node: c
						});
					});
					// We have to delete the child, otherwise it would be exposed as a value in the .dat file
					delete(elt[childName]);
				}
			});
		}
		_processElement(_, writer, elt, entityExportConfig);

		// Now, we can process the children
		children.forEach_(_, function(_, child) {
			_processElement(_, writer, child.node, entityExportConfig.children[child.name]);
		});

		writer.write(_, "7," + header + "\n");
	}

	/// returns whether a relative filename describes a .json meta file (relative to solutionFolder)
	function _isMetaFile(relativeFilename) {
		// Normalize the filename
		relativeFilename = path.join(relativeFilename).toLowerCase();
		if (!relativeFilename.substr(0, config.metaSubFolder.length) == config.metaSubFolder) {
			// This file is not a metadata file
			return false;
		}
		return /\.json$/.test(relativeFilename);
	}

	/// Generates a patch file from all the JSON files contained in jsonFilesList. 
	/// jsonFilesList contains relative filenames (relative to solutionPath)
	/// Depending on config.oneFile, the function will either generate a patch file per JSON file
	/// or a unique patch file for all the JSON files.
	/// This function returns the absolute filenames of all the generated path files
	function _generatePatches(_, jsonFilesList, options) {

		var filenames = [];
		var writer;

		console.log("OneFile = " + config.oneFile);

		function _openWriter(_, shortFilename) {
			var patchFilename = path.join(config.solutionPath, config.patchSubFolder, shortFilename + ".dat");
			filenames.push(patchFilename);
			writer = file.text.writer(patchFilename, "utf8");
			config.trace && config.trace("\tGenerating patch file: " + patchFilename);

			writer.write(_, '1,"' + config.patch.comment + '","' + config.patch.langs.join("/") + '","' + config.patch.version + '","","' + config.patch.product + '","1",\n');
		}

		function _closeWriter(_, writer) {
			writer.write(_, '8,"' + config.patch.comment + '"\n');
			writer.end();
		}

		function _parseFilename(filename) {
			// Normalize the filename
			filename = path.join(filename);
			// Note filename looks like "META_SUB_FOLDER/SUPERV/TABLES/ABANK.json"

			var parts = filename.split(path.sep);

			// Note : we don't know the depth of the folder where the JSON files is, so we have
			// to read infos from the end of the array
			return {
				module: parts[parts.length - 3],
				type: parts[parts.length - 2],
				shortFilename: parts[parts.length - 1],
			};
		}

		// Note : the gitWrapper may have changed the current folder
		process.chdir(config.solutionPath);

		// clean the output folder
		config.trace && config.trace("Cleaning output folder : " + config.patchSubFolder);
		_cleanFolder(_, config.patchSubFolder);

		var patchFolder = path.join(config.solutionPath, config.patchSubFolder);
		if (!fs.exists(patchFolder, _)) {
			config.trace && config.trace("Create output folder " + patchFolder);
			try {
				fs.mkdir(patchFolder, _);
			} catch (err) {
				throw new Error("Could not create patch folder, reason = " + err.message);
			}
		}

		if (config.oneFile)
			_openWriter(_, "patch");

		if (config.oneFile && jsonFilesList.length > 1) {
			// We will generate a single patch file from many json files. 
			// the json files must be ordered (for instance, activityCodes must be imported before classes)
			var typeAbbreviations = {};

			// Load all the entity configurations to be able to link an entity name to its abbreviation
			var resPath = path.join(__dirname, "../../etna-etl/lib/entities/");
			fs.readdir(resPath, _).forEach(function(filename) {
				var req = require(path.join(resPath, filename));
				typeAbbreviations[req.entity.subdir] = req.entity.abbrev;
			});

			jsonFilesList.sort(function(filename1, filename2) {
				var parts1 = _parseFilename(filename1);
				var parts2 = _parseFilename(filename2);
				var idx1 = orderedTypes.indexOf(typeAbbreviations[parts1.type]);
				var idx2 = orderedTypes.indexOf(typeAbbreviations[parts2.type]);
				return idx1 - idx2;
			});
		}

		jsonFilesList.forEach_(_, function(_, filename) {
			// Normalize the filename
			filename = path.join(filename);
			// Note filename looks like "META_SUB_FOLDER/SUPERV/TABLES/ABANK.json"
			config.trace && config.trace("Processing file " + path.join(config.solutionPath, filename));
			if (!_isMetaFile(filename)) {
				// This file is not a metadata file
				return;
			}

			var parts = _parseFilename(filename);
			parts.shortFilename = parts.shortFilename.substring(0, parts.shortFilename.length - 5); // remove the '.json'

			var fullFileName = path.join(config.solutionPath, filename);
			var elt;
			try {
				elt = JSON.parse(fs.readFile(fullFileName, 'utf8', _));
			} catch (err) {
				throw new Error("Could not read file '" + fullFileName + "', reason = " + err.message);
			}
			if (!config.oneFile)
				_openWriter(_, parts.type + "_" + parts.shortFilename);
			var entityExportConfig = require("etna-etl/lib/entities/" + parts.type).entity;
			_processMetaElement(_, writer, entityExportConfig, elt);
			if (!config.oneFile) {
				_closeWriter(_, writer);
			}
		});
		if (config.oneFile) {
			_closeWriter(_, writer);
		}

		return filenames;
	}

	/// Stores the sha1 that was last synchronized
	function _setLastSyncdSha1(_, sha1) {
		try {
			superv.sqlDriver.withConnection(_, function(_, cnx) {
				superv.sqlDriver.execute(_, cnx, "delete from " + config.settingsTable);
				superv.sqlDriver.execute(_, cnx, "insert into " + config.settingsTable + " (GITSHA1) values (" + superv.sqlDriver.param(0) + ")", [sha1]);
			});
		} catch (err) {
			console.log("ERROR : " + err.message);
		}
		config.trace && config.trace("'" + sha1 + "' written as the last sync'd head.");
	}

	function _listModifiedFiles(_, fromSha1, toSha1) {
		var result;
		if (fromSha1) {
			// Return only the files that were modified in the range fromSha1..toSha1
			result = _getGitWrapper().diffStat(_, fromSha1, toSha1 || this.getGitHead(_));
		} else {
			// Retrieve all versionned files
			result = _getGitWrapper().diffStat(_);
		}
		return result.diffs.map(function(diff) {
			switch (diff.touch) {

				case 'A': // Add
				case 'M': // Modified
					return diff.filename;
				case 'D': // Deleted
					// STDEN : ignored for now
					return;
				default:
					// STDEN : ignored for now
					return;
			}
		}).filter(function(d) {
			// Remove 'undefined' entries
			return d;
		});
	}

	function _applyPatches(_, patchFilenames) {
		if (!patchFilenames.length)
			return;
		console.log("******* TODO ***********");
		console.log("apply the following patches : ");
		patchFilenames.forEach(function(patchFilename) {
			console.log("\t-" + patchFilename);
		})
	}

	function _remove(_, s) {
		if (!fs.exists(s, _))
			return;
		try {
			var stat = fs.stat(s, _);
			if (stat.isDirectory()) {
				fs.readdir(s, _).forEach_(_, function(_, f) {
					_remove(_, s + '/' + f);
				});
				fs.rmdir(s, _);
			} else {
				fs.unlink(s, _);
			}
		} catch (err) {
			throw new Error("Could not delete " + s + ", reason = " + err.message);
		}
	}

	function _cleanFolder(_, path) {
		try {
			fs.readdir(path, _).forEach_(_, function(_, name) {
				_remove(_, path + "/" + name);
			});
		} catch (err) {
			throw new Error("Could not clean folder " + path + ", reason = " + err.message);
		}

	}

	return {

		/// Returns the sha1 that was last synchronized
		getLastSyncdSha1: function(_) {
			var sha1;
			try {
				superv.sqlDriver.withConnection(_, function(_, cnx) {
					var row = superv.sqlDriver.reader(_, cnx, "select GITSHA1 from " + config.settingsTable).toArray(_)[0];
					if (!row) {
						return null;
					}
					sha1 = row.GITSHA1;
				});
			} catch (err) {
				console.log("ERROR : " + err.message);
			}
			return sha1;
		},

		/// Returns the current head of the local git repo
		/// ``` javascript
		/// { 
		///		sha1: xxxx,
		///		author: xxxx,
		///		email: xxxx,
		///		date: xxxx,
		///		subject: xxxx,
		/// }
		/// 
		/// ```
		getGitHead: function(_) {
			return _getGitWrapper().getHead(_);
		},

		/// Generates a patch file from all the JSON files contained in jsonFilesList. 
		/// jsonFilesList contains relative filenames (relative to solutionPath)
		/// Depending on config.oneFile, the function will either generate a patch file per JSON file
		/// or a unique patch file for all the JSON files.
		/// This function returns the absolute filenames of all the generated path files
		generatePatches: function(_, jsonFilesList, options) {
			options = options || {};
			return _generatePatches(_, jsonFilesList, options);
		},


		/// Updates the metadata from a git repository.
		/// The local git repo will first be sync'd (git pull) and, if no errors occured,
		/// a patch file will be generated from all the updated/created JSON files.
		/// This patch file will then be sent to the server so that it can update its metadata.
		synchronize: function(_, options) {
			options = options || {};

			if (config.trace) {
				var currentBranchResult = _getGitWrapper().command(_, "symbolic-ref", ["--short", "HEAD"]);
				if (0 === currentBranchResult.exitCode)
					config.trace("Current branch is [" + currentBranchResult.out + "]");
				else
					config.trace("Could not get the current branch, reason = " + currentBranchResult.err);
				config.trace("Local git folder : " + _getGitWrapper().getFolder());
			}

			// Run a git pull command to retreive all the new/updated json files
			config.trace && config.trace("Git pull...");
			var result = _getGitWrapper().pull(_);

			if (result.exitCode) {
				// Something went wrong ... maybe a conflict
				// For now, we can't do anything
				var msg = "The git-pull failed, reason = " + result.err;
				config.trace && config.trace(msg);
				throw new Error(msg);
			}

			var lastSyncdSha1;
			if (!options.full)
				lastSyncdSha1 = this.getLastSyncdSha1(_);
			if (config.trace) {
				if (lastSyncdSha1)
					config.trace("Last sync'd head = " + lastSyncdSha1);
				else
					config.trace("Last sync'd head = not set => full sync");
			}

			var gitHead = this.getGitHead(_);
			config.trace && config.trace("Git head = " + gitHead.sha1);

			// First : retrieve the files that have been updated (or created) between the two revisions			
			var jsonFilesList = _listModifiedFiles(_, lastSyncdSha1, gitHead.sha1).filter(_isMetaFile);

			if (jsonFilesList.length) {
				var patchFilenames = _generatePatches(_, jsonFilesList, options);
				_applyPatches(_, patchFilenames);

				// Store the current head in db so that next sync will be incremental
				_setLastSyncdSha1(_, gitHead.sha1);
			} else {
				config.trace && config.trace("Already up-to-date, no patch needed.")
			}
		},

		getOrderedTypes: function ()
		{
			return orderedTypes;
		}
	}
};
