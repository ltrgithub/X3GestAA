"use strict";
var supervisor = require("etna-supervisor/lib/supervisor");
var fs = require("streamline-fs");
var ez = require("ez-streams");
var file = ez.devices.file;
var ezS3 = require("ez-s3");
var jsonTrans = require("ez-streams").transforms.json;
var s3Helper = require('ez-s3/lib/s3Helper');

// var skipList = /^(ACLOB|ADOCCLB|ADOCFLD|AESPION|AUDIT\w+|STAT|AMOULINETTE|APROCTEXTE|AWRKHIS\w+|CONTACT2)$/;
var skipList = /^([XYZ].*|ACLOB|ADOCCLB|ADOCFLD|AESPION|AUDIT\w+|STAT|AMOULINETTE|ALISTER|ALOGIN|APROCTEXTE|AWRKHIS\w+|CONTACT2)$/;
//var skipList = /^(ATABLE|AABREV)$/;
//var skipList = /^(ATABLE)$/;

function executeWithRetries(_, body, retriesCount) {
	retriesCount = retriesCount || 3;
	var lastError;
	for (var i = 0; i < retriesCount; i++) {
		try {
			if (i > 0)
				setTimeout(~_, 200);
			body(_);
			// if we reach this point, then everything is OK, the body could be executed.

			if (i > 0)
				console.log("executeWithRetries OK (" + i + ") : " + body.toString() + " / " + lastError.message);
			return;
		} catch (err) {
			// Nothing to do, just store the error.
			lastError = err;
		}
	};
	// we only reach this line when all the executions failed.
	// We just can thrown the last error
	throw lastError;
}

function importFiles(_, config, files, tracker) {

	throw new Error("WORK IN PROGRESS .....");

	// don't take risks with non local SQL databases for now
	if (config.sql.hostname !== "localhost") throw new Error("IMPORT only allowed on localhost");

	function trace(str) {
		if (tracker)
			tracker.phaseDetail = str;
		if (config.trace)
			config.trace(str);
	}
	var dataDir = config.solutionPath + "/DATA";
	var superv = supervisor.create(_, config);

	files.forEach_(_, function(_, fname) {
		var name = fname.substring(0, fname.length - 5); // strip .json extension
		if (skipList && skipList.test(name))
			return;
		if (tracker && tracker.abortRequested)
			return;
		if (tracker)
			tracker.phase = "importing file " + fname;

		var reader = file.text.reader(dataDir + '/' + fname).transform(jsonTrans.parser());
		// The first JSON object in the object is the metadata of the table (see exportAll for more details)
		var tableDef = reader.read(_);
		tableDef.schemaName = superv.folderName;
		// Note : for new, we don't create the indexes (it would slow down the insertions)
		// Indexes will be created once all the data are inserted in the table
		if (tracker)
			tracker.phaseDetail = "Creating table if database";
		superv.sqlDriver.createTableFromTableDefinition(_, tableDef, {
			skipIndexes: true
		});

		if (false) {

			if (tracker)
				tracker.phaseDetail = "Importing data";
			var sqlWriter = superv.sqlDriver.createTableWriter(_, tableDef);

			try {
				while (true) {
					var inVal = reader.read(_);
					console.log("--------------- " + JSON.stringify(inVal));
					tableDef.columns.forEach(function(column) {
						console.log("=============== " + column.name + " : " + column.type);
					});
					sqlWriter.write(_, inVal);
					if (inVal === undefined)
						break;
				}
			} catch (err) {
				console.error('ERRRR ' + err.message);
			}
		}

		if (tracker)
			tracker.phaseDetail = "Creating permissions";
		superv.sqlDriver.createPermissions(_, tableDef);

		if (tracker)
			tracker.phaseDetail = "Creating indexes";
		// Now, we can create the indexes
		superv.sqlDriver.createTableFromTableDefinition(_, tableDef, {
			onlyIndexes: true
		});

		setTimeout(~_, 3000);
		process.exit(0);

		/*		
		superv.sqlDriver.withConnection(_, function(_, cnx) {
			try {
				var writer = tableDef.writer(_, cnx);

				var count = reader.map(function(_, data, i) {
					tableDef.convertIn(data);
					return data;
				}).pipe(_, writer).count;
				trace(tableDef.tableName + ": " + count + " inserted");
			} catch (ex) {
				console.log(ex.stack);
				if (/ORA-/.test(ex.message)) trace(name + ": " + ex.message);
				else console.error(ex.message);
				//throw ex;
			}
		});
*/

		/*
		// Stephane 09 jan 2015 : Temp hack .... Should be removed ASAP
		// for an unknown reason, the previous pipe exits before the connection
		// could be reseted to its default state . We can't emit an other request
		// before this state is reset that's why we may have to try more than once,
		// with a small sleep between each try
		// Will investigate later...
		executeWithRetries(_, function(_) {
			tableDef.createIndexes(_);
		});
*/
	});
	trace("DONE!");
};



exports.exportAll = function(_, config, tracker, s3Cfg) {

	//config.trace = config.trace || console.log;

	if (s3Cfg) {
		if (!s3Cfg.connector)
			throw new Error("S3 'connector' is missing");
		if (!s3Cfg.settings)
			throw new Error("S3 'settings' are missing");
		if (!s3Cfg.settings.bucket)
			throw new Error("S3 'settings.bucket' is missing");
	}

	function trace(str) {
		if (tracker)
			tracker.phaseDetail = str;
		if (config.trace)
			config.trace(str);
	}

	var dataDir = config.solutionPath + "/DATA";

	if (!fs.exists(dataDir, _)) fs.mkdir(dataDir, _);
	var superv = supervisor.create(_, config);
	superv.sqlDriver.readTables(_, superv.folderName).forEach_(_, function(_, tableDef, i) {
		//console.error('PROCESSING: ' + i + ': ' + tableDef.name);
		//if (i < 125) return;
		if (skipList && skipList.test(tableDef.tableName))
			return;
		if (tracker && tracker.abortRequested)
			return;
		if (tracker)
			tracker.phase = "exporting " + tableDef.tableName;

		superv.sqlDriver.readTableSchema(_, tableDef);

		if (tableDef.columns.some(function(col) {
			return /^blob$/.test(col.type);
		})) {
			console.error("BLOB COLUMN NOT SUPPORTED YET; SKIPPING " + tableDef.tableName);
			return;
		}
		// if ((tableDef.tableName != "BANREC") && (tableDef.tableName != "BANKPOSD"))
		// 	return;

		var tableReader = superv.sqlDriver.createTableReader(_, tableDef);

		// Build a reader that will first return the metadata (tableDef) and then all the rows of the sql table
		var reader = ez.devices.array.reader([tableDef]).concat(tableReader);

		var filename = dataDir + "/" + tableDef.tableName + ".json";

		var writer = file.text.writer(filename);
		//writer.write(_, JSON.stringify(tableDef));
		var rec, count = 0;
		var message = filename;

		try {
			var transformedReader = reader.map(function(_, rec) {
				rec.ROWID = undefined;
				count++;
				//trace(tableDef.tableName + ": " + count + " ...");
				return rec;
			}).transform(jsonTrans.formatter({
				space: '\t',
			}));

			if (s3Cfg) {
				// An amazon S3 configuration is provided, we have to tee the reader to a S3 writer.
				s3Cfg.settings.key = tableDef.tableName + ".json";
				message += ', S3(' + s3Cfg.settings.bucket + '/' + s3Cfg.settings.key + ')';
				var s3Writer = ezS3.writer(_, s3Cfg.connector, s3Cfg.settings);
				transformedReader = transformedReader.tee(s3Writer);
			}
			transformedReader.pipe(_, writer);
		} catch (ex) {
			if (/ORA-00942/.test(ex.message)) trace(tableDef.tableName + ": " + ex.message);
			else console.error("Could not process table " + tableDef.tableName + ", reason = " + ex.message); // TEMP HACK FOR INCONSISTENT DATA throw ex;
		}
		trace(tableDef.tableName + ": " + count + " -> " + message);
	});
	trace("DONE!");
};

exports.importFilesFromS3 = function(_, config, tracker, s3Cfg) {
	if (!s3Cfg)
		throw new Error('S3 configuration is missing');
	if (!s3Cfg.connector)
		throw new Error("S3 'connector' is missing");
	if (!s3Cfg.settings)
		throw new Error("S3 'settings' are missing");
	if (!s3Cfg.settings.bucket)
		throw new Error("S3 'settings.bucket' is missing");

	function trace(str) {
		if (tracker)
			tracker.phaseDetail = str;
		if (config.trace)
			config.trace(str);
	}

	var list = s3Helper.listObjects(_, s3Cfg.connector, s3Cfg.settings);
	var files = list.Contents.map(function(item) {
		console.log(item);
		return item.Key;
	});

	var dataDir = config.solutionPath + "/DATA";
	if (!fs.exists(dataDir, _)) fs.mkdir(dataDir, _);

	var downloadedFiles = [];
	// First, we have to import the file to the local file system
	files.forEach_(_, function(_, name) {
		s3Cfg.settings.key = name;
		var filename = dataDir + "/" + name;

		var fileWriter = file.text.writer(filename);
		trace("Download file : " + name);

		var s3Reader = ezS3.reader(_, s3Cfg.connector, s3Cfg.settings);
		try {
			s3Reader.pipe(_, fileWriter);
		} catch (err) {
			console.error("Could not download file '" + name + "', reason = " + err.message);
		}
		downloadedFiles.push(name);
	});

	// Now, we can process these files (i.e. import them into Sql)
	importFiles(_, config, downloadedFiles, tracker);

};

exports.importAll = function(_, config, tracker) {
	var dataDir = config.solutionPath + "/DATA";
	if (!fs.exists(dataDir, _)) fs.mkdir(dataDir, _);
	var files = fs.readdir(dataDir, _);
	return importFiles(_, config, files, tracker);
};