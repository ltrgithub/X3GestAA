"use strict";
var supervisor = require("etna-supervisor/lib/supervisor");
var fs = require("streamline-fs");
var ez = require("ez-streams");
var file = ez.devices.file;
var ezS3 = require("ez-s3");
var jsonTrans = require("ez-streams").transforms.json;
var s3Helper = require('ez-s3/lib/s3Helper');

// var skipList = /^(ACLOB|ADOCCLB|ADOCFLD|AESPION|AUDIT\w+|STAT|AMOULINETTE|APROCTEXTE|AWRKHIS\w+|CONTACT2)$/;
var skipList = /^([XYZ].*|ACLOB|ADOCCLB|ADOCFLD|AESPION|AUDIT\w+|STAT|AMOULINETTE|ALISTER|ALOGIN|APROCTEXTE|AWRKHIS\w+|CONTACT2)$/;
//var skipList = /^(ATABLE|AABREV)$/;
//var skipList = /^(ATABLE)$/;

function executeWithRetries(_, body, retriesCount) {
	retriesCount = retriesCount || 3;
	var lastError;
	for (var i = 0; i < retriesCount; i++) {
		try {
			if (i > 0)
				setTimeout(~_, 200);
			body(_);
			// if we reach this point, then everything is OK, the body could be executed.

			if (i > 0)
				console.log("executeWithRetries OK (" + i + ") : " + body.toString() + " / " + lastError.message);
			return;
		} catch (err) {
			// Nothing to do, just store the error.
			lastError = err;
		}
	};
	// we only reach this line when all the executions failed.
	// We just can thrown the last error
	throw lastError;
}

function importFiles(_, config, files, tracker) {

	throw new Error("IN PROGRESS ");
	// don't take risks with non local SQL databases for now
	if (config.sql.hostname !== "localhost") throw new Error("IMPORT only allowed on localhost");

	function trace(str) {
		if (tracker) tracker.phaseDetail = str;
		if (config.trace) config.trace(str);
	}
	var dataDir = config.solutionPath + "/DATA";
	var superv = supervisor.create(_, config);

	files.forEach_(_, function(_, fname) {
		var name = fname.substring(0, fname.length - 5); // strip .json extension
		if (skipList && skipList.test(name)) return;
		if (tracker && tracker.abortRequested) return;
		if (tracker) tracker.phase = "importing " + name;

		var reader = file.text.reader(dataDir + '/' + fname).transform(jsonTrans.parser());
		// The first JSON object in the object is the metadata of the table (see exportAll for more details)
		var table = reader.read(_);

		var sqlWriter = superv.sqlDriver.createTableWriter(_, table);
		/*
		// Stephane 09 jan 2015 : Temp hack .... Should be removed ASAP
		// create the table. It's should not be done because it will only 
		// create columns but not the triggers
		try {
			table.create(_);
			trace("WARNING : table " + name + " was created");
		} catch (ex) {
			// Everything is OK, the creation should fail (the table should already exist)
		}

		// Note : the table MUST already exist in the database because some tables
		// may have triggers, so we can't drop/create the table : we can just clear it
		executeWithRetries(_, function(_) {
			table.deleteIndexes(_);
		});
*/
		console.log("TTTTTTTTTTT Clearing " + table.name);
		executeWithRetries(_, function(_) {
			superv.sqlDriver.clearTable(_, table);
		});

		console.log("TTTTTTTTTTT Cleared " + table.name);

		try {
			while (true) {
				var inVal = reader.read(_);
				console.log("--------------- " + JSON.stringify(inVal));
				table.columns.forEach(function(column) {
					console.log("=============== " + column.name + " : " + column.type);
				});
				sqlWriter.write(_, inVal);
				if (inVal === undefined)
					break;
			}
		} catch (err) {
			console.error('ERRRR ' + err.message);
		}

		console.log("TTTTTTTTTTT imported " + table.name);

		setTimeout(~_, 3000);
		process.exit(0);

		/*		
		superv.sqlDriver.withConnection(_, function(_, cnx) {
			try {
				var writer = table.writer(_, cnx);

				var count = reader.map(function(_, data, i) {
					table.convertIn(data);
					return data;
				}).pipe(_, writer).count;
				trace(table.name + ": " + count + " inserted");
			} catch (ex) {
				console.log(ex.stack);
				if (/ORA-/.test(ex.message)) trace(name + ": " + ex.message);
				else console.error(ex.message);
				//throw ex;
			}
		});
*/

		/*
		// Stephane 09 jan 2015 : Temp hack .... Should be removed ASAP
		// for an unknown reason, the previous pipe exits before the connection
		// could be reseted to its default state . We can't emit an other request
		// before this state is reset that's why we may have to try more than once,
		// with a small sleep between each try
		// Will investigate later...
		executeWithRetries(_, function(_) {
			table.createIndexes(_);
		});
*/
	});
	trace("DONE!");
};



exports.exportAll = function(_, config, tracker, s3Cfg) {

	//config.trace = config.trace || console.log;

	if (s3Cfg) {
		if (!s3Cfg.connector)
			throw new Error("S3 'connector' is missing");
		if (!s3Cfg.settings)
			throw new Error("S3 'settings' are missing");
		if (!s3Cfg.settings.bucket)
			throw new Error("S3 'settings.bucket' is missing");
	}


	function test(_, superv) {
		var tables = superv.sqlDriver.readTables(_);
		//			superv.sqlDriver.readTableSchema(_, tables[0]);
		tables.forEach_(_, function(_, table) {
			superv.sqlDriver.readTableSchema(_, table);
		});
		console.log(JSON.stringify(tables[0]));
		setTimeout(~_, 1000);
		process.exit(0);
	}

	function trace(str) {
		if (tracker) tracker.phaseDetail = str;
		if (config.trace) config.trace(str);
	}

	var dataDir = config.solutionPath + "/DATA";

	if (!fs.exists(dataDir, _)) fs.mkdir(dataDir, _);
	var superv = supervisor.create(_, config);
	superv.sqlDriver.readTables(_).forEach_(_, function(_, table, i) {
		//console.error('PROCESSING: ' + i + ': ' + table.name);
		//if (i < 125) return;
		if (skipList && skipList.test(table.name)) return;
		if (tracker && tracker.abortRequested) return;
		if (tracker) tracker.phase = "exporting " + table.name;

		superv.sqlDriver.readTableSchema(_, table);

		if (table.columns.some(function(col) {
			return /^blob$/.test(col.type);
		})) {
			console.error("BLOB COLUMN NOT SUPPORTED YET; SKIPPING " + table.name);
			return;
		}
		// if ((table.name != "BANREC") && (table.name != "BANKPOSD"))
		// 	return;

		var tableReader = superv.sqlDriver.createTableReader(_, table);

		// Build a reader that will first return the metadata (table) and then all the rows of the sql table
		var reader = ez.devices.array.reader([table]).concat(tableReader);

		var filename = dataDir + "/" + table.name + ".json";

		var writer = file.text.writer(filename);
		//writer.write(_, JSON.stringify(table));
		var rec, count = 0;
		var message = filename;

		try {
			var transformedReader = reader.map(function(_, rec) {
				rec.ROWID = undefined;
				count++;
				//trace(table.name + ": " + count + " ...");
				return rec;
			}).transform(jsonTrans.formatter({
				space: '\t',
			}));

			if (s3Cfg) {
				// An amazon S3 configuration is provided, we have to tee the reader to a S3 writer.
				s3Cfg.settings.key = table.name + ".json";
				message += ', S3(' + s3Cfg.settings.bucket + '/' + s3Cfg.settings.key + ')';
				var s3Writer = ezS3.writer(_, s3Cfg.connector, s3Cfg.settings);
				transformedReader = transformedReader.tee(s3Writer);
			}
			transformedReader.pipe(_, writer);
		} catch (ex) {
			if (/ORA-00942/.test(ex.message)) trace(table.name + ": " + ex.message);
			else console.error("Could not process table " + table.name + ", reason = " + ex.message); // TEMP HACK FOR INCONSISTENT DATA throw ex;
		}
		trace(table.name + ": " + count + " -> " + message);
	});
	trace("DONE!");
};

exports.importFilesFromS3 = function(_, config, tracker, s3Cfg) {
	if (!s3Cfg)
		throw new Error('S3 configuration is missing');
	if (!s3Cfg.connector)
		throw new Error("S3 'connector' is missing");
	if (!s3Cfg.settings)
		throw new Error("S3 'settings' are missing");
	if (!s3Cfg.settings.bucket)
		throw new Error("S3 'settings.bucket' is missing");

	function trace(str) {
		if (tracker) tracker.phaseDetail = str;
		if (config.trace) config.trace(str);
	}

	var list = s3Helper.listObjects(_, s3Cfg.connector, s3Cfg.settings);
	var files = list.Contents.map(function(item) {
		console.log(item);
		return item.Key;
	});

	var dataDir = config.solutionPath + "/DATA";
	if (!fs.exists(dataDir, _)) fs.mkdir(dataDir, _);

	var downloadedFiles = [];
	// First, we have to import the file to the local file system
	files.forEach_(_, function(_, name) {
		s3Cfg.settings.key = name;
		var filename = dataDir + "/" + name;

		var fileWriter = file.text.writer(filename);
		trace("Download file : " + name);

		var s3Reader = ezS3.reader(_, s3Cfg.connector, s3Cfg.settings);
		try {
			s3Reader.pipe(_, fileWriter);
		} catch (err) {
			console.error("Could not download file '" + name + "', reason = " + err.message);
		}
		downloadedFiles.push(name);
	});

	// Now, we can process these files (i.e. import them into Sql)
	importFiles(_, config, downloadedFiles, tracker);

};

exports.importAll = function(_, config, tracker) {
	var dataDir = config.solutionPath + "/DATA";
	if (!fs.exists(dataDir, _)) fs.mkdir(dataDir, _);

	var files = fs.readdir(dataDir, _);
	return importFiles(_, config, files, tracker);
};

exports.oldImportAll = function(_, config, tracker) {
	// don't take risks with non local SQL databases for now
	if (config.sql.hostname !== "localhost") throw new Error("IMPORT only allowed on localhost");

	function trace(str) {
		if (tracker) tracker.phaseDetail = str;
		if (config.trace) config.trace(str);
	}
	var dataDir = config.solutionPath + "/DATA";
	if (!fs.exists(dataDir, _)) fs.mkdir(dataDir, _);
	var superv = supervisor.create(_, config);
	fs.readdir(dataDir, _).forEach_(_, function(_, fname) {
		var name = fname.substring(0, fname.length - 5); // strip .json extension
		if (skipList && skipList.test(name)) return;
		if (tracker && tracker.abortRequested) return;
		if (tracker) tracker.phase = "importing " + name;
		var table = superv.load(_, 'Table', name);
		if (!table) {
			trace(name + ": cannot import: no metadata");
			return;
		}

		// Note : the table MUST already exist in the database because some table
		// may have triggers, so we can't drop/create the table : we can just clear it
		table.deleteIndexes(_);

		table.clear(_);

		// Temp hack : create the table. Should be removed ASAP
		// because it will only create columns but not the triggers
		try {
			table.create(_);
			trace("WARNING : table " + name + " was created");
		} catch (ex) {
			// Everything is OK, the create should fail (the table should already exist)
		}

		var reader = file.text.reader(dataDir + '/' + fname);
		superv.sqlDriver.withConnection(_, function(_, cnx) {
			try {
				var writer = table.writer(_, cnx);
				var count = reader.transform(jsonTrans.parser()).map(function(_, data, i) {
					trace(table.name + ": " + i + " ...");
					table.convertIn(data);
					return data;
				}).pipe(_, writer).count;
				trace(table.name + ": " + count + " inserted");
				//cnx.transitionTo(cnx.STATE.LOGGED_IN);
			} catch (ex) {
				console.log(ex.stack);
				if (/ORA-/.test(ex.message)) trace(name + ": " + ex.message);
				else console.error(ex.message);
				//throw ex;
			}
		});

		// Stephane 09 jan 2015 : Temp hack ....
		// for an unknown reason, the previous pipe exits before the connection
		// could be reseted to its default state . We can't emit an other request
		// before this state is reset that's why we may have to try more than once,
		// with a small sleep between each try
		// Will investigate later...
		executeWithRetries(_, function(_) {
			table.createIndexes(_);
		});
	});
	trace("DONE!");
};