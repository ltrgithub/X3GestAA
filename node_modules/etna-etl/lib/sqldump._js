"use strict";
var supervisor = require("etna-supervisor/lib/supervisor");
var fs = require("streamline-fs");
var file = require("ez-streams").devices.file;
var ezS3 = require("ez-s3");
var jsonTrans = require("ez-streams").transforms.json;
var s3Helper = require('ez-s3/lib/s3Helper');

// var skipList = /^(ACLOB|ADOCCLB|ADOCFLD|AESPION|AUDIT\w+|STAT|AMOULINETTE|APROCTEXTE|AWRKHIS\w+|CONTACT2)$/;
var skipList = undefined;
//var skipList = /^(ATABLE|AABREV)$/;
//var skipList = /^(ATABLE)$/;

function executeWithRetries(_, body, retriesCount) {
	retriesCount = retriesCount || 3;
	var lastError;
	for (var i = 0; i < retriesCount; i++) {
		try {
			if (i > 0)
				setTimeout(~_, 200);
			body(_);
			// if we reach this point, then everything is OK, the body could be executed.

			if (i > 0)
				console.log("executeWithRetries OK (" + i + ") : " + body.toString() + " / " + lastError.message);
			return;
		} catch (err) {
			// Nothing to do, just store the error.
			lastError = err;
		}
	};
	// we only reach this line when all the executions failed.
	// We just can thrown the last error
	throw lastError;
}

function importFiles(_, config, files, tracker) {
	// don't take risks with non local SQL databases for now
	if (config.sql.hostname !== "localhost") throw new Error("IMPORT only allowed on localhost");

	function trace(str) {
		if (tracker) tracker.phaseDetail = str;
		if (config.trace) config.trace(str);
	}
	var dataDir = config.solutionPath + "/DATA";
	var superv = supervisor.create(_, config);

	files.forEach_(_, function(_, fname) {
		var name = fname.substring(0, fname.length - 5); // strip .json extension
		if (skipList && skipList.test(name)) return;
		if (tracker && tracker.abortRequested) return;
		if (tracker) tracker.phase = "importing " + name;
		var table = superv.load(_, 'Table', name);
		if (!table) {
			trace(name + ": cannot import: no metadata");
			return;
		}

		// Stephane 09 jan 2015 : Temp hack .... Should be removed ASAP
		// create the table. It's should not be done because it will only 
		// create columns but not the triggers
		try {
			table.create(_);
			trace("WARNING : table " + name + " was created");
		} catch (ex) {
			// Everything is OK, the creation should fail (the table should already exist)
		}

		// Note : the table MUST already exist in the database because some tables
		// may have triggers, so we can't drop/create the table : we can just clear it
		executeWithRetries(_, function(_) {
			table.deleteIndexes(_);
		});

		executeWithRetries(_, function(_) {
			table.clear(_);
		});

		var reader = file.text.reader(dataDir + '/' + fname);
		superv.sqlDriver.withConnection(_, function(_, cnx) {
			try {
				var writer = table.writer(_, cnx);
				var count = reader.transform(jsonTrans.parser()).map(function(_, data, i) {
					//trace(table.name + ": " + i + " ...");
					table.convertIn(data);
					return data;
				}).pipe(_, writer).count;
				trace(table.name + ": " + count + " inserted");
			} catch (ex) {
				console.log(ex.stack);
				if (/ORA-/.test(ex.message)) trace(name + ": " + ex.message);
				else console.error(ex.message);
				//throw ex;
			}
		});

		// Stephane 09 jan 2015 : Temp hack .... Should be removed ASAP
		// for an unknown reason, the previous pipe exits before the connection
		// could be reseted to its default state . We can't emit an other request
		// before this state is reset that's why we may have to try more than once,
		// with a small sleep between each try
		// Will investigate later...
		executeWithRetries(_, function(_) {
			table.createIndexes(_);
		});
	});
	trace("DONE!");
};



exports.exportAll = function(_, config, tracker, s3Cfg) {

	//config.trace = config.trace || console.log;

	if (s3Cfg) {
		if (!s3Cfg.connector)
			throw new Error("S3 'connector' is missing");
		if (!s3Cfg.settings)
			throw new Error("S3 'settings' are missing");
		if (!s3Cfg.settings.bucket)
			throw new Error("S3 'settings.bucket' is missing");
	}


	function trace(str) {
		if (tracker) tracker.phaseDetail = str;
		if (config.trace) config.trace(str);
	}

	var dataDir = config.solutionPath + "/DATA";

	if (!fs.exists(dataDir, _)) fs.mkdir(dataDir, _);
	var superv = supervisor.create(_, config);
	var dictReader = superv.reader(_, 'Table');
	dictReader.forEach(_, function(_, table) {
		if (skipList && skipList.test(table.name)) return;
		if (tracker && tracker.abortRequested) return;
		if (tracker) tracker.phase = "exporting " + table.name;

		// if ((table.name != "BANREC") && (table.name != "BANKPOSD"))
		// 	return;

		var tableOk = true;
		superv.sqlDriver.withConnection(_, function(_, cnx) {
			// First, make sure that the table exists in the database
			var tmpReader = table.reader(_, cnx, null, null, null, true, {
				limit: 1
			});
			try {
				// Note, we use toArray(_) to make sure that we won't process the next
				// table before the current SQL request is over (we used the 'limit' option to limit
				// the number of results)
				tmpReader.toArray(_);
			} catch (err) {
				if (superv.sqlDriver.isTableNotFound(err)) {
					// The table does not exist ...
					// This may happen when a specific module is not installed (the table
					// is described in the ATABLE table but does not exist in the db)
					trace('Table ' + table.name + ' does not exist in the source database.');
				} else {
					trace('Table ' + table.name + ' skipped, reason = ' + err.message);
				}
				tableOk = false;
			}
		});
		if (!tableOk)
			return;
		superv.sqlDriver.withConnection(_, function(_, cnx) {
			if (tableOk) {
				var reader = table.reader(_, cnx, null, null, null, true);

				var filename = dataDir + "/" + table.name + ".json";

				var writer = file.text.writer(filename);
				var rec, count = 0;
				var message = filename;

				try {
					var transformedReader = reader.map(function(_, rec) {
						rec.ROWID = undefined;
						count++;
						//trace(table.name + ": " + count + " ...");
						return rec;
					}).transform(jsonTrans.formatter({
						space: '\t',
					}));

					if (s3Cfg) {
						// An amazon S3 configuration is provided, we have to tee the reader to a S3 writer.
						s3Cfg.settings.key = table.name + ".json";
						message += ', S3(' + s3Cfg.settings.bucket + '/' + s3Cfg.settings.key + ')';
						var s3Writer = ezS3.writer(_, s3Cfg.connector, s3Cfg.settings);
						transformedReader = transformedReader.tee(s3Writer);
					}
					transformedReader.pipe(_, writer);
				} catch (ex) {
					if (/ORA-00942/.test(ex.message)) trace(table.name + ": " + ex.message);
					else console.error("Could not process table " + table.name + ", reason = " + ex.message); // TEMP HACK FOR INCONSISTENT DATA throw ex;
				}
				trace(table.name + ": " + count + " -> " + message);
			} else {
				console.error("Table " + table.name + " skipped ....");
			}

		});
	});
	trace("DONE!");
};

exports.importFilesFromS3 = function(_, config, tracker, s3Cfg) {
	if (!s3Cfg)
		throw new Error('S3 configuration is missing');
	if (!s3Cfg.connector)
		throw new Error("S3 'connector' is missing");
	if (!s3Cfg.settings)
		throw new Error("S3 'settings' are missing");
	if (!s3Cfg.settings.bucket)
		throw new Error("S3 'settings.bucket' is missing");

	function trace(str) {
		if (tracker) tracker.phaseDetail = str;
		if (config.trace) config.trace(str);
	}

	var list = s3Helper.listObjects(_, s3Cfg.connector, s3Cfg.settings);
	var files = list.Contents.map(function(item) {
		console.log(item);
		return item.Key;
	});

	var dataDir = config.solutionPath + "/DATA";
	if (!fs.exists(dataDir, _)) fs.mkdir(dataDir, _);

	var downloadedFiles = [];
	// First, we have to import the file to the local file system
	files.forEach_(_, function(_, name) {
		s3Cfg.settings.key = name;
		var filename = dataDir + "/" + name;

		var fileWriter = file.text.writer(filename);
		trace("Download file : " + name);

		var s3Reader = ezS3.reader(_, s3Cfg.connector, s3Cfg.settings);
		try {
			s3Reader.pipe(_, fileWriter);
		} catch (err) {
			console.error("Could not download file '" + name + "', reason = " + err.message);
		}
		downloadedFiles.push(name);
	});

	// Now, we can process these files (i.e. import them into Sql)
	importFiles(_, config, downloadedFiles, tracker);

};

exports.importAll = function(_, config, tracker) {
	var dataDir = config.solutionPath + "/DATA";
	if (!fs.exists(dataDir, _)) fs.mkdir(dataDir, _);

	var files = fs.readdir(dataDir, _);
	return importFiles(_, config, files, tracker);
};

exports.oldImportAll = function(_, config, tracker) {
	// don't take risks with non local SQL databases for now
	if (config.sql.hostname !== "localhost") throw new Error("IMPORT only allowed on localhost");

	function trace(str) {
		if (tracker) tracker.phaseDetail = str;
		if (config.trace) config.trace(str);
	}
	var dataDir = config.solutionPath + "/DATA";
	if (!fs.exists(dataDir, _)) fs.mkdir(dataDir, _);
	var superv = supervisor.create(_, config);
	fs.readdir(dataDir, _).forEach_(_, function(_, fname) {
		var name = fname.substring(0, fname.length - 5); // strip .json extension
		if (skipList && skipList.test(name)) return;
		if (tracker && tracker.abortRequested) return;
		if (tracker) tracker.phase = "importing " + name;
		var table = superv.load(_, 'Table', name);
		if (!table) {
			trace(name + ": cannot import: no metadata");
			return;
		}

		// Note : the table MUST already exist in the database because some table
		// may have triggers, so we can't drop/create the table : we can just clear it
		table.deleteIndexes(_);

		table.clear(_);

		// Temp hack : create the table. Should be removed ASAP
		// because it will only create columns but not the triggers
		try {
			table.create(_);
			trace("WARNING : table " + name + " was created");
		} catch (ex) {
			// Everything is OK, the create should fail (the table should already exist)
		}

		var reader = file.text.reader(dataDir + '/' + fname);
		superv.sqlDriver.withConnection(_, function(_, cnx) {
			try {
				var writer = table.writer(_, cnx);
				var count = reader.transform(jsonTrans.parser()).map(function(_, data, i) {
					trace(table.name + ": " + i + " ...");
					table.convertIn(data);
					return data;
				}).pipe(_, writer).count;
				trace(table.name + ": " + count + " inserted");
				//cnx.transitionTo(cnx.STATE.LOGGED_IN);
			} catch (ex) {
				console.log(ex.stack);
				if (/ORA-/.test(ex.message)) trace(name + ": " + ex.message);
				else console.error(ex.message);
				//throw ex;
			}
		});

		// Stephane 09 jan 2015 : Temp hack ....
		// for an unknown reason, the previous pipe exits before the connection
		// could be reseted to its default state . We can't emit an other request
		// before this state is reset that's why we may have to try more than once,
		// with a small sleep between each try
		// Will investigate later...
		executeWithRetries(_, function(_) {
			table.createIndexes(_);
		});
	});
	trace("DONE!");
};