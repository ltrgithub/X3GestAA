"use strict";

var jsonHelper = require('bundles/scm-helper/lib/jsonHelper'),
	path = require('path');


//var defaultExcludedColumns = ["AUUID", "UPDDAT", "UPDUSR", "UPDDATTIM", "CREDAT", "CREUSR", "CREDATTIM", "UPDTICK"];
var defaultExcludedColumns = ["AUUID"];




/// !doc 
/// ### run(_, exporter, entity, tracker, entityNames)
/// Exports the metadata of a set of entities into JSON files
/// This function returns the names of the generated files. 
/// WARNING : The filenames are ABSOLUTE to the solution.metaFolder
///
/// * exporter : the exporter that will be used to serialize the metadata into JSON files
/// * entity : the entity descriptor
/// * tracker : the tracker
/// * entityNames : the name of the entities
exports.run = function(_, exporter, entity, tracker, entityNames, options) {

	options = options || {};
	var tableMetas = {};

	if (entity.tableName === "AENTREE") return [];
	var t0 = Date.now();
	var buildExecute = exporter.buildExecute,
		trace = exporter.trace;

	var excludedColumns = entity.excludedColumns || defaultExcludedColumns;
	var tableMeta = getTableMeta(_, entity.tableName, excludedColumns);
	var mainKey = entity.primaryKey;

	// First, we have to filter the entities, according to the provided filter
	var elts = buildExecute(_, null, [mainKey + "_0", "UPDDATTIM_0"], entity.tableName, mainKey).filter(function(s) {
		if (entityNames) {
			if (entityNames.indexOf(s[mainKey]) == -1) {
				// This entity was not included in the provided filter
				return false;
			}
		}
		if (options.incrementalDate) {
			if (!s["UPDDATTIM"]) {
				// a null date is considered as a 'very long ago' date (sth like 1599/11/31 for oracle)
				// Items with a null date will only be synchronized on the first export.
				// options.incrementalDate is null for the first export (full or incremental)
				return false;
			}
			if (new Date(s["UPDDATTIM"]) <= options.incrementalDate) {
				// This object has already been synchronized.
				return false;
			}
		}
		return !~entity.excludedInitials.indexOf(s[mainKey][0]);
	}).map(function(row) {
		// Remove the UPDDATTIM column. It was only included to compare dates (incremental sync)
		delete row["UPDDATTIM"];
		return row;
	});


	// Query the data for ONE item (i.e. one table, one class, ...)
	// elt : PK of the item
	function queryItem(_, tableMeta, entityDescriptor, elt) {

		function queryChidren(_, childDescriptor, parentRow, activityCode, blockIndex) {
			var childKeys = {};
			var parentMappings = childDescriptor.parentMappings;
			if (!parentMappings) {
				if (entityDescriptor.primaryKey) {
					parentMappings = {};
					parentMappings[entityDescriptor.primaryKey] = entityDescriptor.primaryKey;
				} else
					parentMappings = entityDescriptor.parentMappings;

			}
			Object.keys(parentMappings).forEach(function(childProperty) {
				var parentProperty = parentMappings[childProperty];
				if (parentProperty === "$INDEX")
					childKeys[childProperty] = blockIndex + 1;
				else if ("object" === typeof(parentProperty))
					childKeys[childProperty] = parentProperty.value;
				else
					childKeys[childProperty] = jsonHelper.decodeValueFromJsonString(null, parentRow[parentProperty]).value;
			});
			var childData = queryItem(_,
				getTableMeta(_, childDescriptor.tableName, childDescriptor.excludedColumns || defaultExcludedColumns),
				childDescriptor,
				childKeys);
			return childData[activityCode];
		}

		// Read the data for the entity itself
		var data = queryTable(_, tableMeta, elt, entityDescriptor, null, {
			formatValues: true
		});

		Object.keys(data).forEach_(_, function(_, activityCode) {
			data[activityCode] = data[activityCode].map_(_, function(_, dataPart) {
				dataPart = jsonHelper.createGroups(entityDescriptor, jsonHelper.sortJsonObject(_, dataPart, entityDescriptor));
				if (entityDescriptor.itemIndex) {
					// The property bound to 'itemIndex' is the index of the item in the collection
					// It must be removed from the JSON file and will be recomputed when reading the JSON file
					// This way, if some conflicts have to be resolved on this file and some other items are
					// inserted, they will be correctly re-indexed
					delete dataPart[entityDescriptor.itemIndex];
				}

				if (entityDescriptor.children) {
					// This entity has some child entities (for instance columns or indexes for tables)
					Object.keys(entityDescriptor.children).forEach_(_, function(_, childName) {
						var child = entityDescriptor.children[childName];
						var childData = queryChidren(_, child, dataPart, activityCode);
						dataPart[childName] = childData;
					});
				}

				// Parse all the groups
				if (entityDescriptor.groups) {
					entityDescriptor.groups.filter(function(group) {
						// We are only interested in group with children
						return group.children;
					}).forEach_(_, function(_, group) {
						// We have to parse each block (item of a group) that has been created by the createGroups function.
						dataPart[group.name].items.forEach_(_, function(_, blockData, blockIndex) {

							// Each child must be queried using the current context as a parent context.
							// The parent content will be composed of properties from the parent itself but also of properties
							// from a block.
							// For instance, when querying then 'AMSKZON' child, we will need the 'CODMSK' of the parent (screen)
							// to bind the zones to the right screen.
							Object.keys(group.children).forEach_(_, function(_, childName) {
								var child = group.children[childName];
								blockData[childName] = queryChidren(_, child, dataPart, activityCode, blockIndex);
							});
						});
					});
				}
				return dataPart;
			});
		});
		return data;
	}

	// Query the data for a list of items (tables, classes, ...). All the items are the same type.
	// keys : PKs of the items
	function queryItems(_, tableMeta, entityDescriptor, keys) {
		// Each keys looks like {"ABRFIC" : "XXXX"} where ABRFIC is the PK of the table (here ATABLE) and
		// XXXX the value of the PK for the item to fetch
		var totalResults = {};
		keys.forEach_(_, function(_, key) {
			var results = queryItem(_, tableMeta, entityDescriptor, key);
			// Results are indexed by activityCode
			Object.keys(results).forEach(function(activityCode) {
				totalResults[activityCode] = totalResults[activityCode] || [];
				totalResults[activityCode].push(results[activityCode]);
			});
		});
		return totalResults;
	}

	// Here, elts contains all the keys of the entityType taht should be exported
	// For instance, when exporting tables, elts will look like : 
	// [{"ABRFIC" : "XXX1", "ABRFIC" : "XXX2", "ABRFIC" : "XXX3", .... }] where XXX1, XXX2, XXX3, are the PK in 
	// the ATABLE table of the tables to export.

	var absoluteFilenames = [];

	function getTableMeta(_, tableName, excludedColumns) {
		var tableMeta = tableMetas[tableName];
		if (!tableMeta) {
			tableMeta = exporter.getTableMeta(_, tableName, excludedColumns);
			tableMetas[tableName] = tableMeta;
		}
		return tableMeta;
	}

	function queryTable(_, tableMeta, keys, entityDescriptor, parentDescriptor, options) {
		options = options || {};
		entityDescriptor = entityDescriptor || {};
		entityDescriptor.activityCodeProperty = entityDescriptor.activityCodeProperty || "CODACT";

		if (entityDescriptor && entityDescriptor.linkTable && !options.skipLinkTable) {
			// We have to use the pivot table to retrieve rows
			if (!parentDescriptor)
				throw new Error("Parent descriptor is missing");
			var pivotKeys = {};
			pivotKeys[parentDescriptor.primaryKey] = keys[parentDescriptor.primaryKey];
			var pivots = queryTable(_, getTableMeta(_, entityDescriptor.linkTable.tableName), pivotKeys, null, null, {
				formatValues: false
			});
			var allResults = [];
			// Now, we iterate on each pivot and query the child table

			// We assume that linked entities all belong to the activity code ""
			pivots = pivots[""] || [];
			pivots.forEach_(_, function(_, pivot) {
				var targetKey = {};
				var parentColumn = entityDescriptor.parentKey || parentDescriptor.primaryKey;
				targetKey[parentColumn] = pivot[parentColumn];
				var partialResults = queryTable(_, tableMeta, targetKey, entityDescriptor, parentDescriptor, {
					skipLinkTable: true,
					formatValues: true
				})[""];
				allResults = allResults.concat(partialResults);
			});
			return {
				"": allResults
			};
		}

		// Build the list of columns to query
		var colsToQuery = [];
		Object.keys(tableMeta.columns).forEach(function(colName) {
			var colDef = tableMeta.columns[colName];
			for (var i = 0; i < colDef.dimension; i++) {
				colsToQuery.push(colDef.name + "_" + i);
			};
		});

		var where = entityDescriptor.parentKey;
		if (!where && parentDescriptor)
			where = parentDescriptor.primaryKey;

		var sqlResults = buildExecute(_, tableMeta, colsToQuery, tableMeta.name, entityDescriptor.orderBy, keys, where, entityDescriptor.textLinks, options);
		// Now, we have to dispatch all the results by activity code
		var results = {};
		sqlResults.forEach(function(row) {
			var activityCode = row[entityDescriptor.activityCodeProperty];
			if (!activityCode)
				activityCode = "";
			else {
				// The activityCode is a string that has already been formatted like "S:xx|activityCode"
				// We have to unformat it.
				activityCode = activityCode.substring(activityCode.indexOf('|') + 1).trim();
			}

			results[activityCode] = results[activityCode] || [];
			results[activityCode].push(row);
		});
		return results;
	}

	var data = queryItems(_, tableMeta, entity, elts);

	Object.keys(data).forEach(function(activityCode) {
		data[activityCode] = data[activityCode][0];
	});

	// Now, we can write the files
	// data is on object where ecah key is an activityCode
	var modulePart;
	var mainData = data[""]; // The data for no activityCode (i.e. the data that contains all the common properties)
	if (!mainData) {
		// use the first activity code
		mainData = data[Object.keys(data)[0]];
	}
	if (exporter.folderType == 0)
		modulePart = "SUPERV";
	else if (exporter.moduleNames[mainData.MODULE])
		modulePart = exporter.moduleNames[mainData.MODULE];
	else if (mainData.CHAPITRE) {
		var chapter = mainData.CHAPITRE;
		var idx = chapter.indexOf('|');
		if (idx != -1)
			chapter = chapter.substring(idx + 1);
		modulePart = path.join("CHAPTERS", chapter);
	} else
		modulePart = "GLOBAL";

	Object.keys(data).forEach_(_, function(_, activityCode) {
		var dataPart = data[activityCode][0];
		if (activityCode) {
			// This data concerns a specific activity code
			// We have to insert the PK of the main data
			dataPart[mainKey] = mainData[mainKey];
		}

		// We have to re-sort the JSON object to avoid git differences
		// When a conflict will be detected on this JSON object, the conflict will be resolved and the JSON
		// will be sorted with jsonHelper.sortJsonObject() function. So, the original JSON file (the one we are building now)
		// must be sorted with the same function to limit git differences.
		dataPart = jsonHelper.sortJsonObject(_, dataPart, entity);

		// Now, we can write the file

		var entityPK = jsonHelper.decodeValueFromJsonString(null, dataPart[mainKey]).value;
		absoluteFilenames.push(exporter.writeResource(_, {
			path: path.join(modulePart, entity.subdir),
			name: entityPK + (activityCode ? "." + activityCode : ""),
			data: dataPart
		}));

	});

	trace && trace(entity.title + ": " + elts.length + " resources exported in " + Math.round((Date.now() - t0) / 1000) + " seconds");
	return absoluteFilenames;
};

exports.extractSingle = function(_, exporter, entity, entityTableName) {
	var buildExecute = exporter.buildExecute;

	// Retrieve the columns name of the table (except the excluded ones)
	var mainColumns = exporter.getTableColumns(_, entity.tableName, entity.excludedColumns || defaultExcludedColumns);
	var mainKey = entity.primaryKey;

	return {
		mainKey: mainKey,
		mainKeyValue: entityTableName,
		tableName: entity.tableName,
		data: buildExecute(_, null, mainColumns, entity.tableName, null, {
			'CODFIC': entityTableName
		})[0]
	};
};