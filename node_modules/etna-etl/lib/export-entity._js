"use strict";

var locale = require('streamline-locale'),
	jsonHelper = require('scm-helper/lib/jsonHelper'),
	path = require('path'),
	productsHelper = require('scm-helper/lib/productsHelper');


//var defaultExcludedColumns = ["AUUID", "UPDDAT", "UPDUSR", "UPDDATTIM", "CREDAT", "CREUSR", "CREDATTIM", "UPDTICK"];
var defaultExcludedColumns = ["AUUID"];



/// !doc 
/// ### run(_, exporter, entity, tracker, entityNames)
/// Exports the metadata of a set of entities into JSON files
/// This function returns the names of the generated files. 
/// WARNING : The filenames are ABSOLUTE to the solution.metaFolder
///
/// * exporter : the exporter that will be used to serialize the metadata into JSON files
/// * entity : the entity descriptor
/// * tracker : the tracker
/// * entityNames : the name of the entities
exports.run = function(_, exporter, entity, tracker, entityNames, options) {

	const COLNAME_UPDDATTIM = "UPDDATTIM";
	const COLNAME_MODULE = "MODULE";

	function _trace(message, severity) {
		trace && trace(message);
		if (severity) {
			if (tracker) {
				tracker.$diagnoses = tracker.$diagnoses || [];
				tracker.$diagnoses.push({
					$severity: severity,
					$message: message,
				});
			}
		}
	}

	// Query the data for ONE item (i.e. one table, one class, ...)
	// pkValue : PK of the item to query
	function queryData(_, tableMeta, entityDescriptor, pkValue, defaultActivityCode) {
		function queryChildren(_, childDescriptor, parentRow, defaultActivityCodeForChildren, blockIndex) {
			var childKeys = {};
			var parentMappings = childDescriptor.parentMappings;
			if (!parentMappings) {
				if (entityDescriptor.primaryKey) {
					// Build the parent mappings from the PK of the parent
					parentMappings = entity.primaryKey.reduce(function(global, item) {
						global[item] = item;
						return global;
					}, {});
				} else {
					// Build the parent mappings from the parent mappings of the parent
					parentMappings = entityDescriptor.parentMappings;
				}
				childDescriptor.parentMappings = parentMappings;
			}
			Object.keys(parentMappings).forEach(function(childPropertyName) {
				var parentProperty = parentMappings[childPropertyName];
				if (parentProperty === "$INDEX") {
					childKeys[childPropertyName] = blockIndex + 1;
				} else if ("object" === typeof(parentProperty)) {
					childKeys[childPropertyName] = parentProperty.value;
				} else if (parentProperty.indexOf('"') === 0 || parentProperty.indexOf("'") === 0) { // to manage constant in the keys
					childKeys[childPropertyName] = parentProperty;
				} else {
					childKeys[childPropertyName] = jsonHelper.decodeValueFromJsonString(null, parentRow[parentProperty]).value;
				}
				if (childKeys[childPropertyName] === "") {
					childKeys[childPropertyName] = " ";
				}
			});

			var childData = queryData(_,
				getTableMeta(_, childDescriptor.tableName, childDescriptor.excludedColumns || defaultExcludedColumns),
				childDescriptor,
				childKeys,
				defaultActivityCodeForChildren);
			var formattedValues = {};
			if (Object.keys(childData).length > 0) {
				var dataOfFirstActivityCode = childData[Object.keys(childData)[0]];
				if (dataOfFirstActivityCode.length) {
					// Retrieve the formatted values for the childKeys
					Object.keys(parentMappings).forEach(function(childKeyName) {
						var parentKeyName = parentMappings[childKeyName];
						if (typeof(parentKeyName) === "object") {
							// Do not use static values (see representations for instance, mapping for links.params)
						} else
							formattedValues[parentKeyName] = dataOfFirstActivityCode[0][childKeyName];
					});
				}
			}
			return {
				childKeys: formattedValues,
				data: childData,
			};
		}

		function queryTable(_, tableMeta, keys, entityDescriptor, parentDescriptor, queryOptions) {
			queryOptions = queryOptions || {};
			entityDescriptor = entityDescriptor || {};

			// Build the list of columns to query
			var colsToQuery = [];
			Object.keys(tableMeta.columns).forEach(function(colName) {
				var colDef = tableMeta.columns[colName];
				for (var i = 0; i < colDef.dimension; i++) {
					colsToQuery.push(colDef.columnName + "_" + i);
				};
			});

			var where = parentDescriptor ? parentDescriptor.primaryKey : "";

			queryOptions.entityDescriptor = entityDescriptor;
			var sqlResults = buildExecute(_, tableMeta, colsToQuery, tableMeta.tableName, entityDescriptor.orderBy, keys, where, queryOptions);
			// Now, we have to dispatch all the results by activity code
			var results = {};
			var activityCodePropName;
			if (options.handleActivityCodes) {
				// Note : for the 'ActivityCodes' entity, a null activityCodeProperty is declared
				// because each activityCode will have a 'CODACT' property and we don't want to generate
				// files like XXX.XXX.json - we have to skip the management of activityCodes.
				// Do not use !entityDescriptor.activityCodeProperty but entityDescriptor.hasOwnProperty('activityCodeProperty')
				if (entityDescriptor.hasOwnProperty('activityCodeProperty')) {
					activityCodePropName = entityDescriptor.activityCodeProperty;
				} else {
					activityCodePropName = "CODACT";
				}
			}
			sqlResults.forEach(function(row) {
				var activityCode;
				if (options.handleActivityCodes) {

					if (activityCodePropName) {
						activityCode = row[activityCodePropName];
					}

					if (activityCode) {
						// The activityCode is a string that has already been formatted like "S:xx|activityCode"
						// We have to unformat it.
						activityCode = activityCode.substring(activityCode.indexOf('|') + 1).trim();
					}
					if (!activityCode) {
						activityCode = defaultActivityCode;
					}
				} else {
					activityCode = "";
				}

				results[activityCode] = results[activityCode] || [];
				results[activityCode].push(row);
			});
			return results;
		}

		// Some basic consistency checks
		if (entityDescriptor.itemIndex) {
			if (entityDescriptor.orderBy !== entityDescriptor.itemIndex) {
				throw new Error(locale.format(module, "orderByMismatchesItemIndex", entityDescriptor.tableName, entity.title));
			}
			if (!entityDescriptor.distinctKey) {
				throw new Error(locale.format(module, "distinctKeyIsMissing", entityDescriptor.tableName, entity.title));
			}
			if (entityDescriptor.distinctKey === entityDescriptor.itemIndex) {
				throw new Error(locale.format(module, "distinctKeyMatchesItemIndex", entityDescriptor.tableName, entity.title));
			}
		}
		// Read the data for the entity itself
		var data = queryTable(_, tableMeta, pkValue, entityDescriptor, null, {
			formatValues: true,
			specialExport: options.specialExport,
		});

		if (Object.keys(data).length === 0) {
			return data;
		}

		if (entityDescriptor.children) {
			// Now, query the data for the children of all the items
			Object.keys(entityDescriptor.children).forEach_(_, function(_, childName) {
				var childEntity = entityDescriptor.children[childName];
				// Reminder : data is indexed by activityCode. Each data[activityCode] is an array of items
				Object.keys(data).forEach_(_, function(_, activityCode) {
					data[activityCode].forEach_(_, function(_, itemData) {
						// childData is also indexed by activityCodes
						var childData = queryChildren(_, childEntity, itemData, activityCode);
						Object.keys(childData.data).forEach(function(childActCode) {
							// Warning : a child can be bound to an activity code that is not (yet) declared
							// on the current item. For instance, if we are on a table without any activityCode but 
							// we are loading the columns of the table : one of these columns can be bound to an activityCode.
							// We have to create a skeleton that will contain the PK, it will be usefull when
							// all the JSON files of a given entity (one JSON file per ActivityCode) will be merged.
							// Note : we can't use pkValue because pkValue contains the raw values for the PK. Here, 
							// we need some JSON-encoded values (as if they were loaded from the SQL database).
							if (!data.hasOwnProperty(childActCode)) {
								data[childActCode] = [];
							}

							// We have to find, in data[childActCode], the item that will contain the fetched
							// data i.e. the item that match the pk of the childData. Warning, we have to compare decoded
							// json values (the type of data might differ between the child column and the parent column used
							// to link the 2 items).
							var childDecodedKeys = {};
							Object.keys(childData.childKeys).forEach(function(kn) {
								childDecodedKeys[kn] = jsonHelper.decodeValueFromJsonString(null, childData.childKeys[kn]).value;
							});

							var containerItem = undefined;
							data[childActCode].some(function(obj) {
								var atLeastOneMismatch = Object.keys(childData.childKeys).some(function(pkColumn) {
									return jsonHelper.decodeValueFromJsonString(null, obj[pkColumn]).value !== childDecodedKeys[pkColumn];
								});
								if (!atLeastOneMismatch) {
									containerItem = obj;
								}
								return !atLeastOneMismatch;
							});
							if (!containerItem) {
								containerItem = {};
								Object.keys(childData.childKeys).forEach(function(pkColumn) {
									containerItem[pkColumn] = childData.childKeys[pkColumn];
								});
								data[childActCode].push(containerItem);
							}
							// Note : when we load some children, there is only one item in data[childActCode]
							// that's why we can use data[childActCode][0] that might look strange.
							containerItem[childName] = childData.data[childActCode];
						});
						if (childEntity.parentCount) {
							// The child description defines a property that contains the number of children.
							// This property is a property of the parent : it needs to be removed and it will
							// be automatically recomputed when the JSON file will be read
							delete itemData[childEntity.parentCount];
						}
					});
				});
			});
		}

		Object.keys(data).forEach_(_, function(_, activityCode) {
			data[activityCode] = data[activityCode].map_(_, function(_, dataPart) {
				dataPart = jsonHelper.createGroups(
					entityDescriptor,
					jsonHelper.sortJsonObject(_, dataPart, entityDescriptor),
					getTableMeta(_, entityDescriptor.tableName)
				);
				if (entityDescriptor.itemIndex) {
					// The property bound to 'itemIndex' is the index of the item in the collection
					// It must be removed from the JSON file and will be recomputed when reading the JSON file
					// This way, if some conflicts have to be resolved on this file and some other items are
					// inserted, they will be correctly re-indexed
					delete dataPart[entityDescriptor.itemIndex];
				}

				// Parse all the groups
				if (entityDescriptor.groups) {
					entityDescriptor.groups.filter(function(group) {
						// We are only interested in group with children
						return (group.children && dataPart[group.name]);
					}).forEach_(_, function(_, group) {
						// We have to parse each block (item of a group) that has been created by the createGroups function.
						dataPart[group.name].items.forEach_(_, function(_, blockData, blockIndex) {

							// Each child must be queried using the current context as a parent context.
							// The parent content will be composed of properties from the parent itself but also of properties
							// from a block.
							// For instance, when querying then 'AMSKZON' child, we will need the 'CODMSK' of the parent (screen)
							// to bind the zones to the right screen.
							Object.keys(group.children).forEach_(_, function(_, childName) {
								var child = group.children[childName];
								blockData[childName] = queryChildren(_, child, dataPart, activityCode, blockIndex).data[activityCode];
							});
						});
					});
				}
				if (entityDescriptor.dummyObject) {
					// We are on a dummy object, we must only keep the children and remove any other property.
					// A example of dummy object is documentationlinks
					Object.keys(dataPart).forEach(function(propertyName) {
						if (!Array.isArray(dataPart[propertyName]))
							delete dataPart[propertyName];
					});
				}

				return dataPart;
			});
		});
		return data;
	}

	function getTableMeta(_, tableName, excludedColumns) {
		var tableMeta = tableMetas[tableName];
		if (!tableMeta) {
			tableMeta = exporter.getTableMeta(_, tableName, excludedColumns);
			tableMetas[tableName] = tableMeta;
		}
		return tableMeta;
	}

	// Formats a bunch of values into a srtring
	// _formatPkValues(["AA", "BB"], {AA:1, BB:"XX", CC:"YY"}) = 1~XX
	function _formatPkValues(colNames, data) {
		var arr = colNames.reduce(function(fullArray, colName) {
			var val = data[colName] || "";
			if (typeof(val) === "string") {
				val = val.trim();
			}
			fullArray.push(val);
			return fullArray;
		}, []);
		return arr.join("~");
	}

	options = options || {};
	var tableMetas = {};

	var t0 = Date.now();
	var buildExecute = exporter.buildExecute,
		trace = exporter.trace;

	var excludedColumns = entity.excludedColumns || defaultExcludedColumns;

	var tableMeta = getTableMeta(_, entity.tableName, excludedColumns);

	var colsToQuery = [].concat(entity.primaryKey);
	if (options.incrementalDate)
		colsToQuery.push(COLNAME_UPDDATTIM);
	if (options.specialExport)
		colsToQuery.push(COLNAME_MODULE);

	// First, we have to filter the entities, according to the provided filter
	// Note : here, we don't provide any pk, we want all the entities : they will be filtered later
	// We can't run a 'SELECT .. .FROM ... WHERE ...' query because we can have more than one entityName
	// This would lead to complex (and possibly too long) WHERE clauses : (... AND ... AND ...) OR (... AND ... AND ...) ... 
	var keysToUseForFilter = entity.partialPrimaryKey || entity.primaryKey;
	if (!Array.isArray(keysToUseForFilter))
		keysToUseForFilter = keysToUseForFilter.split(',');
	var alreadyFilteredKeys = [];
	var pkValues = buildExecute(_, null, colsToQuery, entity.tableName, entity.primaryKey).filter(function(s) {
		if (entityNames) {
			// note : entityNames contains names like X~Y~Z where X, Y, Z are the values of the primary key
			// We have to build a string with concatenated values to check if it belongs to entityName
			var pkValuesStr = keysToUseForFilter.map(function(colName, index) {
				const pkVal = s[colName];
				if (pkVal === ' ')
					return '';
				else
					return pkVal;
			}).join('~');
			if (alreadyFilteredKeys.indexOf(pkValuesStr) !== -1) {
				// For instance, on documentationlinks, there is a dummy parent object with a partial primary key
				// all the rows that concern the children of this dummy parent will be accepted with the partial key
				// We only need to validate the first rown the other one will be processed as a child of this 
				// dummy parent
				return false;
			}
			alreadyFilteredKeys.push(pkValuesStr);
			return entityNames.indexOf(pkValuesStr) !== -1;
		}


		if (options.specialExport) {
			return options.modulesFilter.indexOf(s.MODULE) != -1;
		}

		if (options.incrementalDate) {
			if (!s[COLNAME_UPDDATTIM]) {
				// a null date is considered as a 'very long ago' date (sth like 1599/11/31 for oracle)
				// Items with a null date will only be synchronized on the first export.
				// options.incrementalDate is null for the first export (full or incremental)
				return false;
			}
			if (new Date(s[COLNAME_UPDDATTIM]) <= options.incrementalDate) {
				// This object has already been synchronized.
				return false;
			}
		}
		// if (entity.title === "screen") {
		// 	if (s["CODMSK"] < "PLPW2")
		// 		return false;
		// }

		if (entity.excludedInitials) {
			return !~entity.excludedInitials.indexOf(s[entity.primaryKey[0]][0]);
		}
		return true;
	}).map(function(row) {
		// Remove the UPDDATTIM column. It was only included to compare dates (incremental sync)
		if (options.incrementalDate) {
			delete row[COLNAME_UPDDATTIM];
		}
		if (options.specialExport) {
			delete row[COLNAME_MODULE];
		}
		return row;
	});

	// Here, pkValues contains all the keys of the entityType that should be exported
	// For instance, when exporting tables, pkValues will look like : 
	// [{"CODFIC" : "XXX1"}, {"CODFIC" : "XXX2"}, {"CODFIC" : "XXX3"}, .... ] where XXX1, XXX2, XXX3, are the PK in 
	// the ATABLE table of the tables to export.

	var absoluteFilenames = [];

	_trace(locale.format(module, "exportingItems", entity.title, pkValues.length), "info");

	pkValues.forEach_(_, function(_, pkValue, idx) {
		_trace(locale.format(module, "exportingItemsDetail", entity.title, (idx + 1), pkValues.length, JSON.stringify(pkValue)));

		var data = queryData(_, tableMeta, entity, pkValue, "");


		// Now, we can write the files
		// data is an object where each key is an activityCode and the value is an array of data (one per entity)
		var modulePart;
		var mainData = data['']; // The data for no activityCode (i.e. the data that contains all the common properties)
		if (!mainData) {
			// use the first activity code
			mainData = data[Object.keys(data)[0]];
		}
		mainData = mainData[0];
		if (!mainData) {
			return;
		}
		if (exporter.productId === productsHelper.knownProducts.supervisor) {
			// Supervisor specific : to not dispatch the JSON files from their module : always use 'SUPERV'
			modulePart = "SUPERV";
		} else if (exporter.moduleNames[mainData.MODULE]) {
			if (options.specialExport) {
				modulePart = mainData.MODULE + "-" + exporter.moduleNames[mainData.MODULE];
			} else {
				modulePart = exporter.moduleNames[mainData.MODULE];
			}
		} else if (mainData.CHAPITRE) {
			var chapter = mainData.CHAPITRE;
			var idx = chapter.indexOf('|');
			if (idx != -1) {
				chapter = chapter.substring(idx + 1);
			}
			modulePart = path.join("CHAPTERS", chapter);
		} else
			modulePart = "GLOBAL";

		Object.keys(data).forEach_(_, function(_, activityCode) {
			var dataPart = data[activityCode][0];

			if (activityCode) {
				// This data concerns a specific activity code
				// We have to insert the PK of the main data
				entity.primaryKey.forEach(function(colName) {
					dataPart[colName] = dataPart[colName] || mainData[colName];
				});
			}


			// We have to re-sort the JSON object to avoid git differences
			// When a conflict will be detected on this JSON object, the conflict will be resolved and the JSON
			// will be sorted with jsonHelper.sortJsonObject() function. So, the original JSON file (the one we are building now)
			// must be sorted with the same function to limit git differences.
			dataPart = jsonHelper.sortJsonObject(_, dataPart, entity);

			var filename = _formatPkValues(entity.primaryKey, pkValue) + (activityCode ? "." + activityCode : "").trim();
			if (filename === "")
				throw new Error("Could not export entity " + entity.title + ", the primary key (" + entity.primaryKey + ") is empty");

			// Now, we can write the file
			var absoluteFilename = exporter.writeResource(_, {
				path: path.join(modulePart, entity.subdir),
				fileName: filename,
				data: dataPart
			});
			absoluteFilenames.push(absoluteFilename);
		});
	});


	if (absoluteFilenames.length)
		_trace(locale.format(module, "exportDone", entity.title, JSON.stringify(pkValues.length), Math.round((Date.now() - t0) / 1000)), "info");

	return absoluteFilenames;
};