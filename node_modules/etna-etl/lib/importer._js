"use strict";
var locale = require('streamline-locale'),
	fs = require("streamline-fs"),
	path = require('path'),
	mongodb = require('mongodb'),
	datetime = require('syracuse-core').types.datetime,
	jsonHelper = require('scm-helper/lib/jsonHelper');

exports.newImporter = function(_, config) {
	var trace = config.trace;
	var jsondir = config.metaFolder;
	var mongoConfig = config.mongo || {};
	var mgConf = mongoConfig;
	var dbUrl = "mongodb://" + (mgConf.connectionString || ((mgConf.host || "localhost") + ":" + (mgConf.port || 27017))) + "/" + (mgConf.database || "x3meta");

	trace && trace(locale.format(module, "importToMongoWithUrl", dbUrl));
	var db = mongodb.MongoClient.connect(dbUrl, mgConf.options || {
		db: {
			w: 1
		}
	}, _);

	// files[xxx] contains only ABSOLUTE filenames
	var files = {
		/*		
		TEXTS: [],
		MENUS: []
*/
	};

	buildFilesList(_);

	function buildFilesList(_) {
		// Note : config.absoluteFilenames contains ABSOLUTE filenames
		if (config.absoluteFilenames && config.absoluteFilenames.length) {
			config.absoluteFilenames.forEach(function(absoluteFilename) {
				var result = jsonHelper.parseMetaFilename(absoluteFilename);
				files[result.type] = files[result.type] || {};
				files[result.type][result.shortFilename.substring(0, result.shortFilename.length - 5)] = absoluteFilename;
			});
			return;
		}

		// No filenames are provided, we have to parse jsondir to retrieve all the available metadata files

		fs.readdir(jsondir, _).forEach_(_, function(_, module) {
			var moduleDir = path.join(jsondir, module);
			if (fs.stat(moduleDir, _).isDirectory()) {
				fs.readdir(moduleDir, _).forEach_(_, function(_, type) {
					var typeDir = path.join(moduleDir, type);
					if (fs.stat(typeDir, _).isDirectory()) {
						var entries = fs.readdir(typeDir, _);

						entries.filter(function(name) {
							return (/\.json$/).test(name);
						}).forEach_(_, function(_, name) {
							files[type] = files[type] || {};
							files[type][name.substring(0, name.length - 5)] = path.join(typeDir, name);
						});

						entries.filter(function(name) {
							return (/^\w\w\w$/).test(name);
						}).forEach_(_, function(_, lan) {
							fs.readdir(typeDir + "/" + lan, _).filter(function(name) {
								return (/\.json$/).test(name);
							}).forEach_(_, function(_, name) {
								var dest = type === "MENUS" ? files.MENUS : files.TEXTS;
								var absoluteFilename = path.join(jsondir, module, type, lan, name);
								if (config.absoluteFilenames) {
									// The file must belong to the provided list of files to process
									if (config.absoluteFilenames.indexOf(absoluteFilename) == -1) {
										return;
									}
								}
								dest.push(absoluteFilename);
							});
						});
					}
				});
			}
		});

	}

	return {
		open: function(_) {
			//db.open(_);
			return this;
		},
		fillTables: function(_, entity, tracker, dropCollectionBeforeImport) {

			function addDiagnose(message, severity) {
				if (!tracker) {
					return;
				}
				tracker.$diagnoses = tracker.$diagnoses || [];
				tracker.$diagnoses.push({
					$severity: severity || "info",
					$message: message,
				});
			}

			trace && trace(locale.format(module, "insertMetadaWithType", entity.title));
			var t0 = Date.now();
			var groups = [];
			var lastShortName = "";
			var currentGroup;
			Object.keys(files[entity.subdir] || {}).sort().forEach(function(name) {
				// Note 1 : when dealing with activity codes, there will be more than one file for an entity
				// for instance, there will be ATABLES/AOBJTXT.json that contains all the common properties
				// and ATABLES/AOBJTXT.ARCH.json that will only contain the properties whose activity code is 'ARCH'
				// All the files that describe the same entity must be assembled and imported in one pass otherwise, 
				// the import of the second file of an entity might possibly delete the import of the first file
				var index = name.indexOf('.');
				var shortName;
				if (-1 === index) {
					// We are on the main file (AOBJTXT => AOBJTXT.json)
					shortName = name;
				} else {
					// We are on a secondary file (AOBJTXT.ARCH => AOBJTXT.ARCH.json)
					shortName = name.substring(0, index);
				}
				if (shortName !== lastShortName) {
					// This is a new group
					lastShortName = shortName;
					currentGroup = [];
					groups.push(currentGroup);
				}
				currentGroup.push(name);
			});
			var coln = db.collection(entity.tableName, _);

			if (dropCollectionBeforeImport) {
				addDiagnose(locale.format(module, "fullSyncDropCollection", entity.tableName));
				coln.drop();
			}

			var importedFilesCount = 0;
			var etag = datetime.now().toString();
			groups.forEach_(_, function(_, group, i) {
				var allFiles = group.map(function(name) {
					return files[entity.subdir][name];
				});
				if (tracker && tracker.abortRequested) {
					return;
				}

				var msg = locale.format(module, "importJSONWithCount", entity.title, i + 1, groups.length, group[0], allFiles);
				addDiagnose(msg);
				trace && trace(msg);

				importedFilesCount += allFiles.length;
				var data;
				try {
					data = jsonHelper.readAndMergeJsonFiles(_, allFiles, entity, {
						cleanData: true
					});
				} catch (err) {
					var msg = locale.format(module, "importJSONError", group[0], err.message);
					trace && trace(msg);
					addDiagnose(msg, "error");
					console.error(err.stack);
					return;
				}
				var filter = entity.primaryKey.reduce(function(total, item) {
					total[item] = data[item];
					return total;
				}, {});

				data._etag = etag;
				coln.update(filter, data, {
					upsert: true
				}, _);

			});
			if (tracker && tracker.abortRequested) {
				return;
			}
			trace && trace(locale.format(module, "importDone", entity.title, groups.length, Math.round((Date.now() - t0) / 1000)));

			var msg = locale.format(module, "createUniqueIndex", entity.title, entity.primaryKey);
			addDiagnose(msg);
			trace & trace(msg);
			var keys = entity.primaryKey.reduce(function(global, item) {
				global[item] = 1;
				return global;
			}, {});
			coln.ensureIndex(keys, {
				unique: true
			}, _);
			return importedFilesCount;
		},
	};
};