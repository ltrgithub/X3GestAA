"use strict"

/// !doc
/// # Mongodb handle API  
/// usually this object is already instantiated on the context
/// ```javascript
/// var dataModel = require("syracuse-orm/lib/dataModel");
/// var model = dataModel.make(...);
/// // now get the mongodb handle
/// var db = dataModel.getOrm(_, model, dataset);  
/// ```
/// 

var mongodb = require('node-mongodb');
var helpers = require("syracuse-core/lib/helpers");
var forEachKey = helpers.object.forEachKey;
var flows = require("streamline/lib/util/flows");
var locale = require("syracuse-core/lib/locale");
var globals = require('streamline/lib/globals');
var filterHelpers = require("./filters");
var streams = require("streamline/lib/streams/streams");
var ReadableStream = streams.ReadableStream;
var WritableStream = streams.WritableStream;
var sys = require("util");

var config = {};
var connectionPool = null;
var opRef = 0;

var _funnels = {}

var syracuseEscapeMap = {
	$uuid: "_uuid",
	$index: "_index",
	$keys: "_keys",
	$updDate: "_updDate",
	$updUser: "_updUser",
	$creDate: "_creDate",
	$creUser: "_creUser"
}
var syracuseUnescapeMap = {
	_uuid: "$uuid",
	_index: "$index",
	_keys: "$keys",
	_updDate: "$updDate",
	_updUser: "$updUser",
	_creDate: "$creDate",
	_creUser: "$creUser"
}

// escape :
// $ by \u007F

function escapeArray(input) {
	return input.map(function(item) {
		switch(typeof item) {
		case "object":
			return escapeJson(item);
		case "string":
			return (item[0] === "$") ? ("\u007F" + item.substring(1)) : item;
		default:
			return item;
		}
	});
}

function escapeJson(input) {
	// must clone as original object might be used later unescaped
	if(Array.isArray(input))
		return escapeArray(input);
	//
	var out = {};
	forEachKey(input, function(key, value) {
		var escKey = key;
		var escVal = value;
		if(value !== null) {
			if (Array.isArray(value)) {
				escVal = escapeArray(value);
			} else if (typeof value === "object") escVal = escapeJson(value);
			if (syracuseEscapeMap[key]) escKey = syracuseEscapeMap[key];
			else {
				if (key[0] === "$") {
					escKey = "\u007F" + key.substring(1);
					//			escKey = "Ã©"+key.substring(1); 
				}
			}
		}
		out[escKey] = escVal;
	});
	//
	return out;
}
// unescape :
// \u007F by $

function unescapeJson(input) {
	forEachKey(input, function(key, value) {
		var escKey = key;
		var escVal = value;
		if (Array.isArray(value)) {
			escVal = [];
			value.forEach(function(item) {
				if (typeof item === "object") escVal.push(unescapeJson(item));
				else if (typeof item === "string") escVal.push((item[0] === "\u007F") ? ("$" + item.substring(1)) : item);
				else escVal.push(item);
			});
		} else if (typeof value === "object") escVal = unescapeJson(value);
		if (syracuseUnescapeMap[key]) {
			escKey = syracuseUnescapeMap[key];
			delete input[key];
		} else {
			if (key[0] === "\u007F") {
				escKey = "$" + key.substring(1);
				delete input[key];
			}
		}
		input[escKey] = escVal;
	});
	//	console.log("unescaped json: "+sys.inspect(input,null,4));
	return input;
}

function decorateFilter(entity, filter) {
	forEachKey(filter, function(key, value) {
		if(Array.isArray(value)) {
			value.forEach(function(innerFilter) {
				decorateFilter(entity, innerFilter);
			});
		} else {
			var newKey = null;
			var sKey = key.split(".");
			var lastPart = sKey[sKey.length - 1];
			// walk
			var targetEnt = entity;
			var crtRel = null;
			sKey.forEach(function(part) {
				if (targetEnt.$relations[part]) {
					crtRel = targetEnt.$relations[part];
					targetEnt = targetEnt.$relations[part].targetEntity;
				} else crtRel = null;
			});
			// last part is a relation
			if (crtRel) {
				if (crtRel.isPlural) {
					newKey = key + "." + syracuseEscapeMap["$keys"];
					if(value == null) value = {$in:[[], null]};
				}
				else newKey = key + "." + syracuseEscapeMap["$uuid"];
			} else
				if(targetEnt.$properties && targetEnt.$properties[lastPart] && targetEnt.$properties[lastPart].$isLocalized) {
					sKey.push(locale.current);
					newKey = sKey.join(".");
				} else
					// last part is property or technical
					if (sKey.length && syracuseEscapeMap[sKey[sKey.length - 1]]) {
						sKey[sKey.length - 1] = syracuseEscapeMap[lastPart];
						newKey = sKey.join(".");
					}
			if (newKey) {
				filter[newKey] = value;
				delete filter[key];
			}
		}
	});
	return filter;
}

function getSelectFields(entity, shallow) {
	var fields = [];
//	var meta = entity.deepMeta;
	var meta = entity;
	forEachKey(meta.$properties, function(name, prop) {
		if (prop.$isComputed || prop.$isLazy) return;
		fields.push(name);
	});
	if (!shallow) forEachKey(meta.$relations, function(name, rel) {
		if (rel.$isComputed || rel.$isLazy) return;
		fields.push(name);
	});
	// add technical fields
	fields.splice(0, 0, "_creUser", "_creDate", "_updUser", "_updDate");
	//
	return fields;
}

// cursor
function _nextObject(cursor, _) {
	return cursor.nextObject(_);
}
function MongodbCursor(db, entity, cursor) {
	this._cursor = cursor;
	this._entity = entity;
	this._db = db;
	this._dataFuture = _nextObject(this._cursor);
}
var cursorProto = MongodbCursor.prototype;
cursorProto.next = function(_) {
	var self = this;
	var data;
	if (data = self._dataFuture(_)) {
		self._dataFuture = _nextObject(self._cursor);
		data.$key = data._id;
		data.$uuid = data._id;
		data.$loaded = true;
		return self._entity.factory.createInstance(_, unescapeJson(data), self._db);
	} else 
		return null;
}

// stores
// writable stream wrapper for grid store
function GridWritableStream(store) {
	this.store = store;
}
var gdWsProto = GridWritableStream.prototype;
gdWsProto.write = function(_, buffer, enc) {
	if(buffer == null)
		// means end
		this.store.close(_);
	else
		this.store.write(buffer, _);
}
// store constructor
function MongodbFileStore(db, fileName) {
	this.db = db.db;
	this.fileName = fileName;
	this.readStore = null;
	this.writeStore = null;
	this.readPosition = 0;
}
//
function _openStore(_, fileStore, mode) {
	var store = new mongodb.GridStore(fileStore.db, fileStore.fileName, mode);
	return store.open(_);
}
var storeProto = MongodbFileStore.prototype;
storeProto.getProperties = function(_) {
	var store = this.readStore || _openStore(_, this, "r");
	return {
		length: store.length,
		contentType: store.contentType,
		fileName: store.metadata && store.metadata.fileName,
		uploadDate: store.uploadDate,
		chunkSize: store.chunkSize
	}
}
storeProto.fileExists = function(_) {
	if(!this.fileName) return false;
	return mongodb.GridStore.exist(this.db, this.fileName, _);
}
storeProto.setFile = function(_, fileName) {
	this.close(_);
	//
	this.fileName = fileName;
}
// stream interface
storeProto.createReadableStream = function(_) {
	// force open a file store to reset stream read position
	config.tracer && config.tracer("mongodbDbHandle.GridFS open store for read: " + this.fileName);
	return (new ReadableStream((new mongodb.GridStore(this.db, this.fileName, "r")).open(_).stream(true)));
}
storeProto.createWritableStream = function(_, options) {
	var store = new mongodb.GridStore(this.db, this.fileName, "w").open(_);
	//
	store.metadata = store.metadata || {};
	if(options) {
		if(options.contentType) store.contentType = options.contentType;
		if(options.fileName) store.metadata.fileName = options.fileName;
		//
		if(options.referingInstance)
			store.metadata.referingInstance = options.referingInstance;
	}
	var etag = store.metadata.etag || 0;
	store.metadata.etag = ++etag;
	//
	return (new GridWritableStream(store));
}
storeProto.writeMetadata = function(_, options) {
	var store = new mongodb.GridStore(this.db, this.fileName, "w+").open(_);
	//
	store.metadata = store.metadata || {};
	if(options) {
		if(options.contentType) store.contentType = options.contentType;
		if(options.fileName) store.metadata.fileName = options.fileName;
		//
		if(options.referingInstance)
			store.metadata.referingInstance = options.referingInstance;
	}
	var etag = store.metadata.etag || 0;
	store.metadata.etag = ++etag;
	store.close(_);
}
storeProto.deleteFile = function(_) {
	if(this.fileExists(_))
		mongodb.GridStore.unlink(this.db, this.fileName, _);
}
storeProto.close = function(_) {
}

function MongoDbHandle(model, dataset) {
	var self = this;
	self.model = model;
	self.dataset = dataset;

	// initialize the database connection
	self.connect = function(_) {
		var self = this;
		var host = dataset.hostname;
		var port = dataset.port;
		//		var host = "localhost";
		//		var port = 27017;
		if (connectionPool) {
			if (connectionPool[host] && connectionPool[host][port] && connectionPool[host][port][dataset.database]) {
				self.db = connectionPool[host][port][dataset.database];
				config.tracer && config.tracer("Mongodb connect - pool connection for : " + host + ":" + port + "/" + dataset.database + " in state: " + self.db.state);
				if (self.db.state != "connected") self.db.open(_);
				return;
			}
		}
		// create a connection
		//		config.tracer && config.tracer("Mongodb connect : "+dataset.hostname+":"+dataset.port);
		config.tracer && config.tracer("Mongodb connect : " + host + ":" + port);
		var server = new mongodb.Server(host, port, {});
		var db = new mongodb.Db(dataset.database, server, {});
		db = db.open(_);
		self.db = db;
		// add to pool BEFORE synchronize, because sync scripts might use adminUtil and request the admin orm
		if (connectionPool) {
			connectionPool[host] = connectionPool[host] || {};
			connectionPool[host][port] = connectionPool[host][port] || {};
			connectionPool[host][port][dataset.database] = db;
		}
		// synchronize
		var params = db.collection("dbParam", _).find().toArray(_);
		if (params && params.length) {
			var p = params[0];
			config.tracer && config.tracer("mongodbDbHandle.connect ModelName: "+model.name+"; found dbParam: "+sys.inspect(p));
			var actualVersion = ((p[model.name] || {}).dbVersion != null)?(p[model.name] || {}).dbVersion:-1;
			config.tracer && config.tracer("mongodbDbHandle.connect ActualVersion: "+actualVersion);
			if (actualVersion !== (model.dbMeta.version || 0)) _synchronizeDb(_, model, db, actualVersion);
		} else _synchronizeDb(_, model, db, -1);
	}
	//
	// prevent connections as we are synchronizing
	function _lockForSynchronize(_, db) {
		// TODO: implement some kind of restricted access to prevent users to connect while synchronizing
	}
	//
	function _synchronizeDb(_, model, db, actualVersion) {
		var entities = model.getEntities();
		config.tracer && config.tracer("mongodbDbHandle.synchronize; ActualVersion: "+actualVersion+"; ModelVersion: "+model.dbMeta.version);
		// avoid dead-lock
		if(self._isSynchronizing) return;
		self._isSynchronizing = true;
		// db init
		if((actualVersion === -1) && (model.dbMeta.initScript)) {
			config.tracer && config.tracer("mongodbDbHandle.apply initialize script: "+model.dbMeta.initScript);
			var diag = [];
			require("syracuse-import/lib/jsonImport").jsonImport(_, self, model.dbMeta.initScript, {tracer:config.tracer, $diagnoses: diag});
			if(diag.length)
				config.tracer && config.tracer("mongodbDbHandle.apply initialize script errors: "+sys.inspect(diag, null, 4));
		}
		// create indexes
		if (entities) for (var name in entities) {
			var entity = entities[name];
			if (entity.$indexes) for (var idxName in entity.$indexes) {
				var indexItem = entity.$indexes[idxName];
				var fields = {};
				var isUnique = false;
				for (var i in indexItem) {
					if (i !== "$unique") fields[i] = ((indexItem[i] === "descending") || (indexItem[i] == -1)) ? -1 : 1;
				}
				//
				config.tracer && config.tracer("mongodbDbHandle.synchronize ensure index: " + entity.className + "." + sys.inspect(fields));
				db.collection(entity.className, _).ensureIndex(fields, indexItem.$unique, _);
			}
			entity.$uniqueConstraints && entity.$uniqueConstraints.forEach_(_, function(_, uc) {
				var fields = {};
				uc.forEach(function(f) {
					fields[f] = 1;
				});
				config.tracer && config.tracer("mongodbDbHandle.synchronize ensure unique index: " + entity.className + "." + sys.inspect(fields));
				db.collection(entity.className, _).ensureIndex(fields, true, _);
			});
		}
		// data update procedure
		if ((actualVersion !== -1) && model.dbMeta.updateScript) {
			var updateScript = require(model.dbMeta.updateScript);
			updateScript.tracer = config.tracer;
			updateScript.dataUpdate(_, self, actualVersion, model.dbMeta.version);
		}
		// update dbVersion
		if (model.dbMeta.version != null) {
			var data = {};
			data.$set = {};
			data.$set[model.name] = {
				dbVersion: model.dbMeta.version
			};
			db.collection("dbParam", _).update({}, data, {
				safe: true,
				upsert: true
			}, _);
		}
		self._isSynchronizing = false;
	}
	//

	function _paramsToFilter(parameters, entity) {
		var filter = {};
		// support of json filter
//		if (parameters.jsonWhere) filter = parameters.jsonWhere;
//		else {
			// support of text where in sdata syntax
//			if (parameters.sdataWhere && !parameters.where) parameters.where = require("syracuse-sdata/lib/parser/parser").Parser.parse(parameters.sdataWhere);
//			filter = _createFilter(parameters.where);
//		}
		filter = filterHelpers.sdataFilterToJson(parameters.sdataWhere || parameters.where, config);
		// fusion jsonWhere (mostly internal filter parts) in filter (mostly sdata external filter)
		parameters.jsonWhere && forEachKey(parameters.jsonWhere, function(key, value) {
			filter[key] = value;
		});
		// pager
		if(parameters.letter) {
			var sort = _paramsToOrderBy(parameters, entity);
			if(sort.length) {
				filter[sort[0][0]] = sort[0][1] === "ascending" ? { $gte: parameters.letter } : { $lte: parameters.letter };
			}
		}
		// for relations, decorate filter (clone filter to avoid returning modified instance)
		filter = decorateFilter(entity, helpers.object.clone(filter, true));
		// change the $uuid key if any
		if (filter._uuid) {
			filter._id = filter._uuid;
			delete filter._uuid;
		}
		//
		return filter;
	}

	function _paramsToOrderBy(parameters, entity) {
		var sort = [];
		if (parameters.orderBy && parameters.orderBy.length) {
			parameters.orderBy.forEach(function(orderBy) {
				sort.push([orderBy.binding, (orderBy.descending ? "descending" : "ascending")]);
			});
		} else {
			if (entity.defaultOrder && entity.defaultOrder.length) {
				entity.defaultOrder.forEach(function(order) {
					sort.push([order[0], (order[1] ? "ascending" : "descending")]);
				});
			} else {
				sort.push(["$uuid", "ascending"]);
			}
		}
		return sort;
	}
	self.getFileStore = function(fileName) {
		return new MongodbFileStore(this, fileName);
	}
	//
	/// -------------
	/// ## getEntity function :
	/// ``` javascript
	/// var entity = db.getEntity(_, entityName);
	/// ```
	/// Get the class metadata as an entity
	/// 
	/// 
	self.getEntity = function(_, entityName) {
		return this.model.getEntity(entityName);
	}
	// fetch instance
	self.fetchInstance = function(_, entity, uuid) {
		var filter;
		var options = {
			fields: getSelectFields(entity),
			limit: 1
		};
		if (typeof uuid === "object") {
			filter = _paramsToFilter(uuid, entity);
			options.sort = _paramsToOrderBy(uuid, entity);
		} else filter = {
			_id: uuid
		};
		config.tracer && config.tracer("mongodb.fetchInstance filter: "+sys.inspect(filter, null, 4));
		var dataArray = this.db.collection(entity.className, _).find(filter, options).toArray(_);
		if (dataArray.length) {
			config.tracer && config.tracer("mongodb.fetchInstance found: " + entity.name + "\n+" + sys.inspect(uuid) + "\n+" + sys.inspect(dataArray[0]));
			dataArray[0].$key = dataArray[0]._id;
			dataArray[0].$uuid = dataArray[0]._id;
			dataArray[0].$loaded = true;
			return entity.factory.createInstance(_, unescapeJson(dataArray[0]), this);
		} else {
			config.tracer && config.tracer("mongodb.fetchInstance not found: " + entity.name + "\n+" + sys.inspect(uuid, null, 4));
			return null;
		}
	}
	// used for lazy load properties (binary or large text)
	self.fetchInstanceProperty = function(_, entity, propName, param) {
		var filter;
		var options = {
			fields: [propName],
			limit: 1
		};
		if (typeof param === "object") {
			filter = _paramsToFilter(param, entity);
			options.sort = _paramsToOrderBy(param, entity);
		} else 
			filter = {
				_id: param
			};
		var dataArray = this.db.collection(entity.className, _).find(filter, options).toArray(_);
		if (dataArray.length) {
			config.tracer && config.tracer("mongodb.fetchInstanceProperty found: " + entity.name + "\n+" + param + "\n+" + sys.inspect(dataArray[0]));
			return dataArray[0][propName];
		} else {
			config.tracer && config.tracer("mongodb.fetchInstance not found: " + entity.name + "\n+" + param);
			return null;
		}
	}
	//
	self.count = function(_, entity, params) {
		var parameters = params || {};
		//
		var filter = _paramsToFilter(parameters, entity);
		//
		return this.db.collection(entity.className, _).count(filter, _);
	}
	//
	/// -------------
	/// ## createCursor function :
	/// ``` javascript
	/// var cursor = db.createCursor(_, entity, params, shallow);
	/// var data;
	/// while(data = cursor.next(_) {
	///   // do something with data witch is an object instance
	/// }
	/// ```
	/// Creates a cursor allowing to iterate over the objects in a collection
	/// function next(_) on the cursor returns the current instance. Returns null at the end of the cursor
	/// 
	/// ```javascript
	/// // parameters example
	/// params = {
	///   count: 20, // cursor fetch limit
	///   startIndex: 2, // skip parameter
	///   orderBy: [{binding:"name", descending: true}, {binding: title}],
	///   jsonWhere: {/* mongodb style json filter */} // or sdataWhere = sdataClause or where = parsed_expression_object
	/// }
	/// ```
	/// 
	self.createCursor = function(_, entity, params, shallow) {
		var parameters = params || {};
		config.tracer && config.tracer("mongodb.createCursor " + entity.className + " parameters: " + sys.inspect(parameters));
		var options = {};
		if (parameters.count) options.limit = parameters.count;
		if (parameters.startIndex) options.skip = parameters.startIndex - 1;
		options.sort = _paramsToOrderBy(parameters, entity);
		options.fields = getSelectFields(entity, shallow);
		//
		var filter = _paramsToFilter(parameters, entity);
		//
		config.tracer && config.tracer("mongodb.createCursor filter: " + sys.inspect(filter));
		config.tracer && config.tracer("mongodb.createCursor options: " + sys.inspect(options));
		//
		return new MongodbCursor(this, entity, this.db.collection(entity.className, _).find(filter, options));
	}
	// fetch all instances acording to parameters
	self.fetchInstances = function(_, entity, params, shallow, context) {
		var instances = [];
		var cursor = this.createCursor(_, entity, params, shallow);
		var data;
		while(data = cursor.next(_))
			instances.push(data);
		config.tracer && config.tracer("mongodb.fetchInstances found " + instances.length + " " + entity.className);
		//
		return instances;
	}
	//
	self.saveInstance = function(_, instance) {
		var self = this;
		if(instance._meta.$sequentialStorage) {
			var funnel = _funnels[instance._meta.name];
			if(!funnel)
				funnel = _funnels[instance._meta.name] = flows.funnel(1);
			return funnel(_, function(_) {
				return _internalSave(_, instance, self.db);
			});
		} else 
			return _internalSave(_, instance, self.db);
	}
	// persist instance and its childs
	function _internalSave(_, instance, db) {
		var data = {
			$set: {}
		};
		var pull = null;
		//

		function _getDirtyProps(_, delta, meta, path) {
			var locPath = (path ? (path + ".") : "");
			flows.eachKey(_, delta, function(_, key, value) {
				if (key === "$index") data.$set[locPath + key] = value;
				// escaped key
				var escKey = syracuseEscapeMap[key] || key;
				if (meta.$properties && meta.$properties.hasOwnProperty(key) && !meta.$properties[key].$compute) {
					if(value && (typeof value === "object"))
						value = escapeJson(value);
//					if (value) {
//						if (meta.$properties[key].$type === "json") value = escapeJson(value);
//					} 
					if (meta.$properties[key].$isLocalized) {
						Object.keys(value).forEach(function(loc) {
							data.$set[locPath + escKey + "." + loc] = value[loc];
						});
					} else
						data.$set[locPath + escKey] = value;
				}
				var rel = meta.$relations && meta.$relations.hasOwnProperty(key) && meta.$relations[key];
				if (rel && !rel.$compute && !rel.isComputed) {
					if (meta.$relations[key].isPlural) {
						// each key works in both array and object list representation !!!
						flows.eachKey(_, delta[key], function(_, listKey, listValue) {
							if (listValue.$isDeleted) {
								data.$unset = data.$unset || {};
								data.$unset[locPath + escKey + "." + delta[key][listKey].$uuid] = 1;
								// keys array allow reverse relation loading
								if (!meta.$relations[key].isChild) {
									pull = pull || {};
									pull.$pullAll = pull.$pullAll || {};
									var pullPath = locPath + escKey + "." + syracuseEscapeMap["$keys"];
									pull.$pullAll[pullPath] = pull.$pullAll[pullPath] || [];
									pull.$pullAll[pullPath].push(delta[key][listKey].$uuid);
								}
							} else {
								if (meta.$relations[key].isChild) 
									_getDirtyProps(_, listValue, meta.$relations[key].targetEntity, locPath + escKey + "." + delta[key][listKey].$uuid);
								else {
									var setKey = locPath + escKey + "." + syracuseEscapeMap["$keys"];
									if (meta.$relations[key].targetAssoEntity) 
										_getDirtyProps(_, listValue, meta.$relations[key].targetAssoEntity, locPath + escKey + "." + delta[key][listKey].$uuid);
									else 
										data.$set[locPath + escKey + "." + delta[key][listKey].$uuid] = 1; // dummy payload to define property
									data.$addToSet = data.$addToSet || {};
									data.$addToSet[setKey] = data.$addToSet[setKey] || {
										$each: []
									};
									data.$addToSet[setKey].$each.push(delta[key][listKey].$uuid);
								}
							}
						});
					} else {
						if (meta.$relations[key].isChild) {
							if (!value) {
								//										throw new Error("Cannot save null child for relation: "+key);
								data.$set[locPath + escKey] = {};
							} else {
								_getDirtyProps(_, value, meta.$relations[key].targetEntity, locPath + escKey);
								data.$set[locPath + escKey + "." + syracuseEscapeMap["$uuid"]] = value.$uuid;
							}
						} else {
							if (value) data.$set[locPath + escKey + "." + syracuseEscapeMap["$uuid"]] = value.$uuid;
							else data.$set[locPath + escKey] = {};
						}
					}
				}
				//					}
				//				}
			});
		}
		//
		var _opRef = opRef++;
		config.tracer && config.tracer("mongodb.save enter: opRef="+_opRef);
		//
		if (instance._snapshotEnabled) var saveDelta = instance.getSaveSnapshotDelta(_);
		else var saveDelta = instance.serializeInstance(_);
		config.tracer && config.tracer("mongodb.save delta: opRef=" + _opRef + "; " + sys.inspect(saveDelta));
		//
		_getDirtyProps(_, saveDelta, instance._meta);
		// technical meta
		var updDate = new Date();
		if(instance.$created) {
			data.$set._creUser = instance.$creUser;
			data.$set._creDate = instance.$creDate = updDate;
		}
		data.$set._updUser = instance.$updUser;
		// TODO: for now, mongodb doesn't seems to accept javascript in update, so we'll send the Syracuse server date
		// It would be best if it was the mongodb server date 
		data.$set._updDate = instance.$updDate = updDate;
		//
		var collection = db.collection(instance.getClassName(), _);
		var instanceFilter = (instance._meta.$lockType && (instance._meta.$lockType === "noLock")) ? {
			_id: instance.$uuid
		} : {
			_id: instance.$uuid,
			$or: [{
				_updDate: instance.$initialUpdDate
			}, {
				_updDate: null
			}]
		};
		// crnit110825
		// in current mongodb version there is an issue making an atomic $pull and $addToSet on the same array
		// http://jira.mongodb.org/browse/SERVER-1050
		// this should be fixed but for now we'll make a distinct pull operation before
		// after mongodb fixes this, add pull to data and make just one call to update
		pull && config.tracer && config.tracer("mongodb.save data pull: opRef=" + _opRef + "; " + instance.getClassName() + ";" + sys.inspect(pull));
		pull && collection.update(instanceFilter, pull, {
			safe: true
		}, _);
		//
		config.tracer && config.tracer("mongodb.save data: opRef=" + _opRef + "; " + instance.getClassName() + ";" + sys.inspect(data));
		// TODO: if result is 0, detail error conditions
		var result;
		if(instance.$created) {
			// creation, do not check concurency conditions. Use update because of the common use of $set for insert and for update.
			result = collection.update({
				_id: instance.$uuid
			}, data, {
				safe: true,
				upsert: true
			}, _);
		} else {
			config.tracer && config.tracer("mongodb.save data instanceFilter: opRef=" + _opRef + "; " + sys.inspect(instanceFilter));
			// check concurency with updDate
			result = collection.update(instanceFilter, data, {
				safe: true,
				upsert: false
			}, _);
		}
		//
		if(result) instance.$initialUpdDate = instance.$updDate;
		config.tracer && config.tracer("mongodb.save data result: opRef=" + _opRef + "; " + result);
		return result;
	}

	//
	self.deleteInstance = function(_, instance) {
		var self = this;
		if(instance._meta.$sequentialStorage) {
			var funnel = _funnels[instance._meta.name];
			if(!funnel)
				funnel = _funnels[instance._meta.name] = flows.funnel(1);
			return funnel(_, function(_) {
				return _deleteInstance(_, instance, self.db);
			});
		} else 
			return _deleteInstance(_, instance, self.db);
	}
	// delete instance and its childs
	function _deleteInstance(_, instance, db) {
		config.tracer && config.tracer("mongodb.deleteInstance: "+instance.$uuid);
		db.collection(instance.getClassName(), _).remove({
			_id: instance.$uuid
		}, {
			safe: true
		}, _);
	}
	
	// atomicaly create a instance lock
	self.lockInstance = function(_, instance) {
		if(!instance) return null;
		if(!instance.$uuid) return null;
		var session = globals.context.session;
		var userLogin = (session && session.getUserLogin(_)) || "anonymous";
		var ssid = (session && session.id) || "anonymous";
		// try un upsert with _id=instance.$uuid and currect sessionId. If allready locked, returns count of 0
		var lockId = instance.$uuid;
		try {
			var coll = this.db.collection("dbLocks", _);
			var res = coll.update({
				_id: lockId,
				sessionId: ssid
			}, {
				$set: {
					sessionId: ssid,
					lockDate: new Date(),
					lockUser: userLogin
				}
			}, {
				safe: true,
				upsert: true
			}, _);
			if(res == 1)
				return { status: "success", id: lockId };
		} catch(ex) {
			// return null;
			// pk violation, allready locked
		}
		// read the lock record to return meta
		var locks = coll.find({ _id: lockId }).toArray(_);
		if(locks && locks[0])
			return { status: "locked", lock: locks[0] };
		else
			return { status: "error" }	
	}
	self.unlockInstance = function(_, instance) {
		this.db.collection("dbLocks", _).remove({
			_id: instance.$uuid
		}, {
			safe: true
		}, _);
	}
}

helpers.defineClass(MongoDbHandle);

exports.create = function(_, model, dataset) {
	var handle = new MongoDbHandle(model, dataset);
	handle.connect(_);
	return handle;
}

//
exports.setup = function(mongodbConfig, mongoConnPool) {
	config = mongodbConfig || {};
	connectionPool = mongoConnPool;
}