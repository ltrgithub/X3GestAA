"use strict"

var mongodb = require('node-mongodb');
var helpers = require("syracuse-core/lib/helpers");
var forEachKey = helpers.object.forEachKey;
var flows = require("streamline/lib/util/flows");
var locale = require("syracuse-core/lib/locale");
var globals = require('streamline/lib/globals');
var sys = require("util");

var config = {};
var connectionPool = null;
var opRef = 0;

var _funnels = {}

var syracuseEscapeMap = {
	$uuid: "_uuid",
	$index: "_index",
	$keys: "_keys",
	$updDate: "_updDate",
	$updUser: "_updUser",
	$creDate: "_creDate",
	$creUser: "_creUser"
}
var syracuseUnescapeMap = {
	_uuid: "$uuid",
	_index: "$index",
	_keys: "$keys",
	_updDate: "$updDate",
	_updUser: "$updUser",
	_creDate: "$creDate",
	_creUser: "$creUser"
}

// escape :
// $ by \u007F

function escapeJson(input) {
	// must clone as original object might be used later unescaped
	var out = {};
	forEachKey(input, function(key, value) {
		var escKey = key;
		var escVal = value;
		if (Array.isArray(value)) {
			escVal = [];
			value.forEach(function(item) {
				if (typeof item === "object") escVal.push(escapeJson(item));
				else if (typeof item === "string") escVal.push((item[0] === "$") ? ("\u007F" + item.substring(1)) : item);
				//					escVal.push((item[0] === "$")?("é"+item.substring(1)):item);
				else escVal.push(item);
			})
		} else if (typeof value === "object") escVal = escapeJson(value);
		if (syracuseEscapeMap[key]) escKey = syracuseEscapeMap[key];
		else {
			if (key[0] === "$") {
				escKey = "\u007F" + key.substring(1);
				//			escKey = "é"+key.substring(1); 
			}
		}
		out[escKey] = escVal;
	});
	//
	return out;
}
// unescape :
// \u007F by $

function unescapeJson(input) {
	forEachKey(input, function(key, value) {
		var escKey = key;
		var escVal = value;
		if (Array.isArray(value)) {
			escVal = [];
			value.forEach(function(item) {
				if (typeof item === "object") escVal.push(unescapeJson(item));
				else if (typeof item === "string") escVal.push((item[0] === "\u007F") ? ("$" + item.substring(1)) : item);
				else escVal.push(item);
			});
		} else if (typeof value === "object") escVal = unescapeJson(value);
		if (syracuseUnescapeMap[key]) {
			escKey = syracuseUnescapeMap[key];
			delete input[key];
		} else {
			if (key[0] === "\u007F") {
				escKey = "$" + key.substring(1);
				delete input[key];
			}
		}
		input[escKey] = escVal;
	});
	//	console.log("unescaped json: "+sys.inspect(input,null,4));
	return input;
}

function decorateFilter(entity, filter) {
	forEachKey(filter, function(key, value) {
		if(Array.isArray(value)) {
			value.forEach(function(innerFilter) {
				decorateFilter(entity, innerFilter);
			});
		} else {
			var newKey = null;
			var sKey = key.split(".");
			var lastPart = sKey[sKey.length - 1];
			// walk
			var targetEnt = entity;
			var crtRel = null;
			sKey.forEach(function(part) {
				if (targetEnt.$relations[part]) {
					crtRel = targetEnt.$relations[part];
					targetEnt = targetEnt.$relations[part].targetEntity;
				} else crtRel = null;
			});
			// last part is a relation
			if (crtRel) {
				if (crtRel.isPlural) {
					newKey = key + "." + syracuseEscapeMap["$keys"];
					if(value == null) value = {$in:[[], null]};
				}
				else newKey = key + "." + syracuseEscapeMap["$uuid"];
			} else
				if(targetEnt.$properties && targetEnt.$properties[lastPart] && targetEnt.$properties[lastPart].$isLocalized) {
					sKey.push(locale.current);
					newKey = sKey.join(".");
				} else
					// last part is property or technical
					if (sKey.length && syracuseEscapeMap[sKey[sKey.length - 1]]) {
						sKey[sKey.length - 1] = syracuseEscapeMap[lastPart];
						newKey = sKey.join(".");
					}
			if (newKey) {
				filter[newKey] = value;
				delete filter[key];
			}
		}
	});
	return filter;
}

function getSelectFields(entity, shallow) {
	var fields = [];
//	var meta = entity.deepMeta;
	var meta = entity;
	forEachKey(meta.$properties, function(name, prop) {
		if (prop.$isComputed || prop.$isLazy) return;
		fields.push(name);
	});
	if (!shallow) forEachKey(meta.$relations, function(name, rel) {
		if (rel.$isComputed || rel.$isLazy) return;
		fields.push(name);
	});
	// add technical fields
	fields.splice(0, 0, "_creUser", "_creDate", "_updUser", "_updDate");
	//
	return fields;
}

function MongodbFileStore(db, fileName) {
	this.db = db.db;
	this.fileName = fileName;
	this.readStore = null;
	this.writeStore = null;
	this.readPosition = 0;
}
//
function _openStore(_, fileStore, mode) {
	var store = new mongodb.GridStore(fileStore.db, fileStore.fileName, mode);
	return store.open(_);
}
var storeProto = MongodbFileStore.prototype;
storeProto.getProperties = function(_) {
	var store = this.readStore || _openStore(_, this, "r");
	return {
		length: store.length,
		contentType: store.contentType,
		fileName: store.metadata && store.metadata.fileName,
		uploadDate: store.uploadDate,
		chunkSize: store.chunkSize
	}
}
storeProto.fileExists = function(_) {
	if(!this.fileName) return false;
	return mongodb.GridStore.exist(this.db, this.fileName, _);
}
storeProto.setFile = function(_, fileName) {
	this.close(_);
	//
	this.fileName = fileName;
}
storeProto.readOpen = function(_) {
	// force open a file store to reset stream read position
	this.readStore = this.readStore || _openStore(_, this, "r");
	this.readStore.seek(0, _);
	this.readPosition = 0;
	config.tracer && config.tracer("mongodbDbHandle.GridFS open store for read: " + this.fileName);
}
storeProto.read = function(_, len) {
	if(!this.readStore) 
		throw new Error("Error: File store not open");
	//
	if(this.readPosition >= this.readStore.length)
		return null;
	//
	len = len || this.readStore.length;
	len = Math.min(len, this.readStore.length - this.readPosition);
	config.tracer && config.tracer("mongodbDbHandle.GridFS read file: " + this.fileName + "length: " + this.readStore.length + " position: " + this.readPosition + " len: " + len);
	this.readPosition += len;
	//
	return this.readStore.read(len, _);
}
storeProto.write = function(_, buffer, options) {
	if(!this.writeStore) {
		var store = new mongodb.GridStore(this.db, this.fileName, "w");
		this.writeStore = store.open(_);
		if(options) {
			this.writeStore.metadata = this.writeStore.metadata || {};
			if(options.contentType) this.writeStore.contentType = options.contentType;
			if(options.fileName) this.writeStore.metadata.fileName = options.fileName;
		}
		//
		this.writeStore.metadata = this.writeStore.metadata || {};
		var etag = this.writeStore.metadata.etag || 0;
		this.writeStore.metadata.etag = ++etag;
		//
		if(options.referingInstance)
			this.writeStore.metadata.referingInstance = options.referingInstance;
	}
	//
	this.writeStore.write(buffer, _);
}
storeProto.deleteFile = function(_) {
	if(this.fileExists(_))
		mongodb.GridStore.unlink(this.db, this.fileName, _);
}
storeProto.close = function(_) {
	if(this.readStore) {
//		this.readStore.close(_);
		this.readStore = null;
	}
	if(this.writeStore) {
		this.writeStore.close(_);
		this.writeStore = null;
	}
}

function MongoDbHandle(model, dataset) {
	var self = this;
	self.model = model;
	self.dataset = dataset;

	// initialize the database connection
	self.connect = function(_) {
		var self = this;
		var host = dataset.hostname;
		var port = dataset.port;
		//		var host = "localhost";
		//		var port = 27017;
		if (connectionPool) {
			if (connectionPool[host] && connectionPool[host][port] && connectionPool[host][port][dataset.database]) {
				self.db = connectionPool[host][port][dataset.database];
				config.tracer && config.tracer("Mongodb connect - pool connection for : " + host + ":" + port + "/" + dataset.database + " in state: " + self.db.state);
				if (self.db.state != "connected") self.db.open(_);
				return;
			}
		}
		// create a connection
		//		config.tracer && config.tracer("Mongodb connect : "+dataset.hostname+":"+dataset.port);
		config.tracer && config.tracer("Mongodb connect : " + host + ":" + port);
		var server = new mongodb.Server(host, port, {});
		var db = new mongodb.Db(dataset.database, server, {});
		db = db.open(_);
		self.db = db;
		// add to pool BEFORE synchronize, because sync scripts might use adminUtil et request the admin orm
		if (connectionPool) {
			connectionPool[host] = connectionPool[host] || {};
			connectionPool[host][port] = connectionPool[host][port] || {};
			connectionPool[host][port][dataset.database] = db;
		}
		// synchronize
		var params = db.collection("dbParam", _).find().toArray(_);
		if (params && params.length) {
			var p = params[0];
			config.tracer && config.tracer("mongodbDbHandle.connect ModelName: "+model.name+"; found dbParam: "+sys.inspect(p));
			var actualVersion = ((p[model.name] || {}).dbVersion != null)?(p[model.name] || {}).dbVersion:-1;
			config.tracer && config.tracer("mongodbDbHandle.connect ActualVersion: "+actualVersion);
			if (actualVersion !== (model.dbMeta.version || 0)) _synchronizeDb(_, model, db, actualVersion);
		} else _synchronizeDb(_, model, db, -1);
	}
	//
	// prevent connections as we are synchronizing
	function _lockForSynchronize(_, db) {
		// TODO: implement some kind of restricted access to prevent users to connect while synchronizing
	}
	//
	function _synchronizeDb(_, model, db, actualVersion) {
		var entities = model.getEntities();
		config.tracer && config.tracer("mongodbDbHandle.synchronize; ActualVersion: "+actualVersion+"; ModelVersion: "+model.dbMeta.version);
		// db init
		if((actualVersion === -1) && (model.dbMeta.initScript)) {
			config.tracer && config.tracer("mongodbDbHandle.apply initialize script: "+model.dbMeta.initScript);
			require("syracuse-import/lib/jsonImport").jsonImport(_, self, model.dbMeta.initScript, {tracer:config.tracer});
		}
		// create indexes
		if (entities) for (var name in entities) {
			var entity = entities[name];
			if (entity.$indexes) for (var idxName in entity.$indexes) {
				var indexItem = entity.$indexes[idxName];
				var fields = {};
				var isUnique = false;
				for (var i in indexItem) {
					if (i !== "$unique") fields[i] = ((indexItem[i] === "descending") || (indexItem[i] == -1)) ? -1 : 1;
				}
				//
				config.tracer && config.tracer("mongodbDbHandle.synchronize ensure index: " + entity.className + "." + sys.inspect(fields));
				db.collection(entity.className, _).ensureIndex(fields, indexItem.unique, _);
			}
		}
		// data update procedure
		if ((actualVersion !== -1) && model.dbMeta.updateScript) {
			var updateScript = require(model.dbMeta.updateScript);
			updateScript.tracer = config.tracer;
			updateScript.dataUpdate(_, self, actualVersion, model.dbMeta.version);
		}
		// update dbVersion
		if (model.dbMeta.version != null) {
			var data = {};
			data.$set = {};
			data.$set[model.name] = {
				dbVersion: model.dbMeta.version
			};
			db.collection("dbParam", _).update({}, data, {
				safe: true,
				upsert: true
			}, _);
		}
	}
	//

	function _left(where) {
		var result = "";
		if (!where) return result;
		switch (where.type) {
		case "operator":
			switch (where.value.code) {
			case ".":
				result = _left(where.children[0]) + "." + _left(where.children[1]);
				break;
			default:
				throw new Error("_left : \"" + where.value.code + "\" not yet implemented");
			}
			break;
		default:
			result = where.value;
		}
		config.tracer && config.tracer("mongodb.filter.left: " + result);
		return result;
	}

	function _createFilter(where) {
		function _format(value) {
			return ((typeof value === "object") && value.toString())?value.toString():value;
		}
		config.tracer && config.tracer("mongodbDbHandle.create filter enter: " + sys.inspect(where));
		if (!where) return {};
		//
		var result = {};
		switch (where.type) {
		case "operator":
			switch (where.value.code) {
			case "and":
				if (where.children.length < 2) throw new Error("Invalid \"AND\" condition");
				result = _createFilter(where.children[0]);
				var right = _createFilter(where.children[1]);
				for (var p in right) {
					if (result.hasOwnProperty(p)) {
						if (typeof result[p] !== "object") throw Error("Cannot combine \"=\" operator for property: " + p);
						// concat filters for same property
						for (var r in right[p])
							result[p][r] = right[p][r];
					} else 
						result[p] = right[p];
				}
				break;
			case "or":
				if (where.children.length < 2) throw new Error("Invalid \"OR\" condition");
				result = {
					$or: [_createFilter(where.children[0]), _createFilter(where.children[1])]
				}
				break;
			default:
				if (where.value.code === "=") {
					result[_left(where.children[0])] = _format(where.children[1].value);
				} else {
					var oper = where.value.text;
					if(oper === "between") {
						result[where.children[0]] = {$gte:_format(where.children[1].value), $lte:_format(where.children[2].value)};
					} else {
						var right = _format(where.children[1].value);
						// oper translation from sData to mongo
						switch (oper) {
						case "le":
							oper = "lte";
							break;
						case "ge":
							oper = "gte";
							break;
						case "like":
							oper = "regex";
							if(right.charAt(0) != "%")
								right = "^" + right;
							right = right.replace(/%/g, ".*");
							break;
						}
						//
						oper = "$" + oper;
						//
						result[where.children[0]] = {};
						result[where.children[0]][oper] = right;
					}
				}
			}
			break;
		default:
			throw new Error(where.type + " not yet implemented");
		}
		config.tracer && config.tracer("create filter exit: " + sys.inspect(result));
		return result;
	}

	function _paramsToFilter(parameters, entity) {
		var filter = {};
		// support of json filter
		if (parameters.jsonWhere) filter = parameters.jsonWhere;
		else {
			// support of text where in sdata syntax
			if (parameters.sdataWhere && !parameters.where) parameters.where = require("syracuse-sdata/lib/parser/parser").Parser.parse(parameters.sdataWhere);
			filter = _createFilter(parameters.where);
		}
		// pager
		if(parameters.letter) {
			var sort = _paramsToOrderBy(parameters, entity);
			if(sort.length) {
				filter[sort[0][0]] = sort[0][1] === "ascending" ? { $gte: parameters.letter } : { $lte: parameters.letter };
			}
		}
		// for relations, decorate filter (clone filter to avoid returning modified instance)
		filter = decorateFilter(entity, helpers.object.clone(filter, true));
		// change the $uuid key if any
		if (filter._uuid) {
			filter._id = filter._uuid;
			delete filter._uuid;
		}
		//
		return filter;
	}

	function _paramsToOrderBy(parameters, entity) {
		var sort = [];
		if (parameters.orderBy && parameters.orderBy.length) {
			parameters.orderBy.forEach(function(orderBy) {
				sort.push([orderBy.binding, (orderBy.descending ? "descending" : "ascending")]);
			});
		} else {
			if (entity.defaultOrder && entity.defaultOrder.length) {
				entity.defaultOrder.forEach(function(order) {
					sort.push([order[0], (order[1] ? "ascending" : "descending")]);
				});
			} else {
				sort.push(["$uuid", "ascending"]);
			}
		}
		return sort;
	}
	self.getFileStore = function(fileName) {
		return new MongodbFileStore(this, fileName);
	}
	// fetch instance
	self.fetchInstance = function(_, entity, uuid, shallow, context) {
		var filter;
		var options = {
			fields: getSelectFields(entity, shallow),
			limit: 1
		};
		if (typeof uuid === "object") {
			filter = _paramsToFilter(uuid, entity);
			options.sort = _paramsToOrderBy(uuid, entity);
		} else filter = {
			_id: uuid
		};
		config.tracer && config.tracer("mongodb.fetchInstance filter: "+sys.inspect(filter, null, 4));
		var dataArray = this.db.collection(entity.className, _).find(filter, options).toArray(_);
		if (dataArray.length) {
			config.tracer && config.tracer("mongodb.fetchInstance found: " + entity.name + "\n+" + sys.inspect(uuid) + "\n+" + sys.inspect(dataArray[0]));
			dataArray[0].$key = dataArray[0]._id;
			dataArray[0].$uuid = dataArray[0]._id;
			dataArray[0].$loaded = true;
			return entity.factory.createInstance(_, unescapeJson(dataArray[0]), this, context);
		} else {
			config.tracer && config.tracer("mongodb.fetchInstance not found: " + entity.name + "\n+" + sys.inspect(uuid, null, 4));
			return null;
		}
	}
	// used for lazy load properties (binary or large text)
	self.fetchInstanceProperty = function(_, entity, propName, param) {
		var filter;
		var options = {
			fields: [propName],
			limit: 1
		};
		if (typeof param === "object") {
			filter = _paramsToFilter(param, entity);
			options.sort = _paramsToOrderBy(param, entity);
		} else 
			filter = {
				_id: param
			};
		var dataArray = this.db.collection(entity.className, _).find(filter, options).toArray(_);
		if (dataArray.length) {
			config.tracer && config.tracer("mongodb.fetchInstanceProperty found: " + entity.name + "\n+" + param + "\n+" + sys.inspect(dataArray[0]));
			return dataArray[0][propName];
		} else {
			config.tracer && config.tracer("mongodb.fetchInstance not found: " + entity.name + "\n+" + param);
			return null;
		}
	}
	//
	self.count = function(_, entity, params) {
		var parameters = params || {};
		//
		var filter = _paramsToFilter(parameters, entity);
		//
		return this.db.collection(entity.className, _).count(filter, _);
	}
	// fetch all instances acording to parameters
	self.fetchInstances = function(_, entity, params, shallow, context) {
		var parameters = params || {};
		//		config.tracer && config.tracer("mongodb.fetchInstances entity: "+sys.inspect(entity));
		config.tracer && config.tracer("mongodb.fetchInstances " + entity.className + " parameters: " + sys.inspect(parameters));
		var options = {};
		if (parameters.count) options.limit = parameters.count;
		if (parameters.startIndex) options.skip = parameters.startIndex - 1;
		options.sort = _paramsToOrderBy(parameters, entity);
		options.fields = getSelectFields(entity, shallow);
		//
		var filter = _paramsToFilter(parameters, entity);
		//
		config.tracer && config.tracer("mongodb.fetchInstances filter: " + sys.inspect(filter));
		config.tracer && config.tracer("mongodb.fetchInstances options: " + sys.inspect(options));
		var instances = [];
		var self = this;
		var cursor = this.db.collection(entity.className, _).find(filter, options);
		var idx = 0;

		var stopFetch = false;
		// cursor.nextObject is not "streamline" so we need this helper function
		function _nextObject(cursor, _) {
			return cursor.nextObject(_, idx);
		}
		var dataFuture = _nextObject(cursor);
		//		console.log("got future");
		while (!stopFetch) {
			idx++;
			//			console.log("future call");
			var data = dataFuture(_);
			//			console.log("future call end");
			dataFuture = _nextObject(cursor);
			if (data) {
				//				console.log("instance start: "+idx);
				data.$key = data._id;
				data.$uuid = data._id;
				data.$loaded = true;
				instances.push(entity.factory.createInstance(_, unescapeJson(data), self, context));
				//				console.log("instance end: "+idx);
			} else stopFetch = true;
		}

/*		cursor.toArray(_).forEach_(_, function(_, data){
			data.$key = data._id;
			data.$uuid = data._id;
			data.$loaded = true;
			instances.push(entity.factory.createInstance(_, unescapeJson(data), self));
		});
*/		//
		config.tracer && config.tracer("mongodb.fetchInstances found " + instances.length + " " + entity.className);
//		console.log("instances: "+sys.inspect(instances, null, 4));
		//
		return instances;
	}
	//
	self.saveInstance = function(_, instance) {
		var self = this;
		if(instance._meta.$sequentialStorage) {
			var funnel = _funnels[instance._meta.name];
			if(!funnel)
				funnel = _funnels[instance._meta.name] = flows.funnel(1);
			return funnel(_, function(_) {
				return _internalSave(_, instance, self.db);
			});
		} else 
			return _internalSave(_, instance, self.db);
	}
	// persist instance and its childs
	function _internalSave(_, instance, db) {
		var data = {
			$set: {}
		};
		var pull = null;
		//

		function _getDirtyProps(_, delta, meta, path) {
			var locPath = (path ? (path + ".") : "");
			flows.eachKey(_, delta, function(_, key, value) {
				if (key === "$index") data.$set[locPath + key] = value;
				// escaped key
				var escKey = syracuseEscapeMap[key] || key;
				if (meta.$properties && meta.$properties.hasOwnProperty(key) && !meta.$properties[key].$compute) {
					if(value && (typeof value === "object"))
						value = escapeJson(value);
//					if (value) {
//						if (meta.$properties[key].$type === "json") value = escapeJson(value);
//					} 
					if (meta.$properties[key].$isLocalized) {
						Object.keys(value).forEach(function(loc) {
							data.$set[locPath + escKey + "." + loc] = value[loc];
						});
					} else
						data.$set[locPath + escKey] = value;
				}
				var rel = meta.$relations && meta.$relations.hasOwnProperty(key) && meta.$relations[key];
				if (rel && !rel.$compute && !rel.isComputed) {
					if (meta.$relations[key].isPlural) {
						// each key works in both array and object list representation !!!
						flows.eachKey(_, delta[key], function(_, listKey, listValue) {
							if (listValue.$isDeleted) {
								data.$unset = data.$unset || {};
								data.$unset[locPath + escKey + "." + delta[key][listKey].$uuid] = 1;
								// keys array allow reverse relation loading
								if (!meta.$relations[key].isChild) {
									pull = pull || {};
									pull.$pull = pull.$pull || {};
									pull.$pull[locPath + escKey + "." + syracuseEscapeMap["$keys"]] = delta[key][listKey].$uuid;
								}
							} else {
								if (meta.$relations[key].isChild) _getDirtyProps(_, listValue, meta.$relations[key].targetEntity, locPath + escKey + "." + delta[key][listKey].$uuid);
								else {
									var setKey = locPath + escKey + "." + syracuseEscapeMap["$keys"];
									if (meta.$relations[key].targetAssoEntity) _getDirtyProps(_, listValue, meta.$relations[key].targetAssoEntity, locPath + escKey + "." + delta[key][listKey].$uuid);
									else data.$set[locPath + escKey + "." + delta[key][listKey].$uuid] = 1; // dummy payload to define property
									data.$addToSet = data.$addToSet || {};
									data.$addToSet[setKey] = data.$addToSet[setKey] || {
										$each: []
									};
									data.$addToSet[setKey].$each.push(delta[key][listKey].$uuid);
								}
							}
						});
					} else {
						if (meta.$relations[key].isChild) {
							if (!value) {
								//										throw new Error("Cannot save null child for relation: "+key);
								data.$set[locPath + escKey] = {};
							} else {
								_getDirtyProps(_, value, meta.$relations[key].targetEntity, locPath + escKey);
								data.$set[locPath + escKey + "." + syracuseEscapeMap["$uuid"]] = value.$uuid;
							}
						} else {
							if (value) data.$set[locPath + escKey + "." + syracuseEscapeMap["$uuid"]] = value.$uuid;
							else data.$set[locPath + escKey] = {};
						}
					}
				}
				//					}
				//				}
			});
		}
		//
		var _opRef = opRef++;
		config.tracer && config.tracer("mongodb.save enter: opRef="+_opRef);
		//
		if (instance._snapshotEnabled) var saveDelta = instance.getSaveSnapshotDelta(_);
		else var saveDelta = instance.serializeInstance(_);
		config.tracer && config.tracer("mongodb.save delta: opRef=" + _opRef + "; " + sys.inspect(saveDelta));
		//
		_getDirtyProps(_, saveDelta, instance._meta);
		// technical meta
		var updDate = new Date();
		if(instance.$created) {
			data.$set._creUser = instance.$creUser;
			data.$set._creDate = instance.$creDate = updDate;
		}
		data.$set._updUser = instance.$updUser;
		// TODO: for now, mongodb doesn't seems to accept javascript in update, so we'll send the Syracuse server date
		// It would be best if it was the mongodb server date 
		data.$set._updDate = instance.$updDate = updDate;
		//
		var collection = db.collection(instance.getClassName(), _);
		var instanceFilter = (instance._meta.$lockType && (instance._meta.$lockType === "noLock")) ? {
			_id: instance.$uuid
		} : {
			_id: instance.$uuid,
			$or: [{
				_updDate: instance.$initialUpdDate
			}, {
				_updDate: null
			}]
		};
		// crnit110825
		// in current mongodb version there is an issue making an atomic $pull and $addToSet on the same array
		// http://jira.mongodb.org/browse/SERVER-1050
		// this should be fixed but for now we'll make a distinct pull operation before
		// after mongodb fixes this, add pull to data and make just one call to update
		pull && collection.update(instanceFilter, pull, {
			safe: true
		}, _);
		//
		config.tracer && config.tracer("mongodb.save data: opRef=" + _opRef + "; " + instance.getClassName() + ";" + sys.inspect(data));
		// TODO: if result is 0, detail error conditions
		var result;
		if(instance.$created) {
			// creation, do not check concurency conditions. Use update because of the common use of $set for insert and for update.
			result = collection.update({
				_id: instance.$uuid
			}, data, {
				safe: true,
				upsert: true
			}, _);
		} else {
			config.tracer && config.tracer("mongodb.save data instanceFilter: opRef=" + _opRef + "; " + sys.inspect(instanceFilter));
			// check concurency with updDate
			result = collection.update(instanceFilter, data, {
				safe: true,
				upsert: false
			}, _);
		}
		//
		if(result) instance.$initialUpdDate = instance.$updDate;
		config.tracer && config.tracer("mongodb.save data result: opRef=" + _opRef + "; " + result);
		return result;
	}

	//
	self.deleteInstance = function(_, instance) {
		var self = this;
		if(instance._meta.$sequentialStorage) {
			var funnel = _funnels[instance._meta.name];
			if(!funnel)
				funnel = _funnels[instance._meta.name] = flows.funnel(1);
			return funnel(_, function(_) {
				return _deleteInstance(_, instance, self.db);
			});
		} else 
			return _deleteInstance(_, instance, self.db);
	}
	// delete instance and its childs
	function _deleteInstance(_, instance, db) {
		config.tracer && config.tracer("mongodb.deleteInstance: "+instance.$uuid);
		db.collection(instance.getClassName(), _).remove({
			_id: instance.$uuid
		}, {
			safe: true
		}, _);
	}
	
	// atomicaly create a instance lock
	self.lockInstance = function(_, instance) {
		if(!instance) return null;
		if(!instance.$uuid) return null;
		var session = globals.context.session;
		var userLogin = (session && session.getUserLogin(_)) || "anonymous";
		var ssid = (session && session.id) || "anonymous";
		// try un upsert with _id=instance.$uuid and currect sessionId. If allready locked, returns count of 0
		var lockId = instance.$uuid;
		try {
			var coll = this.db.collection("dbLocks", _);
			var res = coll.update({
				_id: lockId,
				sessionId: ssid
			}, {
				$set: {
					sessionId: ssid,
					lockDate: new Date(),
					lockUser: userLogin
				}
			}, {
				safe: true,
				upsert: true
			}, _);
			if(res == 1)
				return { status: "success", id: lockId };
		} catch(ex) {
			// return null;
			// pk violation, allready locked
		}
		// read the lock record to return meta
		var locks = coll.find({ _id: lockId }).toArray(_);
		if(locks && locks[0])
			return { status: "locked", lock: locks[0] };
		else
			return { status: "error" }	
	}
	self.unlockInstance = function(_, instance) {
		this.db.collection("dbLocks", _).remove({
			_id: instance.$uuid
		}, {
			safe: true
		}, _);
	}
}

helpers.defineClass(MongoDbHandle);

exports.create = function(_, model, dataset) {
	var handle = new MongoDbHandle(model, dataset);
	handle.connect(_);
	return handle;
}

//
exports.setup = function(mongodbConfig, mongoConnPool) {
	config = mongodbConfig || {};
	connectionPool = mongoConnPool;
}