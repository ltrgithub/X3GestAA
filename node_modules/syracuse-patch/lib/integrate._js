var fs = require('fs');
var util = require('util');
var zlib = require('zlib');
var write = require('./write');
var child_process = require('child_process');
var os = require('os');
var path = require('path');

var tracer = console.log;

var LOGFILE = os.tmpDir()+"/patch2.log";

// var patchlogger = console.log;
var patchlogger = function(text) {
	fs.appendFileSync(LOGFILE, JSON.stringify(new Date())+text+"\n")
}

var DIFF_ENTRIES = 0x01
var LOADED = 0x02
var BINARY = 0x04



// for base85 decoding
var d85 = [  0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
			 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
			 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
			 0, 0, 0,63, 0,64,65,66,67, 0,
			68,69,70,71, 0,72, 0, 0, 1, 2,
			 3, 4, 5, 6, 7, 8, 9,10, 0,73,
			74,75,76,77,78,11,12,13,14,15,
			16,17,18,19,20,21,22,23,24,25,
			26,27,28,29,30,31,32,33,34,35,
			36, 0, 0, 0,79,80,81,37,38,39,
			40,41,42,43,44,45,46,47,48,49,
			50,51,52,53,54,55,56,57,58,59,
			60,61,62,82,83,84,85 ];

			
			
function BinBuffer(buffer) {
	this.b = buffer;
	this.offset = 0;
}

BinBuffer.prototype.readLength = function() {
	if (this.offset >= this.b.length)
		throw "End of buffer";
	var result = 0;
	var shift = 0;	
	while (this.offset < this.b.length) {
		var current = this.b[this.offset]
		if (current & 0x80) { // not last byte
			result += (current & 0x7F) << shift;
		} else { // last byte
			result += (current & 0x7F) << shift;
			this.offset++;
			return result;
		}
		shift += 7;
		this.offset++;
		if (shift > 32) 
			throw "Too many bytes at "+offset;
	}
}

BinBuffer.prototype.readInstruction = function() {
	if (this.offset >= this.b.length)
		return false; // no further instructions
	var type = this.b[this.offset++];
	var resultOffset = 0;
	var resultLength = 0;
	var sourceBuffer = this.sourceBuf;
	if (type & 0x80) { // copy instruction
		if (type & 0x01)
			resultOffset += this.b[this.offset++]
		if (type & 0x02)
			resultOffset += (this.b[this.offset++] << 8)
		if (type & 0x04)
			resultOffset += (this.b[this.offset++] << 16)
		if (type & 0x08)
			resultOffset += (this.b[this.offset++] << 24)
		if (type & 0x70) { // length not maximum length of 64 kB
			if (type & 0x10)
				resultLength += this.b[this.offset++]
			if (type & 0x20)
				resultLength += (this.b[this.offset++] << 8)
			if (type & 0x40)
				resultLength += (this.b[this.offset++] << 16)
		} else {
			resultLength = 0x10000;
		}
		if (this.offset > this.b.length+1) // too many bytes
			throw "Too many bytes in copy instruction";
		tracer && tracer("Copy offset "+resultOffset+ " length " + resultLength);
		
	} else { // insert instruction
		sourceBuffer = this.b;
		resultOffset = this.offset;
		this.offset += type;
		resultLength = type;
		if (this.offset > this.b.length+1) // too many bytes
			throw "Too many bytes in insert instruction";
		tracer && tracer("Insert offset "+resultOffset+ " length " + resultLength);
	}	
	sourceBuffer.copy(this.destBuf, this.targetOffset, resultOffset, resultOffset+resultLength);
	this.targetOffset += resultLength;
	return true;
}
	
	
BinBuffer.prototype.transform = function(targetDirectory, file_from, file_to, sha1_from, sha1_to, checksums, _) {
	this.offset = 0; // offset of instruction buffer
	this.targetOffset = 0; // offset of target buffer
	var sourceLen = this.readLength();
	var destLen = this.readLength();
	this.sourceBuf = fs.readFile(targetDirectory+"/"+file_from, _);
	if (sourceLen !== this.sourceBuf.length)
		throw "Wrong length of "+file_from+" expected "+sourceLen+" actual "+this.sourceBuf.len;
	if (!write.check_sha1_binary(this.sourceBuf, sha1_from))
		throw "Wrong checksum of "+file_from;
	this.destBuf = new Buffer(destLen);
	// perform insert/copy instructions
	while (this.readInstruction()) {}
	if (destLen !== this.targetOffset)
		throw "Wrong length of destination "+file_from+" expected "+destLen+" actual "+this.targetOffset;
	if (!write.check_sha1_binary(this.destBuf, sha1_to))
		throw "Wrong checksum of "+file_to;
	write.writeFile(targetDirectory +"/"+ file_to, this.destBuf, _);
	checksums[path.dirname(file_to)][path.basename(file_to)] = "F "+sha1_to;
}

function decode85(line, buffer, bufferoffset) {
	// first character is length of bytes
	var len = line.charCodeAt(0)-64;
	if (len > 32) len -= 6;
	// deciphering base85
	var i, code, decode, number;
	number = 0;
	for (i=1; i< line.length; i++) {
		var code = line.charCodeAt(i);
		if (code >= d85.length || (decode = d85[code]) === 0)
			throw "Invalid character code "+code+" in "+line
		number = 85*number+decode-1;
		if (i % 5 === 0) {
			var transfer = len > 4 ? 4 : len;
			len -= transfer;
			if (transfer < 4) {
				number >>>= (32-8*transfer)
			}
			for (var j = transfer-1; j >= 0; j--) {
				// console.log("b["+(bufferoffset+j)+"] = "+(number % 256)+" "+number);
				buffer[bufferoffset+j] = number % 256
				number >>>= 8;
			}
			bufferoffset += transfer
			if (len === 0)
				return bufferoffset;
		}
	}
	throw "Line too short "+line;
}
	
/// reads lines in binary GIT patch format
/// result: object with i: index in lines array after last content line, buffer: buffer with data
function readBinary(lines, i, read, _) {
	// find out length of base85 decoded data
	var len = 0;
	var j = i;
	var literal = false;
	var fullLength = 0;
	var r;
	if (r = /^(literal|delta) (\d+)/.exec(lines[j])) {
	console.log("regex "+r[1]+" "+r[2]);
		if (r[1] === "literal")
			literal = true;
		fullLength = r[2];
	} else {
		throw "Wrong binary patch description "+lines[j];
	}
	j++;
	i++;
	// all but last line have maximal length 52 and start with 'z'
	while (j < lines.length && lines[j].substr(0, 1) === 'z') {
		len += 52;
		j++;
	}
	// last line may be shorter
	if (j < lines.length && lines[j].match(/^[A-Za-y]\S+$/)) {
	    var lastLength = lines[j].charCodeAt(0)-64;
		if (lastLength > 32)
			lastLength -= 6;
		len += lastLength;
		j++;
	}
	if (!read) {
		var result = { i: j, literal: literal };
		return result;
	}
	
	// console.log("LENGTH1"+len);
	var zipBuffer = new Buffer(len);
	var bufferoffset = 0;
	while (i < j) {
		bufferoffset = decode85(lines[i], zipBuffer, bufferoffset);
		i++;
	}
	var buffer;
	buffer = zlib.inflate(zipBuffer, _);
	if (buffer.length - fullLength != 0)
		throw "Wrong length after inflating "+buffer.length+" expected "+fullLength;
	console.log("BLEN"+buffer.length+" lit "+literal);
	var result = { i: j, buffer: buffer, literal: literal };
	return result;
}

/// write target text file
function write_data(targetDirectory, status, file_from, file_to, sha1_to, file_lines, checksums, _) {
	console.log("WRITE_DATA "+status);
	if ((status & LOADED) != 0) {
		if (file_from && file_from !== file_to) {
			fs.unlink(targetDirectory + "/" + file_from, _);
			delete checksums[path.dirname(file_from)][path.basename(file_from)];
		}
		console.log(2)
		var buffer = file_lines.join("\n");
		console.log(23)
		var sha1 = write.get_sha1_binary(buffer);
		console.log(sha1)
		if (!write.equal_sha1(sha1, sha1_to))
			patchlogger("Wrong check sum for "+file_to+" expected "+sha1_to);
		console.log(25)
		patchlogger("Write file "+targetDirectory+"/"+file_to);		
		console.log(26)
		write.writeFile(targetDirectory + "/" + file_to, buffer, _);	
		console.log(path.dirname(file_to)+" "+path.basename(file_to))
		checksums[path.dirname(file_to)][path.basename(file_to)] = "F "+sha1;
	} else if ((status & DIFF_ENTRIES) != 0 && file_from && file_from !== file_to) {
		// just renaming
		fs.rename(targetDirectory+"/"+file_from, targetDirectory+"/"+file_to, _);
		checksums[path.dirname(file_to)][path.basename(file_to)] = checksums[path.dirname(file_from)][path.basename(file_from)];
		delete checksums[path.dirname(file_from)][path.basename(file_from)];
	}
	status = 0;
}

function checkVersions(parts, _) {
	var oldRelNumber = parts[2];
	var oldPatchNumber = parts[3];
	var newDate = parts[4];
	var newRelNumber = parts[5];
	var newPatchNumber = parts[6];
	var oldHash = parts[7];
	var newHash = parts[8];
	var baseDir = ".";
	patchlogger("checkVersions: Data: oldHash "+oldHash+" old release number "+oldRelNumber+" new hash "+newHash+" new release number "+newRelNumber);				
	// consistency checks
	var versionInformation = {};
	// check whether there is release directory
	if (!write.exists(write.RELEASE_DIRECTORY, _)) {
		patchlogger("No release directory available");
		versionInformation = write.readVersionFile(".", _);
		if (!versionInformation.init)
			throw new Error("No release directory although version is not initial")
		patchlogger("Copy recursive . to "+write.RELEASE_DIRECTORY);
		write.copyRec(".", write.RELEASE_DIRECTORY, false, _);
		patchlogger("End copy recursive . to "+write.RELEASE_DIRECTORY);
	} else {
		if (oldPatchNumber === "0")
			baseDir = write.RELEASE_DIRECTORY;
		versionInformation = write.readVersionFile(baseDir, _);
	}
	patchlogger("Version information "+util.format(versionInformation))
	if (versionInformation.commit === newHash) // patch already applied
		return null;
	if (versionInformation.commit !== oldHash) 
		throw new Error("Base version mismatch. Expected "+versionInformation.commit+" ("+versionInformation.comment+"), actual "+oldHash+" ("+comment+")");
	versionInformation.init = false;
	versionInformation.commit = newHash;
	versionInformation.relNumber = newRelNumber;
	versionInformation.patchNumber = newPatchNumber;
	// copy everything into temporary directory
	patchlogger("Fast copy recursive "+baseDir+" to "+write.TEMP_DIRECTORY);
	try {
		write.copyRec(baseDir, write.TEMP_DIRECTORY, true, _);
		// copy nodelocal.js into temp directory
		var buf = fs.readFile("nodelocal.js", _);
		fs.writeFile(write.TEMP_DIRECTORY+"/nodelocal.js", buf, _);
	} catch (e) { // errors in fast copy: check base directory 
		patchlogger("Error in fast copy "+e);
		var errors = write.checkChecksumsV(baseDir, _);
		if (errors.length > 0) {
			patchlogger("Errors in checkChecksumsV "+errors.join(", "));
			throw new Error("Invalid base directory. "+baseDirectory+". Installation is damaged. Patch cannot be applied")
		}
		// base directory OK. Therefore full copy
		patchlogger("Full copy recursive "+baseDir+" to "+write.TEMP_DIRECTORY);
		write.copyRec(baseDir, write.TEMP_DIRECTORY, false, _);
	}
	patchlogger("End checkVersion "+util.format(versionInformation));
	return versionInformation;
}	


// apply a patch
// result: 0 patch could be applied
//         1 patch has already been applied
function patch(targetDirectory, filename, options, _) {
	patchlogger("============= PATCH =================")
	console.log("----------------------------------")
	var lines = fs.readFile(filename, 'utf8', _).split(/[\n\r]+/);
	var i;
	var file_from;
	var file_to;
	var sha1_from;
	var sha1_to;
	var status = 0x0; // bits: 1: care about diff entries, 2: input file already loaded, 4: binary content, 8: no line feed at end
	var file_lines;
	var checksums = {};
	var versionInformation = null;
	for (i=0; i<lines.length; i++) {
		var line = lines[i];
		console.log("LINE"+util.format(line));
		if (line.substr(0, 9) === "syracuse ") { // patch meta information
			var parts = line.split(/\s+/);
			patchlogger("T "+util.format(parts));
			
			if (parts[1] === "patch") {
			patchlogger("Before checkVersions")
				versionInformation = checkVersions(parts, _);
				if (versionInformation === null) // patch already applied
					return 1;
				
				patchlogger("Set targetDirectory");
				targetDirectory = write.TEMP_DIRECTORY;
			}
			if (parts[1] === "patchcomment" && versionInformation) 
				versionInformation.comment = parts.slice(2).join(" ");
		}
		if (line.substr(0, 3) === '+++' || line.substr(0, 3) === '---' || /^(copy|rename) (from|to)\b/.exec(line))
			continue;
		var m;
		// start of diff
		if (line.substr(0, 10) === 'diff --git') {
			write_data(targetDirectory, status, file_from, file_to, sha1_to, file_lines, checksums, _);				
			if (m = /^diff --git a\/(.*) b\/\1$/.exec(line)) {
				file_from = m[1];
				file_to = m[1];
				sha1_from = "";
				sha1_to = "";
				status = DIFF_ENTRIES;				
			} else
			if (m = /^diff --git a\/(\S+) b\/(\S+)$/.exec(line)) {
				file_from = m[1];
				file_to = m[2];
				sha1_from = "";
				sha1_to = "";
				status = DIFF_ENTRIES;
			} else {
				status = 0;
				console.log('wrong file names in '+line);
			}
			if (status) {
				var parent = path.dirname(file_from);
				if (!(parent in checksums))
					checksums[parent] = write.getChecksumContent(targetDirectory, parent, _);
				parent = path.dirname(file_to);
				if (checksums && !(parent in checksums))
					checksums[parent] = write.getChecksumContent(targetDirectory, parent, _);				
			}
			continue;
		}
		if (line.substr(0, 6) === 'index ') {
			r = /^index ([0-9a-f]+)\.\.([0-9a-f]+)/.exec(lines[i]);
			if (r) {			
				sha1_from = r[1];
				sha1_to = r[2];
				console.log("SHA1 "+sha1_from+" "+sha1_to);
			} else {
				status = 0;
				console.log('no index available for '+file_from);
			}
		}
		if (line.substr(0, 8) === 'new file') {
			file_from = "";
			file_lines = [];
			status |= LOADED;
			console.log("NEW FILE"+status+"---"+file_to);
			continue;
		}
		if (line.substr(0, 12) === 'deleted file') {
			fs.unlink(targetDirectory + "/" + file_from, _);
			delete checksums[path.dirname(file_from)][path.basename(file_from)]
			status = 0;
			continue;
		}
		if (line.substr(0, 16) === "GIT binary patch") {
			i++;
			var res = readBinary(lines, i, status !== 0, _);
			i = res.i;
			// end
			if (status) {
				if (res.literal) {
					if (!write.check_sha1_binary(res.buffer, sha1_to))
						throw "Wrong checksum of "+file_to+"-"+sha1_to+"-"+sha1(res.buffer);
					write.writeFile(targetDirectory + "/" + file_to, res.buffer, _);
					checksums[path.dirname(file_to)][path.basename(file_to)] = "F "+sha1_to;
					// console.log("NACH fs.write"+file_to+res.buffer.length);
				} else {
					// apply changes
					var binBuffer = new BinBuffer(res.buffer, file_from);
					binBuffer.transform(targetDirectory, file_from, file_to, sha1_from, sha1_to, checksums, _);
					console.log("transform end");
				}
			}
			res = readBinary(lines, i, false, _);
			i = res.i;
			status = 0;
			i--;
			continue;
		}

		// diff area
		if (m = /^\@\@ \-\d+(?:,(\d+))? +\+(\d+)(?:,(\d+))?/.exec(line)) {
			// read input file unless read
			if ((status & (DIFF_ENTRIES+LOADED)) === DIFF_ENTRIES) {
				if (!write.equal_sha1(checksums[path.dirname(file_from)][path.basename(file_from)], sha1_from))
					throw new Error("READ file:Wrong check sum for "+file_from+" expected "+sha1_from+ "indeed "+checksums[path.dirname(file_from)][path.basename(file_from)]);
				file_lines = fs.readFile(targetDirectory + "/" + file_from, 'utf8', _).split(/(?:\r\n|\r|\n)/);
				console.log("IIII "+file_from+" "+util.format(checksums));
				status |= LOADED;
			}
			// lines count from 1, index counts from 0
			var cur_line = m[2]-1;
			var remainingExistingLines = (m[1] === undefined ? 1 : 1*m[1]);
			var remainingTargetLines = (m[3] === undefined ? 1 : 1*m[3]);
			if (remainingTargetLines == 0)
				cur_line++;
			console.log("DIFF "+cur_line+" "+remainingExistingLines+" "+remainingTargetLines);
			i++;
			while (i < lines.length && (remainingExistingLines > 0 || remainingTargetLines > 0) && (m = /^([\\ \-\+])/.exec(lines[i]))) {
				console.log("VERARB "+lines[i]+">>"+util.format(file_lines)+"||"+util.format(m)+"II"+remainingExistingLines+"UU"+remainingTargetLines);
				if (!(status & DIFF_ENTRIES))
					break;
				line = lines[i].substr(1);
				switch (m[1]) {
				case ' ': // just test current line
					console.log("check");
					remainingExistingLines--;
					remainingTargetLines--;
					if (remainingExistingLines < 0 || remainingTargetLines < 0) {
						console.log("Too many lines in diff area at "+lines[i]);						
						status = 0;
					} else if (line !== file_lines[cur_line]) {
						console.log("Line mismatch: >"+line+"< expected: >"+file_lines[cur_line]+"<");
						status = 0;
					}
					cur_line++;
					break;
				case '+': // insert line at current position
					console.log("insert");
					remainingTargetLines--;
					if (remainingExistingLines < 0) {
						console.log("Too many lines deleted at "+lines[i]);
						status = 0;
					} else {
						console.log("ZZZZZZZZZZZ "+util.format(file_lines));
						file_lines.splice(cur_line++, 0, line)
					}
					// check for line break
					var next_line = lines[i+1];
					if (next_line.substr(0, 1) !== '+') {
						if (next_line.substr(0, 12) === "\\ No newline") {
							if (file_lines.length === cur_line+1 && file_lines[cur_line] === '')
								file_lines.pop();
						} else {
							if (file_lines.length === cur_line)
								file_lines.push('');
						}
					}
					// maybe 
					break;
				case '-': // delete line at current position
					console.log("del");
					remainingExistingLines--;
					if (remainingExistingLines < 0) {
						console.log("Too many lines deleted at "+lines[i]);
						status = 0;
					} else if (line !== file_lines[cur_line]) {
						console.log("Line mismatch: >"+line+"< expected: >"+file_lines[cur_line]+"<");
						status = 0;
					} else {
						file_lines.splice(cur_line, 1)
					}
					break;
				case '\\': // no new line
					break;
				}
				if (remainingExistingLines < 0 || remainingTargetLines < 0) {
						console.log("Too many lines");
						status = 0;
				}
				i++;
			}
			i--;
			continue;
		}	
	}
	write_data(targetDirectory, status, file_from, file_to, sha1_to, file_lines, checksums, _);
	if (write.exists(write.EXTRA_FUNCTIONS, _)) {
		patchlogger("Copy "+write.EXTRA_FUNCTIONS+" to "+targetDirectory+"/"+write.EXTRA_FUNCTIONS_OLD)
		var extraOld = fs.readFile(write.EXTRA_FUNCTIONS, _)
		fs.writeFile(targetDirectory+"/"+write.EXTRA_FUNCTIONS_OLD, extraOld, _);
		// update checksum for copy of extra.fkt
		checksums["."][write.EXTRA_FUNCTIONS_OLD] = "F "+write.get_sha1_binary(extraOld);
	}
	var sha1 = write.updateChecksums(targetDirectory, checksums, _);	
	if (versionInformation) {
		versionInformation.sha1 = sha1;
		// write new version information
		patchlogger("Write version information "+JSON.stringify(versionInformation))		
		fs.writeFile(write.TEMP_DIRECTORY+"/"+write.VERSION_FILE, JSON.stringify(versionInformation), "utf8", _);
		// start new process
		if ("restart" in options) {
			patchlogger("Kill node")
			write.exchangeProcess(write.TEMP_DIRECTORY, LOGFILE, options.restart ? "PATCH" : "PATCH0");
			
		}
	}
	return 0;
}
		
exports.patch = patch;


