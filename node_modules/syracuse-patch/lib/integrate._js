"use strict";
var fs = require('streamline-fs');
var util = require('util');
var zlib = require('zlib');
var os = require('os');
var path = require('path');
var locale = require('streamline-locale');
var config = require('config');
var mock = require('syracuse-load/lib/mock');
var ballot = require('./ballot');
var adminHelper = require("../../../src/collaboration/helpers").AdminHelper;
var patchtools = require('syracuse-patch/lib/patchtools');

/// !doc
/// # Patch integration  
/// ```javascript
/// var integrate = require('syracuse-patch/lib/integrate')  
/// ```
/// 

var tracer = require('@sage/syracuse-core').getTracer('patch');

var DIFF_ENTRIES = 0x01;
// file contents have been loaded into memory
var LOADED = 0x02;
// binary file
var BINARY = 0x04;

// timeout for patch integration request (should exceed http.Server.timeout)
var PATCH_INTEGRATION_TIMEOUT = 130000;

// for base85 decoding
var d85 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 63, 0, 64, 65, 66, 67, 0,
	68, 69, 70, 71, 0, 72, 0, 0, 1, 2,
	3, 4, 5, 6, 7, 8, 9, 10, 0, 73,
	74, 75, 76, 77, 78, 11, 12, 13, 14, 15,
	16, 17, 18, 19, 20, 21, 22, 23, 24, 25,
	26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
	36, 0, 0, 0, 79, 80, 81, 37, 38, 39,
	40, 41, 42, 43, 44, 45, 46, 47, 48, 49,
	50, 51, 52, 53, 54, 55, 56, 57, 58, 59,
	60, 61, 62, 82, 83, 84, 85
];

function BinBuffer(buffer) {
	this.b = buffer;
	this.offset = 0;
}

BinBuffer.prototype.readLength = function() {
	if (this.offset >= this.b.length) throw locale.format(module, "endOfBuffer");
	var result = 0;
	var shift = 0;
	while (this.offset < this.b.length) {
		var current = this.b[this.offset];
		if (current & 0x80) { // not last byte
			result += (current & 0x7F) << shift;
		} else { // last byte
			result += (current & 0x7F) << shift;
			this.offset++;
			return result;
		}
		shift += 7;
		this.offset++;
		if (shift > 32) throw locale.format(module, "tooMany", this.offset);
	}
};

BinBuffer.prototype.readInstruction = function() {
	if (this.offset >= this.b.length) return false; // no further instructions
	var type = this.b[this.offset++];
	var resultOffset = 0;
	var resultLength = 0;
	var sourceBuffer = this.sourceBuf;
	if (type & 0x80) { // copy instruction
		if (type & 0x01) resultOffset += this.b[this.offset++];
		if (type & 0x02) resultOffset += (this.b[this.offset++] << 8);
		if (type & 0x04) resultOffset += (this.b[this.offset++] << 16);
		if (type & 0x08) resultOffset += (this.b[this.offset++] << 24);
		if (type & 0x70) { // length not maximum length of 64 kB
			if (type & 0x10) resultLength += this.b[this.offset++];
			if (type & 0x20) resultLength += (this.b[this.offset++] << 8);
			if (type & 0x40) resultLength += (this.b[this.offset++] << 16);
		} else {
			resultLength = 0x10000;
		}
		if (this.offset > this.b.length + 1) // too many bytes
			throw locale.format(module, "tooManyCopy");
		tracer.debug && tracer.debug("Copy offset " + resultOffset + " length " + resultLength);

	} else { // insert instruction
		sourceBuffer = this.b;
		resultOffset = this.offset;
		this.offset += type;
		resultLength = type;
		if (this.offset > this.b.length + 1) // too many bytes
			throw locale.format(module, "tooManyInsert");
		tracer.debug && tracer.debug("Insert offset " + resultOffset + " length " + resultLength);
	}
	sourceBuffer.copy(this.destBuf, this.targetOffset, resultOffset, resultOffset + resultLength);
	this.targetOffset += resultLength;
	return true;
};

BinBuffer.prototype.transform = function(targetDirectory, file_from, file_to, sha1_from, sha1_to, checksums, _) {
	this.offset = 0; // offset of instruction buffer
	this.targetOffset = 0; // offset of target buffer
	var sourceLen = this.readLength();
	var destLen = this.readLength();
	this.sourceBuf = fs.readFile(targetDirectory + "/" + file_from, _);
	if (sourceLen !== this.sourceBuf.length) throw locale.format(module, "wrongLength", file_from, sourceLen, this.sourceBuf.len);
	if (!patchtools.check_sha1_binary(this.sourceBuf, sha1_from)) throw locale.format(module, "wrongChecksum", file_from);
	this.destBuf = new Buffer(destLen);
	// perform insert/copy instructions
	while (this.readInstruction()) {}
	if (destLen !== this.targetOffset) throw locale.format(module, "wrongLength", file_to, destLen, this.targetOffset);
	if (!patchtools.check_sha1_binary(this.destBuf, sha1_to)) throw locale.format(module, "wrongChecksum", file_to);
	patchtools.writeFile(targetDirectory + "/" + file_to, this.destBuf, _);
	checksums[path.dirname(file_to)][path.basename(file_to)] = "F " + sha1_to;
};

function _decode85(line, buffer, bufferoffset) {
	// first character is length of bytes
	var len = line.charCodeAt(0) - 64;
	if (len > 32) len -= 6;
	// deciphering base85
	var i, code, decode, number;
	number = 0;
	for (i = 1; i < line.length; i++) {
		var code = line.charCodeAt(i);
		if (code >= d85.length || (decode = d85[code]) === 0) throw locale.format(module, "invalidChar", code, line);
		number = 85 * number + decode - 1;
		if (i % 5 === 0) {
			var transfer = len > 4 ? 4 : len;
			len -= transfer;
			if (transfer < 4) {
				number >>>= (32 - 8 * transfer);
			}
			for (var j = transfer - 1; j >= 0; j--) {
				buffer[bufferoffset + j] = number % 256;
				number >>>= 8;
			}
			bufferoffset += transfer;
			if (len === 0) return bufferoffset;
		}
	}
	throw locale.format(module, "tooShort", line);
}

/// reads lines in binary GIT patch format
/// result: object with i: index in lines array after last content line, buffer: buffer with data

function _readBinary(lines, i, read, _) {
	// find out length of base85 decoded data
	var len = 0;
	var j = i;
	var literal = false;
	var fullLength = 0;
	var r;
	if (r = /^(literal|delta) (\d+)/.exec(lines[j])) {
		if (r[1] === "literal") literal = true;
		fullLength = r[2];
	} else {
		if (read) throw locale.format(module, "wrongDescBinary", lines[j]);
		else {
			var result = {
				i: j
			};
			return result;
		}
	}
	j++;
	i++;
	// all but last line have maximal length 52 and start with 'z'
	while (j < lines.length && lines[j].substr(0, 1) === 'z') {
		len += 52;
		j++;
	}
	// last line may be shorter
	if (j < lines.length && lines[j].match(/^[A-Za-y]\S+$/)) {
		var lastLength = lines[j].charCodeAt(0) - 64;
		if (lastLength > 32) lastLength -= 6;
		len += lastLength;
		j++;
	}
	if (!read) {
		var result = {
			i: j,
			literal: literal
		};
		return result;
	}

	var zipBuffer = new Buffer(len);
	var bufferoffset = 0;
	while (i < j) {
		bufferoffset = _decode85(lines[i], zipBuffer, bufferoffset);
		i++;
	}
	var buffer;
	buffer = zlib.inflate(zipBuffer, _);
	if (buffer.length - fullLength != 0) throw locale.format(module, "wrongLengthInflate", buffer.length, fullLength);
	var result = {
		i: j,
		buffer: buffer,
		literal: literal
	};
	return result;
}

/// write target text file

function _write_data(targetDirectory, status, file_from, file_to, sha1_to, file_lines, checksums, access_rights, _) {
	if ((status & LOADED) != 0) {
		if (file_from && file_from !== file_to) {
			fs.unlink(targetDirectory + "/" + file_from, _);
			delete checksums[path.dirname(file_from)][path.basename(file_from)];
		}
		var buffer = new Buffer(file_lines.join("\n"), "utf8");
		var sha1 = patchtools.get_sha1_binary(buffer);
		if (!patchtools.equal_sha1(sha1, sha1_to)) {
			tracer.error && tracer.error("Wrong check sum for " + file_to + " expected " + sha1_to);
			throw new Error(locale.format(module, "wrongChecksum", file_to));
		}
		tracer.info && tracer.info("Write file " + targetDirectory + "/" + file_to + " access rights " + access_rights);
		patchtools.writeFile(targetDirectory + "/" + file_to, buffer, _);
		fs.chmod(targetDirectory + "/" + file_to, patchtools.elevate(access_rights), _);
		checksums[path.dirname(file_to)][path.basename(file_to)] = "F " + sha1;
	} else if ((status & DIFF_ENTRIES) != 0 && file_from && file_from !== file_to) {
		// just renaming
		fs.rename(targetDirectory + "/" + file_from, targetDirectory + "/" + file_to, _);
		checksums[path.dirname(file_to)][path.basename(file_to)] = checksums[path.dirname(file_from)][path.basename(file_from)];
		delete checksums[path.dirname(file_from)][path.basename(file_from)];
	}
	status = 0;
}

// checks whether the current version of the installation matches the patch file, and copies contents to the temp directory

function _checkVersions(parts, _, lastHash) {
	var oldRelNumber = parts[2];
	var oldPatchNumber = parts[3];
	var newDate = parts[4];
	var newRelNumber = parts[5];
	var newPatchNumber = parts[6];
	var oldHash = parts[7];
	var newHash = parts[8];
	var baseDir = patchtools.BASE_DIRECTORY;
	tracer.info && tracer.info("checkVersions: Data: oldHash " + oldHash + " old release number " + oldRelNumber + " new hash " + newHash + " new release number " + newRelNumber);
	// consistency checks
	var versionInformation = {};
	// check whether there is release directory
	if (!patchtools.exists(patchtools.BASE_DIRECTORY + "/" + patchtools.RELEASE_DIRECTORY, _)) {
		tracer.warn && tracer.warn("No release directory available");
		versionInformation = patchtools.readVersionFile(patchtools.BASE_DIRECTORY, _);
		if (!versionInformation.init) throw new Error(locale.format(module, "noRelease"));
		tracer.info && tracer.info("Copy recursive . to " + patchtools.RELEASE_DIRECTORY);
		patchtools.copyRec(patchtools.BASE_DIRECTORY, patchtools.BASE_DIRECTORY + "/" + patchtools.RELEASE_DIRECTORY, false, _);
		tracer.debug && tracer.debug("End copy recursive . to " + patchtools.RELEASE_DIRECTORY);
	} else {
		if (oldPatchNumber === "0") baseDir = patchtools.BASE_DIRECTORY + "/" + patchtools.RELEASE_DIRECTORY;
		versionInformation = patchtools.readVersionFile(baseDir, _);
	}
	tracer.debug && tracer.debug("Version information " + util.format(versionInformation));
	if (versionInformation.commit === lastHash) return null // patch already applied;
	if (versionInformation.commit !== oldHash) throw new Error(locale.format(module, "wrongBaseVersion", versionInformation.relNumber + "-" + versionInformation.patchNumber, versionInformation.comment, oldRelNumber + "-" + oldPatchNumber));
	versionInformation.init = false;
	versionInformation.commit = newHash;
	versionInformation.relNumber = newRelNumber;
	versionInformation.patchNumber = newPatchNumber;
	versionInformation.src = parts[9]; // commit of source repository
	// copy everything into temporary directory
	tracer.info && tracer.info("Fast copy recursive " + baseDir + " to " + patchtools.TEMP_DIRECTORY);
	try {
		patchtools.copyRec(baseDir, patchtools.BASE_DIRECTORY + "/" + patchtools.TEMP_DIRECTORY, true, _);
		// copy nodelocal.js into temp directory
		var buf = fs.readFile("nodelocal.js", _);
		patchtools.writeFile(patchtools.BASE_DIRECTORY + "/" + patchtools.TEMP_DIRECTORY + "/nodelocal.js", buf, _);

	} catch (e) { // errors in fast copy: check base directory 
		tracer.error && tracer.error("Error in fast copy", e);
		var errors = patchtools.checkChecksumsV(baseDir, _);
		if (errors.length > 0) {
			tracer.error && tracer.error("Errors in checkChecksumsV " + errors.join(", "));
			throw new Error(locale.format(module, "invalidBaseDirectory", baseDir));
		}
		// base directory OK. Therefore full copy
		tracer.info && tracer.info("Full copy recursive " + baseDir + " to " + patchtools.TEMP_DIRECTORY);
		patchtools.copyRec(baseDir, patchtools.BASE_DIRECTORY + "/" + patchtools.TEMP_DIRECTORY, false, _);
	}
	if (!newPatchNumber) { // extra check when installing new release
		errors = patchtools.checkChecksumsV(patchtools.BASE_DIRECTORY + "/" + patchtools.TEMP_DIRECTORY, _);
		if (errors.length > 0) {
			tracer.error && tracer.error("Check temp directory " + errors.join(";"));
			throw new Error(locale.format(module, "inconsistenciesTemp"));
		}
	}
	tracer.debug && tracer.debug("End checkVersion " + util.format(versionInformation));
	return versionInformation;
}

function getMetaData(contents) {
	var startIndex = contents.indexOf('syracuse patch ');
	if (startIndex === 0 || contents.charAt(startIndex - 1) === '\n') {
		var endIndex = contents.indexOf('\n', startIndex);
		if (endIndex >= 0) {
			var result = contents.substring(startIndex + 15, endIndex);
			startIndex = contents.indexOf('\nsyracuse patch ', startIndex + 1);
			if (startIndex > 0) {
				endIndex = contents.indexOf('\n', startIndex + 2);
				if (endIndex > 0) {
					tracer.debug && tracer.debug("ST " + startIndex + " E " + endIndex + " StS <<<" + contents.substring(startIndex + 16, endIndex) + ">>>");
					var parts1 = result.split(/ +/);
					var parts2 = contents.substring(startIndex + 16, endIndex).split(/ +/);
					parts2[0] = parts1[0];
					parts2[1] = parts1[1];
					parts2[5] = parts1[5];
					return parts2.join(" ");
				}
			}

			return result;
		}
	}
	return null;
}

// for unit tests
exports.getMetaData = getMetaData;

/// ------------
/// ## Patch integration in a cluster
/// Arguments: filename on the computer which receives the patch: name of file or directory with patches. Is empty on servers which just get the contents from another server 
///            contents: contents of the patch

function clusterPatch(filename, contents, options, _) {
	tracer.info && tracer.info("============= PATCH =================");
	// find out current versions
	tracer.info && tracer.info("Base directory " + patchtools.BASE_DIRECTORY);
	try {
		fs.mkdir(patchtools.BASE_DIRECTORY + "/" + patchtools.TEMP_DIRECTORY, _);
	} catch (e) {} // ignore
	var integratePatch = true;
	var currentVersion = patchtools.readVersionFile(patchtools.BASE_DIRECTORY, _);
	var releaseVersion;
	var markIntegration = false; // write into database that new patch is in temp directory
	try {
		releaseVersion = patchtools.readVersionFile(patchtools.BASE_DIRECTORY + "/" + patchtools.RELEASE_DIRECTORY, _);
	} catch (e) {
		tracer.error && tracer.error("release directory version file", e);
		releaseVersion = currentVersion;
	}

	tracer.debug && tracer.debug("Current version " + util.format(currentVersion) + ". Release version " + util.format(releaseVersion));
	if (filename) {
		// preparation of patch files
		contents = collectFiles(patchtools.BASE_DIRECTORY, filename, currentVersion.commit, releaseVersion.commit, _, contents);
		// error or patch already integrated
		if (!contents) return contents;
	}

	var serverCount = 0; // number of servers on which a patch can be integrated
	if (config.mockServer) {
		var opt = {
			path: "/nannyCommand/infojson",
			method: "GET"
		};
		try {
			var text = mock.simpleRequest(config.mockServer.mockClient, opt, null, _);
			var clusterData = JSON.parse(text);
			clusterData.forEach(function(host) {
				if (host.status >= 3) serverCount++;
			});
		} catch (e) {
			tracer.error && tracer.error("Error in infojson", e);
		}
	}
	var notificationFuture; // notification request to other servers
	var patchMetaData = getMetaData(contents);
	var metadataParts = patchMetaData.split(" ");
	if (!filename || serverCount > 1) { // patch has to be integrated on several hosts
		var data = {
			patch: patchMetaData
		};
		var time = ballot.writeVote(null, data, _);
		if (filename) { // notify other servers
			var opt = {
				path: "/nannyCommand/notifyOtherNannies/notifyOne/patch/integration",
				method: "PUT",
				timeout: PATCH_INTEGRATION_TIMEOUT
			};
			// start notification as a future
			notificationFuture = mock.simpleRequest(config.mockServer.mockClient, opt, contents, !_);
		}
		ballot.wait(1000, _);
		var firstServer = ballot.readVotes(data, time, _);
		if (firstServer !== os.hostname()) {
			integratePatch = false;
			markIntegration = true;
			tracer.info && tracer.info("No patch integration: different host is first " + firstServer);
		} else {
			var tempVersion = patchtools.readVersionFile(patchtools.BASE_DIRECTORY + '/' + patchtools.TEMP_DIRECTORY, _);
			tracer.debug && tracer.debug("Meta data parts " + patchMetaData + " " + util.format(metadataParts));
			if (tempVersion.commit === metadataParts[6]) { // patch already integrated
				integratePatch = false;
				markIntegration = true;
				tracer.warn && tracer.warn("Patch already integrated in temp directory");
			}
		}
	}
	if (integratePatch) {
		options.content = true;
		normalPatch(patchtools.BASE_DIRECTORY, contents, options, _, metadataParts);
	}
	if (integratePatch || markIntegration) { // write into database that new patch has been integrated in temp directory
		var db = adminHelper.getCollaborationOrm(_);
		var hostData = db.fetchInstance(_, db.model.getEntity(_, "host"), {
			hostname: os.hostname()
		});
		hostData.patchStatus(_, metadataParts[3] + "." + metadataParts[4]);
		hostData.syracuseNoNotifyMarker = true; // do not notify other hosts about this change 
		hostData.save(_);
	}
	// wait for other servers
	if (notificationFuture) {
		try {
			notificationFuture(_);
		} catch (e) {
			tracer.error && tracer.error("Error in notification", e);
		}
	}
	if (filename && (integratePatch || markIntegration)) {
		// notify servers that server is about to stop
		require('../../../src/session/dispatcher').notifyEnd(_);
		if (config.mockServer) {
			var options = {
				path: "/nannyCommand/notifyNannies/stopSessions",
				method: "PUT",
				headers: {}
			};
			options.headers[mock.BALANCER_HEADER] = config.port;
			try {
				tracer.info && tracer.info("Sent stop sessions request");
				var res = mock.simpleRequest(config.mockServer.mockClient, options, null, _);
				tracer.debug && tracer.debug("Finish stop sessions request " + res);
			} catch (e) {
				tracer.error && tracer.error("Error during stopSessions", e);
			}
		}
	}
	return 1;
}

exports.clusterPatch = clusterPatch;

// returns true if patch file header fits the requirements
exports.testPatchHeader = function(content) {
	if (content.substr(0, 2) === "1,") {
		if (content.split(",")[5] !== '"Syracuse"') return false;
	}
	return true;
};

// integration in batch mode without load balancer (for cloud)
// parameters: filename: name of file or directory
// result: 0 patch correctly integrated
//         10 patch already integrated
//         Error: integration not possible
exports.batchIntegration = function(_, filename) {
	if (!filename) throw new Error(locale.format(module, "noPatchFile"));
	var currentVersion = patchtools.readVersionFile(patchtools.BASE_DIRECTORY, _);
	var releaseVersion;
	try {
		releaseVersion = patchtools.readVersionFile(patchtools.BASE_DIRECTORY + "/" + patchtools.RELEASE_DIRECTORY, _);
	} catch (e) {
		tracer.error && tracer.error("release directory version file", e);
		releaseVersion = currentVersion;
	}
	var contents = collectFiles(patchtools.BASE_DIRECTORY, filename, currentVersion.commit, releaseVersion.commit, _);
	if (!contents) {
		tracer.warn && tracer.warn(locale.format(module, "integrated"));
		return 10;
	}
	var res = normalPatch(patchtools.BASE_DIRECTORY + "/" + patchtools.TEMP_DIRECTORY, contents, {
		content: true,
		tryagain: true
	}, _);
	return 0;
};


// combine a set of patch files to a single patch file which is suitable for the current version or release

function collectFiles(targetDirectory, filename, currentVersion, currentRelease, _, content) {
	// one or more patch files
	var patchfiles;
	if (!content) {
		if (fs.stat(filename, _).isDirectory()) {
			var files = fs.readdir(filename, _);
			patchfiles = [];
			files.forEach(function(file) {
				if (file.lastIndexOf('.dat') === file.length - 4) {
					patchfiles.push(filename + "/" + file);
				}
			});
		} else {
			patchfiles = [filename];
		}
	}
	// copy interesting parts together
	var patchContents = {};
	var currentVersionFits = false;
	var currentReleaseFits = false;
	var currentVersionFitsEnd = false;
	var contentAvailable = false;
	var j = content ? 1 : patchfiles.length;
	while (--j >= 0) {
		var startIndex = 0;
		var metadata = [];
		var lines;
		if (content) {
			lines = content.split(/[\n\r]+/);
		} else {
			var file = patchfiles[j];
			tracer.debug && tracer.debug("Patch file " + file);
			var lines = fs.readFile(file, 'utf8', _).split(/[\n\r]+/);
			// test for Syracuse patch
			if (!exports.testPatchHeader(lines[0]))
				throw new Error(locale.format(module, "noSyraPatch"));
		}
		var startContent = 2;
		for (var i = 0; i < lines.length; i++) {
			var line = lines[i];
			if (line.substr(0, 8) === '2,"ASR",') {
				if (metadata.length > 7) {
					metadata[9] = lines.slice(startIndex + startContent, i).join("\n");
					patchContents[metadata[5]] = metadata;
					metadata = [];
				}
				startIndex = i + 1;
				continue;
			}
			if (line.substr(0, 15) === 'syracuse patch ') {
				contentAvailable = true;
				if (metadata.length > 7) {
					metadata[9] = lines.slice(startIndex + startContent, i).join("\n");
					patchContents[metadata[5]] = metadata;
					metadata = [];
				}
				startIndex = i;
				startContent = 2;

				// metadata parts: 0 start release, 1 start patch number, 2 date, 3 end release, 4 end patch number, 5 start hash, 6 end hash, 7 end source hash, 8 comment, 9 patch content, 10 streamline configuration
				metadata = line.substr(15).split(" ");
				tracer.debug && tracer.debug("Syracuse patch " + line.substr(15) + " metadata " + util.format(metadata) + " current " + currentVersion + " " + currentRelease);
				if (metadata[5] === currentVersion) currentVersionFits = true;
				if (metadata[5] === currentRelease) currentReleaseFits = true;
				if (metadata[6] === currentVersion) currentVersionFitsEnd = true;
				continue;
			};
			if (i === startIndex + 1 && line.substr(0, 22) === 'syracuse patchcomment ') metadata[8] = line;
			if (i === startIndex + 2 && line.substr(0, 20) === 'syracuse streamline ') {
				startContent = 3;
				metadata[10] = line;
				continue;
			}
			if (line.substr(0, 8) === '7,"ASR",') {
				// end of Syracuse patch section
				if (metadata.length > 7) {
					metadata[9] = lines.slice(startIndex + startContent, i).join("\n");
					patchContents[metadata[5]] = metadata;
					metadata = [];
				}
				continue;
			}
		}
		/*		if (metadata.length > 7) {
			metadata[9] = lines.slice(startIndex + startContent, i).join("\n");
			patchContents[metadata[5]] = metadata;
			metadata = [];
		}
		*/
		if (metadata.length > 7) { // no surrounding elements but Syracuse data
			var endIndex = lines.length;
			if (lines[endIndex - 1] === '') endIndex--;
			metadata[9] = lines.slice(startIndex + startContent, endIndex).join("\n");
			patchContents[metadata[5]] = metadata;
		}
	};
	tracer.debug && tracer.debug("cont" + contentAvailable + "curr vers fits " + currentVersionFits + " curr release fits " + currentReleaseFits + " curr vers fits end " + currentVersionFitsEnd);
	if (!contentAvailable) throw new Error(locale.format(module, "noContent"));
	var startVersion = (currentVersionFits ? currentVersion : (currentReleaseFits ? currentRelease : null));
	tracer.info && tracer.info("Start version " + startVersion);
	if (!startVersion) {
		if (currentVersionFitsEnd) return ""; // no patch integration necessary
		// patch does not fit to current version
		throw new Error(locale.format(module, "baseVersionMismatch"));
	}
	tracer.debug && tracer.debug("Patch contents " + util.format(patchContents));
	var versions = [startVersion];
	var lastStartVersion = startVersion;
	var lastVersion = startVersion;
	var lastReleaseMetadata;
	var lastMetadata = patchContents[startVersion];
	metadata = lastMetadata;
	if (lastStartVersion in patchContents) {
		while ((lastVersion = lastMetadata[6]) in patchContents) {
			lastStartVersion = lastVersion;
			if (lastMetadata[4] === "0") { // patch is for new release
				lastReleaseMetadata = lastMetadata;
			}
			lastMetadata = patchContents[lastVersion];
		}
	}
	if (lastVersion === currentVersion) return ""; // patch already integrated
	// write final file
	// var metadata = patchContents[startVersion];
	// find out whether there is a release change
	// here metadata contains the metadata of the first patch content, currentContent the metadata of the latest patch content
	if (metadata[0] !== lastMetadata[3] && lastMetadata[4] > 0) { // patch from one release to patchlevel > 0 of another release
		if (!lastReleaseMetadata || lastReleaseMetadata[3] !== lastMetadata[3]) throw new Error("No patch ending in current release");
		lastMetadata = lastReleaseMetadata;
	} else lastReleaseMetadata = null;
	var finalResult = "";
	while (lastMetadata) {
		var header = "syracuse patch " + metadata[0] + " " + metadata[1] + " ";
		header += lastMetadata[2] + " " + lastMetadata[3] + " " + lastMetadata[4] + " " + metadata[5] + " " + lastMetadata[6] + " " + lastMetadata[7];
		header += "\n" + lastMetadata[8] + "\n";
		var streamlineConfig = lastMetadata[10];
		var tempVersion = metadata[5];
		var result = "";
		while (tempVersion !== lastMetadata[6]) { // compare with end hash of latest version
			var currMetadata = patchContents[tempVersion];
			patchContents[tempVersion] = undefined; // these data are not longer necessary 
			if (currMetadata[10]) streamlineConfig = currMetadata[10];
			result += currMetadata[9] + "\n";
			tempVersion = currMetadata[6];
		}
		if (streamlineConfig) {
			header += streamlineConfig + "\n";
		}
		finalResult += (header + result);
		if (lastReleaseMetadata) {
			metadata = patchContents[lastMetadata[6]]; // metadata of patch starting at last release
			lastMetadata = patchContents[lastStartVersion];
			lastReleaseMetadata = null;
		} else lastMetadata = null;
	}
	tracer.debug && tracer.debug("FINAL " + finalResult);
	return finalResult;
}


// for unit tests
exports.collectFiles = collectFiles;


/// -------------
/// ## Patch integration function `patch`
/// integrate a Syracuse patch
/// Parameters:
/// - targetDirectory: directory in which the file changes should take place
/// - patchdata: name of patch file (may only contain a single Syracuse patch) or contents of patch (when option 'content' is set)
/// - options: tryagain: make full copy if there are errors during patch integration; restart: restart node after integrating the patch; content: patch contents are given
/// - metadataParts: optional: start and end version of patch as returned by getMetaData() and splitting into parts
///
/// Result: empty object: patch could be applied, no further action
///         object with versionerror: patch cannot be applied due to version issues; versionerror===null: patch already applied; other values: errors when checking versions
///         object with kill: kill node and execute the contained function

function normalPatch(targetDirectory, patchdata, options, _, metadataParts) {
	tracer.info && tracer.info("============= PATCH =================");
	var lines = (options.content ? patchdata : fs.readFile(patchdata, 'utf8', _)).split(/[\n\r]+/);
	if (options.tryagain) {
		try {
			return _patchIntern(targetDirectory, lines, options, _, metadataParts);
		} catch (e) {
			tracer.error && tracer.error("Exception when integrating patch", e);
			// exception when integrating patch: maybe temp directory is corrupt. Full copy
			var errors = patchtools.checkChecksumsV(".", _);
			var baseDirectory = ".";
			if (errors.length > 0) {
				tracer.warn && tracer.warn("Check checksums: " + util.format(errors));
				errors = patchtools.checkChecksumsV(patchtools.RELEASE_DIRECTORY, _);
				if (errors.length === 0) baseDirectory = patchtools.RELEASE_DIRECTORY;
				else {
					tracer.error && tracer.error("Error during check checksums in release directory: " + util.format(errors));
					throw new Error(locale.format(module, "corruptDirectories"));
				}
			}
			tracer.info && tracer.info("Second attempt after full copying directory " + baseDirectory + " into temp directory");
			patchtools.copyRec(baseDirectory, patchtools.BASE_DIRECTORY + "/" + patchtools.TEMP_DIRECTORY, false, _);
		}
	}
	return _patchIntern(targetDirectory, lines, options, _, metadataParts);
}

// internal function to integrate a patch

function _patchIntern(targetDirectory, lines, options, _, metadataParts) {
	var i;
	var file_from;
	var file_to;
	var sha1_from;
	var sha1_to;
	var status = 0x0; // bits: 1: care about diff entries, 2: input file already loaded, 4: binary content, 8: no line feed at end
	var file_lines;
	var access_rights;
	var checksums = {};
	var versionInformation = null;
	var streamlineConfig;
	var patchOccurred = false;
	for (i = 0; i < lines.length; i++) {
		var line = lines[i];
		if (line.substr(0, 9) === "syracuse ") { // patch meta information
			var parts = line.split(/\s+/);
			tracer.debug && tracer.debug("Patch meta information " + util.format(parts));

			if (parts[1] === "patch") {
				var special = patchtools.BASE_DIRECTORY + "/" + patchtools.TEMP_DIRECTORY + "/" + patchtools.SPECIAL_DIRECTORY;
				if (patchOccurred) {
					// copy current contents into special directory
					tracer.info && tracer.info("Write checksums and version file");
					_lastActions(targetDirectory, status, file_from, file_to, sha1_to, file_lines, checksums, access_rights, versionInformation, _);
					tracer.info && tracer.info("Copy current version into special directory");
					patchtools.copyRec(patchtools.BASE_DIRECTORY + "/" + patchtools.TEMP_DIRECTORY, special, false, _);
					versionInformation.commit = parts[8];
					versionInformation.relNumber = parts[5];
					versionInformation.patchNumber = parts[6];
					versionInformation.src = parts[9]; // commit of source repository
				} else {
					patchOccurred = true;
					try {
						patchtools.rmdirRec(special, _);
					} catch (e) {
						tracer.error && tracer.error("Remove special directory", e);
					}
					if (!metadataParts) {
						metadataParts = parts.slice(2);
					}
					tracer.debug && tracer.debug("Before checkVersions " + util.format(parts) + " metadata " + util.format(metadataParts));
					versionInformation = _checkVersions(parts, _, metadataParts[6]);
					if (versionInformation === null) // patch already applied
						return {
						versionerror: null
					};
				}
				targetDirectory = patchtools.BASE_DIRECTORY + "/" + patchtools.TEMP_DIRECTORY;
				tracer.info && tracer.info("Set targetDirectory to " + targetDirectory);
			}
			if (versionInformation) {
				if (parts[1] === "patchcomment") versionInformation.comment = parts.slice(2).join(" ");
				if (parts[1] === "streamline") {
					var r = /\{.*\}/.exec(line);
					tracer.info && tracer.info("Streamline config change in " + line);
					if (r) {
						tracer.debug && tracer.debug("Streamline config change content " + r[0]);
						try {
							versionInformation.streamline = JSON.parse(r[0]);
						} catch (e) {
							tracer.error && tracer.error("Error during parsing streamline configuration", e);
						}
					}
				}

			}
		}
		var m;
		// start of diff
		if (line.substr(0, 5) === "FILE ") {
			_write_data(targetDirectory, status, file_from, file_to, sha1_to, file_lines, checksums, access_rights, _);
			m = /^FILE (\w) (\d+) \"(.*?)\" \"(.*?)\" (\w*)\-(\w*)/.exec(line);
			if (m) {
				sha1_from = m[5];
				sha1_to = m[6];
				file_from = m[3];
				file_to = m[4] || file_from;
				status = DIFF_ENTRIES;
				if (m[1] === "N") {
					file_from = "";
					file_lines = [];
					status |= LOADED;
				}
				// get access rights of original file
				if (file_from) {
					try {
						var stats = fs.stat(targetDirectory + "/" + file_from, _);
						access_rights = (stats.mode * 1 & 0xFFF).toString(8);
					} catch (e) {
						access_rights = m[2];
					}
				} else {
					access_rights = m[2];
				}
				if (status) {
					var parent = path.dirname(file_from);
					if (!(parent in checksums)) checksums[parent] = patchtools.getChecksumContent(targetDirectory, parent, _);
					parent = path.dirname(file_to);
					if (checksums && !(parent in checksums)) checksums[parent] = patchtools.getChecksumContent(targetDirectory, parent, _);
				}
				if (m[1] === "D") {
					patchtools.deleteFileDir(targetDirectory, file_from, checksums, _);
					status = 0;
				}
			}
			continue;
		}
		if (line.substr(0, 8) === "literal " || line.substr(0, 6) === "delta ") {
			var res = _readBinary(lines, i, status !== 0, _);
			i = res.i;
			// end
			if (status) {
				if (res.literal) {
					if (!patchtools.check_sha1_binary(res.buffer, sha1_to)) throw locale.format(module, "wrongChecksum", file_to);
					patchtools.writeFile(targetDirectory + "/" + file_to, res.buffer, _);
					checksums[path.dirname(file_to)][path.basename(file_to)] = "F " + sha1_to;
				} else {
					// apply changes
					var binBuffer = new BinBuffer(res.buffer, file_from);
					binBuffer.transform(targetDirectory, file_from, file_to, sha1_from, sha1_to, checksums, _);
				}
				fs.chmod(targetDirectory + "/" + file_to, access_rights, _);
				tracer.info && tracer.info("Write binary file " + file_to + " access rights " + access_rights);
			}
			// optional information for undoing the patch (not used)
			res = _readBinary(lines, i, false, _);
			i = res.i;
			status = 0;
			i--;
			continue;
		}

		// diff area
		if (m = /^\@\@ \-\d+(?:,(\d+))? +\+(\d+)(?:,(\d+))?(\!)?/.exec(line)) {
			// read input file unless read
			if ((status & (DIFF_ENTRIES + LOADED)) === DIFF_ENTRIES) {
				if (!patchtools.equal_sha1(checksums[path.dirname(file_from)][path.basename(file_from)], sha1_from)) throw new Error(locale.format(module, "wrongChecksum", file_from));
				file_lines = fs.readFile(targetDirectory + "/" + file_from, 'utf8', _).split(/(?:\r\n|\r|\n)/);
				status |= LOADED;
			}
			// lines count from 1, index counts from 0
			var cur_line = m[2] - 1;
			var remainingExistingLines = (m[1] === undefined ? 1 : 1 * m[1]);
			var remainingTargetLines = (m[3] === undefined ? 1 : 1 * m[3]);
			if (remainingTargetLines == 0) cur_line++;
			if (m[4] && remainingExistingLines > 0) { // in compressed patch format there are no deleted lines
				// remove these lines
				file_lines.splice(cur_line, remainingExistingLines);
				remainingExistingLines = 0;
			}
			i++;
			var partialLine = "";
			while (i < lines.length && (remainingExistingLines > 0 || remainingTargetLines > 0) && (m = /^([\\ \-\+\=])/.exec(lines[i]))) {
				if (!(status & DIFF_ENTRIES)) break;
				line = lines[i].substr(1);
				switch (m[1]) {
					case ' ':
						// just test current line
						remainingExistingLines--;
						remainingTargetLines--;
						if (remainingExistingLines < 0 || remainingTargetLines < 0) {
							tracer.error && tracer.error("Too many lines in diff area at " + lines[i]);
							status = 0;
						} else if (line !== file_lines[cur_line]) {
							tracer.error && tracer.error("Line mismatch: >" + line + "< expected: >" + file_lines[cur_line] + "<");
							status = 0;
						}
						cur_line++;
						break;
					case '=':
						// part of long line
						partialLine += line;
						break;
					case '+':
						// insert line at current position
						remainingTargetLines--;
						if (remainingExistingLines < 0) {
							tracer.error && tracer.error("+ Too many lines deleted at " + lines[i]);
							status = 0;
						} else {
							file_lines.splice(cur_line++, 0, partialLine + line);
							partialLine = "";
						}
						// check for line break
						var next_line = lines[i + 1];
						if (next_line.substr(0, 1) !== '+') {
							if (next_line.substr(0, 12) === "\\ No newline") { // no new line at end of appended block
								if (file_lines.length === cur_line + 1 && file_lines[cur_line] === '') file_lines.pop();
							} else {
								if (file_lines.length === cur_line) file_lines.push('');
							}
						}
						// maybe 
						break;
					case '-':
						// delete line at current position
						remainingExistingLines--;
						if (remainingExistingLines < 0) {
							tracer.error && tracer.error("- Too many lines deleted at " + i + " " + lines[i]);
							status = 0;
						} else if (line !== file_lines[cur_line]) {
							tracer.error && tracer.error("- Line mismatch: >" + line + "< expected: >" + file_lines[cur_line] + "<");
							status = 0;
						} else {
							file_lines.splice(cur_line, 1);
						}
						break;
					case '\\':
						// no new line
						break;
				}
				if (remainingExistingLines < 0 || remainingTargetLines < 0) {
					tracer.error && tracer.error("Too many lines");
					status = 0;
				}
				i++;
			}
			i--;
			continue;
		}
		// this code is here just for compatibility and to run old unit tests. This enables the module to read git diff output directly
		if (line.substr(0, 10) === 'diff --git') {
			_write_data(targetDirectory, status, file_from, file_to, sha1_to, file_lines, checksums, access_rights, _);
			if (m = /^diff --git a\/(.*) b\/\1$/.exec(line)) {
				file_from = m[1];
				file_to = m[1];
				sha1_from = "";
				sha1_to = "";
				status = DIFF_ENTRIES;
			} else if (m = /^diff --git a\/(\S+) b\/(\S+)$/.exec(line)) {
				file_from = m[1];
				file_to = m[2];
				sha1_from = "";
				sha1_to = "";
				status = DIFF_ENTRIES;
			} else {
				status = 0;
				tracer.error && tracer.error('wrong file names in ' + line);
			}
			if (status) {
				var parent = path.dirname(file_from);
				if (!(parent in checksums)) checksums[parent] = patchtools.getChecksumContent(targetDirectory, parent, _);
				parent = path.dirname(file_to);
				if (checksums && !(parent in checksums)) checksums[parent] = patchtools.getChecksumContent(targetDirectory, parent, _);
			}
			continue;
		}
		if (line.substr(0, 6) === 'index ') {
			var r = /^index ([0-9a-f]+)\.\.([0-9a-f]+)(?:\s+(\d+))?/.exec(lines[i]);
			if (r) {
				sha1_from = r[1];
				sha1_to = r[2];
				var tmp_rights = r[3] || "";
				access_rights = tmp_rights.substr(tmp_rights.length - 3);
				// console.log("SHA1 "+sha1_from+" "+sha1_to);
			} else {
				status = 0;
				tracer.error && tracer.error('no index available for ' + file_from);
			}
		}
		if (line.substr(0, 8) === 'new file') {
			file_from = "";
			file_lines = [];
			status |= LOADED;
			continue;
		}
		if (line.substr(0, 12) === 'deleted file') {
			patchtools.deleteFileDir(targetDirectory, file_from, checksums, _);
			status = 0;
			continue;
		}
		if (line.substr(0, 3) === '+++' || line.substr(0, 3) === '---' || /^(?:copy|rename|GIT binary) /.exec(line)) continue;
	}
	_lastActions(targetDirectory, status, file_from, file_to, sha1_to, file_lines, checksums, access_rights, versionInformation, _);
	return {};
}

function _lastActions(targetDirectory, status, file_from, file_to, sha1_to, file_lines, checksums, access_rights, versionInformation, _) {
	_write_data(targetDirectory, status, file_from, file_to, sha1_to, file_lines, checksums, access_rights, _);
	if (patchtools.exists(patchtools.EXTRA_FUNCTIONS, _)) {
		tracer.info && tracer.info("Copy " + patchtools.EXTRA_FUNCTIONS + " to " + targetDirectory + "/" + patchtools.EXTRA_FUNCTIONS_OLD);
		var extraOld = fs.readFile(patchtools.EXTRA_FUNCTIONS, _);
		patchtools.writeFile(targetDirectory + "/" + patchtools.EXTRA_FUNCTIONS_OLD, extraOld, _);
		// update checksum for copy of extra.fkt
		if (!("." in checksums)) checksums["."] = patchtools.getChecksumContent(targetDirectory, ".", _);
		checksums["."][patchtools.EXTRA_FUNCTIONS_OLD] = "F " + patchtools.get_sha1_binary(extraOld);
	}
	var sha1 = patchtools.updateChecksums(targetDirectory, checksums, _);
	if (versionInformation) {
		versionInformation.sha1 = sha1;
		// write new version information
		tracer.debug && tracer.debug("Write version information " + JSON.stringify(versionInformation));
		if (!versionInformation.streamline) {
			// get streamline information from old version file
			try {
				var oldVersionContent = fs.readFile(patchtools.BASE_DIRECTORY + "/" + patchtools.TEMP_DIRECTORY + "/" + patchtools.VERSION_FILE, _, "utf8");
				versionInformation.streamline = JSON.parse(oldVersionContent).streamline;
			} catch (e) {
				tracer.error && tracer.error("No version information available", e);
			}
		}
		patchtools.writeFile(patchtools.BASE_DIRECTORY + "/" + patchtools.TEMP_DIRECTORY + "/" + patchtools.VERSION_FILE, new Buffer(JSON.stringify(versionInformation)), _);
	}
}

exports.normalPatch = normalPatch;