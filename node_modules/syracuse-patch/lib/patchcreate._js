"use strict";

var child_process = require('child_process');
var util = require('util');
var fs = require('streamline-fs');
var path = require('path');
var os = require('os');
var transformModule = require('streamline/lib/compiler/compile').transformModule;
var encrypter;
try {
	var globalConfig = require(__dirname + "/../../../nodelocal").config;
} catch (e) {
	globalConfig = {};
}


var patchtools = require('./patchtools');
var relNumberCmp = patchtools.relNumberCmp;
var deepEqual = require('syracuse-load/lib/certTools').deepEqual;


/// !doc
/// # Patch creation  
/// ```javascript
/// var patchcreate = require('syracuse-patch/lib/patchcreate')  
/// ```
/// 

//sha1 hash of first commit of the Syracuse repository
var FIRST_COMMIT = '9c1bdb6f3144a8295416acb66197f1a99ce4d71e';
var CONFIG_FILE = "config.txt";

var logfile = os.tmpDir() + "/apatch.log";

var tracer = console.log;
var patchlogger = function(text) {
	fs.appendFileSync(logfile, JSON.stringify(new Date()) + text + "\n");
};

//markers for patch and release
var PATCH = "PATCH";
var RELEASE = "RELEASE";

/// returns array of all releases. If testRelease is given, it checks whether the value is contained 
/// in the list of releases. If not, an exception occurs
function _taglist(patchConfig, testRelease, _) {
	var tags = [];
	var tmptags = _execute(patchConfig.git + ' tag', patchConfig.rolloutRepo, _).trim().split(/[\r\n\s]+/);
	var found = !testRelease;
	var i = 0;
	while (i < tmptags.length) {
		var tag = tmptags[i++];
		if (/^T\d[\d\.]*$/.test(tag)) tags.push(tag.substr(1));
		if (!found && "T" + testRelease === tag) found = true;
	}
	if (!found) throw new Error("Release " + testRelease + " does not exist");
	tags = tags.sort(relNumberCmp);
	return tags;
}

/// automatic release number creation
function _automaticRelease(tags, pattern) {

}


/// -------------
/// ## Patch creation function `patch`
/// create a Syracuse patch
/// Parameters:
/// -  track: tracker function. If set, it can be used to show progress status to the user. It will be invoked with parameters:
///       phase, phaseDetail, progress (number between 0 and 100)
/// -  newPatch generate new patch from source repository into roll-out repository
/// -  startFromRelease output patch file should start from latest release rather than from latest patch
/// -  newRelease generate new release (implies newPatch)
/// -  relNumberNew number of new release (only necessary if newRelease is true). Release number must only consist of digits and dots and must be greater than previous release number
/// -  commitComment comment. This is obligatory if newPatch or newRelease is true. Otherwise the contents will override the comment of the latest patch/release (if set)
/// -  baseRelease  optional: number of release for which the action should be performed. Default is latest release
/// -  patchfile: path of patchfile which will be generated
/// -  sha1Old:  SHA1 hash of commit of base version of patch file in roll-out repository. Must not be set when new patch/release will be created. Will be set to hash of latest patch of base release or base release itself if empty. If it starts with 'V', a version (release and patch) will be expected, e. g. V5.1-5
/// -  sha1New:  SHA1 hash of commit of final version of patch file in roll-out repository. Must not be set when new patch/release will be created. Default: HEAD. If it starts with 'V', a version (release and patch) will be expected, e. g. V5.1-5
/// -  x3Information: include X3 header and footer for patches
/// -  checkSource: check whether source repository is clean (without uncommitted changes)
/// 
///   Remark: for each new patch/release there must be changes of the roll-out repository to commit, e. g. if a patch of just node.js should be delivered, there must be data to commit in the roll-out repository
///    (e. g. just stage the changes in node.js)
function createPatch(track, newPatch, startFromRelease, newRelease, relNumberNew, commitComment, baseRelease, patchfile, sha1Old, sha1New, x3Information, checkSource, _) {
	var stdlogger = tracer;
	tracer = patchlogger;
	try {
		if (!globalConfig || !globalConfig.patch) throw new Error("No patch without patch settings in global configuration object");
		if (!patchtools.exists(globalConfig.patch.rolloutRepo, _)) throw new Error("Roll-out repository path does not exist: " + globalConfig.patch.rolloutRepo);
		globalConfig.patch.git = globalConfig.patch.git || "git";
		if (globalConfig.patch.logfile) logfile = globalConfig.patch.logfile;
		if (logfile) {
			try {
				console.error("Delete log file " + logfile);
				fs.unlink(logfile, _);
			} catch (e) {}
		}
		if (globalConfig.patch.testMode) tracer("Test mode!!!");
		track && track("Init", "Adjust branch", 0);
		tracer("START PATCH newPatch " + newPatch + " startFromRelease " + startFromRelease + " newRelease " + newRelease + " relNumberNew " + relNumberNew + " commitComment " + commitComment + " baseRelease " + baseRelease + " sha1Old " + sha1Old + " sha1New " + sha1New + " patchfile " + patchfile);
		tracer("Rollout repository " + globalConfig.patch.rolloutRepo + " Customer image directory " + globalConfig.patch.customerImage);
		// get list of tags, select tags which start with 'R' and strip 'R'
		var tags = globalConfig.patch.testMode ? [] : _taglist(globalConfig.patch, baseRelease, _);
		tracer("releases " + util.format(tags));
		if (tags.length == 0) {
			if (!newRelease) throw new Error("No release data available. New release must be created");
			baseRelease = null;
		} else {
			if (!baseRelease) baseRelease = tags[tags.length - 1]; // latest release by default
		}
		if (sha1Old && sha1Old.substr(0, 1) === "V") {
			sha1Old = _getHashFromVersion(globalConfig, sha1Old.substr(1), _);
		}
		if (sha1New && sha1New.substr(0, 1) === "V") {
			sha1New = _getHashFromVersion(globalConfig, sha1New.substr(1), _);
		}
		if (newRelease) {
			if (!relNumberNew) throw new Error("Release number for new release must be provided");
			if (relNumberNew.indexOf('X') >= 0) {
				var data = patchtools.nextRelease(tags, relNumberNew);
				if (data[0]) baseRelease = data[0];
				relNumberNew = data[1];
			} else {
				if (!/^\d[\d\.]*$/.test(relNumberNew)) throw new Error("Release number can only consist of digits and dots " + relNumberNew);
			}
			if (baseRelease) {
				if (baseRelease !== tags[tags.length - 1]) throw new Error("For new release, base release must be latest release");
				if (relNumberCmp(relNumberNew, baseRelease) <= 0) throw new Error("For new release, number must be greater than number of base release " + baseRelease);
			}
			newPatch = true;
		}

		if (newPatch && (sha1Old || sha1New)) throw new Error("No explicit commit hashes when new patch/release is created");

		var latestSha1 = "HEAD";
		var currentBranchNo; // number of current branch before switching to new branch (stays undefined if there is no active branch)
		// switch roll-out repo to correct release. Branch name is R+(release number). Keep unstaged files.
		if (baseRelease) {
			var branches = _execute(globalConfig.patch.git + ' branch -v --no-abbrev', globalConfig.patch.rolloutRepo, _);
			if (newPatch) {
				// new patch: checkout relevant release
				var r = /(?:^|\r|\n)\*\s(\S+)/.exec(branches);
				if (r) {
					currentBranchNo = r[1];
				}
				if (!r || r[1] !== 'R' + baseRelease) { // not on correct branch
					_execute(globalConfig.patch.git + ' checkout R' + baseRelease, globalConfig.patch.rolloutRepo, _);
				}
			} else {
				// just get head commit of that release
				var reg = new RegExp("(?:^|\r|\n)\*?\s+R" + baseRelease.replace(/\./g, ".") + "\s+(\w+)");
				var r = new RegExp("(?:^|\\r|\\n)\\*?\\s+R" + baseRelease.replace(/\./g, ".") + "\\s+(\\w+)").exec(branches);
				if (r) latestSha1 = r[1];
				else throw new Error("Inconsistency. Base release not in " + branches);
			}
		}
		track && track("Init", "Read versions", 1);

		var baseVersion; // base version for patch file
		var latestPatch; // latest patch of roll-out repository for updating roll-out repository from source repository when a new version is created
		var targetVersion; // final version for patch file
		if (tags.length > 0) { // get log data from git
			if (sha1Old) {
				baseVersion = commitDataFromHash(sha1Old, globalConfig.patch, _);
			} else {
				var gitlog = new GitLog(globalConfig.patch, latestSha1);
				latestPatch = gitlog.next(false, _);
				if (!latestPatch) throw new Error("Inconsistency: Tags available but no release");
				if (startFromRelease) {
					if (newPatch) { // a new patch/release will be created. Then old version is latest already available release
						if (latestPatch.release) { // latest current patch is release
							baseVersion = latestPatch;
						} else baseVersion = gitlog.next(true, _);
					} else { // previous version is latest release before latest patch
						baseVersion = gitlog.next(true, _);
					}
				} else {
					if (newPatch) { // a new patch/release will be created. Then old version is latest already available patch/release
						baseVersion = latestPatch;
					} else { // set previous version which is patch/release before latest patch
						baseVersion = gitlog.next(false, _);
					}
				}
			}
		}
		tracer("Base version " + util.format(baseVersion));
		tracer("Latest patch " + util.format(latestPatch));
		var newStreamlineConfig;
		if (newPatch) { // collect data for new patch or release (newPatch will be set if newRelease is set)
			// configuration for copying contents to roll-out repository
			var contents = fs.readFile(__dirname + "/" + CONFIG_FILE, "utf8", _);
			var config = _readConfig(contents);
			// take rolloutRepo and streamline options from globalConfig so that globalConfig need not be passed to all functions
			config.rolloutRepo = globalConfig.patch.rolloutRepo;
			config.git = globalConfig.patch.git;
			config.streamline = config.streamline || globalConfig.streamline;
			globalConfig.patch.streamline = config.streamline; // for customer image
			config.track = track;
			config.checkSource = checkSource;
			tracer("-------------- Collect files for patch");
			track && track("Write to roll out repository", "", 2);
			if (!commitComment) {
				throw new Error("No comment provided");
			}
			if (newRelease && latestPatch) {
				// create new branch for new release
				_execute(globalConfig.patch.git + ' branch R' + relNumberNew, globalConfig.patch.rolloutRepo, _);
				_execute(globalConfig.patch.git + ' checkout R' + relNumberNew, globalConfig.patch.rolloutRepo, _);
			}
			if (!globalConfig.patch.testMode && checkSource && _execute('git status -s', patchtools.BASE_DIRECTORY, _)) throw new Error("No new patch with uncommitted changes in source tree");
			var sourceCommitOld = (latestPatch ? latestPatch.source : FIRST_COMMIT);
			var sourceCommitCurrent = _execute(globalConfig.patch.git + ' log -1 --pretty=format:%H', patchtools.BASE_DIRECTORY, _);
			if (!sourceCommitCurrent) throw new Error("No current commit in source repository");
			tracer && tracer("Old source commit " + sourceCommitOld + " current " + sourceCommitCurrent);
			// this may set config._syracuseConfigChanged
			_collect(sourceCommitOld, sourceCommitCurrent, config, _);
			if (config._streamlineConfigChanged) {
				tracer && tracer("Set new streamline configuration");
				newStreamlineConfig = config.streamline;
			}
			// add changes to staging area
			if (globalConfig.patch.testMode) return ""; // faster execution in test mode - just to show which files would be in rollout repository


			track && track("Commit changes", "git add", 40);
			_execute(globalConfig.patch.git + ' add --all .', globalConfig.patch.rolloutRepo, _);
			// commit data
			var comment = [];
			if (newRelease) {
				comment.push(relNumberNew);
				comment.push("0"); // patch number 0 for new release
			} else {
				comment.push(baseRelease);
				comment.push(1 * latestPatch.patchNumber + 1);
			}
			comment.push(sourceCommitCurrent);
			// for future use
			comment.push("-");
			// add real comment
			comment.push(commitComment);

			var commentString = comment.join(" ");
			commentString = commentString.replace(/\"/g, "'"); // replace quotation marks
			// commit the changes
			track && track("Commit changes", globalConfig.patch.git + " commit", 50);
			try {
				_execute(globalConfig.patch.git + ' commit --no-status -q -m "' + commentString + '"', globalConfig.patch.rolloutRepo, _);
			} catch (e) {
				var status = _execute(globalConfig.patch.git + ' status --porcelain', globalConfig.patch.rolloutRepo, _);
				if (!status) {
					if (currentBranchNo && latestPatch && newRelease) { // delete newly created branch
						_execute(globalConfig.patch.git + ' checkout ' + currentBranchNo, globalConfig.patch.rolloutRepo, _);
						_execute(globalConfig.patch.git + ' branch -d R' + relNumberNew, globalConfig.patch.rolloutRepo, _);
					}
					throw new Error("No changes in roll-out repository");
				}
				throw new Error("Changes cannot be committed: " + e);
			}
			if (newRelease) {
				if (!latestPatch) {
					// create new branch
					_execute(globalConfig.patch.git + ' branch R' + relNumberNew, globalConfig.patch.rolloutRepo, _);
				}
				// create tag
				_execute(globalConfig.patch.git + ' tag T' + relNumberNew, globalConfig.patch.rolloutRepo, _);
				console.log("New release " + relNumberNew);
			}
			// get the hash of the current commit
			tracer("-------------- Roll-out repository updated");
			targetVersion = commitDataFromHash("HEAD", globalConfig.patch, _); // set data of targetVersion to the really latest new data 
			if (!latestPatch) {
				//	createCustomerImage(track, globalConfig.patch, _, relNumberNew, targetVersion.rollout, commitComment);
				return; // do not create patch file 
			}
		} else {
			if (sha1New) targetVersion = commitDataFromHash(sha1New, globalConfig.patch, _);
			else targetVersion = commitDataFromHash("HEAD", globalConfig.patch, _);
			// has streamline configuration changed?
			tracer("1Base version " + util.format(baseVersion));
			tracer("1Latest patch " + util.format(targetVersion));
			var relative = path.relative(patchtools.BASE_DIRECTORY, __dirname + "/" + CONFIG_FILE).replace(/\\/g, "/");
			var difference = _execute(globalConfig.patch.git + ' diff --no-color --unified=0 ' + baseVersion.source + ' ' + targetVersion.source + ' -- ' + relative, patchtools.BASE_DIRECTORY, _);
			if (difference) {
				var r = /\+\s*streamline\s+(\{.*\})/m.exec(difference);
				if (r) {
					tracer("1Latest patch " + r[1]);
					newStreamlineConfig = JSON.parse(r[1]);
				}
			}
		}
		// create patch file
		if (!patchfile) throw new Error("No patch file available");
		if (baseVersion.rollout === targetVersion.rollout) throw new Error("Base version equals target version - empty patch");
		if (relNumberCmp(baseVersion.relNumber, targetVersion.relNumber) > 0 || baseVersion.relNumber === targetVersion.relNumber && baseVersion.patchNumber - targetVersion.patchNumber > 0) {
			throw new Error("No downgrade with patch from " + baseVersion.relNumber + "-" + baseVersion.patchNumber + " to " + targetVersion.relNumber + "-" + targetVersion.patchNumber);
		}
		patchfile = _replaceVersions(baseVersion, targetVersion, patchfile);
		console.log(_replaceVersions(baseVersion, targetVersion, "Patch file %S-%s %E-%e"));
		tracer("-------------- Create patch file " + patchfile);
		track && track("Create patch file", "git diff", 80);
		if (!patchfile) throw new Error("Patch file name missing");
		var patchElement = '"ASR","PATCH","' + targetVersion.comment + '"';
		var gitDiff = _execute(globalConfig.patch.git + ' diff --irreversible-delete --minimal --binary --no-color --unified=0 ' + baseVersion.rollout + ' ' + targetVersion.rollout, globalConfig.patch.rolloutRepo, _).split(/[\r\n]+/);
		// filter the output
		var target = [];
		if (x3Information) target.push('1,"","ENG","1","","X3","2",', "2," + patchElement);
		target.push("syracuse patch " + baseVersion.relNumber + " " + baseVersion.patchNumber + " " + targetVersion.date + " " + targetVersion.relNumber + " " + targetVersion.patchNumber + " " + baseVersion.rollout + " " + targetVersion.rollout + " " + targetVersion.source,
			"syracuse patchcomment " + targetVersion.comment);
		if (newStreamlineConfig) target.push("syracuse streamline " + JSON.stringify(newStreamlineConfig));

		// remove 
		track && track("Create patch file", "process git diff", 90);
		shrink(target, gitDiff);
		track && track("Create patch file", "write file", 95);
		if (x3Information) {
			if (target[target.length - 1] === '') target.pop();
			target.push('**********',
				'7,' + patchElement,
				'8,""',
				'');
		}
		fs.writeFile(patchfile, target.join("\n"), "utf8", _);
		tracer("-------------- Patch file created");
		tracer("END PATCH");
	} catch (e) {
		tracer(e);
		throw e;
	} finally {
		tracer = stdlogger;
	}
}

exports.createPatch = createPatch;

// replaces placeholders %S, %s: release/patch of start version, %E, %e release/patch of end version
function _replaceVersions(baseVersion, targetVersion, input) {
	return input.replace(/\%[sSEe]/g, function(text) {
		switch (text.substr(1)) {
			case 'S':
				return baseVersion.relNumber;
			case 's':
				return baseVersion.patchNumber;
			case 'E':
				return targetVersion.relNumber;
			case 'e':
				return targetVersion.patchNumber;
			default:
				return "";
		}
	});
}

/// shrink
/// condenses the git diff output to a syracuse patch file content
function shrink(target, gitDiff) {
	var binary = false;
	var file_from;
	var file_to;
	var mode;
	var access_rights;
	for (var i = 0; i < gitDiff.length; i++) {
		var line = gitDiff[i];
		var r;
		// lines to ignore
		if (line.substr(0, 3) === '+++' || line.substr(0, 3) === '---' || /^(copy|rename|GIT binary) /.exec(line)) continue;
		if (line.substr(0, 1) === '-') { // remove deleted lines (including '\ No new line')
			while (i < gitDiff.length - 1 && /^[\-\\]/.test(gitDiff[i + 1]))
			i++;
			continue;
		}
		if (line.substr(0, 10) === 'diff --git') {
			if (r = /^diff --git a\/(.*) b\/\1$/.exec(line)) {
				file_from = r[1];
				file_to = r[1];
			} else if (r = /^diff --git a\/(\S+) b\/(\S+)$/.exec(line)) {
				file_from = r[1];
				file_to = r[2];
			}
			mode = 'A';
			access_rights = null;
			continue;
		}
		if (line.substr(0, 8) === 'new file') {
			mode = 'N';
			if (r = /mode (\d+)/.exec(line)) access_rights = r[1];
			continue;
		}
		if (line.substr(0, 12) === 'deleted file') {
			mode = 'D';
			continue;
		}
		if (line.substr(0, 6) === 'index ') {
			r = /^index ([0-9a-f]+)\.\.([0-9a-f]+)(?:\s+(\d*))?/.exec(line);
			if (r) {
				if (mode === 'N') r[1] = "";
				else if (mode === 'D') r[2] = "";
				if (file_to === file_from) file_to = "";
				if (r[3]) access_rights = r[3].substr(r[3].length - 3);
				if (!/^[0-7]{3}$/.test(access_rights)) access_rights = "644";
				target.push("FILE " + mode + ' ' + access_rights + ' "' + file_from + '" "' + file_to + '" ' + r[1] + '-' + r[2]);
			} else throw new Error("Unnormal index line " + line);
			continue;
		}
		// remove second part of binary patch		
		if (/^(literal|delta) /.test(line)) {
			binary = !binary;
			if (binary) target.push(line);
			// all but last line have maximal length 52 and start with 'z'
			while (i < gitDiff.length - 1 && gitDiff[i + 1].substr(0, 1) === 'z') {
				i++;
				if (binary) target.push(gitDiff[i]);
			}
			if (i < gitDiff.length - 1 && /^[A-Za-y]\S+$/.test(gitDiff[i + 1])) {
				i++;
				if (binary) target.push(gitDiff[i]);
			}
			continue;
		}
		// diff area
		var r = /^\@\@[\-\+\d, ]+/.exec(line);
		if (r) {
			line = r[0].trim() + "!";
		}
		if (line.charAt(0) === '+' && line.length > 251) { // split very long lines
			var j = 1;
			while (j + 250 < line.length) {
				target.push("=" + line.substr(j, 250));
				j += 250;
			}
			target.push("+" + line.substr(j));
			continue;
		}
		target.push(line);
	}
}

/// creates customer image from rollout repository which contains all necessary metadata for Syracuse patching, but no .git data
/// parameters:
/// track: tracking function
///  patchConfig: paths of rollout repository and customer image
/// optional parameters:
/// release: release number of release (latest release if empty)
function createCustomerImage(track, patchConfig, _, release) {
	if (!patchConfig || !patchConfig.rolloutRepo || !patchConfig.customerImage) {
		throw new Error("Directories must be given " + util.format(patchConfig));
	}
	if (patchConfig.logfile) logfile = patchConfig.logfile;
	if (logfile) {
		try {
			console.error("Delete log file " + logfile);
			fs.unlink(logfile, _);
		} catch (e) {}
	}
	patchConfig.git = patchConfig.git || "git";
	if (!patchtools.exists(patchConfig.rolloutRepo, _)) throw new Error("Roll-out repository path does not exist: " + patchConfig.rolloutRepo);
	var oldlogger = tracer;
	tracer = patchlogger;
	try {
		tracer("-------------- Create customer image " + patchConfig.customerImage + " from " + patchConfig.rolloutRepo);
		track && track("Create customer image", "", 2);
		// find out or check release
		var tags = _taglist(patchConfig, release, _);
		if (tags.length === 0) throw new Error("Customer repository empty");
		if (!release) release = tags[tags.length - 1];
		// 	remove existing customerImage
		if (patchtools.exists(patchConfig.customerImage, _)) {
			track && track("Create customer image", "Delete existing customer image", 10);
			if (fs.stat(patchConfig.customerImage, _).isDirectory) {
				tracer("Delete existing directory " + patchConfig.customerImage);
				patchtools.rmdirRec(patchConfig.customerImage, _);
			} else {
				tracer("Delete existing file " + patchConfig.customerImage);
				fs.unlink(patchConfig.customerImage, _);
			}
		}
		// use git to create a copy of repository which has unix style line endings (-l: local copy, -s: do not copy objects)
		track && track("Create customer image", "clone repository", 20);
		console.log("Customer image " + release);
		_execute(patchConfig.git + ' clone -l -s -c core.eol=lf -c core.autocrlf=input --branch T' + release + ' ' + patchConfig.rolloutRepo + ' ' + patchConfig.customerImage, patchtools.BASE_DIRECTORY, _);
		tracer("Clone finished");
		var gitlog = new GitLog(patchConfig);
		var newVersion = gitlog.next(false, _);
		if (!newVersion) throw new Error("Inconsistency: Tags available but no release");
		var relative = path.relative(patchtools.BASE_DIRECTORY, __dirname + "/" + CONFIG_FILE).replace(/\\/g, "/");
		var oldConfig = _execute(patchConfig.git + ' show ' + newVersion.source + ':' + relative, patchtools.BASE_DIRECTORY, _);
		oldConfig = _readConfig(oldConfig);
		// 	delete git contents of customer image
		tracer("Delete .git subdirectory");
		track && track("Create customer image", "delete .git directory", 70);
		patchtools.rmdirRec(patchConfig.customerImage + "/.git", _);
		// 		create checksum files
		tracer("Write checksum files");
		track && track("Create customer image", "write checksums", 80);
		var sha1 = patchtools.makeChecksums(patchConfig.customerImage, _);
		// create file for initial version
		var initialVersion = JSON.stringify({
			commit: newVersion.rollout,
			relNumber: release,
			patchNumber: 0,
			comment: newVersion.comment,
			init: true,
			sha1: sha1,
			streamline: oldConfig.streamline
		});
		tracer("Write " + patchtools.VERSION_FILE + ": " + initialVersion);
		patchtools.writeFile(patchConfig.customerImage + "/" + patchtools.VERSION_FILE, initialVersion, _);
		tracer("Double-check checksums");
		track && track("Create customer image", "double check checksums", 90);
		var errors = patchtools.checkChecksumsV(patchConfig.customerImage, _);
		if (errors.length > 0) {
			throw new Error("Errors when checking checksums " + errors.join("\n"));
			tracer("errors when checking checksums " + errors.join(","));
		}
		tracer("-------------- Create customer image completed");
	} finally {
		tracer = oldlogger;
	}
}

exports.createCustomerImage = createCustomerImage;

/// reads config file and writes results to config object: transformationRules as an array of regular expressions with corresponding actions,
///  commands hash with one time action names and corresponding batch file invocations
function _readConfig(contents) {
	var lines = contents.split(/\r\n|\r|\n/);
	var config = {};
	config.transformationRules = [];
	config.commands = {};
	var i = 0;
	var r;
	var section = "";
	while (i < lines.length) {
		var line = lines[i++];
		r = /^(\w+)\s+(.*)/.exec(line);
		if (r) {
			if (section === "options") {
				if (r[1] === "streamline") {
					try {
						config.streamline = JSON.parse(r[2]);
					} catch (e) {
						tracer("Error in parsing streamline options " + e);
					}
				} else if (r[1] === "uglify") {
					try {
						config.uglify = JSON.parse(r[2]);
					} catch (e) {
						tracer("Error in parsing uglify options " + e);
					}
				} else console.log("Unknown settings " + r[1]);
			} else if (section === "files") { // associations of file paths to actions
				if (r[1] === "noCrypt") {
					config.noCrypt = r[2];
					tracer("nocrypt " + r[2]);
					continue;
				}
				if (r[1].indexOf('_') === 0 && !(r[1] in config.commands)) throw new Error("Command " + r[1] + " is not defined");
				config.transformationRules.push(makeRule(r[1], r[2], config.noCrypt, i));
			} else if (section === "commands") { // definitions of one time actions
				config.commands[r[1]] = r[2];
			}
		} else {
			r = /^\[(\w+)\]/i.exec(line);
			if (r) section = r[1].toLowerCase();
		}
	}
	tracer("Rules " + util.format(config));
	return config;
}

//splits command line into parts; parts surrounded by "" will be treated as one argument. No special treatment of ''!
function splitargs(cmdline) {
	var args1 = cmdline.trim().split(/\"/);
	var result = [];
	for (var i = 0; i < args1.length; i++) {
		if (i % 2) {
			if (args1[i - 1].charAt(args1[i - 1].length - 1) === ' ') result.push(args1[i]);
			else result[result.length - 1] += '"' + args1[i] + '"';
		} else {
			if (args1[i] === "") continue;
			var tmpArgs = args1[i].trim().split(/\s+/);
			for (var j = 0; j < tmpArgs.length; j++)
			result.push(tmpArgs[j]);
		}
	}
	return result;
}

//execute external command and return stdout as a string. There is no fixed limit on the size of stdout.
var _execute = _(function(cmdline, directory, callback) {
	var finished = false;
	tracer("EXECUTE (" + directory + ") " + cmdline);
	if (!directory) {
		finished = true;
		return callback(new Error("Working directory empty"));
	}
	var args = splitargs(cmdline);
	var buffers = [];
	var stderr = "";
	var child = child_process.spawn(args[0], args.slice(1), {
		cwd: directory
	});
	child.stdout.on('data', function(data) {
		buffers.push(data);
	});
	child.stderr.on('data', function(data) {
		stderr += data.toString("utf8");
	});
	child.on('close', function(code) {
		var b = Buffer.concat(buffers);
		var stdout = b.toString("utf8");
		b = null;
		if (code !== 0) {
			tracer("Error (exit code " + code + "): " + stdout + " " + stderr);
			if (!finished) {
				finished = true;
				return callback(new Error(stderr ? stderr : stdout));
			}
		} else {
			if (stderr) tracer('Warning: ' + stderr);
			if (!finished) {
				finished = true;
				return callback(null, stdout);
			}
		}
	});
	child.on('error', function(error) {
		tracer("Error code " + error);
		if (!finished) {
			finished = true;
			return callback(new Error("Cannot execute " + args[0] + ": " + error));
		}
	});
}, 2);

//apply encrypt and copy rule for one file
function _applyRule(data, mode, config, _) {
	if (!data) return;
	if (data.rule.charAt(0) === '_') return data.rule;
	mode = mode || data.mode;
	// config file may have been changed when checkSource is false - therefore delete even ignored files
	if ((config.checkSource || mode !== "D") && (data.rule === "ignore" || data.rule === "norule")) return;
	var fullTargetFileName = config.rolloutRepo + "/" + data.file;
	if (mode === "D") { // delete file
		try {
			patchtools.deleteFileDir(config.rolloutRepo, data.file, null, _);
			// fs.unlink(fullTargetFileName, _);
		} catch (e) {
			if (e.code === "ENOENT") {
				tracer("Already deleted " + fullTargetFileName);
			} else throw e;
		}
	} else {
		var buff = fs.readFile(patchtools.BASE_DIRECTORY + "/" + data.f, _);
		if ((data.rule === "uglify" || data.rule === "encrypt" || data.rule === "streamline" || data.rule === "hide") && /\._?js$/.test(data.f)) {
			// code transformations for customer site
			var code = buff.toString("utf8");
			try {
				var uglifyjs = require('uglifyjs2');
				var doStreamlining = /\._js$/.test(data.f);
				if (doStreamlining) // streamline ._js files
				var streamlineConfig = {};
				Object.keys(config.streamline).forEach(function(key) {
					streamlineConfig[key] = config.streamline[key];
				});
				code = transformModule(buff.toString("utf8"), data.f, streamlineConfig);
				if (data.rule !== "streamline") {
					// 1. parse
					var toplevel = null;
					toplevel = uglifyjs.parse(code, {
						filename: data.f
					});

					// 2. compress
					toplevel.figure_out_scope();
					var sq = uglifyjs.Compressor(config.uglify || {
						sequences: false,
						unsafe: false,
						// properties    : false,
						// dead_code     : false,
						// drop_debugger : false,
						// conditionals  : false,
						// comparisons   : false,
						// evaluate      : false, // !!
						// booleans      : false,
						// loops         : false,
						unused: false,
						hoist_vars: false,
						if_return: false,
						// join_vars     : false,
						cascade: false,
						side_effects: false,
						hoist_funs: false

						/* ,
			    	unused: false, 
			    	side_effects: false */
					});
					toplevel = toplevel.transform(sq);

					// 3. mangle
					toplevel.figure_out_scope();
					toplevel.compute_char_frequency();
					toplevel.mangle_names();

					// 4. output
					var map = null;
					var inMap = null;
					var stream = uglifyjs.OutputStream({
						indent_level: 0,
						space_colon: false,
						semicolons: false
					});
					toplevel.print(stream);
					code = stream + "";
				}
				buff = new Buffer(code, "utf8");
			} catch (e) {
				tracer("Exception when preprocessing " + data.f + ": " + util.format(e));
			}
			if (data.rule === "encrypt" || data.rule === "hide") {
				if (!encrypter) encrypter = require('syracuse-license').load("encrypt");
				buff = encrypter.encrypt(data.file, buff, data.rule === "hide", require);
			}
		}
		patchtools.writeFile(fullTargetFileName, buff, _);
	}

	return null;
}

//parse file path pattern and replace backslashes and convert "**/", "*", "?" into regular expressions
function makeRule(name, pattern, noCrypt, line) {
	// make regular expression
	// replace backslashes with slashes for paths
	pattern = pattern.replace(/\\/g, "/");
	// temporary replace of **/
	pattern = pattern.replace(/\*{2,}\//g, "\0");
	// replace *
	pattern = pattern.replace(/\*+/g, "[^\\/]*");
	// replace ?
	pattern = pattern.replace(/\?/g, "[^\\/]");
	// mask of .
	pattern = pattern.replace(/\./g, "\\.");
	// real replace of **/
	pattern = pattern.replace(/\x00/g, "(?:.*\/)?");
	if (noCrypt && (name === "hide" || name === "encrypt")) name = "uglify";
	if (noCrypt > 1 && (name === "uglify")) name = "streamline";
	if (noCrypt > 2 && (name === "streamline")) name = "copy";
	return [new RegExp("^" + pattern + "$"), name, line];
}

/// parse a line for a one time action and replace $$, $/, $R, $S with corresponding values
function replacements(line, rolloutRepo) {
	line = line.trim();
	// 	temporarily replace $$
	line = line.replace(/\$\$/g, "\0");
	// 	slash
	line = line.replace(/\$\//g, path.sep);
	// source repository
	line = line.replace(/\$S/g, path.normalize(process.cwd()));
	// roll-out repository
	line = line.replace(/\$R/g, path.normalize(rolloutRepo));
	// finally replace $$ with $.
	line = line.replace(/\x00/g, "$");
	return line;
}

function findRule(line, config, suppressMessage) {
	var pattern = /([A-Z]+)\s+(.*)/g;
	var r;
	if (r = pattern.exec(line)) {
		var i = 0;
		var filename = r[2];
		var result = {
			mode: r[1],
			f: filename
		};
		while (i < config.transformationRules.length) {
			var rule = config.transformationRules[i++];
			var ru = rule[1];
			if (rule[0].test(filename)) {
				// changes in filename
				if (!/\._?js$/.test(filename) && (ru === "streamline" || ru === "uglify" || ru === "encrypt" || ru === "hide")) ru = "copy";
				else if (ru === "streamline" && filename.substr(filename.length - 3) == ".js") ru = "copy";
				else {
					if (ru === "streamline" || ru === "uglify") filename = filename.replace(/\._js$/, ".js");
					else if (ru === "encrypt" || ru === "hide") filename = filename.replace(/\._?js$/, ".jsc");
				}
				if (!suppressMessage) {
					tracer(ru + "(" + rule[2] + ") " + r[1] + " " + r[2]);
				}
				if (ru === "extra") {
					result.extra = true;
					continue;
				}
				result.rule = ru;
				result.file = filename;
				return result;
			}
		}
		tracer("No rule found for " + filename);
		result.rule = "norule";
		result.file = filename;
		return result;
	}
	return null;
}

//collect extra functions from a file
function _extra(oneTimeActions, data, _) {
	if (data.mode != "D") {
		var contents = fs.readFile(patchtools.BASE_DIRECTORY + "/" + data.f, "utf8", _);
		var functionPattern = /(?:^|[\r\n])\s*exports\.(patch\w*)/g;
		var regexpResult;
		oneTimeActions.extra = oneTimeActions.extra || [];
		while (regexpResult = functionPattern.exec(contents)) {
			oneTimeActions.extra.push(data.file + " " + regexpResult[1]);
			tracer("Pattern for extra function " + regexpResult[1]);
		}
	}
}

function executeDiff(diff, oldCommit, config, _) {
	// changes in configuration file?
	var relative = path.relative(patchtools.BASE_DIRECTORY, __dirname + "/" + CONFIG_FILE).replace(/\\/g, "/");
	var oneTimeActions = {};
	var r;
	tracer("Relative path of config file " + relative);
	// get contents of current diff
	var lines = diff.split(/[\r\n]+/);
	// data for tracker
	var startPercentage = 10;
	var diffPercentage = 30;
	// config file has changed (this is not important for very first version)
	if (oldCommit !== FIRST_COMMIT && diff.indexOf(relative) > 0) {
		startPercentage = 25;
		diffPercentage = 15;
		var currentDiffContents = {};
		for (var i = 0; i < lines.length; i++) {
			if (r = /[A-Z]+\s+(.*)/.exec(lines[i])) currentDiffContents[r[1]] = lines[i];
		}
		var oldConfig = _execute(config.git + ' show ' + oldCommit + ':' + relative, patchtools.BASE_DIRECTORY, _);
		oldConfig = _readConfig(oldConfig);
		var changedRuleConfigurations = {}; // rules which have to be applied because the configuration has changed
		var changedRulePattern;
		if (!deepEqual(oldConfig.streamline, config.streamline)) {
			tracer("Streamline configuration change from " + JSON.stringify(oldConfig.streamline) + " to " + JSON.stringify(config.streamline));
			changedRuleConfigurations.hide = changedRuleConfigurations.encrypt = changedRuleConfigurations.uglify = changedRuleConfigurations.streamline = /\._js$/;
			config._streamlineConfigChanged = true;
		}
		if (!deepEqual(oldConfig.uglify, config.uglify)) {
			tracer("Uglify configuration change from " + JSON.stringify(oldConfig.uglify) + " to " + JSON.stringify(config.uglify));
			changedRuleConfigurations.hide = changedRuleConfigurations.encrypt = changedRuleConfigurations.uglify = /\._?js$/;
		}
		var fullDiffLines = _execute(config.git + ' diff --name-status ' + FIRST_COMMIT + ' HEAD', patchtools.BASE_DIRECTORY, _).split(/[\r\n]+/);
		for (i = 0; i < fullDiffLines.length; i++) {
			if ((i % 200) < 1) {
				var processed = i;
				config.track && config.track("Write differently generated files to roll out repository", processed + " of " + fullDiffLines.length, Math.round(10 + 15 * (processed / fullDiffLines.length)));
			}

			var line = fullDiffLines[i];
			tracer("LINE " + line);
			var resNew = findRule(line, config, true);
			var resOld = findRule(line, oldConfig, true);
			if (resOld && resNew) {
				if (resOld.rule !== resNew.rule || resOld.extra !== resNew.extra || ((changedRulePattern = changedRuleConfigurations[resNew.rule]) && changedRulePattern.test(line))) { // different rule
					tracer("Configuration change for " + resOld.f + ": " + resOld.rule + " -> " + resNew.rule);
					var action;
					if (resOld.file !== resNew.file || resNew.rule === "ignore" || resNew.rule === "norule") { // different target file name
						// delete old file
						_applyRule(resOld, "D", config, _);
						// add new file
						action = _applyRule(resNew, "N", config, _);
					} else {
						action = _applyRule(resNew, "M", config, _);
					}
					if (action) oneTimeActions[action] = "";
					if (resNew.f in currentDiffContents && resNew.extra) {
						_extra(oneTimeActions, resNew, _);
					}
					delete currentDiffContents[resNew.f];
				}
			}
		}
		lines.length = 0;
		for (var key in currentDiffContents) {
			tracer("KKK " + key + " " + currentDiffContents[key]);
			lines.push(currentDiffContents[key]);
		}
	}
	for (i = 0; i < lines.length; i++) {
		if ((i % 200) < 1) {
			var processed = i;
			config.track && config.track("Write to roll out repository", processed + " of " + lines.length, Math.round(startPercentage + diffPercentage * (processed / lines.length)));
		}
		var res = findRule(lines[i], config);
		if (res) {
			var action = _applyRule(res, res.mode, config, _);
			if (action) oneTimeActions[action] = "";
			if (res.extra) {
				_extra(oneTimeActions, res, _);
			}
		}
	}
	tracer("END EXEC");
	return oneTimeActions;
}

/// collect differences from git log
function _collect(oldCommit, newCommit, config, _) {
	// log differences
	var diff = _execute(config.git + ' diff --name-status ' + oldCommit + ' ' + newCommit, patchtools.BASE_DIRECTORY, _);
	var oneTimeActions = executeDiff(diff, oldCommit, config, _);
	diff = ""; // data are not necessary any more
	config.track && config.track("Write to roll out repository", "one time actions", 40);
	// execute oneTimeActions
	if ("extra" in oneTimeActions) {
		tracer("EXTRA " + oneTimeActions.extra.sort().join(", "));
		patchtools.writeFile(config.rolloutRepo + "/" + patchtools.EXTRA_FUNCTIONS, oneTimeActions.extra.sort().join("\n") + "\n", _);
		delete oneTimeActions.extra;
	}
	var actions = Object.keys(oneTimeActions);
	var i = actions.length;
	while (--i >= 0) { // one time action as a batch file
		tracer("One time action " + actions[i]);
		var result = replacements(config.commands[actions[i]], config.rolloutRepo);
		// execute the command
		try {
			_execute(result, patchtools.BASE_DIRECTORY, _);
		} catch (e) {
			throw new Error("Error in one time action " + actions[i] + " with command " + result.command + ": " + e);
		}
	}
}

//loops over git log and parses the commit comments
function GitLog(cfg, headCommit, git) {
	this._logs = [];
	this.finished = false;
	this._i = 1;
	this._count = 10;

	// get data from previous release or patch
	// parameter release: only look for release commits
	this.next = function(release, _) {
		while (!this.finished) {
			while (this._i < this._logs.length) {
				var res = commitData(this._logs[this._i++], release);
				if (res) return res;
			}
			var currentCommit = headCommit || "HEAD";
			if (this._logs.length > 0) {
				currentCommit = this._logs[this._logs.length - 1].substr(0, 40);
				this._i = 1;
			} else this._i = 0;
			this._logs = _execute(cfg.git + ' log -' + this._count + ' --pretty=format:"%H %cd %s" --date=short ' + currentCommit, cfg.rolloutRepo, _).split(/[\r\n]+/);
			this._count *= 2;
			if (!this._logs[this._logs.length - 1]) this._logs.pop();
			if (this._logs.length <= this._i) {
				this.finished = true;
				return null;
			}
		}
		return null;
	};
}


function cmdLinePatch(config, _) {
	// parse command line
	var mode = process.argv[2];
	if (!mode) throw new Error("No patching mode given");
	var args = process.argv.slice(3);
	var startFromRelease;
	var baseRelease;
	var newRelease;
	var patchFile;
	var checkSource = true;
	var x3Information = true;
	var startVersion;
	var endVersion;
	var description;
	for (var i = 0; i < args.length; i++) {
		var argument = args[i];
		switch (argument) { // arguments without parameter
			case '--start-from-release':
				startFromRelease = true;
				break;
			case '--no-check':
				checkSource = false;
				break;
			case '--no-x3-patch-info':
				x3Information = false;
				break;
			default:
				if (i === args.length - 1 || !args[i + 1] || args[i + 1].substr(0, 2) === "--") throw new Error("No argument given for option");
				switch (argument) {
					case '--git':
						config.patch.git = args[++i];
						break;
					case '--rollout':
						config.patch.rolloutRepo = args[++i];
						break;
					case '--base-release':
						baseRelease = args[++i];
						break;
					case '--release':
						newRelease = args[++i];
						break;
					case '--patch-file':
						patchFile = args[++i];
						break;
					case '--image':
						config.patch.customerImage = args[++i];
						break;
					case '--logfile':
						config.patch.logfile = args[++i];
						break;
					case '--start-version':
						startVersion = "V" + args[++i];
						break;
					case '--end-version':
						endVersion = "V" + args[++i];
						break;
					case '--desc':
						description = args[++i];
						break;
					default:
						throw new Error("wrong argument " + args[i]);
				}
		}
	}
	switch (mode) {
		case 'new-release':
			globalConfig = config;
			return createPatch(null, true, startFromRelease, true, newRelease, description, baseRelease, patchFile, null, null, x3Information, checkSource, _);
		case 'customer-image':
			return createCustomerImage(null, config.patch, _, newRelease);
		case 'new-patch':
			globalConfig = config;
			return createPatch(null, true, startFromRelease, false, null, description, baseRelease, patchFile, null, null, x3Information, checkSource, _);
		case 'patch-file':
			globalConfig = config;
			createPatch(null, false, startFromRelease, false, null, null, baseRelease, patchFile, startVersion, endVersion, x3Information, checkSource, _);
	}
}

function _getHashFromVersion(config, version, _) {
	var parts = version.split(/\-/);
	var pattern = "^" + parts[0].replace(/\./, "\\.") + " " + parts[1];
	var result = _execute(config.patch.git + ' log --all -1 --grep "' + pattern + '" --pretty=format:%H', config.patch.rolloutRepo, _);
	if (!result) throw new Error("Cannot find version " + version);
	return result;
}

exports.cmdLinePatchCb = function(config, cb) {
	cmdLinePatch(config, _ >> cb);
};

//returns all versions of all releases. This cannot be done just using GitLog, because there may be branches from older
function allPatches(patchConfig, _) {
	patchConfig.git = patchConfig.git || "git";
	// find out branch names and patch sha1 checksums
	var tmpBranches = _execute(patchConfig.git + ' branch -v --no-abbrev', patchConfig.rolloutRepo, _).split(/[\r\n]+/);
	var releases = [];
	var releasesHash = {};
	var i = 0;
	while (i < tmpBranches.length) {
		var line = tmpBranches[i++];
		var r = /^[\*\s]+R(\d[\d\.]*)\s+(\w{40})/.exec(line);
		if (r) {
			releases.push(r[1]);
			releasesHash[r[1]] = r[2];
		}
	}
	tmpBranches = undefined;
	releases = releases.sort(relNumberCmp);
	i = releases.length;
	var branchings = {};
	var result = [];
	var patch = null;
	var gitlog = new GitLog(patchConfig, releasesHash[releases[i - 1]]);
	while (--i >= 0) {
		var currentRelease = releases[i];
		if (!patch) patch = gitlog.next(false, _);
		var found = false;
		while (patch) {
			if (patch.relNumber === currentRelease) {
				if (patch.rollout in branchings) patch.branchings = branchings[patch.rollout].trim();
				result.push(patch);
				found = true;
				patch = gitlog.next(false, _);
				continue;
			}
			// older patch
			if (found) {
				if (patch.rollout in branchings) branchings[patch.rollout] += currentRelease + " ";
				else branchings[patch.rollout] = currentRelease + " ";
			}
			if (i > 0 && patch.rollout !== releasesHash[releases[i - 1]]) {
				gitlog = new GitLog(patchConfig, releasesHash[releases[i - 1]]);
				patch = null;
			}
			break;
		}
	}
	return result;
}

exports.allPatches = allPatches;

//extract information from "git log --pretty=oneline" line
function commitData(line, release) {
	// matching group 6 is for future use!
	var pattern = release ? /^\"?(\w{40}) (\d\d\d\d\-\d\d\-\d\d) ([\d\.]+) (0) (\w{40}) (\S+) ([^"]*)/ : /^\"?(\w{40}) (\d\d\d\d\-\d\d\-\d\d) ([\d\.]+) (\d+) (\w{40}) (\S+) ([^"]*)/;
	var r = pattern.exec(line);
	if (r) {
		return {
			release: (r[4] === "0"),
			source: r[5],
			rollout: r[1],
			relNumber: r[3],
			patchNumber: 1 * r[4],
			comment: r[7],
			date: r[2]
		};
	}
	return null;
}

//invoke git to get all data from the commit with the given sha1 checksum
function commitDataFromHash(sha1, patchConfig, _) {
	var result = commitData(_execute(patchConfig.git + ' log -1 --pretty=format:"%H %cd %s" --date=short ' + sha1, patchConfig.rolloutRepo, _), false);
	if (!result) throw new Error("Inconsistency: No data for commit " + sha1);
	return result;
}

exports.commitDataFromHash = commitDataFromHash;

//for unit tests
exports.makeRule = makeRule;
exports.findRule = findRule;
exports.replacements = replacements;
exports.commitData = commitData;
exports.shrink = shrink;
exports.splitargs = splitargs;