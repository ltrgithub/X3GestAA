"use strict";

var child_process = require('child_process');
var util = require('util');
var fs = require('streamline-fs');
var path = require('path');
var os = require('os');
var babelTransform = require('babel-core').transform;
require('babel-plugin-flow-comments');
require('babel-plugin-streamline');

var encrypter;
try {
	var globalConfig = require('config');
} catch (e) {
	globalConfig = {};
}

var helpers = require("syracuse-core/lib/helpers");
var patchtools = require('./patchtools');
var relNumberCmp = helpers.relNumberCmp;
var deepEqual = require('syracuse-load/lib/certTools').deepEqual;


/// !doc
/// # Patch creation  
/// ```javascript
/// var patchcreate = require('syracuse-patch/lib/patchcreate')  
/// ```
/// 

//sha1 hash of first commit of the Syracuse repository
var FIRST_COMMIT = '9c1bdb6f3144a8295416acb66197f1a99ce4d71e';
var CONFIG_FILE = __dirname + "/config.txt";

var logfile = os.tmpDir() + "/apatch.log";

var tracer; // = console.log;

var patchlogger = function(text) {
	fs.appendFileSync(logfile, JSON.stringify(new Date()) + text + "\n");
};

//markers for patch and release
var PATCH = "PATCH";
var RELEASE = "RELEASE";

/// returns array of all releases. If testRelease is given, it checks whether the value is contained 
/// in the list of releases. If not, an exception occurs

function _taglist(patchConfig, testRelease, _) {
	var tags = [];
	var tmptags = _execute(patchConfig.git + ' tag', patchConfig.rolloutRepo, _).trim().split(/[\r\n\s]+/);
	var found = !testRelease;
	var i = 0;
	while (i < tmptags.length) {
		var tag = tmptags[i++];
		if (/^T\d[\d\.]*$/.test(tag)) tags.push(tag.substr(1));
		if (!found && "T" + testRelease === tag) found = true;
	}
	if (!found) throw new Error("Release " + testRelease + " does not exist");
	tags = tags.sort(relNumberCmp);
	return tags;
}

/// automatic release number creation

function _automaticRelease(tags, pattern) {

}

// Direct customer image creation without rollout repository
// parameters: commitComment: comment for new image
//             releaseNumber: some kind of release number
//             configuration: Object with 
//                 - customerImage: path for customer image (obligatory!)
//                 - git: alternative name for git command
//                 - logfile: logging into file
//                 - configFile: configuration file
//             checkSource: check whether original sources must be without uncommitted changes
function directImage(releaseNumber, commitComment, configuration, checkSource, _) {
	var stdlogger = tracer;
	tracer = console.log;
	var releaseCreated = false; // has new branch been created in rollout repository? Must be removed in case of error!
	var currentBranchNo; // number of current branch before switching to new branch (stays undefined if there is no active branch)
	try {
		if (!configuration.customerImage) throw new Error("Must specify path for image");
		configuration.git = configuration.git || "git";
		if (!commitComment) {
			throw new Error("No comment provided");
		}
		configuration.configFile = configuration.configFile || CONFIG_FILE;
		if (configuration.logfile) {
			logfile = configuration.logfile;
			try {
				console.error("Delete log file " + logfile);
				fs.unlink(logfile, _);
			} catch (e) {}
			tracer = patchlogger;
		}
		var uncommitted;
		if (checkSource && (uncommitted = _execute('git status -s', patchtools.BASE_DIRECTORY, _))) throw new Error("No new patch with uncommitted changes in source tree:\n" + uncommitted);
		var contents = fs.readFile(configuration.configFile, "utf8", _);
		var config = _readConfig(contents);
		// take rolloutRepo and streamline options from globalConfig so that globalConfig need not be passed to all functions
		config.git = configuration.git;
		config.configFile = configuration.configFile;
		if (!config.streamline) throw new Error("No streamline configuration in " + configuration.configFile);
		config.track = null;
		config.rolloutRepo = configuration.customerImage;
		var sourceCommitOld = FIRST_COMMIT;
		var sourceCommitCurrent = _execute(configuration.git + ' log -1 --pretty=format:%H', patchtools.BASE_DIRECTORY, _);
		if (!sourceCommitCurrent) throw new Error("No current commit in source repository");
		tracer && tracer("Old source commit " + sourceCommitOld + " current " + sourceCommitCurrent);
		// 	remove existing customerImage
		if (patchtools.exists(configuration.customerImage, _)) {
			if (fs.stat(configuration.customerImage, _).isDirectory) {
				tracer("Delete existing directory " + configuration.customerImage);
				patchtools.rmdirRec(configuration.customerImage, _);
			} else {
				tracer("Delete existing file " + configuration.customerImage);
				fs.unlink(configuration.customerImage, _);
			}
		}
		// this may set config._syracuseConfigChanged
		_collect(sourceCommitOld, sourceCommitCurrent, config, _);
		// problem with line feeds: will be different on different platforms
		// var sha1 = patchtools.makeChecksums(configuration.customerImage, _);
		// create file for initial version
		var initialVersion = JSON.stringify({
			commit: "-",
			relNumber: releaseNumber || "",
			patchNumber: 0,
			comment: commitComment,
			init: true,
			sha1: "-",
			streamline: config.streamline,
			src: sourceCommitCurrent
		});
		tracer("Write " + patchtools.VERSION_FILE + ": " + initialVersion);
		patchtools.writeFile(configuration.customerImage + "/" + patchtools.VERSION_FILE, initialVersion, _);

	} catch (e) {
		tracer(e);
		throw e;
	} finally {
		tracer = stdlogger;
	}
}

exports.createPatch = createPatch;





/// -------------
/// ## Patch creation function `patch`
/// create a Syracuse patch
/// Parameters:
/// -  track: tracker function. If set, it can be used to show progress status to the user. It will be invoked with parameters:
///       phase, phaseDetail, progress (number between 0 and 100)
/// -  newPatch generate new patch from source repository into roll-out repository
/// -  startFromRelease output patch file should start from latest release rather than from latest patch
/// -  newRelease generate new release (implies newPatch)
/// -  relNumberNew number of new release (only necessary if newRelease is true). Release number must only consist of digits and dots and must be greater than previous release number
/// -  commitComment comment. This is obligatory if newPatch or newRelease is true. Otherwise the contents will override the comment of the latest patch/release (if set)
/// -  baseRelease  optional: number of release for which the action should be performed. Default is latest release
/// -  patchfile: path of patchfile which will be generated
/// -  sha1Old:  SHA1 hash of commit of base version of patch file in roll-out repository. Must not be set when new patch will be created. Will be set to hash of latest patch of base release or base release itself if empty. If it starts with 'V', a version (release and patch) will be expected, e. g. V5.1-5
/// -  sha1New:  SHA1 hash of commit of final version of patch file in roll-out repository. Must not be set when new patch/release will be created. Default: HEAD. If it starts with 'V', a version (release and patch) will be expected, e. g. V5.1-5
/// -  x3Information: include X3 header and footer for patches
/// -  checkSource: check whether source repository is clean (without uncommitted changes)
/// 
///   Remark: for each new patch/release there must be changes of the roll-out repository to commit, e. g. if a patch of just node.js should be delivered, there must be data to commit in the roll-out repository
///    (e. g. just stage the changes in node.js)

function createPatch(track, newPatch, startFromRelease, newRelease, relNumberNew, commitComment, baseRelease, patchfile, sha1Old, sha1New, x3Information, checkSource, _, rebuild) {
	var stdlogger = tracer;
	tracer = patchlogger;
	var releaseCreated = false; // has new branch been created in rollout repository? Must be removed in case of error!
	var currentBranchNo; // number of current branch before switching to new branch (stays undefined if there is no active branch)
	try {
		if (!globalConfig || !globalConfig.patch) throw new Error("No patch without patch settings in global configuration object");
		if (!patchtools.exists(globalConfig.patch.rolloutRepo, _)) throw new Error("Roll-out repository path does not exist: " + globalConfig.patch.rolloutRepo);
		globalConfig.patch.git = globalConfig.patch.git || "git";
		globalConfig.patch.configFile = globalConfig.patch.configFile || CONFIG_FILE;
		if (globalConfig.patch.logfile) logfile = globalConfig.patch.logfile;
		if (logfile) {
			try {
				console.error("Delete log file " + logfile);
				fs.unlink(logfile, _);
			} catch (e) {}
		}
		if (globalConfig.patch.testMode) tracer("Test mode!!!");
		track && track("Init", "Adjust branch", 0);
		tracer("START PATCH newPatch " + newPatch + " startFromRelease " + startFromRelease + " newRelease " + newRelease + " relNumberNew " + relNumberNew + " commitComment " + commitComment + " baseRelease " + baseRelease + " sha1Old " + sha1Old + " sha1New " + sha1New + " patchfile " + patchfile + " rebuild " + rebuild);
		tracer("Rollout repository " + globalConfig.patch.rolloutRepo + " Customer image directory " + globalConfig.patch.customerImage);
		// get list of tags, select tags which start with 'R' and strip 'R'
		var tags = globalConfig.patch.testMode ? [] : _taglist(globalConfig.patch, baseRelease, _);
		tracer("releases " + util.format(tags));
		if (tags.length == 0) {
			if (!newRelease) throw new Error("No branch data available. New branch must be created");
			baseRelease = null;
		} else {
			if (!baseRelease) baseRelease = tags[tags.length - 1]; // latest release by default
			if (!patchfile) throw new Error("No patch file available");
		}
		if (sha1Old && sha1Old.substr(0, 1) === "V") {
			sha1Old = _getHashFromVersion(globalConfig, sha1Old.substr(1), _);
		}
		if (sha1New && sha1New.substr(0, 1) === "V") {
			sha1New = _getHashFromVersion(globalConfig, sha1New.substr(1), _);
		}
		if (newRelease) {
			if (!relNumberNew) throw new Error("Branch number for new branch must be provided");
			if (relNumberNew.indexOf('X') >= 0) {
				var data = patchtools.nextRelease(tags, relNumberNew);
				if (data[0]) baseRelease = data[0];
				relNumberNew = data[1];
			} else {
				if (!/^\d[\d\.]*$/.test(relNumberNew)) throw new Error("Branch number can only consist of digits and dots " + relNumberNew);
			}
			// test whether new number already exists
			if (tags.indexOf(relNumberNew) >= 0) throw new Error("New branch " + relNumberNew + " already exists");
			if (sha1Old) {
				// find out data of base commit
				baseVersion = commitDataFromHash(sha1Old, globalConfig.patch, _);
				// test whether new version is higher than old version
				if (relNumberCmp(relNumberNew, baseVersion.relNumber) <= 0) throw new Error("New branch " + relNumberNew + " must be higher than old branch " + baseVersion.relNumber);
				_execute(globalConfig.patch.git + ' branch R' + relNumberNew + ' ' + sha1Old, globalConfig.patch.rolloutRepo, _);
				releaseCreated = true;
				_execute(globalConfig.patch.git + ' checkout R' + relNumberNew, globalConfig.patch.rolloutRepo, _);
				baseRelease = relNumberNew;
				currentBranchNo = 'R' + baseVersion.relNumber;
				sha1Old = null;
			} else if (baseRelease) {
				if (relNumberCmp(relNumberNew, baseRelease) <= 0) throw new Error("For new branch, number must be greater than number of base branch " + baseRelease);
			}
			newPatch = true;
		}

		if (newPatch && (sha1Old || sha1New)) throw new Error("No explicit commit hashes when new level of a branch is created");

		var branches = _execute(globalConfig.patch.git + ' config core.ignorecase false', globalConfig.patch.rolloutRepo, _);
		var latestSha1 = "HEAD";
		// switch roll-out repo to correct release. Branch name is R+(release number). Keep unstaged files.
		if (baseRelease) {
			var branches = _execute(globalConfig.patch.git + ' branch -v --no-abbrev', globalConfig.patch.rolloutRepo, _);
			if (newPatch) {
				// new patch: checkout relevant release
				var r = /(?:^|\r|\n)\*\s(\S+)/.exec(branches);
				if (r && !currentBranchNo) {
					currentBranchNo = r[1];
				}
				if (!r || r[1] !== 'R' + baseRelease) { // not on correct branch
					_execute(globalConfig.patch.git + ' checkout R' + baseRelease, globalConfig.patch.rolloutRepo, _);
				}
			} else {
				// just get head commit of that release
				var reg = new RegExp("(?:^|\r|\n)\*?\s+R" + baseRelease.replace(/\./g, ".") + "\s+(\w+)");
				var r = new RegExp("(?:^|\\r|\\n)\\*?\\s+R" + baseRelease.replace(/\./g, ".") + "\\s+(\\w+)").exec(branches);
				if (r) latestSha1 = r[1];
				else throw new Error("Inconsistency. Base branch not in " + branches);
			}
		}
		track && track("Init", "Read versions", 1);

		var baseVersion; // base version for patch file
		var latestPatch; // latest patch of roll-out repository for updating roll-out repository from source repository when a new version is created
		var targetVersion; // final version for patch file
		if (tags.length > 0) { // get log data from git
			if (sha1Old) {
				baseVersion = commitDataFromHash(sha1Old, globalConfig.patch, _);
			} else {
				var gitlog = new GitLog(globalConfig.patch, latestSha1);
				latestPatch = gitlog.next(false, _);
				if (!latestPatch) throw new Error("Inconsistency: Tags available but no branch");
				if (startFromRelease) {
					if (newPatch) { // a new patch/release will be created. Then old version is latest already available release
						if (latestPatch.release) { // latest current patch is release
							baseVersion = latestPatch;
						} else baseVersion = gitlog.next(true, _);
					} else { // previous version is latest release before latest patch
						baseVersion = gitlog.next(true, _);
					}
				} else {
					if (newPatch) { // a new patch/release will be created. Then old version is latest already available patch/release
						baseVersion = latestPatch;
					} else { // set previous version which is patch/release before latest patch
						baseVersion = gitlog.next(false, _);
					}
				}
			}
		}
		tracer("Base version " + util.format(baseVersion));
		tracer("Latest patch " + util.format(latestPatch));
		if (newPatch) { // collect data for new patch or release (newPatch will be set if newRelease is set)
			// configuration for copying contents to roll-out repository
			var contents = fs.readFile(globalConfig.patch.configFile, "utf8", _);
			var config = _readConfig(contents);
			// take rolloutRepo and streamline options from globalConfig so that globalConfig need not be passed to all functions
			config.rolloutRepo = globalConfig.patch.rolloutRepo;
			config.git = globalConfig.patch.git;
			config.configFile = globalConfig.patch.configFile;
			config.streamline = config.streamline || globalConfig.streamline;
			globalConfig.patch.streamline = config.streamline; // for customer image
			config.track = track;
			config.checkSource = checkSource;
			tracer("-------------- Collect files for patch");
			track && track("Write to roll out repository", "", 2);
			if (!commitComment) {
				throw new Error("No comment provided");
			}
			if (!globalConfig.patch.testMode && checkSource && _execute('git status -s', patchtools.BASE_DIRECTORY, _)) throw new Error("No new patch with uncommitted changes in source tree");
			var sourceCommitOld = ((latestPatch && !rebuild) ? latestPatch.source : FIRST_COMMIT);
			var sourceCommitCurrent = _execute(globalConfig.patch.git + ' log -1 --pretty=format:%H', patchtools.BASE_DIRECTORY, _);
			if (!sourceCommitCurrent) throw new Error("No current commit in source repository");
			tracer && tracer("Old source commit " + sourceCommitOld + " current " + sourceCommitCurrent);
			if (newRelease && latestPatch && !releaseCreated) {
				// create new branch for new release
				_execute(globalConfig.patch.git + ' branch R' + relNumberNew, globalConfig.patch.rolloutRepo, _);
				releaseCreated = true;
				_execute(globalConfig.patch.git + ' checkout R' + relNumberNew, globalConfig.patch.rolloutRepo, _);
			}
			// this may set config._syracuseConfigChanged
			_collect(sourceCommitOld, sourceCommitCurrent, config, _);
			// add changes to staging area
			if (globalConfig.patch.testMode) return ""; // faster execution in test mode - just to show which files would be in rollout repository


			track && track("Commit changes", "git add", 40);
			_execute(globalConfig.patch.git + ' add --all --force .', globalConfig.patch.rolloutRepo, _);
			// commit data
			var comment = [];
			if (newRelease) {
				comment.push(relNumberNew);
				comment.push("0"); // patch number 0 for new release
			} else {
				comment.push(baseRelease);
				comment.push(1 * latestPatch.patchNumber + 1);
			}
			comment.push(sourceCommitCurrent);
			// for future use
			comment.push("-");
			// add real comment
			comment.push(commitComment);

			var commentString = comment.join(" ");
			commentString = commentString.replace(/\"/g, "'"); // replace quotation marks
			// commit the changes
			track && track("Commit changes", globalConfig.patch.git + " commit", 50);
			try {
				_execute(globalConfig.patch.git + ' commit --no-status -q -m "' + commentString + '"', globalConfig.patch.rolloutRepo, _);
			} catch (e) {
				var status = _execute(globalConfig.patch.git + ' status --porcelain', globalConfig.patch.rolloutRepo, _);
				if (!status) {
					var error = new Error("No changes in roll-out repository");
					error.special_status = 10; // special return status for batch invocation
					throw error;
				}
				throw new Error("Changes cannot be committed: " + e);
			}
			if (newRelease) {
				if (!latestPatch) {
					// create new branch
					_execute(globalConfig.patch.git + ' branch R' + relNumberNew, globalConfig.patch.rolloutRepo, _);
				}
				// create tag
				_execute(globalConfig.patch.git + ' tag T' + relNumberNew, globalConfig.patch.rolloutRepo, _);
				console.log("New branch " + relNumberNew);
			}
			// get the hash of the current commit
			tracer("-------------- Roll-out repository updated");
			targetVersion = commitDataFromHash("HEAD", globalConfig.patch, _); // set data of targetVersion to the really latest new data 
			if (!latestPatch) {
				//	createCustomerImage(track, globalConfig.patch, _, relNumberNew, targetVersion.rollout, commitComment);
				return; // do not create patch file 
			}
		} else {
			if (sha1New) targetVersion = commitDataFromHash(sha1New, globalConfig.patch, _);
			else targetVersion = commitDataFromHash("HEAD", globalConfig.patch, _);
			// has streamline configuration changed?
			tracer("1Base version " + util.format(baseVersion));
			tracer("1Latest patch " + util.format(targetVersion));
		}
		// create patch file
		if (baseVersion.rollout === targetVersion.rollout) throw new Error("Base version equals target version - empty patch");
		if (relNumberCmp(baseVersion.relNumber, targetVersion.relNumber) > 0 || baseVersion.relNumber === targetVersion.relNumber && baseVersion.patchNumber - targetVersion.patchNumber > 0) {
			throw new Error("No downgrade with patch file from " + baseVersion.relNumber + "-" + baseVersion.patchNumber + " to " + targetVersion.relNumber + "-" + targetVersion.patchNumber);
		}
		patchfile = _replaceVersions(baseVersion, targetVersion, patchfile);
		console.log(_replaceVersions(baseVersion, targetVersion, "Patch file %S-%s %E-%e"));
		tracer("-------------- Create patch file " + patchfile);
		track && track("Create patch file", "git diff", 80);
		var secondTarget;
		if (baseVersion.relNumber !== targetVersion.relNumber && targetVersion.patchNumber > 0) {
			var result = _execute(globalConfig.patch.git + ' log --all -1 --grep "^' + targetVersion.relNumber.replace(/\./, "\\.") + ' 0 " --pretty=format:"%H %cd %s" --date=short', globalConfig.patch.rolloutRepo, _);
			tracer("Branch commit comment " + result);
			secondTarget = targetVersion;
			targetVersion = commitData(result, targetVersion.relNumber);
		}


		var target = [];
		if (x3Information) target.push('1,"","ENG","1","","X3","2",');
		var relative = path.relative(patchtools.BASE_DIRECTORY, globalConfig.patch.configFile).replace(/\\/g, "/");
		while (targetVersion) {
			tracer("VERSIONS " + util.format(baseVersion) + " - " + util.format(targetVersion) + " - " + util.format(secondTarget));
			var patchElement = '"ASR","PATCH","' + targetVersion.comment + '"';
			target.push("2," + patchElement);
			var gitDiff = _execute(globalConfig.patch.git + ' diff --irreversible-delete --minimal --binary --no-color --unified=0 ' + baseVersion.rollout + ' ' + targetVersion.rollout, globalConfig.patch.rolloutRepo, _).split(/[\r\n]+/);
			// filter the output
			target.push("syracuse patch " + baseVersion.relNumber + " " + baseVersion.patchNumber + " " + targetVersion.date + " " + targetVersion.relNumber + " " + targetVersion.patchNumber + " " + baseVersion.rollout + " " + targetVersion.rollout + " " + targetVersion.source,
				"syracuse patchcomment " + targetVersion.comment);
			var difference = _execute(globalConfig.patch.git + ' diff --no-color --unified=0 ' + baseVersion.source + ' ' + targetVersion.source + ' -- ' + relative, patchtools.BASE_DIRECTORY, _);
			if (difference) {
				var r = /\+\s*streamline\s+(\{.*\})/m.exec(difference);
				if (r) {
					tracer("1Latest patch " + r[1]);
					target.push("syracuse streamline " + r[1]);
				}
			}
			// remove 
			track && track("Create patch file", "process git diff", 90);
			shrink(target, gitDiff);
			track && track("Create patch file", "write file", 95);
			if (x3Information) {
				if (target[target.length - 1] === '') target.pop();
				target.push('**********',
					'7,' + patchElement);
			}
			if (secondTarget) {
				baseVersion = targetVersion;
				targetVersion = secondTarget;
				secondTarget = null;
			} else targetVersion = null;
		}
		if (x3Information) target.push('8,""', '');
		fs.writeFile(patchfile, target.join("\n"), "utf8", _);
		tracer("-------------- Patch file created");
		tracer("END PATCH");
	} catch (e) {
		tracer(e);
		// remove newly created branch, so that no unused branch remains
		if (globalConfig && globalConfig.patch && currentBranchNo && releaseCreated && globalConfig && relNumberNew) { // delete newly created branch
			_execute(globalConfig.patch.git + ' checkout ' + currentBranchNo, globalConfig.patch.rolloutRepo, _);
			_execute(globalConfig.patch.git + ' branch -d R' + relNumberNew, globalConfig.patch.rolloutRepo, _);
		}
		throw e;
	} finally {
		tracer = stdlogger;
	}
}

exports.createPatch = createPatch;

// replaces placeholders %S, %s: release/patch of start version, %E, %e release/patch of end version

function _replaceVersions(baseVersion, targetVersion, input) {
	return input.replace(/\%[sSEe]/g, function(text) {
		switch (text.substr(1)) {
			case 'S':
				return baseVersion.relNumber;
			case 's':
				return baseVersion.patchNumber;
			case 'E':
				return targetVersion.relNumber;
			case 'e':
				return targetVersion.patchNumber;
			default:
				return "";
		}
	});
}

/// shrink
/// condenses the git diff output to a syracuse patch file content

function shrink(target, gitDiff) {
	var binary = false;
	var file_from;
	var file_to;
	var mode;
	var access_rights;
	for (var i = 0; i < gitDiff.length; i++) {
		var line = gitDiff[i];
		var r;
		// lines to ignore
		if (line.substr(0, 3) === '+++' || line.substr(0, 3) === '---' || /^(copy|rename|GIT binary) /.exec(line)) continue;
		if (line.substr(0, 1) === '-') { // remove deleted lines (including '\ No new line')
			while (i < gitDiff.length - 1 && /^[\-\\]/.test(gitDiff[i + 1]))
				i++;
			continue;
		}
		if (line.substr(0, 10) === 'diff --git') {
			if (r = /^diff --git a\/(.*) b\/\1$/.exec(line)) {
				file_from = r[1];
				file_to = r[1];
			} else if (r = /^diff --git a\/(\S+) b\/(\S+)$/.exec(line)) {
				file_from = r[1];
				file_to = r[2];
			}
			mode = 'A';
			access_rights = null;
			continue;
		}
		if (line.substr(0, 8) === 'new file') {
			mode = 'N';
			if (r = /mode (\d+)/.exec(line)) access_rights = r[1];
			continue;
		}
		if (line.substr(0, 12) === 'deleted file') {
			mode = 'D';
			continue;
		}
		if (line.substr(0, 6) === 'index ') {
			r = /^index ([0-9a-f]+)\.\.([0-9a-f]+)(?:\s+(\d*))?/.exec(line);
			if (r) {
				if (mode === 'N') r[1] = "";
				else if (mode === 'D') r[2] = "";
				if (file_to === file_from) file_to = "";
				if (r[3]) access_rights = r[3].substr(r[3].length - 3);
				if (!/^[0-7]{3}$/.test(access_rights)) access_rights = "644";
				target.push("FILE " + mode + ' ' + access_rights + ' "' + file_from + '" "' + file_to + '" ' + r[1] + '-' + r[2]);
			} else throw new Error("Unnormal index line " + line);
			continue;
		}
		// remove second part of binary patch		
		if (/^(literal|delta) /.test(line)) {
			binary = !binary;
			if (binary) target.push(line);
			// all but last line have maximal length 52 and start with 'z'
			while (i < gitDiff.length - 1 && gitDiff[i + 1].substr(0, 1) === 'z') {
				i++;
				if (binary) target.push(gitDiff[i]);
			}
			if (i < gitDiff.length - 1 && /^[A-Za-y]\S+$/.test(gitDiff[i + 1])) {
				i++;
				if (binary) target.push(gitDiff[i]);
			}
			continue;
		}
		// diff area
		var r = /^\@\@[\-\+\d, ]+/.exec(line);
		if (r) {
			line = r[0].trim() + "!";
		}
		if (line.charAt(0) === '+' && line.length > 251) { // split very long lines
			var j = 1;
			while (j + 250 < line.length) {
				target.push("=" + line.substr(j, 250));
				j += 250;
			}
			target.push("+" + line.substr(j));
			continue;
		}
		target.push(line);
	}
}

/// creates customer image from rollout repository which contains all necessary metadata for Syracuse patching, but no .git data
/// parameters:
/// track: tracking function
///  patchConfig: paths of rollout repository and customer image
/// optional parameters:
/// release: release number of release (latest release if empty)

function createCustomerImage(track, patchConfig, _, release) {
	if (!patchConfig || !patchConfig.rolloutRepo || !patchConfig.customerImage) {
		throw new Error("Directories must be given " + util.format(patchConfig));
	}
	if (patchConfig.logfile) logfile = patchConfig.logfile;
	if (logfile) {
		try {
			console.error("Delete log file " + logfile);
			fs.unlink(logfile, _);
		} catch (e) {}
	}
	patchConfig.git = patchConfig.git || "git";
	patchConfig.configFile = patchConfig.configFile || CONFIG_FILE;

	if (!patchtools.exists(patchConfig.rolloutRepo, _)) throw new Error("Roll-out repository path does not exist: " + patchConfig.rolloutRepo);
	var oldlogger = tracer;
	tracer = patchlogger;
	try {
		tracer("-------------- Create customer image " + patchConfig.customerImage + " from " + patchConfig.rolloutRepo);
		track && track("Create customer image", "", 2);
		// find out or check release
		var tags = _taglist(patchConfig, release, _);
		if (tags.length === 0) throw new Error("Customer repository empty");
		if (!release) release = tags[tags.length - 1];
		// 	remove existing customerImage
		if (patchtools.exists(patchConfig.customerImage, _)) {
			track && track("Create customer image", "Delete existing customer image", 10);
			if (fs.stat(patchConfig.customerImage, _).isDirectory) {
				tracer("Delete existing directory " + patchConfig.customerImage);
				patchtools.rmdirRec(patchConfig.customerImage, _);
			} else {
				tracer("Delete existing file " + patchConfig.customerImage);
				fs.unlink(patchConfig.customerImage, _);
			}
		}
		// use git to create a copy of repository which has unix style line endings (-l: local copy, -s: do not copy objects)
		track && track("Create customer image", "clone repository", 20);
		console.log("Customer image " + release);
		_execute(patchConfig.git + ' clone -l -s -c core.eol=lf -c core.autocrlf=input --branch T' + release + ' ' + patchConfig.rolloutRepo + ' ' + patchConfig.customerImage, patchtools.BASE_DIRECTORY, _);
		tracer("Clone finished");
		var result = _execute(patchConfig.git + ' log --all -1 --grep "^' + release.replace(/\./, "\\.") + ' 0 " --pretty=format:"%H %cd %s" --date=short', patchConfig.rolloutRepo, _);
		tracer("Commit comment " + result);
		var newVersion = commitData(result, release);
		if (!newVersion) throw new Error("Inconsistency: Tags available but no release");
		var relative = path.relative(patchtools.BASE_DIRECTORY, patchConfig.configFile).replace(/\\/g, "/");
		var oldConfig = _execute(patchConfig.git + ' show ' + newVersion.source + ':' + relative, patchtools.BASE_DIRECTORY, _);
		oldConfig = _readConfig(oldConfig);
		// 	delete git contents of customer image
		tracer("Delete .git subdirectory");
		track && track("Create customer image", "delete .git directory", 70);
		patchtools.rmdirRec(patchConfig.customerImage + "/.git", _);
		// 		create checksum files
		tracer("Write checksum files");
		track && track("Create customer image", "write checksums", 80);
		var sha1 = patchtools.makeChecksums(patchConfig.customerImage, _);
		// create file for initial version
		var initialVersion = JSON.stringify({
			commit: newVersion.rollout,
			relNumber: release,
			patchNumber: 0,
			comment: newVersion.comment,
			init: true,
			sha1: sha1,
			streamline: oldConfig.streamline,
			src: newVersion.source
		});
		tracer("Write " + patchtools.VERSION_FILE + ": " + initialVersion);
		patchtools.writeFile(patchConfig.customerImage + "/" + patchtools.VERSION_FILE, initialVersion, _);
		tracer("Double-check checksums");
		track && track("Create customer image", "double check checksums", 90);
		var errors = patchtools.checkChecksumsV(patchConfig.customerImage, _);
		if (errors.length > 0) {
			throw new Error("Errors when checking checksums " + errors.join("\n"));
			tracer("errors when checking checksums " + errors.join(","));
		}
		tracer("-------------- Create customer image completed");
	} finally {
		tracer = oldlogger;
	}
}

exports.createCustomerImage = createCustomerImage;

/// reads config file and writes results to config object: transformationRules as an array of regular expressions with corresponding actions,
///  commands hash with one time action names and corresponding batch file invocations

function _readConfig(contents) {
	var lines = contents.split(/\r\n|\r|\n/);
	var config = {};
	config.transformationRules = [];
	config.commands = {};
	var i = 0;
	var r;
	var section = "";
	while (i < lines.length) {
		var line = lines[i++];
		r = /^(\w+)\s+(.*)/.exec(line);
		if (r) {
			if (section === "options") {
				if (r[1] === "streamline") {
					try {
						config.streamline = JSON.parse(r[2]);
					} catch (e) {
						tracer && tracer("Error in parsing streamline options " + e);
					}
				} else if (r[1] === "uglify") {
					try {
						config.uglify = JSON.parse(r[2]);
					} catch (e) {
						tracer && tracer("Error in parsing uglify options " + e);
					}
				} else console.log("Unknown settings " + r[1]);
			} else if (section === "files") { // associations of file paths to actions
				if (r[1] === "noCrypt") {
					config.noCrypt = r[2];
					tracer && tracer("nocrypt " + r[2]);
					continue;
				}
				if (r[1].indexOf('_') === 0 && !(r[1] in config.commands)) throw new Error("Command " + r[1] + " is not defined");
				config.transformationRules.push(makeRule(r[1], r[2], config.noCrypt, i));
			} else if (section === "commands") { // definitions of one time actions
				config.commands[r[1]] = r[2];
			}
		} else {
			r = /^\[(\w+)\]/i.exec(line);
			if (r) section = r[1].toLowerCase();
		}
	}
	tracer && tracer("Rules " + util.format(config));
	return config;
}

//splits command line into parts; parts surrounded by "" will be treated as one argument. No special treatment of ''!

function splitargs(cmdline) {
	var args1 = cmdline.trim().split(/\"/);
	var result = [];
	for (var i = 0; i < args1.length; i++) {
		if (i % 2) {
			if (args1[i - 1].charAt(args1[i - 1].length - 1) === ' ') result.push(args1[i]);
			else result[result.length - 1] += '"' + args1[i] + '"';
		} else {
			if (args1[i] === "") continue;
			var tmpArgs = args1[i].trim().split(/\s+/);
			for (var j = 0; j < tmpArgs.length; j++)
				result.push(tmpArgs[j]);
		}
	}
	return result;
}

//execute external command and return stdout as a string. There is no fixed limit on the size of stdout.
var _execute = function(cmdline, directory, callback) {
	var finished = false;
	tracer && tracer("EXECUTE (" + directory + ") " + cmdline);
	if (!directory) {
		finished = true;
		return callback(new Error("Working directory empty"));
	}
	var args = splitargs(cmdline);
	var buffers = [];
	var stderr = "";
	var child = child_process.spawn(args[0], args.slice(1), {
		cwd: directory
	});
	child.stdout.on('data', function(data) {
		buffers.push(data);
	});
	child.stderr.on('data', function(data) {
		stderr += data.toString("utf8");
	});
	child.on('close', function(code) {
		var b = Buffer.concat(buffers);
		var stdout = b.toString("utf8");
		b = null;
		if (code !== 0) {
			tracer && tracer("Error (exit code " + code + "): " + stdout + " " + stderr);
			if (!finished) {
				finished = true;
				return callback(new Error(stderr ? stderr : stdout));
			}
		} else {
			if (stderr && tracer) tracer('Warning: ' + stderr);
			if (!finished) {
				finished = true;
				return callback(null, stdout);
			}
		}
	});
	child.on('error', function(error) {
		tracer && tracer("Error code " + error);
		if (!finished) {
			finished = true;
			return callback(new Error("Cannot execute " + args[0] + ": " + error));
		}
	});
};

//takes a stack trace and splits it into an array

function _analyzeStack(stack, list) {
	// console.log("LINES !!!!!" + stack + "!!!!!");
	var lines = stack.split(/[\n\r]+/);
	var result = [];
	var workdir;
	var first = true; // first line (may contain error text)
	lines.forEach(function(line) {
		if (line.indexOf("__streamline$run (eval at makeTransform") >= 0) return;
		var reg = /^\s*at\s+(\S+)\s+\((.*)\:(\d+)\:(\d+)\)$/m.exec(line);
		var comp;
		var element;
		if (reg) {
			comp = reg[2];
			comp = comp.replace(/\\/g, "/");
			element = {
				name: reg[1],
				comp: comp,
				line: +reg[3],
				column: +reg[4]
			};
		} else {
			reg = /^\s*at\s+(\S+)\:(\d+)\:(\d+)/m.exec(line);
			if (reg) {
				comp = reg[1];
				comp = comp.replace(/\\/g, "/");
				element = {
					name: null,
					comp: comp,
					line: +reg[2],
					column: +reg[3]
				};
			} else {
				reg = /^\s*([\w\.]+)\.(\w+)(\<[\w\.\/\<]+)?(\/[\w\/]+)?\@.*?\:\d+\/([\w\/\-\.]+)\:(\d+)$/m.exec(line);
				if (reg) {
					if (reg[3] && (reg[5].indexOf("client/require.js") > 0)) {
						// search for component
						var regex = new RegExp("^.*\\/" + reg[2] + "\\.js\\s*$", "mig");
						var reg1;
						while (reg1 = regex.exec(list)) {
							comp = reg1[0];
							if (comp.indexOf("/test/") >= 0 || comp.indexOf("/tests/") >= 0 || comp.indexOf("/examples/") >= 0) {
								continue; // do not use test components
							}
							comp = comp.replace(/^[A-Z]\s+/, ""); // remove extra GIT information
							var name = reg[3] + (reg[4] || "");
							name = name.replace(/</g, "");
							element = {
								name: name,
								comp: comp,
								line: +reg[6],
								column: -1
							};
						}
					} else {
						comp = "node_modules/" + reg[5];
						var name = reg[1] + "." + reg[2] + (reg[4] || "");
						element = {
							name: name,
							comp: comp,
							line: +reg[6],
							column: -1
						};
					}
					workdir = ".";
				} else {
					if (line) {
						if (first) {
							result.errortext = line;
						} else {
							console.error("Cannot analyze line <" + line + ">");
							return;
						}
					}
				}
			}
		}
		first = false;
		if (comp) {
			result.push(element);
			if (comp.indexOf("/") > 0 && element.column >= 0) { // only paths are interesting, no internal node.js code files
				// Chrome client stack trace
				if (comp.lastIndexOf("/node_modules/") < 0 && /^\/?(syracuse-\w+|jsurl|js-xml|streamline(?:-\w+)?)\//.test(comp)) {
					if (!/\.js$/.test(comp)) comp += ".js";
					element.comp = "node_modules/" + comp;
					workdir = ".";
				} else if (workdir && comp.indexOf(workdir) === 0) {
					// OK
				} else {
					var index = comp.lastIndexOf("/node_modules/");
					if (index < 0) index = comp.lastIndexOf("/");
					if (!workdir || workdir.substr(0, index) === comp.substr(0, index)) {
						workdir = comp.substr(0, index);
						// OK
					} else {
						console.error("workdir inconsistency " + workdir + " <" + comp + "> ");
						throw new Error("Inconsistency");
					}
				}
			}
		}
	});
	if (workdir) result.workdir = workdir;
	return result;
}
exports._analyzeStack = _analyzeStack;

function _getFileList(_, basepath, path) {
	var result = "";
	var files = fs.readdir(basepath + "/" + path, _);
	files.forEach_(_, function(_, file) {
		var pathfile = path + "/" + file;
		if (fs.stat(basepath + "/" + pathfile, _).isDirectory()) {
			if (file !== "resources" && file !== "test" && file !== "tests" && file !== "html" && file !== "examples") {
				result += _getFileList(_, basepath, pathfile);
			}
		} else {
			if (/\.js$/.test(file)) {
				result += pathfile + "\n";
			}
		}
	});
	return result;
}


exports.translateStackTrace = function(_, sha1, originalTrace) {
	originalTrace = originalTrace || "at c:/workspace/Syracuse2/node_modules/syracuse-main/lib/syracuse._js:3:7";
	var SourceMapConsumer = require('source-map').SourceMapConsumer;
	var cfg;
	if (sha1) {
		var relative = path.relative(patchtools.BASE_DIRECTORY, CONFIG_FILE).replace(/\\/g, "/");
		cfg = _execute('git show ' + sha1 + ':' + relative, patchtools.BASE_DIRECTORY, _);
	} else {
		cfg = fs.readFile(CONFIG_FILE, "utf8", _);
	}
	cfg = _readConfig(cfg);
	var list;
	if (/\D\:\d+\s*$/.test(originalTrace)) {
		// Firefox: get list of components
		if (sha1) {
			list = _execute('git diff --name-status ' + FIRST_COMMIT + ' ' + sha1, patchtools.BASE_DIRECTORY, _);
		} else {
			list = ["syracuse-rtf", "syracuse-sdata", "syracuse-x3", "syracuse-main", "syracuse-ui", "syracuse-core", "streamline", "jsurl", "js-xml"].map_(_, function(_, name) {
				return _getFileList(_, patchtools.BASE_DIRECTORY, "node_modules/" + name);
			}).join("");
		}
	}
	var analyzed = _analyzeStack(originalTrace, list);
	tracer && tracer("analyzed stack trace " + util.format(analyzed));
	if (!analyzed.workdir) { // no working directory found: cannot translate anything
		return originalTrace;
	}
	var loop = true;
	for (var i = 0; i < analyzed.length; i++) {
		var line = analyzed[i];
		if (line.translated) continue;
		var compOriginal = line.comp;
		var relative = path.relative(analyzed.workdir, compOriginal).replace(/\\/g, "/");
		if (compOriginal.indexOf("/") < 0 || !/\.jsc?$/.test(compOriginal)) {
			// internal component or no Javascript - no translation necessary
			line.comp = path.join(patchtools.BASE_DIRECTORY, relative);
			line.translated = true;
			continue;
		}
		relative = relative.replace(/\.jsc$/, ".js");
		var originalContent;
		var originalName = path.join(patchtools.BASE_DIRECTORY, relative);
		try {
			if (sha1) {
				originalContent = _execute('git show ' + sha1 + ':' + relative, patchtools.BASE_DIRECTORY, _);
			} else {
				originalContent = fs.readFile(originalName, _);
			}
		} catch (e) {
			relative = relative.replace(/\.js$/, "._js");
			originalName = path.join(patchtools.BASE_DIRECTORY, relative);
			try {
				if (sha1) {
					originalContent = _execute('git show ' + sha1 + ':' + relative, patchtools.BASE_DIRECTORY, _);
				} else {
					originalContent = fs.readFile(originalName, _);
				}
			} catch (e) {
				console.error("Cannot find file " + relative);
			}
		}
		var rule = findRule("T " + relative, cfg, true);
		var transformed = _transform(originalContent, rule.f, rule.rule, cfg, true);
		var consumer = transformed[1] ? new SourceMapConsumer(transformed[1]) : undefined;
		for (var j = i; j < analyzed.length; j++) {
			var line2 = analyzed[j];
			if (line2.comp === compOriginal) {
				_translate(line2, consumer);
				if (consumer) line2.transformed = true;
				line2.comp = originalName;
				line2.translated = true;
			}
		}
	}
	// stringify stacktrace
	var res = analyzed.errortext ? analyzed.errortext + "\n" : "";
	analyzed.forEach(function(line) {
		if (line.endLine) {
			if (line.name || line.endName || line.originalName) {
				res += "  at/between " + (line.originalName || "") + ((line.name || line.endName) ? " [" + (line.name || "") + "-" + (line.endName || "") + "]" : "") + " (" + line.comp + ":" + line.line + ":" + line.column + "-" + line.endLine + ":" + line.endColumn + ")\n";
			} else {
				res += "  at/between " + line.comp + ":" + line.line + ":" + line.column + "-" + line.endLine + ":" + line.endColumn + "\n";
			}
		} else {
			var marker = (line.transformed ? "*" : "");
			if (line.name) {
				res += "  at " + line.name + " (" + line.comp + ":" + line.line + (line.column > 0 ? ":" + line.column : "") + marker + ")\n";
			} else {
				res += "  at " + line.comp + ":" + line.line + ":" + (line.column > 0 ? ":" + line.column : "") + marker + "\n";
			}
		}
	});
	return res;
};


// translate the stack trace element using a source map consumer

function _translate(element, consumer) {
	if (!element || !consumer) return;
	if (element.line === 1) element.column -= 64; // node.js puts a function declaration in the first line
	else element.column--; // source maps count columns from 0
	if (element.column < 0) { // Firefox
		element.column = 0;
		element.line -= 11; // shown line numbers are by 11 too high
		var result = consumer.originalPositionFor(element);
		element.line++;
		var result2 = consumer.originalPositionFor(element);
		element.line = result.line;
		element.column = result.column + 1;
		if (result.line !== result2.line || result.column !== result2.column) {
			element.endLine = result2.line;
			element.endColumn = result2.column + 1;
			if (result2.name) {
				element.endName = result2.name;
			}
		}
		element.originalName = element.name;
		if (result.name) {
			element.name = result.name;
		}
	} else {
		var result = consumer.originalPositionFor(element);
		element.line = result.line;
		element.column = result.column + 1;
		if (result.name) {
			element.name = result.name;
		}
	}
}
exports._translate = _translate;

//transform code according to a rule and optionally generate a sourcemap. No encryption is done!!!
//parameters: buff: buffer with file contents
//data: object with fields "f": source file name, "rule": rule to apply
//config: configuration, e. g. config.streamline streamline configuration, config.uglifyjs uglify configuration
//genMap: generate source map (in this case do no perform encryption) 

function _transform(buff, filename, rule, config, genMap) {
	var map; // generated source map
	if ((rule === "hidepretty" || rule === "encryptpretty" || rule === "encrypt" || rule === "hide" || rule === "uglify" || rule === "streamline" || rule === "babel") && /\._?js$/.test(filename)) {
		// code transformations for customer site
		var code = buff.toString("utf8");
		if (genMap) {
			code = code.replace(/\t/g, "    ");
		}
		try {
			var uglifyjs = require('uglify-js');
			// babel transformation
			var doStreamlining = /\._js$/.test(filename);
			var babelOptions = {
				filename: filename,
				code: true,
				ast: false,
				sourceMaps: genMap,
				compact: false
			};
			if (doStreamlining) // streamline ._js files
			{
				var streamlineConfig = {};
				if (config) {
					Object.keys(config.streamline).forEach(function(key) {
						streamlineConfig[key] = config.streamline[key];
					});
				}
				babelOptions.plugins = ['flow-comments', 'streamline'],
				babelOptions.extra = {
					streamline: streamlineConfig
				};
			}
			var code0 = babelTransform(code, babelOptions);
			if (code0) code = code0.code;
			map = code0.map;
			if (rule !== "streamline" && rule !== "hidepretty" && rule !== "encryptpretty" && rule !== "babel") {
				// 1. parse
				var toplevel = null;
				toplevel = uglifyjs.parse(code, {
					filename: filename
				});

				// 2. compress
				toplevel.figure_out_scope();
				var sq = uglifyjs.Compressor(config && config.uglify || {
					sequences: false,
					unsafe: false,
					// properties    : false,
					// dead_code     : false,
					// drop_debugger : false,
					// conditionals  : false,
					// comparisons   : false,
					// evaluate      : false, // !!
					// booleans      : false,
					// loops         : false,
					unused: false,
					hoist_vars: false,
					if_return: false,
					// join_vars     : false,
					cascade: false,
					side_effects: false,
					hoist_funs: false

					/* ,
		    	unused: false, 
		    	side_effects: false */
				});
				toplevel = toplevel.transform(sq);

				// 3. mangle
				toplevel.figure_out_scope();
				toplevel.compute_char_frequency();
				toplevel.mangle_names();

				// 4. output
				if (genMap) {
					map = uglifyjs.SourceMap({
						file: filename + ".map",
						// root: "",
						orig: map
					});

				}
				var stream = uglifyjs.OutputStream({
					indent_level: 0,
					space_colon: false,
					semicolons: false,
					source_map: map
				});
				toplevel.print(stream);
				code = stream + "";
				if (map) {
					// get a real source map out of the preliminary source map		
					map = map.get().toJSON();
				}
			}
			buff = new Buffer(code, "utf8");
		} catch (e) {
			tracer && tracer("Exception when preprocessing " + filename + ": " + util.format(e.stack));
		}
	}
	return [buff, map];
}
// for unit tests
exports.Consumer = require('source-map').SourceMapConsumer;
exports._transform = _transform;


//apply encrypt and copy rule for one file

function _applyRule(data, mode, config, _) {
	if (!data) return;
	if (data.rule.charAt(0) === '_') return data.rule;
	mode = mode || data.mode;
	// config file may have been changed when checkSource is false - therefore delete even ignored files
	if ((config.checkSource || mode !== "D") && (data.rule === "ignore" || data.rule === "norule")) return;
	var fullTargetFileName = config.rolloutRepo + "/" + data.file;
	if (mode === "D") { // delete file
		try {
			patchtools.deleteFileDir(config.rolloutRepo, data.file, null, _);
			// fs.unlink(fullTargetFileName, _);
		} catch (e) {
			if (e.code === "ENOENT") {
				tracer && tracer("Already deleted " + fullTargetFileName);
			} else throw e;
		}
	} else {
		try {
			var buff = fs.readFile(patchtools.BASE_DIRECTORY + "/" + data.f, _);
			buff = _transform(buff, data.f, data.rule, config, false)[0];
			if (data.rule === "encrypt" || data.rule === "hide" || data.rule === "encryptpretty" || data.rule === "hidepretty") {
				if (!encrypter) encrypter = require('syracuse-license').load("encrypt");
				buff = encrypter.encrypt(data.file, buff, data.rule === "hide" || data.rule === "hidepretty", require);
			}
			if (/\.es5$/.test(fullTargetFileName)) {
				try {
					patchtools.unlinkP(fullTargetFileName.replace(/\.es5$/, ".js"), _);
					tracer && tracer("Delete obsolete file " + fullTargetFileName.replace(/\.es5$/, ".js"));
				} catch (e) {
					if (e.code !== "ENOENT") {
						tracer && tracer("Cannot delete " + fullTargetFileName.replace(/\.es5$/, ".js"));
					}
				}
			}
			patchtools.writeFile(fullTargetFileName, buff, _);
		} catch (e) {
			if (e.code === "EISDIR") { // submodule: replace whole directory
				tracer && tracer("Delete old submodule contents for " + data.f);
				// delete it first
				try {
					patchtools.rmdirRec(fullTargetFileName, _);
				} catch (e1) {
					if (e1.code === "ENOTDIR") { // was file instead of directory
						patchtools.unlinkP(fullTargetFileName, _);
					} else if (e1.code === "ENOENT") {
						// does not exist: ignore
					} else throw e1;
				}
				// copy all contents recursively
				copyDirectory(_, data.f, fullTargetFileName, config);
			} else throw e;
		}
	}
	return null;
}

// copy contents of whole directory according to rules
// source: relative path of start directory with respect to patchtools.BASE_DIRECTORY
// target: absolute path of target directory
// config: current rules configuration
function copyDirectory(_, source, target, config) {
	var sourceA = patchtools.BASE_DIRECTORY + "/" + source;
	var files = fs.readdir(sourceA, _);
	var i = files.length;
	while (--i >= 0) {
		var currFile = source + "/" + files[i];
		if (fs.stat(patchtools.BASE_DIRECTORY + "/" + currFile, _).isDirectory()) {
			// Recursive function back to the beginning
			copyDirectory(_, currFile, target + "/" + files[i], config);
		} else {
			var res = findRule("A " + currFile, config);
			if (res) {
				_applyRule(res, res.mode, config, _);
			}
		}
	}
}

//parse file path pattern and replace backslashes and convert "**/", "*", "?" into regular expressions

function makeRule(name, pattern, noCrypt, line) {
	// make regular expression
	// replace backslashes with slashes for paths
	pattern = pattern.replace(/\\/g, "/");
	// temporary replace of **/
	pattern = pattern.replace(/\*{2,}\//g, "\0");
	// replace *
	pattern = pattern.replace(/\*+/g, "[^\\/]*");
	// replace ?
	pattern = pattern.replace(/\?/g, "[^\\/]");
	// mask of .
	pattern = pattern.replace(/\./g, "\\.");
	// real replace of **/
	pattern = pattern.replace(/\x00/g, "(?:.*\/)?");
	if (name === "hide" || name === "encrypt") {
		if (noCrypt > 0) name = "uglify";
		else if (noCrypt < 0) name += "pretty";
	}
	if (noCrypt > 0 && (name === "hidepretty" || name === "encryptpretty")) {
		name = "streamline";
	}
	if ((noCrypt > 1 || noCrypt < 0) && (name === "uglify")) name = "streamline";
	if (noCrypt > 2 && (name === "streamline")) name = "babel";
	return [new RegExp("^" + pattern + "$"), name, line];
}

/// parse a line for a one time action and replace $$, $/, $R, $S with corresponding values

function replacements(line, rolloutRepo) {
	line = line.trim();
	// 	temporarily replace $$
	line = line.replace(/\$\$/g, "\0");
	// 	slash
	line = line.replace(/\$\//g, path.sep);
	// source repository
	line = line.replace(/\$S/g, path.normalize(process.cwd()));
	// roll-out repository
	line = line.replace(/\$R/g, path.normalize(rolloutRepo));
	// finally replace $$ with $.
	line = line.replace(/\x00/g, "$");
	return line;
}

function findRule(line, config, suppressMessage) {
	var pattern = /([A-Z]+)\s+(.*)/g;
	var r;
	if (r = pattern.exec(line)) {
		var i = 0;
		var filename = r[2];
		var result = {
			mode: r[1],
			f: filename
		};
		while (i < config.transformationRules.length) {
			var rule = config.transformationRules[i++];
			var ru = rule[1];
			if (rule[0].test(filename)) {
				// changes in filename
				if (!/\._?js$/.test(filename) && (ru === "encryptpretty" || ru === "hidepretty" || ru === "encrypt" || ru === "hide" || ru === "streamline" || ru === "uglify" || ru === "babel")) ru = "copy";
				else if ((ru === "streamline" || ru === "uglify") && filename.substr(filename.length - 3) == ".js") {
					if (ru === "streamline") ru = "babel";
					filename = filename.replace(/\.js$/, ".es5");
				} else {
					if (ru === "streamline" || ru === "uglify") filename = filename.replace(/\._js$/, ".es5");
					else if (ru === "encryptpretty" || ru === "hidepretty" || ru === "encrypt" || ru === "hide") filename = filename.replace(/\._?js$/, ".jsc");
				}
				if (!suppressMessage) {
					tracer && tracer(ru + "(" + rule[2] + ") " + r[1] + " " + r[2]);
				}
				if (ru === "extra") {
					result.extra = true;
					continue;
				}
				result.rule = ru;
				result.file = filename;
				return result;
			}
		}
		tracer && tracer("No rule found for " + filename);
		result.rule = "norule";
		result.file = filename;
		return result;
	}
	return null;
}

//collect extra functions from a file

function _extra(oneTimeActions, data, _) {
	if (data.mode != "D") {
		var contents = fs.readFile(patchtools.BASE_DIRECTORY + "/" + data.f, "utf8", _);
		var functionPattern = /(?:^|[\r\n])\s*exports\.(patch\w*)/g;
		var regexpResult;
		oneTimeActions.extra = oneTimeActions.extra || [];
		while (regexpResult = functionPattern.exec(contents)) {
			oneTimeActions.extra.push(data.file + " " + regexpResult[1]);
			tracer && tracer("Pattern for extra function " + regexpResult[1]);
		}
	}
}

// perform changes in file system according to contents of git diff, streamline version change, patch configuration change

function executeDiff(diff, oldCommit, config, _) {
	// changes in configuration file?
	var relative = path.relative(patchtools.BASE_DIRECTORY, config.configFile).replace(/\\/g, "/");
	var oneTimeActions = {};
	var r;
	tracer && tracer("Relative path of config file " + relative);
	// get contents of current diff
	var lines = diff.split(/[\r\n]+/);
	// data for tracker
	var startPercentage = 10;
	var diffPercentage = 30;
	var streamlineVersionChanged = (diff.indexOf("node_modules/streamline/lib/version") >= 0);
	if (streamlineVersionChanged) {
		tracer && tracer("Streamline version change");
	}
	// delete files first (because otherwise renamings just from upper to lower case and vice versa will cause problems under Windows, because
	// then the file will just be deleted)
	for (i = lines.length - 1; i >= 0; i--) {
		if ((i % 500) < 1) {
			var processed = i;
			config.track && config.track("Delete files from roll out repository", processed + " of " + fullDiffLines.length, Math.round(12 - 2 * (processed / fullDiffLines.length)));
		}
		var line = lines[i];
		if (line[0] === "D") {
			try {
				line = line.substr(2);
				tracer && tracer("Delete file (deleted in git): " + line);
				patchtools.deleteFileDir(config.rolloutRepo, line, null, _);
				// fs.unlink(fullTargetFileName, _);
			} catch (e) {
				if (e.code === "ENOENT") {
					tracer && tracer("Already deleted " + line);
				} else throw e;
			}
			lines.splice(i, 1);
		}
	}

	// config file has changed (this is not important for very first version)
	if (oldCommit !== FIRST_COMMIT && (diff.indexOf(relative) > 0 || streamlineVersionChanged)) {
		startPercentage = 25;
		diffPercentage = 15;
		var currentDiffContents = {};
		for (var i = 0; i < lines.length; i++) {
			if (r = /[A-Z]+\s+(.*)/.exec(lines[i])) currentDiffContents[r[1]] = lines[i];

		}
		var oldConfig = _execute(config.git + ' show ' + oldCommit + ':' + relative, patchtools.BASE_DIRECTORY, _);
		oldConfig = _readConfig(oldConfig);
		var changedRuleConfigurations = {}; // rules which have to be applied because the configuration has changed
		var changedRulePattern;
		if (!deepEqual(oldConfig.streamline, config.streamline) || streamlineVersionChanged) {
			if (!streamlineVersionChanged) tracer && tracer("Streamline configuration change from " + JSON.stringify(oldConfig.streamline) + " to " + JSON.stringify(config.streamline));
			changedRuleConfigurations.hidepretty = changedRuleConfigurations.encryptpretty = changedRuleConfigurations.hide = changedRuleConfigurations.encrypt = changedRuleConfigurations.uglify = changedRuleConfigurations.streamline = /\._js$/;
		}
		if (!deepEqual(oldConfig.uglify, config.uglify)) {
			tracer && tracer("Uglify configuration change from " + JSON.stringify(oldConfig.uglify) + " to " + JSON.stringify(config.uglify));
			changedRuleConfigurations.hide = changedRuleConfigurations.encrypt = changedRuleConfigurations.uglify = /\._?js$/;
		}
		var fullDiffLines = _execute(config.git + ' diff --name-status ' + FIRST_COMMIT + ' HEAD', patchtools.BASE_DIRECTORY, _).split(/[\r\n]+/);
		for (i = 0; i < fullDiffLines.length; i++) {
			if ((i % 200) < 1) {
				var processed = i;
				config.track && config.track("Write differently generated files to roll out repository", processed + " of " + fullDiffLines.length, Math.round(12 + 13 * (processed / fullDiffLines.length)));
			}
			var line = fullDiffLines[i];
			if (line[0] === "D") continue;
			// always include submodules (easy, but not very efficient, but configuration changes are rare)
			var filename = line.substr(2);
			if (filename && fs.stat(filename, _).isDirectory()) {
				currentDiffContents[filename] = line;
				continue;
			}
			var resNew = findRule(line, config, true);
			var resOld = findRule(line, oldConfig, true);
			if (resOld && resNew) {
				if (resOld.rule !== resNew.rule || resOld.extra !== resNew.extra || ((changedRulePattern = changedRuleConfigurations[resNew.rule]) && changedRulePattern.test(line))) { // different rule
					tracer && tracer("Configuration change for " + resOld.f + ": " + resOld.rule + " -> " + resNew.rule);
					var action;
					if (resOld.file !== resNew.file || resNew.rule === "ignore" || resNew.rule === "norule") { // different target file name
						// delete old file
						_applyRule(resOld, "D", config, _);
						// add new file
						action = _applyRule(resNew, "N", config, _);
					} else {
						action = _applyRule(resNew, "M", config, _);
					}
					if (action) oneTimeActions[action] = "";
					if (resNew.f in currentDiffContents && resNew.extra) {
						_extra(oneTimeActions, resNew, _);
					}
					delete currentDiffContents[resNew.f];
				}
			}
		}
		lines.length = 0;
		for (var key in currentDiffContents) {
			lines.push(currentDiffContents[key]);
		}
	}
	for (i = 0; i < lines.length; i++) {
		if ((i % 200) < 1) {
			var processed = i;
			config.track && config.track("Write to roll out repository", processed + " of " + lines.length, Math.round(startPercentage + diffPercentage * (processed / lines.length)));
		}
		var res = findRule(lines[i], config);
		if (res) {
			var action = _applyRule(res, res.mode, config, _);
			if (action) oneTimeActions[action] = "";
			if (res.extra) {
				_extra(oneTimeActions, res, _);
			}
		}
	}
	tracer && tracer("END EXEC");
	return oneTimeActions;
}

/// collect differences from git log

function _collect(oldCommit, newCommit, config, _) {
	// log differences
	var diff = _execute(config.git + ' diff --name-status ' + oldCommit + ' ' + newCommit, patchtools.BASE_DIRECTORY, _);
	var oneTimeActions = executeDiff(diff, oldCommit, config, _);
	diff = ""; // data are not necessary any more
	config.track && config.track("Write to roll out repository", "one time actions", 40);
	// execute oneTimeActions
	if ("extra" in oneTimeActions) {
		tracer && tracer("EXTRA " + oneTimeActions.extra.sort().join(", "));
		patchtools.writeFile(config.rolloutRepo + "/" + patchtools.EXTRA_FUNCTIONS, oneTimeActions.extra.sort().join("\n") + "\n", _);
		delete oneTimeActions.extra;
	}
	var actions = Object.keys(oneTimeActions);
	var i = actions.length;
	while (--i >= 0) { // one time action as a batch file
		tracer && tracer("One time action " + actions[i]);
		var result = replacements(config.commands[actions[i]], config.rolloutRepo);
		// execute the command
		try {
			_execute(result, patchtools.BASE_DIRECTORY, _);
		} catch (e) {
			throw new Error("Error in one time action " + actions[i] + " with command " + result.command + ": " + e);
		}
	}
}

//loops over git log and parses the commit comments

function GitLog(cfg, headCommit, git) {
	this._logs = [];
	this.finished = false;
	this._i = 1;
	this._count = 10;

	// get data from previous release or patch
	// parameter release: only look for release commits
	this.next = function(release, _) {
		while (!this.finished) {
			while (this._i < this._logs.length) {
				var res = commitData(this._logs[this._i++], release);
				if (res) return res;
			}
			var currentCommit = headCommit || "HEAD";
			if (this._logs.length > 0) {
				currentCommit = this._logs[this._logs.length - 1].substr(0, 40);
				this._i = 1;
			} else this._i = 0;
			this._logs = _execute(cfg.git + ' log -' + this._count + ' --pretty=format:"%H %cd %s" --date=short ' + currentCommit, cfg.rolloutRepo, _).split(/[\r\n]+/);
			this._count *= 2;
			if (!this._logs[this._logs.length - 1]) this._logs.pop();
			if (this._logs.length <= this._i) {
				this.finished = true;
				return null;
			}
		}
		return null;
	};
}

// Creating a patch file or customer image from command line (without database and not necessarily with nodelocal.js)

function cmdLinePatch(config, _) {
	// parse command line
	var mode = process.argv[2];
	if (!mode) throw new Error("No patching mode given");
	var args = process.argv.slice(3);
	var startFromRelease;
	var baseRelease;
	var newRelease;
	var patchFile;
	var checkSource = true;
	var rebuild = false;
	var x3Information = true;
	var startVersion;
	var endVersion;
	var description;
	for (var i = 0; i < args.length; i++) {
		var argument = args[i];
		switch (argument) { // arguments without parameter
			case '--start-from-release':
			case '--start-from-branch':
				startFromRelease = true;
				break;
			case '--rebuild':
				rebuild = true;
				break;
			case '--no-check':
				checkSource = false;
				break;
			case '--no-x3-patch-info':
				x3Information = false;
				break;
			default:
				if (i === args.length - 1 || !args[i + 1] || args[i + 1].substr(0, 2) === "--") throw new Error("No argument given for option");
				switch (argument) {
					case '--git':
						config.patch.git = args[++i];
						break;
					case '--rollout':
						config.patch.rolloutRepo = args[++i];
						break;
					case '--base-release':
					case '--base-branch':
						baseRelease = args[++i];
						break;
					case '--release':
					case '--branch':
						newRelease = args[++i];
						break;
					case '--patch-file':
						patchFile = args[++i];
						break;
					case '--image':
						config.patch.customerImage = args[++i];
						break;
					case '--logfile':
						config.patch.logfile = args[++i];
						break;
					case '--start-version':
						startVersion = "V" + args[++i];
						break;
					case '--end-version':
						endVersion = "V" + args[++i];
						break;
					case '--desc':
						description = args[++i];
						break;
					case '--config-file':
						config.patch.configFile = args[++i];
						break;
					default:
						throw new Error("wrong argument " + args[i]);
				}
		}
	}
	switch (mode) {
		case 'new-release':
		case 'new-branch':
			globalConfig = config;
			return createPatch(null, true, startFromRelease, true, newRelease, description, baseRelease, patchFile, startVersion, null, x3Information, checkSource, _, rebuild);
		case 'customer-image':
			return createCustomerImage(null, config.patch, _, newRelease);
		case 'new-patch':
		case 'new-level':
			globalConfig = config;
			return createPatch(null, true, startFromRelease, false, null, description, baseRelease, patchFile, null, null, x3Information, checkSource, _, rebuild);
		case 'patch-file':
			globalConfig = config;
			return createPatch(null, false, startFromRelease, false, null, null, baseRelease, patchFile, startVersion, endVersion, x3Information, checkSource, _, rebuild);
		case 'direct':
			return directImage(newRelease, description, config.patch, checkSource, _);
	}
}

function _getHashFromVersion(config, version, _) {
	var parts = version.split(/\-/);
	var pattern = "^" + parts[0].replace(/\./, "\\.") + " " + parts[1];
	var result = _execute(config.patch.git + ' log --all -1 --grep "' + pattern + '" --pretty=format:%H', config.patch.rolloutRepo, _);
	if (!result) throw new Error("Cannot find version " + version);
	return result;
}

exports.cmdLinePatchCb = function(config, cb) {
	cmdLinePatch(config, cb);
};

//returns all versions of all releases. This cannot be done just using GitLog, because there may be branches from older

function allPatches(patchConfig, _) {
	patchConfig.git = patchConfig.git || "git";
	// find out branch names and patch sha1 checksums
	var tmpBranches = _execute(patchConfig.git + ' branch -v --no-abbrev', patchConfig.rolloutRepo, _).split(/[\r\n]+/);
	var releases = [];
	var releasesHash = {};
	var i = 0;
	while (i < tmpBranches.length) {
		var line = tmpBranches[i++];
		var r = /^[\*\s]+R(\d[\d\.]*)\s+(\w{40})/.exec(line);
		if (r) {
			releases.push(r[1]);
			releasesHash[r[1]] = r[2];
		}
	}
	tmpBranches = undefined;
	releases = releases.sort(relNumberCmp);
	i = releases.length;
	var branchings = {};
	var result = [];
	var patch = null;
	var gitlog = new GitLog(patchConfig, releasesHash[releases[i - 1]]);
	while (--i >= 0) {
		var currentRelease = releases[i];
		if (!patch) patch = gitlog.next(false, _);
		var found = false;
		while (patch) {
			if (patch.relNumber === currentRelease) {
				if (patch.rollout in branchings) patch.branchings = branchings[patch.rollout].trim();
				result.push(patch);
				found = true;
				patch = gitlog.next(false, _);
				continue;
			}
			// older patch
			if (found) {
				if (patch.rollout in branchings) branchings[patch.rollout] += currentRelease + " ";
				else branchings[patch.rollout] = currentRelease + " ";
			}
			if (i > 0 && patch.rollout !== releasesHash[releases[i - 1]]) {
				gitlog = new GitLog(patchConfig, releasesHash[releases[i - 1]]);
				patch = null;
			}
			break;
		}
	}
	return result;
}

exports.allPatches = allPatches;

//extract information from "git log --pretty=oneline" line

function commitData(line, release) {
	// matching group 6 is for future use!
	var pattern = release ? /^\"?(\w{40}) (\d\d\d\d\-\d\d\-\d\d) ([\d\.]+) (0) (\w{40}) (\S+) ([^"]*)/ : /^\"?(\w{40}) (\d\d\d\d\-\d\d\-\d\d) ([\d\.]+) (\d+) (\w{40}) (\S+) ([^"]*)/;
	var r = pattern.exec(line);
	if (r) {
		return {
			release: (r[4] === "0"),
			source: r[5],
			rollout: r[1],
			relNumber: r[3],
			patchNumber: +r[4],
			comment: r[7],
			date: r[2]
		};
	}
	return null;
}

//invoke git to get all data from the commit with the given sha1 checksum

function commitDataFromHash(sha1, patchConfig, _) {
	var result = commitData(_execute(patchConfig.git + ' log -1 --pretty=format:"%H %cd %s" --date=short ' + sha1, patchConfig.rolloutRepo, _), false);
	if (!result) throw new Error("Inconsistency: No data for commit " + sha1);
	return result;
}

exports.commitDataFromHash = commitDataFromHash;

//for unit tests
exports.makeRule = makeRule;
exports.findRule = findRule;
exports.replacements = replacements;
exports.commitData = commitData;
exports.shrink = shrink;
exports.splitargs = splitargs;