var fs = require('fs');
var util = require('util');
var crypto = require('crypto');
var path = require('path');

// file for version information at customer's site
exports.VERSION_FILE = "version.txt";
// file containing extra functions which should be executed before restarting the program
exports.EXTRA_FUNCTIONS = 'extra.fkt';

/// Description: auxiliary functions for IO and streamline wrappers


// writes content into file and creates directory if necessary
// parameters: content may be buffer or string. If it is a string, encoding 'utf8' will be assumed 
function writeFile(targetFile, content, _) {
	// console.log("WRITEFILE "+targetFile)
	try {
		fs.writeFile(targetFile, content, _);
	} catch (e) {
		if (e.code === 'ENOENT') { // maybe directory does not exist
			mkdirs(targetFile);
			fs.writeFile(targetFile, content, _);
		} else 
			throw e;
	}
}

exports.writeFile = writeFile;

function createWriteStream(targetFile, _) {
	try {
		return fs.createWriteStream(targetFile);
	} catch (e) {
		if (e.code === 'ENOENT') { // maybe directory does not exist
			mkdirs(targetFile);
			return fs.createWriteStream(targetFile);
		} else 
			throw e;
	}
}

exports.createWriteStream = createWriteStream 
	
function open(targetFile, _) {
	try {
		return fs.open(targetFile, "w", _);
	} catch (e) {
		if (e.code === 'ENOENT') { // maybe directory does not exist
			mkdirs(targetFile);
			return fs.open(targetFile, "w", _);
		} else 
			throw e;
	}
}



exports.open = open; 

/// mkdirs
/// create directory including all intermediate directories. Accepts backslash as directory separator
function mkdirs(targetFile) {
	var segs = targetFile.split('\/');
	var p = '';
	var i = 0;
	while (i < segs.length-1) {
		var seg = segs[i];
		p += (i ? '/' : '') + seg;
		if (!fs.existsSync(p))
			fs.mkdirSync(p);
		i++;
	}	
}

/// copyRec
/// copy start directory recursively into target directory
/// parameters: start: directory (must exist and be a directory)
///			 target: target which should contain the contents of start in the end (except for excluded files). Will be created if necessary
///			 exclude: object with file names (without paths) which should be regarded as non existing in the start directory (will be removed from target directory if they exist)
function copyRec(start, target, exclude, _) {
	if (!exists(target, _)) { // create target directory
		mkdir(target, _);
	}
	if (!(fs.stat(target, _).isDirectory())) { // target exists and is no directory: delete it first
		unlink(target, _);
		mkdir(target, _);
	}	
	return copyContents(start, target, exclude, _); // copy contents of directory
}

exports.copyRec = copyRec;

/// copyContents
/// copy contents start directory recursively into target directory
/// parameters: start: directory (must exist and be a directory)
///			 target: target which should contain the contents of start in the end (except for excluded files)
///			 exclude: object with file names (without paths) which should be excluded from copy action
function copyContents(start, target, exclude, _) {
	var startFiles = fs.readdir(start, _);
	var targetFiles = fs.readdir(target, _);
	var targetFilesHash = {};
	var i = targetFiles.length;
	while (--i >= 0) {
		targetFilesHash[targetFiles[i]] = "";
	}
	i = startFiles.length;
	while (--i >= 0) {
		var filename = startFiles[i];
		if (exclude && filename in exclude)
			continue; // exclude this file
		var startFile = start+"/"+filename;
		var targetFile = target+"/"+filename;
		if (fs.stat(startFile, _).isDirectory()) { // start is directory: copy recursively
			copyRec(startFile, targetFile, null, _);
		} else { // start file is no directory
			if (filename in targetFilesHash && fs.stat(targetFile, _).isDirectory())
				rmdirRec(targetFile, _);
			// copy file
			var buffer = fs.readFile(startFile, _);
			fs.writeFile(targetFile, buffer, _);
			buffer = null;
		}
		// target file has been handled
		delete targetFilesHash[filename];
	}
	targetFiles = Object.keys(targetFilesHash);
	i = targetFiles.length;
	while (--i >= 0) {
		var targetFile = target+"/"+targetFiles[i];
		if (fs.stat(targetFile, _).isDirectory())
			rmdirRec(targetFile, _);
		else
			unlink(targetFile, _);
	}
}

// asynchronous file existence test for streamline
function exists(path, callback) {
	fs.exists(path, function(res, error) { return callback(error, res)});
} 

exports.exists = exists;

//asynchronous unlink
function unlink(path, callback) {
	fs.unlink(path, function(ex) { return callback(null, ex)});
}

exports.unlink = unlink;

//asynchronous rmdir
function rmdir(path, callback) {
	fs.rmdir(path, function(ex) { return callback(null, ex)});
}

//asynchronous rename
function rename(path, callback) {
	fs.rename(path, function(ex) { return callback(null, ex)});
}
exports.rename = rename;

//asynchronous mkdir
function mkdir(path, callback) {
	fs.mkdir(path, function(ex) { return callback(null, ex)});
}

exports.mkdir = mkdir;

//asynchronous chmod for streamline
function chmod(path, mode, callback) {
	fs.chmod(path, mode, function(ex) { return callback(null, ex)});
}

// delete directory recursively
function rmdirRec(path, _) {
	var files = fs.readdir(path, _);
	var i = files.length;
	/* Loop through and delete everything in the sub-tree after checking it */
	while (--i >= 0) {
		var currFile = path + "/" + files[i];
		
		if(fs.stat(currFile, _).isDirectory()) // Recursive function back to the beginning
			rmdirRec(currFile, _);
		else {// Assume it's a file - perhaps a try/catch belongs here?
			try {
				unlink(currFile, _);
			} catch (e) {
				if (e.code === 'EPERM') {
					chmod(currFile, '666', _) // allow write access
					unlink(currFile, _);
				}
			}
		}
	}
	return rmdir(path, _);
};

exports.rmdirRec = rmdirRec;

/// getChecksumContent
/// reads and parses the contents of the .checksums file in the specified directory
/// returns empty object if file does not exist yet
function getChecksumContent(directory, path, _) {
	var buffer = null;
	try {
		buffer = fs.readFile(directory+"/"+path+"/.checksums", _);
		try {
			var result = JSON.parse(buffer.toString("utf8"));
			return result;
		} catch (e) {
			throw new Error("Invalid checksum file in "+path+": "+e);
		}
	} catch (e) {
		if (e.code === 'ENOENT') {
			var result = {};
			return result; // file does not exist yet				
		} else
			throw new Error("Error when reading checksum file in "+path+": "+e);
	}

}

exports.getChecksumContent = getChecksumContent;

/// updateChecksums
/// After applying the patch, the contents of some directories have changed. 
/// The object 'list' contains the names of these directories as keys and the contents of their checksum files as values.
/// This function adds the missing intermediate directories and updates all checksum files
/// return value: checksum of top level directory
function updateChecksums(directory, list, _) {	
	var current = Object.keys(list);
	var parents = [];
	var i;
	// add intermediate directories. Strategy: loop over all directories and add parent directory (and its checksums contents) if it does not exist yet.
	// after the loop over directories has finished, start a new loop of the added parent directories	
	while (current.length > 0) {
		i = current.length;
		while (--i >= 0) {
			var parent = path.dirname(current[i]);
			if (!(parent in list)) { // parent directory not yet in the list
				parents.push(parent);
				list[parent] = getChecksumContent(directory, parent, _);
			}
		}		
		current = parents;
		parents = [];
	}
	
	// sort with ascending length so that no directory will be scanned before any of its subdirectories
	// in order to assure that root directory "." is really the last, a special comparison puts the char code of "." (46) to be the lowest value.
	var dirs = Object.keys(list).sort(function(a,b) { return (a.length-b.length || a.length === 1 && Math.abs(a.charCodeAt(0)-46)-Math.abs(b.charCodeAt(0)-46) || 0); });
	i = dirs.length;	
	while (--i >= 0) {
		// write checksum file of current directory
		var dir = dirs[i];
		var buffer = new Buffer(JSON.stringify(list[dir]), "utf8");
		var sha1 = get_sha1_binary(buffer);
		fs.writeFile(directory+"/"+dir+"/.checksums", buffer, _);		
		if (dir !== ".") {
			// update contents of checksums of parent directory. The ordering of dirs assures that the checksums of the parent directory will be written later
			list[path.dirname(dir)][path.basename(dir)] = "D "+sha1;
		} else {
			return sha1;
		}
	}
	return "";
}

function excludeFile(file) {
	if (file.substr(-4) === ".bbb" || file === ".checksums" || file === exports.VERSION_FILE || file === "nodelocal.js") {
		return true;
	}
	return false;
}

exports.updateChecksums = updateChecksums;

/// creates checksum files. Assumes that all line endings are unix style endings (therefore no distinction between binary and text files)
/// parameters: directory: directory to search
///			 errors: if not null, checksum files will be assumed to exist and to be correct, and mismatches will be appended to array
/// return value: checksum of current directory (i. e. of .checksums file)
function makeChecksums(path, _) {
		var files = fs.readdir(path, _);
		var contents = {};
		var i = files.length;
		while (--i >= 0) {
			var file = files[i];
			// do not include checksums file and backup files
			if (excludeFile(file)) {
				continue;
				
			}
			var filePath = path + "/" + file;
			var currFile = fs.stat(filePath, _);
			if (currFile.isDirectory()) { // Recursive function back to the beginning
				var sha1 = makeChecksums(filePath, _);
				contents[file] = "D "+ sha1;
			} else {
				var buffer = fs.readFile(filePath, _)
				var sha1 = get_sha1_binary(buffer);
				contents[file] = "F "+ sha1;
			}
		}
		var buf = new Buffer(JSON.stringify(contents), "utf8");
		fs.writeFile(path+"/.checksums", buf, _);
		return get_sha1_binary(buf);
}

exports.makeChecksums = makeChecksums;

/// checks checksum files. Assumes that all line endings are unix style endings (therefore no distinction between binary and text files)
/// parameters: directory: directory to search
///			 errors: if not null, checksum files will be assumed to exist and to be correct, and mismatches will be appended to array
/// return value: checksum of current directory (i. e. of .checksums file)
function checkChecksums(path, errors, _) {
	try {
		var files = fs.readdir(path, _);
		var contents = {};
		var result = ""; 
		try {
			buf = fs.readFile(path+"/.checksums", "utf8", _)
	  		contents = JSON.parse(buf);
			result = get_sha1_binary(buf);
		} catch (e) {
	  		errors.push(e.toString());
	  		return result;
	  	}
		for (var i = 0; i < files.length; i++) {
			var file = files[i];
			var filePath = path + "/"+file;
			// do not include checksums file and backup files
			if (excludeFile(file))
				continue;
			if (!(file in contents)) {
				errors.push("New file: "+filePath);
				continue;
			}	  	
			var currFile = fs.stat(filePath, _);			
			if (currFile.isDirectory()) { // Recursive function back to the beginning
				if (contents[file].substr(0, 2) != "D ")
					errors.push("No directory expected at "+filePath);
				else {
					var sha1 = checkChecksums(path + "/" + file, errors, _);
					if (contents[file] !== "D "+sha1) {
						errors.push("Wrong checksum of "+filePath+". Expected "+contents[file].substr(2)+" indeed "+sha1);
					}					
				}
			} else {
				var buffer = fs.readFile(filePath, _)
				var sha1 = get_sha1_binary(buffer);
				if (contents[file] !== "F "+sha1) {
					if (contents[file].substr(0, 2) != "F ")
						errors.push("Directory expected at "+filePath);
					else
						errors.push("Wrong checksum of "+filePath+". Expected "+contents[file].substr(2)+" indeed "+sha1);
				}
			}
			delete contents[file];
		}
		// errors for remaining files
		for (var file in contents) {
			errors.push("File has been deleted: "+path+"/"+file)
		}
	} catch (err) { errors.push("Other error "+err); }
	return result;
}

exports.checkChecksums = checkChecksums;


/// get sha1 sum of binary content
function get_sha1_binary(buffer) {
	var shasum = crypto.createHash('sha1');
	// GIT specific header
	shasum.update("blob "+buffer.length+"\0", "utf8");
	shasum.update(buffer);
	var digest = shasum.digest('hex');
	return digest;	
}

exports.get_sha1_binary = get_sha1_binary;

/// tests SHA1 checksums for equality or whether one is an abbreviation of the other
function equal_sha1(sum, sumGit) {
	if (sum.substr(0, 2) === "F ")
		sum = sum.substr(2); // strip directory/file information in checksums file
	return sum === sumGit || sum.substr(0, sumGit.length) == sumGit; 
}

exports.equal_sha1 = equal_sha1;

/// check whether checksum is correct for binary file
/// input
function check_sha1_binary(buffer, sha1) {
	return (get_sha1_binary(buffer).substr(0, sha1.length) === sha1);
}
exports.check_sha1_binary = check_sha1_binary;
