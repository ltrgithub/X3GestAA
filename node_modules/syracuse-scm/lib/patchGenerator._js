"use strict";
var path = require("path"),
	ez = require("ez-streams"),
	file = ez.devices.file,
	fs = require("streamline-fs"),
	decodeValueFromJsonString = require("etna-etl/lib/exporter").decodeValueFromJsonString,
	readAndMergeJsonFiles = require("etna-etl/lib/importer").readAndMergeJsonFiles;

var orderedTypes = [
	"ACV", "AML", "ELT", "BIA", "TXT", "EXE", "AHI", "ATN", "ADC", "ANG", "ADX", "TRT", "ETA", "ACS", "ANM", "ACT", "AFC", "ACL", "ASL", "ATYP", "AGB", "ACTX", "ACST", "ASU", "ATY", "ADV", "ADI", "ATB", "AVW", "AUR", "AMK", "ARP", "AOB", "AOP", "ADP", "AWI", "AOE", "AEN", "ACN", "PS1", "PS2", "TAB", "GAU", "AWM", "AWR", "AWA", "AWW", "ABT", "ABA", "ABG", "ACLA", "ASW", "ADZ", "ADO", "ADF", "ALH", "ALQ", "ALT", "ABF", "ABI", "ABM", "ABV", "ABO", "AHH", "AII", "ASY", "TFO", "APR", "AWE", "ANT", "AMC", "AY", "AYS", "ELX", "AYG", "AYD", "AYF", "AYM", "AYI", "AYE", "AYB", "AYO", "AYA", "AYL", "AYW", "AYC", "AYU", "IND"
];

/// !doc
/// # Patch generator
/// Tools to generate patch files from versionned (git) JSON files that contain metadata
/// Usage : 
/// ```
/// require("syracuse-scm/lib/patchGenerator").newGenerator(_, config).synchonize(_);
/// ```
exports.newGenerator = function(_, config) {

	config.patch = config.patch || {};
	config.patch.langs = config.patch.langs || ["ENG", "FRA"];
	config.patch.comment = config.patch.comment || "test";
	config.patch.version = config.patch.version || 1;
	config.patch.product = config.patch.product || "X3";
	config.settingsTable = config.settingsTable || "_SETTINGS";
	if (undefined === config.oneFile)
		config.oneFile = true;


	// Normalize the meta folder
	config.metaSubFolder = path.join(config.metaSubFolder + "/").toLowerCase();

	function _processElement(_, writer, elt, eltConfig) {
		// Compute the title of the block
		var blockTitle;
		if (eltConfig.titleFunction) {
			blockTitle = _invokeTitleFunction(eltConfig.titleFunction, elt);
		} else {
			var pk = eltConfig.primaryKey || eltConfig.patchPK;
			if (!pk) {
				if (!eltConfig.orderBy)
					throw new Error("'orderBy' property is missing on element " + (eltConfig.title ? eltConfig.title : eltConfig.tableName));
				pk = eltConfig.orderBy.split(',')[0];
			}
			blockTitle = decodeValueFromJsonString(pk, elt[pk]).value;
		}

		writer.write(_, "3,\"" + eltConfig.abbrev + "\"," + blockTitle + "\n");

		var allLines = {};

		function _formatValues(lineType, name, dimension, values, valueType) {
			var line = lineType + ',"' + name + '",' + dimension;
			if (25 === lineType) {
				// Clob
				line += "\r\n" + values.length + "\n" + values + "\n" + "**********";
			} else {
				if (!Array.isArray(values))
					values = [values];
				values.forEach(function(value) {
					line += ',';
					if (typeof(value) == "string") {
						if (value == " ")
							value = "";
						line += '"' + value + '"';
					} else {
						if ((4 === lineType) && valueType && ("date" === valueType) && !value) {
							// null dates are written as 000000
							value = "000000";
						}
						line += value;
					}
				});
			}
			return line;
		}

		function _enqueueItem(lineType, name, dimension, values, valueType) {
			allLines[name] = allLines[name] || [];
			allLines[name].push(_formatValues(lineType, name, dimension, values, valueType));
		}

		if (elt["##texts##"]) {
			var texts = elt["##texts##"];
			Object.keys(texts).forEach_(_, function(_, columnName) {
				if (!elt.hasOwnProperty(columnName))
					return;
				var textIds = elt[columnName];
				if (!Array.isArray(textIds))
					textIds = [textIds];

				// Some texts can have multiple dimensions (AWINDOW.INTMSK for instance)
				textIds.forEach_(_, function(_, textId, textDimension) {

					config.patch.langs.forEach_(_, function(_, langCode) {
						var valsToWrite = [
							texts[columnName][textDimension][langCode] || "",
							langCode,
							textId,
						];

						if (elt["##comments##"] && elt["##comments##"][columnName] && elt["##comments##"][columnName][textDimension] && elt["##comments##"][columnName][textDimension][langCode])
							valsToWrite.push(elt["##comments##"][columnName][textDimension][langCode]);
						else
							valsToWrite.push("");
						_enqueueItem(5, columnName, textDimension, valsToWrite);
					});

					_enqueueItem(5, columnName, textDimension, ["", "***"]);
				});

				delete(elt[columnName]);
			});
			delete(elt["##texts##"]);
			delete(elt["##comments##"]);
		}

		Object.keys(elt).forEach_(_, function(_, key) {
			if (/^##\w+##$/.test(key)) {
				// Special tags : ##texts##, ##comments##, ##extraTables##, ...
				return;
			}

			var val = decodeValueFromJsonString(key, elt[key]);
			if ("array" == val.type) {
				val.value.forEach_(_, function(_, arrayItem, itemIdx) {
					_enqueueItem(4, key, itemIdx, arrayItem.value, arrayItem.type);
				});
			} else if ("clob" == val.type) {
				_enqueueItem(25, key, 0, val.value, val.type);
			} else {
				_enqueueItem(4, key, 0, val.value, val.type);
			}
		});

		Object.keys(allLines).sort().forEach_(_, function(_, lines) {
			allLines[lines].forEach_(_, function(_, line) {
				writer.write(_, line + "\n");
			});
		});

		if (elt["##extraTables##"] && elt["##extraTables##"].ATEXTRA) {
			var texts = elt["##extraTables##"].ATEXTRA;
			Object.keys(texts).forEach_(_, function(_, columnName) {
				var atLeastOneText = false;
				config.patch.langs.forEach_(_, function(_, langCode) {
					var valsToWrite = [
						texts[columnName][langCode] || "",
						langCode,
					];
					var textVals = texts[columnName];
					// Note : textVals is an object indexed by ATEXTRA.IDENT2_0.
					if (textVals) {
						// Here, we only consider the first ATEXTRA.IDENT2_0.
						var t = texts[columnName][Object.keys(texts[columnName])[0]];
						if (t[langCode]) {
							writer.write(_, _formatValues(9, columnName, 0, [t[langCode], langCode, "" + elt[eltConfig.primaryKey], Object.keys(texts[columnName])[0]]) + "\n");
							atLeastOneText = true;
						}
					}
				});
				if (atLeastOneText)
					writer.write(_, _formatValues(9, columnName, 0, ["", "***"]) + "\n");
			});
			delete(elt["##extraTables##"]);
		}

		writer.write(_, "6,\"" + eltConfig.abbrev + "\"\n");
	}

	function _invokeTitleFunction(fct, elt) {
		var arg = {};
		Object.keys(elt).forEach(function(key) {
			arg[key] = decodeValueFromJsonString(key, elt[key]).value;
		});
		var title = fct(arg);
		if (title && title["ENG"])
			title = title["ENG"];
		return title;
	}

	function _processMetaElement(_, writer, entityExportConfig, elt) {
		var title;
		if (elt["##texts##"]) {
			title = elt["##texts##"][entityExportConfig.textLinks[0]][0]["ENG"];
		} else {
			if (entityExportConfig.mainTitleFunction)
				title = _invokeTitleFunction(entityExportConfig.mainTitleFunction, elt);
			else
				throw new Error("No localized label are defined for element '" + entityExportConfig.title + "', you must provide a 'mainTitleFunction' function.");
		}
		var header = '"' + entityExportConfig.abbrev + '","' + decodeValueFromJsonString(entityExportConfig.primaryKey, elt[entityExportConfig.primaryKey]).value + '","' + title + '"';
		writer.write(_, "2," + header + "\n");
		var children = [];
		if (entityExportConfig.children) {
			// The configuration describes some child-node, we have to keep them in a separate list.
			// They will be processed later.
			Object.keys(entityExportConfig.children).forEach(function(childName) {
				// For instance, in tables.js, childName == 'COLUMNS' or 'INDEXES'
				if (elt[childName]) {
					// note : elt[childName] is an array. Each item describes a child (i.e. one index or one column)
					elt[childName].forEach(function(c) {
						children.push({
							name: childName,
							node: c
						});
					});
					// We have to delete the child, otherwise it would be exposed as a value in the .dat file
					delete(elt[childName]);
				}
			});
		}
		_processElement(_, writer, elt, entityExportConfig);

		// Now, we can process the children
		children.forEach_(_, function(_, child) {
			_processElement(_, writer, child.node, entityExportConfig.children[child.name]);
		});

		writer.write(_, "7," + header + "\n");
	}

	// returns whether an ABSOLUTE filename describes a .json meta file
	function _isMetaFile(absoluteFilename) {
		return /\.json$/.test(absoluteFilename);
	}

	// Generates a patch file from all the JSON files contained in filesList. 
	// filesList contains ABSOLUTE filenames
	// Depending on config.oneFile, the function will either generate a patch file per JSON file
	// or a unique patch file for all the JSON files.
	// This function returns the absolute filenames of all the generated path files
	function _generatePatches(_, filesList, options) {

		var filenames = [];
		var writer;

		// Convention for activity codes : 
		// null / undefined / [''] : process all the secondary files (xxx.activityCode.json)
		// [null] / [undefined] : process only the primary file (xxx.json)
		// ['yyy', 'zzz'] : process xxx.json, xxx.yyy.json, xxx.zzz.json (and skip all the other secondary files)
		if (!options.activityCodes) {
			// Process the primary files and all the secondary files
			options.activityCodes = [''];
		} else {
			if ((options.activityCodes.length == 1) && (!options.activityCodes[0])) {
				// Only process the primary files (xxx.json) and skip any secondary file (xxx.activityCode.json)
				options.activityCodes = undefined;
			}
		}

		function _openWriter(_, shortFilename) {
			var patchFilename = path.join(config.folder, shortFilename + ".dat");
			filenames.push(patchFilename);
			writer = file.text.writer(patchFilename, "utf8");
			config.trace && config.trace("\tGenerating patch file: " + patchFilename);

			var header = '1,"' + config.patch.comment + '","' + config.patch.langs.join("/") + '","' + config.patch.version + '","';
			if (options.activityCode && options.activityCode.length && options.activityCode[0] !== '')
				header += options.activityCodes.sort().join('/');
			header += '","' + config.patch.product + '","1",\n';
			writer.write(_, header);
		}

		function _closeWriter(_, writer) {
			writer.write(_, '8,"' + config.patch.comment + '"\n');
			writer.end();
		}

		function _parseFilename(filename) {
			// Normalize the filename
			filename = path.join(filename);
			// Note filename looks like "META_SUB_FOLDER/SUPERV/TABLES/ABANK.json"

			var parts = filename.split(path.sep);

			// Note : we don't know the depth of the folder where the JSON files is, so we have
			// to read infos from the end of the array
			return {
				path: parts.slice(0, parts.length - 3).join(path.sep),
				module: parts[parts.length - 3],
				type: parts[parts.length - 2],
				shortFilename: parts[parts.length - 1],
			};
		}

		var jsonFilesList = filesList.filter(_isMetaFile);
		if (jsonFilesList.length == 0) {
			// Nothing to do :-)
			return [];
		}
		var patchFolder = config.folder;

		if (fs.exists(patchFolder, _)) {
			config.trace && config.trace("Cleaning output folder : " + patchFolder);
			_cleanFolder(_, patchFolder);
		} else {
			config.trace && config.trace("Create output folder " + patchFolder);
			try {
				fs.mkdir(patchFolder, _);
			} catch (err) {
				throw new Error("Could not create patch folder, reason = " + err.message);
			}
		}

		// Note : the gitWrapper may have changed the current folder
		process.chdir(patchFolder);

		if (config.oneFile)
			_openWriter(_, "patch");

		if (config.oneFile && jsonFilesList.length > 1) {
			// We will generate a single patch file from many json files. 
			// the json files must be ordered (for instance, activityCodes must be exported before classes)
			var typeAbbreviations = {};

			// Load all the entity configurations to be able to link an entity name to its abbreviation
			var resPath = path.join(__dirname, "../../etna-etl/lib/entities/");
			fs.readdir(resPath, _).forEach(function(filename) {
				var req = require(path.join(resPath, filename));
				typeAbbreviations[req.entity.subdir] = req.entity.abbrev;
			});

			jsonFilesList.sort(function(filename1, filename2) {
				var parts1 = _parseFilename(filename1);
				var parts2 = _parseFilename(filename2);
				var idx1 = orderedTypes.indexOf(typeAbbreviations[parts1.type]);
				var idx2 = orderedTypes.indexOf(typeAbbreviations[parts2.type]);
				return idx1 - idx2;
			});
		}

		var regExps;
		jsonFilesList.forEach_(_, function(_, filename) {
			// Normalize the filename
			filename = path.join(filename);
			// Note filename looks like "META_SUB_FOLDER/SUPERV/TABLES/ABANK.json"
			config.trace && config.trace("Processing file " + filename);
			if (!_isMetaFile(filename)) {
				// This file is not a metadata file
				return;
			}

			var parts = _parseFilename(filename);
			// parts.shortFilename has the following format xxxx[.activityCode].json (activityCode is optional)
			// We just keep the 'xxxx'
			parts.shortFilename = parts.shortFilename.substring(0, parts.shortFilename.indexOf('.'));

			var allFiles;
			if (options.activityCodes) {
				var includeAllActivityCodes = options.activityCodes.some(function(activityCode) {
					return "" === activityCode;
				});
				var fileFolder = path.dirname(filename);
				// We have to retrieve all the xxxx.activityCode.json files whose activityCode matched option.activityCodes
				allFiles = fs.readdir(fileFolder, _).filter(function(file) {
					var idx1 = file.indexOf('.');
					var idx2 = file.lastIndexOf('.');
					if (file.substring(0, idx1) != parts.shortFilename) {
						// This is a file for another entity
						return false;
					}
					if (idx1 === idx2) {
						// Primary file (xxxx.json)
						return true;
					}
					if (includeAllActivityCodes)
						return true;
					var fileActivityCode = file.substring(idx1 + 1, idx2);
					if (options.activityCodes.some(function(activityCode) {
						return (activityCode === fileActivityCode);
					}))
						return true;
					// Last chance, we can try to interpret the activityCodes as regular expressions
					if (!regExps) {
						regExps = options.activityCodes.map(function(activityCode) {
							return new RegExp(activityCode);
						});
					}
					return regExps.some(function(regex) {
						return regex.test(fileActivityCode);
					});
				}).map(function(file) {
					// use absolute filenames
					return path.join(fileFolder, file);
				});
				config.trace && config.trace("Will process file group : " + allFiles);
			} else {
				// Only process the primary files (xxx.json) and skip any secondary file (xxx.activityCode.json)
				allFiles = [filename];
			}

			var entityDescriptor = require("etna-etl/lib/entities/" + parts.type).entity;

			var elt;

			try {
				elt = readAndMergeJsonFiles(_, allFiles, entityDescriptor);
			} catch (err) {
				throw new Error("Could not read file '" + filename + "', reason = " + err.message);
			}

			if (!config.oneFile)
				_openWriter(_, parts.type + "_" + parts.shortFilename);
			_processMetaElement(_, writer, entityDescriptor, elt);
			if (!config.oneFile) {
				_closeWriter(_, writer);
			}
		});
		if (config.oneFile) {
			_closeWriter(_, writer);
		}

		return filenames;
	}

	function _remove(_, s) {
		if (!fs.exists(s, _))
			return;
		try {
			var stat = fs.stat(s, _);
			if (stat.isDirectory()) {
				fs.readdir(s, _).forEach_(_, function(_, f) {
					_remove(_, s + '/' + f);
				});
				fs.rmdir(s, _);
			} else {
				fs.unlink(s, _);
			}
		} catch (err) {
			throw new Error("Could not delete " + s + ", reason = " + err.message);
		}
	}

	function _cleanFolder(_, path) {
		try {
			fs.readdir(path, _).forEach_(_, function(_, name) {
				_remove(_, path + "/" + name);
			});
		} catch (err) {
			throw new Error("Could not clean folder " + path + ", reason = " + err.message);
		}

	}

	return {

		/// !doc
		/// --------------------------
		/// ### generatePatches(_, filesList, options)
		/// Generates a patch file from all the JSON files contained in filesList. 
		/// filesList contains ABSOLUTE filenames
		/// Depending on config.oneFile, the function will either generate a patch file per JSON file
		/// or a unique patch file for all the JSON files.
		/// This function returns the absolute filenames of all the generated path files
		generatePatches: function(_, filesList, options) {
			options = options || {};
			return _generatePatches(_, filesList, options);
		},

		/// !doc
		/// --------------------------
		/// ### getOrderedTypes()
		/// Returns the order that should be used to export entities in a path file (for 
		/// instance, activityCodes must be exported before classes).
		/// Each entity type is described by the abbreviation of its table (ATABLE.ABRFIC).
		getOrderedTypes: function() {
			return orderedTypes;
		},

	};


};